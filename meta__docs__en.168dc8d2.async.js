"use strict";(self.webpackChunk_antv_g_site=self.webpackChunk_antv_g_site||[]).push([[9706],{81363:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(67086);var n={}},9830:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(27624);var n={}},60968:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(85635);var n={}},53781:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(5797);var n={}},61826:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(89200);var n={}},86984:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(11771);var n={}},66116:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(89455);var n={}},559:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(6177);var n={}},97049:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(6730);var n={}},15929:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(47213);var n={}},29123:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(7968);var n={}},71737:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(18947);var n={}},99481:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(65788);var n={}},10621:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(30030);var n={}},62010:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(59243);var n={}},93366:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(27234);var n={}},60964:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(62464);var n={}},62056:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(96249);var n={}},1575:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(56666);var n={}},12:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(28463);var n={}},66237:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(81581);var n={}},3518:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(17223);var n={}},42694:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(72199);var n={}},38746:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(30160);var n={}},18791:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(37094);var n={}},59140:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(15533);var n={}},94415:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(45786);var n={}},264:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(20606);var n={}},99881:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(79047);var n={}},43914:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(94211);var n={}},80465:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(87262);var n={}},25763:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(49212);var n={}},24466:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(14434);var n={}},74866:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(62425);var n={}},41402:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(16260);var n={}},74366:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(87521);var n={}},86582:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(68043);var n={}},10100:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(9396);var n={}},46616:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(94305);var n={}},39103:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(43442);var n={}},92648:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(48112);var n={}},47817:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(47230);var n={}},29044:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(97337);var n={}},21182:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(51353);var n={}},4271:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(24103);var n={}},14005:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(20152);var n={}},33744:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(70104);var n={}},43153:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(7298);var n={}},24642:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(63480);var n={}},97163:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(77668);var n={}},39278:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(3803);var n={}},54190:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(57549);var n={}},89590:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(6387);var n={}},48945:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(82702);var n={}},97436:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(49457);var n={}},85303:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(34429);var n={}},52613:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(59279);var n={}},35622:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(76334);var n={}},85825:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(32585);var n={}},32547:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(40135);var n={}},88787:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(21763);var n={}},71738:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(11098);var n={}},95784:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(11720);var n={}},3438:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(67884);var n={}},64288:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(69058);var n={}},8682:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(10023);var n={}},72176:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(83891);var n={}},89701:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(98246);var n={}},51280:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(87587);var n={}},43893:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(21973);var n={}},47118:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(93519);var n={}},55029:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(71452);var n={}},68007:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(44328);var n={}},94874:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(50090);var n={}},73121:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(57706);var n={}},50394:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(3882);var n={}},41551:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(94524);var n={}},78935:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(46989);var n={}},37685:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(42070);var n={}},34313:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(66847);var n={}},28560:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(9600);var n={}},57958:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(96430);var n={}},27991:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(60060);var n={}},25773:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(91575);var n={}},88783:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(22207);var n={}},60283:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(91001);var n={}},14022:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(61496);var n={}},6983:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(5364);var n={}},28304:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(77585);var n={}},39507:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(45767);var n={}},9460:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(2361);var n={}},62104:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(40113);var n={}},12541:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(66668);var n={}},13390:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(43217);var n={}},48869:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(82858);var n={}},42853:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(19077);var n={}},64128:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(18473);var n={}},65980:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(26015);var n={}},75474:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(20299);var n={}},89807:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(19267);var n={}},95298:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(1472);var n={}},17249:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(74384);var n={}},65322:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(21798);var n={}},43570:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(21932);var n={}},87479:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(36871);var n={}},59277:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(28853);var n={}},67581:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(2085);var n={}},66850:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(38053);var n={}},89073:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(29236);var n={}},59070:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(89394);var n={}},41063:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(36500);var n={}},91585:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(38090);var n={}},86936:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(40311);var n={}},71374:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(39644);var n={}},13169:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(41451);var n={}},64454:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(86762);var n={}},23621:function(e,a,t){t.r(a),t.d(a,{demos:function(){return n}});t(67294),t(53334);var n={}},78984:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(67086);const n=[{value:"在 2D 场景中对于整个场景的常见交互有平移、缩放和旋转，通过",paraId:0},{value:"相机",paraId:1},{value:"动作实现。",paraId:0},{value:"例如对场景的平移等价于固定视点，让相机沿 u、v 轴（G 的世界坐标系 Y 轴正向向下）方向移动，也称作 ",paraId:2},{value:"pan",paraId:3},{value:" 相机动作，在具体实现中通过对鼠标 move 系列事件的监听实现，同时由于相机固定为正交投影，视点是否固定并不影响最终成像效果。",paraId:2},{value:"但而在 3D 场景中，同样的鼠标平移动作可能包含不同的语义。例如在模型观察场景中，我们希望固定视点，改变相机位置，而在第一/三人称开放世界中，我们希望固定相机位置，改变视点。",paraId:4},{value:"我们提供了 ",paraId:5},{value:"g-plugin-control",paraId:5},{value:" 插件，目前支持观察者模式，即通过鼠标交互固定视点，改变相机位置：",paraId:5},{value:"鼠标拖拽将引起相机在 u、v 轴的移动，即 pan 动作",paraId:6},{value:"鼠标滚轮缩放将引起相机在 n 轴的移动，即 dolly 动作",paraId:6},{value:"示例",paraId:7},{value:"：",paraId:8},{value:"import { Plugin as PluginControl } from '@antv/g-plugin-control';\n\nrenderer.registerPlugin(new Plugin3D());\n",paraId:9}]},33237:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(27624);const n=[{value:"雾和光源一样，都属于场景级别的对象，距离相机近处的物体能见度较大。",paraId:0},{value:"在下面的 ",paraId:1},{value:"示例",paraId:2},{value:" 中展示了红色的雾，注意远离相机的地方（球体边缘处）：",paraId:1},{value:"const fog = new Fog();\ncanvas.appendChild(fog);\n",paraId:3},{value:"当不需要时可以随时移除：",paraId:4},{value:"canvas.removeChild(fog);\n",paraId:5},{value:"整个场景中只会有一个 Fog 生效，因此添加多个无效。",paraId:6},{value:"颜色，默认值为 ",paraId:7,tocIndex:1},{value:"'black'",paraId:7,tocIndex:1},{value:"类型，支持以下枚举值，默认为 ",paraId:8,tocIndex:2},{value:"FogType.NONE",paraId:8,tocIndex:2},{value:"，即无效果：",paraId:8,tocIndex:2},{value:"export enum FogType {\n  NONE = 0,\n  EXP = 1,\n  EXP2 = 2,\n  LINEAR = 3,\n}\n",paraId:9,tocIndex:2},{value:"效果强度，默认值为 0",paraId:10,tocIndex:3},{value:"type 取 ",paraId:11,tocIndex:4},{value:"FogType.LINEAR",paraId:11,tocIndex:4},{value:" 时生效。最近距离，默认值为 1",paraId:11,tocIndex:4},{value:"type 取 ",paraId:12,tocIndex:5},{value:"FogType.LINEAR",paraId:12,tocIndex:5},{value:" 时生效。最远距离，默认值为 1000",paraId:12,tocIndex:5}]},31823:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(85635);const n=[{value:"再复杂的模型都可以用“三角面”来描述，区别只在于数量多少。因此在 3D 世界中我们用这种描述能力更强的方式定义几何形状，它们可以是我们熟悉的 Circle、Rect，也可以是“犹他茶壶”。",paraId:0},{value:"我们内置了一些常用的几何，例如 Cube、Sphere 等，它们在运行时程序化生成。",paraId:1},{value:"可以随时启用材质的 ",paraId:2},{value:"wireframe",paraId:3},{value:" 属性查看几何中包含的三角面：",paraId:2},{value:"material.wireframe = true;\n",paraId:4},{value:"在该",paraId:5},{value:"示例",paraId:6},{value:"中效果如下，可以看出一个 Sphere 球体是由不同经纬度上的众多三角面组成：",paraId:5},{value:"当我们想修改几何信息时，例如改变一个几何形状为 CubeGeometry 的 Mesh 时，应该在几何而非 Mesh 上操作：",paraId:7,tocIndex:0},{value:"import {\n    MeshBasicMaterial,\n    CubeGeometry,\n    Mesh,\n    Plugin as Plugin3D,\n} from '@antv/g-plugin-3d';\n\n// 创建几何\nconst cubeGeometry = new CubeGeometry(device, {\n    width: 200,\n    height: 200,\n    depth: 200,\n});\n\n// 创建 Mesh\nconst cube = new Mesh({\n    style: {\n        fill: '#1890FF',\n        opacity: 1,\n        geometry: cubeGeometry,\n        material: basicMaterial,\n    },\n});\n\n// 修改这个形状为 Cube 的 Mesh 宽度\n// 正确用法\ncubeGeometry.width = 300;\n// 或者\ncube.style.geometry.width = 300;\n\n// 错误用法\ncube.style.width = 300;\n",paraId:8,tocIndex:0},{value:"立方体，",paraId:9,tocIndex:1},{value:"示例",paraId:10,tocIndex:1},{value:"属性名",paraId:11,tocIndex:1},{value:"说明",paraId:11,tocIndex:1},{value:"width",paraId:11,tocIndex:1},{value:"宽度，必填",paraId:11,tocIndex:1},{value:"height",paraId:11,tocIndex:1},{value:"高度，必填",paraId:11,tocIndex:1},{value:"depth",paraId:11,tocIndex:1},{value:"深度，必填",paraId:11,tocIndex:1},{value:"widthSegments",paraId:11,tocIndex:1},{value:"影响程序化生成，默认值为 1",paraId:11,tocIndex:1},{value:"heightSegments",paraId:11,tocIndex:1},{value:"影响程序化生成，默认值为 1",paraId:11,tocIndex:1},{value:"depthSegments",paraId:11,tocIndex:1},{value:"影响程序化生成，默认值为 1",paraId:11,tocIndex:1},{value:"球体，",paraId:12,tocIndex:2},{value:"示例",paraId:13,tocIndex:2},{value:"属性名",paraId:14,tocIndex:2},{value:"说明",paraId:14,tocIndex:2},{value:"radius",paraId:14,tocIndex:2},{value:"球半径，必填，默认值为 0.5",paraId:14,tocIndex:2},{value:"latitudeBands",paraId:14,tocIndex:2},{value:"默认值为 16",paraId:14,tocIndex:2},{value:"longitudeBands",paraId:14,tocIndex:2},{value:"默认值为 16",paraId:14,tocIndex:2},{value:"平面，默认躺在 XZ 平面上，",paraId:15,tocIndex:3},{value:"示例",paraId:16,tocIndex:3},{value:"属性名",paraId:17,tocIndex:3},{value:"说明",paraId:17,tocIndex:3},{value:"width",paraId:17,tocIndex:3},{value:"宽度",paraId:17,tocIndex:3},{value:"depth",paraId:17,tocIndex:3},{value:"深度",paraId:17,tocIndex:3},{value:"widthSegments",paraId:17,tocIndex:3},{value:"默认值为 5",paraId:17,tocIndex:3},{value:"depthSegments",paraId:17,tocIndex:3},{value:"默认值为 5",paraId:17,tocIndex:3},{value:"圆环，",paraId:18,tocIndex:4},{value:"示例",paraId:19,tocIndex:4},{value:"属性名",paraId:20,tocIndex:4},{value:"说明",paraId:20,tocIndex:4},{value:"tubeRadius",paraId:20,tocIndex:4},{value:"选填，默认值为 0.2",paraId:20,tocIndex:4},{value:"ringRadius",paraId:20,tocIndex:4},{value:"选填，默认值为 0.3",paraId:20,tocIndex:4},{value:"segments",paraId:20,tocIndex:4},{value:"选填，默认值为 30",paraId:20,tocIndex:4},{value:"sides",paraId:20,tocIndex:4},{value:"选填，默认值为 20",paraId:20,tocIndex:4},{value:"圆柱，",paraId:21,tocIndex:5},{value:"示例",paraId:22,tocIndex:5},{value:"属性名",paraId:23,tocIndex:5},{value:"说明",paraId:23,tocIndex:5},{value:"radius",paraId:23,tocIndex:5},{value:"圆柱体顶面半径，默认值为 0.5",paraId:23,tocIndex:5},{value:"height",paraId:23,tocIndex:5},{value:"圆柱体高度，默认值为 1",paraId:23,tocIndex:5},{value:"heightSegments",paraId:23,tocIndex:5},{value:"圆柱体身体曲面划分数目，默认值为 5",paraId:23,tocIndex:5},{value:"capSegments",paraId:23,tocIndex:5},{value:"圆柱体顶面划分数目，默认值为 20",paraId:23,tocIndex:5},{value:"圆锥，",paraId:24,tocIndex:6},{value:"示例",paraId:25,tocIndex:6},{value:"属性名",paraId:26,tocIndex:6},{value:"说明",paraId:26,tocIndex:6},{value:"baseRadius",paraId:26,tocIndex:6},{value:"圆锥体底面半径，默认值为 0.5",paraId:26,tocIndex:6},{value:"peakRadius",paraId:26,tocIndex:6},{value:"圆锥体顶面半径，默认值为 0",paraId:26,tocIndex:6},{value:"height",paraId:26,tocIndex:6},{value:"圆锥体高度，默认值为 1",paraId:26,tocIndex:6},{value:"heightSegments",paraId:26,tocIndex:6},{value:"圆锥体身体曲面划分数目，默认值为 5",paraId:26,tocIndex:6},{value:"capSegments",paraId:26,tocIndex:6},{value:"圆锥体顶面划分数目，默认值为 20",paraId:26,tocIndex:6},{value:"胶囊，",paraId:27,tocIndex:7},{value:"示例",paraId:28,tocIndex:7},{value:"属性名",paraId:29,tocIndex:7},{value:"说明",paraId:29,tocIndex:7},{value:"radius",paraId:29,tocIndex:7},{value:"胶囊半径，默认值为 0.5",paraId:29,tocIndex:7},{value:"height",paraId:29,tocIndex:7},{value:"胶囊高度，默认值为 1",paraId:29,tocIndex:7},{value:"heightSegments",paraId:29,tocIndex:7},{value:"胶囊身体曲面划分数目，默认值为 1",paraId:29,tocIndex:7},{value:"sides",paraId:29,tocIndex:7},{value:"胶囊顶面划分数目，默认值为 20",paraId:29,tocIndex:7},{value:"以上内置几何都继承自 BufferGeometry，因此需要自定义时也可以使用它。",paraId:30,tocIndex:8},{value:"在",paraId:31,tocIndex:8},{value:"示例",paraId:32,tocIndex:8},{value:"中，我们创建了一个完全自定义的几何体，配合 ",paraId:31,tocIndex:8},{value:"Mesh",paraId:33,tocIndex:8},{value:" 和 ",paraId:31,tocIndex:8},{value:"MeshBasicMaterial",paraId:34,tocIndex:8},{value:"：",paraId:31,tocIndex:8},{value:"import { BufferGeometry, MeshBasicMaterial, Mesh } from '@antv/g-plugin-3d';\n\nconst bufferGeometry = new BufferGeometry(device);\nconst basicMaterial = new MeshBasicMaterial(device);\nconst mesh = new Mesh({\n    style: {\n        fill: '#1890FF',\n        opacity: 1,\n        geometry: bufferGeometry,\n        material: basicMaterial,\n    },\n});\n\nbufferGeometry.setVertexBuffer({\n    bufferIndex: 1,\n    byteStride: 4 * 3,\n    stepMode: VertexStepMode.VERTEX,\n    attributes: [\n        {\n            format: Format.F32_RGB,\n            bufferByteOffset: 4 * 0,\n            location: VertexAttributeLocation.POSITION,\n        },\n    ],\n    data: Float32Array.from([\n        -100.0,\n        100.0,\n        100.0, // 顶点1\n        100.0,\n        100.0,\n        100.0, // 顶点2\n        100.0,\n        -100.0,\n        100.0, // 顶点3\n        100.0,\n        -100.0,\n        100.0, // 顶点4\n        -100.0,\n        -100.0,\n        100.0, // 顶点5\n        -100.0,\n        100.0,\n        100.0, // 顶点6\n    ]),\n});\nbufferGeometry.vertexCount = 6;\n",paraId:35,tocIndex:8},{value:"设置需要绘制的顶点数目，默认全部绘制，后续可以随时修改。",paraId:36,tocIndex:9},{value:"geometry.vertexCount = 10;\n",paraId:37,tocIndex:9},{value:"在 instanced 模式下，绘制的实例数目。",paraId:38,tocIndex:10},{value:"geometry.instancedCount = 10;\n",paraId:39,tocIndex:10},{value:"使用索引数组（drawElements）绘制时的起始位置，默认为 0。",paraId:40,tocIndex:11},{value:"geometry.indexStart = 3;\n",paraId:41,tocIndex:11},{value:"使用非索引数组（drawArrays）绘制时的起始位置，默认为 0。",paraId:42,tocIndex:12},{value:"geometry.primitiveStart = 3;\n",paraId:43,tocIndex:12},{value:"设置索引数组。",paraId:44,tocIndex:14},{value:"参数列表：",paraId:45,tocIndex:14},{value:"indices ",paraId:46,tocIndex:14},{value:"number[] | Int32Array | Uint32Array | Uint16Array",paraId:46,tocIndex:14},{value:" 索引数组",paraId:46,tocIndex:14},{value:"例如在内置程序化生成的几何中，最终都会设置索引数组：",paraId:47,tocIndex:14},{value:"geometry.setIndices(new Uint32Array(indices));\n",paraId:48,tocIndex:14},{value:"设置顶点数组。",paraId:49,tocIndex:15},{value:"参数列表：",paraId:50,tocIndex:15},{value:"descriptor ",paraId:51,tocIndex:15},{value:"GeometryVertexBufferDescriptor",paraId:51,tocIndex:15},{value:" 顶点描述符",paraId:51,tocIndex:15},{value:"其中描述符结构如下：",paraId:52,tocIndex:15},{value:"bufferIndex 索引",paraId:53,tocIndex:15},{value:"byteStride stride 长度（以 byte 为单位）",paraId:53,tocIndex:15},{value:"stepMode 支持 vertex 和 instance 两种",paraId:53,tocIndex:15},{value:"attributes 支持 interleave，其中每个属性包括：\n",paraId:53,tocIndex:15},{value:"format 对应 Shader 中的数据类型",paraId:54,tocIndex:15},{value:"bufferByteOffset 在 stride 中的偏移量",paraId:54,tocIndex:15},{value:"byteStride 属性长度",paraId:54,tocIndex:15},{value:"location 与 Shader 中 location 对应",paraId:54,tocIndex:15},{value:"divisor 选择 instance 模式后生效",paraId:54,tocIndex:15},{value:"data 数据",paraId:53,tocIndex:15},{value:"export interface GeometryVertexBufferDescriptor {\n    bufferIndex: number;\n    byteStride: number;\n    stepMode: VertexStepMode;\n    attributes: Array<{\n        format: Format,\n        bufferByteOffset: number,\n        byteStride?: number,\n        location: number,\n        divisor?: number,\n    }>;\n    data: ArrayBufferView;\n}\n",paraId:55,tocIndex:15},{value:"例如在 Vertex Shader 中声明了如下顶点属性：",paraId:56,tocIndex:15},{value:"layout(location = 10) attribute vec3 a_Position;\n",paraId:57,tocIndex:15},{value:"在不使用 interleave 的情况下，数组中仅包含位置属性：",paraId:58,tocIndex:15},{value:"geometry.setVertexBuffer({\n    bufferIndex: ProceduralGeometryAttributeLocation.POSITION,\n    byteStride: 4 * 3,\n    stepMode: VertexStepMode.VERTEX,\n    attributes: [\n        {\n            format: Format.F32_RGB, // 与 vec3 对应\n            bufferByteOffset: 4 * 0,\n            location: VertexAttributeLocation.POSITION, // 与 location 对应\n        },\n    ],\n    data: Float32Array.from(positions),\n});\n",paraId:59,tocIndex:15},{value:"在初始化之后，顶点数据有时也需要修改。",paraId:60,tocIndex:16},{value:"例如更新上面的位置属性时，首先通过 ",paraId:61,tocIndex:16},{value:"bufferIndex",paraId:61,tocIndex:16},{value:" 定位到具体 Buffer，再通过 ",paraId:61,tocIndex:16},{value:"bufferByteOffset",paraId:61,tocIndex:16},{value:" 指定偏移量，最后更新部分或者全部数据：",paraId:61,tocIndex:16},{value:"geometry.updateVertexBuffer(\n    ProceduralGeometryAttributeLocation.POSITION,\n    VertexAttributeLocation.MAX,\n    0,\n    new Uint8Array(positions.buffer),\n);\n",paraId:62,tocIndex:16},{value:"对程序化生成的几何应用变换矩阵。由于 G 的坐标系 Y 轴正向向下，因此在生成后需要进行 Y 轴翻转。该方法对位置、法线应用变换。",paraId:63,tocIndex:17},{value:"参数列表：",paraId:64,tocIndex:17},{value:"matrix ",paraId:65,tocIndex:17},{value:"mat4",paraId:65,tocIndex:17},{value:" 变换矩阵",paraId:65,tocIndex:17},{value:"geometry.applyMat4(mat4.fromScaling(mat4.create(), vec3.fromValues(1, -1, 1)));\n",paraId:66,tocIndex:17}]},24045:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(5797);const n=[{value:"材质",paraId:0},{value:"需要配合光源呈现出某种“立体感”。",paraId:1},{value:"日常生活中的光源有很多，太阳、台灯、手电筒。它们需要被抽象成可参数化描述的光源。",paraId:2},{value:"例如太阳可以看作是“平行光”，它通过颜色、强度、方向来描述。通常光源是作用于整个场景的，因此在具体使用渲染引擎时，会将它添加到场景 / 画布上，以 G 为例：",paraId:3},{value:"import { DirectionalLight } from '@antv/g-plugin-3d';\n// 创建一个平行光\nconst light = new DirectionalLight({\n    style: {\n        fill: 'white',\n        direction: [-1, 0, 1],\n    },\n});\n// 加入画布\ncanvas.appendChild(light);\n",paraId:4},{value:"对于某些光源来说，在世界坐标系下的位置是有意义的，当我们想移动光源时，和其他 2D 图形完全一致：",paraId:5},{value:"light.translate();\nlight.setPosition();\n",paraId:6},{value:"我们复用 G 中基础图形的部分样式属性，不同光源也有独有的属性。例如我们可以随时改变一个光源的颜色：",paraId:7,tocIndex:0},{value:"light.style.fill = 'red';\n",paraId:8,tocIndex:0},{value:"光源颜色",paraId:9,tocIndex:1},{value:"光照强度，默认为 ",paraId:10,tocIndex:2},{value:"Math.PI",paraId:10,tocIndex:2},{value:"世界坐标系下的方向，类型为 ",paraId:11,tocIndex:5},{value:"[number, number, number]",paraId:11,tocIndex:5},{value:"。",paraId:11,tocIndex:5},{value:"示例",paraId:12,tocIndex:5},{value:"light.style.direction = [-1, 0, 1];\n",paraId:13,tocIndex:5},{value:"严格意义上讲这并不是一种光源，它是一种简单模拟全局光照的手段。当我们想提亮整个场景时，可以使用它。",paraId:14,tocIndex:8},{value:"示例",paraId:15,tocIndex:8},{value:"import { AmbientLight } from '@antv/g-plugin-3d';\nconst ambientLight = new AmbientLight({\n    style: {\n        fill: 'white',\n    },\n});\ncanvas.appendChild(ambientLight);\n",paraId:16,tocIndex:8}]},59788:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(89200);const n=[{value:"不同于 2D 场景下我们用“填充色”、“描边色”、“透明度”等属性描述图形的外观，3D 场景由于需要营造某种“立体感”甚至是“真实感”，需要更为强大、复杂的描述能力，通常称之为“材质” Material。",paraId:0},{value:"材质定义了渲染 API 的一些全局状态（例如 OpenGL / WebGL 中的 Blend、深度测试、模版测试等）以及 Shader。其中 Shader 通过程序定义了该材质对于光照的“反应”。",paraId:1},{value:"我们知道人眼之所以能看到物体，是由于光线经过场景中一系列复杂的传播，由各种不同的物体表面反射进入人眼。最简单的材质当然是无视“光照”，它呈现出类似 2D 图形的质感，Three.js 中称作 “MeshBasicMaterial”。另一个极端当然是追求极致的“真实感”，也称作 PBR（Physically based rendering），在绝大多数游戏级别的渲染引擎中你都能看到它。在我们熟悉的可视化场景中通常使用介于两者之间的光照模型，它既能看出一定的立体感，又不需要追求极度的真实，Phong 模型就符合这样的要求。",paraId:2},{value:"当然除了内置的材质，也可以通过 ShaderMaterial 这种完全自定义的方式使用。",paraId:3},{value:"在",paraId:4},{value:"示例",paraId:5},{value:"中，我们使用 ",paraId:4},{value:"Mesh",paraId:6},{value:" 创建了一个球体，它的几何形体由 ",paraId:4},{value:"Geometry",paraId:7},{value:" 定义，而外观由 ",paraId:4},{value:"MeshPhongMaterial",paraId:8},{value:" 决定。可以看到它的很多用法和 2D 基础图形完全一样，例如添加到画布、变换等：",paraId:4},{value:"import {\n    MeshPhongMaterial,\n    SphereGeometry,\n    DirectionalLight,\n    Mesh,\n    Plugin as Plugin3D,\n} from '@antv/g-plugin-3d';\n\n// 等待画布初始化完成\nawait canvas.ready;\n// 获取 GPU Device\nconst plugin = renderer.getPlugin('device-renderer');\nconst device = plugin.getDevice();\n\nconst sphereGeometry = new SphereGeometry(device, {\n    radius: 200,\n});\nconst material = new MeshPhongMaterial(device, {\n    map: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*npAsSLPX4A4AAAAAAAAAAAAAARQnAQ',\n    // 省略其他参数,\n});\n\n// 创建一个 Mesh\nconst sphere = new Mesh({\n    style: {\n        x: 300, // 设置局部坐标系下的位置\n        y: 250,\n        z: 0, // z 轴坐标\n        fill: '#1890FF',\n        opacity: 1,\n        geometry: sphereGeometry,\n        material,\n    },\n});\n// 添加到画布\ncanvas.appendChild(sphere);\n",paraId:9},{value:"我们可以随时修改以下属性，例如：",paraId:10,tocIndex:0},{value:"material.wireframe = true;\nmaterial.cullMode = CullMode.BACK;\n",paraId:11,tocIndex:0},{value:"使用 GLSL 300 语法编写的 Shader 字符串。",paraId:12,tocIndex:1},{value:"使用 GLSL 300 语法编写的 Shader 字符串。",paraId:13,tocIndex:2},{value:"是否绘制 wireframe，常用于直观展示三角面。开启后将额外生成重心坐标，原理详见 ",paraId:14,tocIndex:3},{value:"https://zhuanlan.zhihu.com/p/48499247",paraId:14,tocIndex:3},{value:"。",paraId:14,tocIndex:3},{value:"const basicMaterial = new MeshBasicMaterial({\n    wireframe: true,\n    map: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*_aqoS73Se3sAAAAAAAAAAAAAARQnAQ',\n});\n",paraId:15,tocIndex:3},{value:"开启 wireframe 后可指定颜色，默认为 ",paraId:16,tocIndex:4},{value:"'black'",paraId:16,tocIndex:4},{value:"。",paraId:16,tocIndex:4},{value:"开启 wireframe 后可指定线宽，默认为 1。",paraId:17,tocIndex:5},{value:"支持以下枚举值，默认使用 ",paraId:18,tocIndex:6},{value:"CullMode.NONE",paraId:18,tocIndex:6},{value:"，即不开启背面剔除：",paraId:18,tocIndex:6},{value:"export enum CullMode {\n  None,\n  Front,\n  Back,\n  FrontAndBack,\n}\n",paraId:19,tocIndex:6},{value:"默认使用 ",paraId:20,tocIndex:7},{value:"FrontFace.CCW",paraId:20,tocIndex:7},{value:"，即逆时针方向作为正面 winding order：",paraId:20,tocIndex:7},{value:"export enum FrontFace {\n  CCW = GL.CCW,\n  CW = GL.CW,\n}\n",paraId:21,tocIndex:7},{value:"是否开启深度测试，默认开启。",paraId:22,tocIndex:8},{value:"默认使用 ",paraId:23,tocIndex:9},{value:"CompareMode.LessEqual",paraId:23,tocIndex:9},{value:"，不同于 WebGL 的默认值 ",paraId:23,tocIndex:9},{value:"CompareMode.Less",paraId:23,tocIndex:9},{value:"：",paraId:23,tocIndex:9},{value:"export enum CompareMode {\n  Never = GL.NEVER,\n  Less = GL.LESS,\n  Equal = GL.EQUAL,\n  LessEqual = GL.LEQUAL,\n  Greater = GL.GREATER,\n  NotEqual = GL.NOTEQUAL,\n  GreaterEqual = GL.GEQUAL,\n  Always = GL.ALWAYS,\n}\n",paraId:24,tocIndex:9},{value:"是否开启模版测试，默认不开启。",paraId:25,tocIndex:10},{value:"compare 默认使用 ",paraId:26,tocIndex:11},{value:"CompareMode.Never",paraId:26,tocIndex:11},{value:"，枚举值同 ",paraId:26,tocIndex:11},{value:"depthCompare",paraId:26,tocIndex:11},{value:"。",paraId:26,tocIndex:11},{value:"passOp 默认使用 ",paraId:26,tocIndex:11},{value:"StencilOp.Keep",paraId:26,tocIndex:11},{value:"，支持以下枚举值：",paraId:26,tocIndex:11},{value:"export enum StencilOp {\n  Keep = GL.KEEP,\n  Zero = GL.ZERO,\n  Replace = GL.REPLACE,\n  Invert = GL.INVERT,\n  IncrementClamp = GL.INCR,\n  DecrementClamp = GL.DECR,\n  IncrementWrap = GL.INCR_WRAP,\n  DecrementWrap = GL.DECR_WRAP,\n}\n",paraId:27,tocIndex:11},{value:"混合模式支持以下枚举值：",paraId:28,tocIndex:12},{value:"export enum BlendMode {\n  Add = GL.FUNC_ADD,\n  Subtract = GL.FUNC_SUBTRACT,\n  ReverseSubtract = GL.FUNC_REVERSE_SUBTRACT,\n}\n",paraId:29,tocIndex:12},{value:"枚举值同 blendEquation",paraId:30,tocIndex:13},{value:"export enum BlendFactor {\n  Zero = GL.ZERO,\n  One = GL.ONE,\n  Src = GL.SRC_COLOR,\n  OneMinusSrc = GL.ONE_MINUS_SRC_COLOR,\n  Dst = GL.DST_COLOR,\n  OneMinusDst = GL.ONE_MINUS_DST_COLOR,\n  SrcAlpha = GL.SRC_ALPHA,\n  OneMinusSrcAlpha = GL.ONE_MINUS_SRC_ALPHA,\n  DstAlpha = GL.DST_ALPHA,\n  OneMinusDstAlpha = GL.ONE_MINUS_DST_ALPHA,\n}\n",paraId:31,tocIndex:14},{value:"枚举值同 blendSrc",paraId:32,tocIndex:15},{value:"枚举值同 blendSrc",paraId:33,tocIndex:16},{value:"枚举值同 blendSrc",paraId:34,tocIndex:17},{value:"添加一组 Uniform，需要与 Shader 中声明的变量类型匹配。",paraId:35,tocIndex:19},{value:"参数列表：",paraId:36,tocIndex:19},{value:"uniforms: ",paraId:37,tocIndex:19},{value:"Record<string, number | number[] | Texture>",paraId:37,tocIndex:19},{value:"例如 MeshPhongMaterial 在初始化时会添加如下：",paraId:38,tocIndex:19},{value:"material.setUniform({\n    u_Specular: [0, 0, 0],\n    u_BumpScale: 5,\n    u_Map: mapTexture,\n});\n",paraId:39,tocIndex:19},{value:"对应 Shader 中的 Uniform 声明，例如 ",paraId:40,tocIndex:19},{value:"u_Specular",paraId:40,tocIndex:19},{value:" 的类型为 ",paraId:40,tocIndex:19},{value:"vec3",paraId:40,tocIndex:19},{value:"，在设置时就需要使用长度为 3 的数组进行赋值：",paraId:40,tocIndex:19},{value:"layout(std140) uniform ub_MaterialParams {\n  vec3 u_Specular;\n  float u_BumpScale;\n};\n\nuniform sampler2D u_Map;\n",paraId:41,tocIndex:19},{value:"一个特殊的情况是纹理，例如上面的例子中 ",paraId:42,tocIndex:20},{value:"u_Map",paraId:42,tocIndex:20},{value:" 为采样器，在设置时就需要使用纹理：",paraId:42,tocIndex:20},{value:"const mapTexture = plugin.loadTexture(\n    'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*_aqoS73Se3sAAAAAAAAAAAAAARQnAQ',\n);\nmaterial.setUniform({\n    u_Map: mapTexture,\n});\n",paraId:43,tocIndex:20},{value:"例如我们为平行光定义了如下结构体：",paraId:44,tocIndex:21},{value:"struct DirectionalLight {\n  vec3 direction;\n  float intensity;\n  vec3 color;\n};\n",paraId:45,tocIndex:21},{value:"一种特殊情况是结构体数组，例如在 Shader 中声明了一个平行光数组：",paraId:46,tocIndex:21},{value:"DirectionalLight directionalLights[NUM_DIR_LIGHTS];\n",paraId:47,tocIndex:21},{value:"当我们想给数组中第一个元素赋值时：",paraId:48,tocIndex:21},{value:"material.setUniform({\n    'directionalLights[0].direction': [0, 0, 0],\n    'directionalLights[0].color': [0, 0, 0],\n});\n",paraId:49,tocIndex:21},{value:"使用 Point 原语绘制。",paraId:50,tocIndex:23},{value:"示例",paraId:51,tocIndex:23},{value:"默认值为 1。例如 WebGL 有最大值限制 ",paraId:52,tocIndex:24},{value:"gl.ALIASED_POINT_SIZE_RANGE",paraId:52,tocIndex:24},{value:"。",paraId:52,tocIndex:24},{value:"贴图。",paraId:53,tocIndex:25},{value:"和 Three.js 保持一致：",paraId:54,tocIndex:26},{value:"https://threejs.org/docs/#api/en/materials/MeshBasicMaterial",paraId:54,tocIndex:26},{value:"该材质不受光照影响，从 FragmentShader 可以看出直接使用 fill 定义的颜色或者 map 定义的贴图：",paraId:55,tocIndex:26},{value:"// material.basic.frag\n\n// 公共的 Uniform 定义\n#pragma glslify: import('@antv/g-shader-components/scene.both.glsl')\n#pragma glslify: import('@antv/g-shader-components/material.both.glsl')\n\n#pragma glslify: import('@antv/g-shader-components/batch.declaration.frag')\n#pragma glslify: import('@antv/g-shader-components/uv.declaration.frag')\n#pragma glslify: import('@antv/g-shader-components/map.declaration.frag')\n#pragma glslify: import('@antv/g-shader-components/wireframe.declaration.frag')\n#pragma glslify: import('@antv/g-shader-components/fog.declaration.frag')\n\nvoid main() {\n  // 通用属性，例如 fill opacity\n  #pragma glslify: import('@antv/g-shader-components/batch.frag')\n  // 贴图\n  #pragma glslify: import('@antv/g-shader-components/map.frag')\n\n  gbuf_color = u_Color;\n  gbuf_color.a = gbuf_color.a * u_Opacity;\n\n  // 绘制 wireframe\n  #pragma glslify: import('@antv/g-shader-components/wireframe.frag')\n  // 场景雾\n  #pragma glslify: import('@antv/g-shader-components/fog.frag')\n}\n",paraId:56,tocIndex:26},{value:"漫反射贴图，例如：",paraId:57,tocIndex:27},{value:"const map = plugin.loadTexture(\n    'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*_aqoS73Se3sAAAAAAAAAAAAAARQnAQ',\n);\nconst basicMaterial = new MeshBasicMaterial({\n    map,\n});\n",paraId:58,tocIndex:27},{value:"继承自 MeshBasicMaterial，使用 Lambertian 模型，无高光。",paraId:59,tocIndex:28},{value:"继承自 MeshBasicMaterial，使用 Blinn-Phong 光照模型。",paraId:60,tocIndex:29},{value:"在多伦多大学的某教学页面上可以看到 Phong 模型的一个基础实现： ",paraId:61,tocIndex:29},{value:"http://www.cs.toronto.edu/~jacobson/phong-demo/",paraId:61,tocIndex:29},{value:"该模型将直接光照部分“漫反射”、高光与间接光照部分“环境光”累加，得出最终的贡献值。从下图中我们能看到物体表面的法线、光源到物体表面的入射方向，以及人眼（相机）的观察方向都需要考虑。",paraId:62,tocIndex:29},{value:"下图为实际渲染效果：",paraId:63,tocIndex:29},{value:"以下参数可以在该",paraId:64,tocIndex:29},{value:"示例",paraId:65,tocIndex:29},{value:"中调整。",paraId:64,tocIndex:29},{value:"自发光颜色。",paraId:66,tocIndex:30},{value:"高光颜色。",paraId:67,tocIndex:31},{value:"高光贴图。例如",paraId:68,tocIndex:32},{value:"示例",paraId:69,tocIndex:32},{value:"中使用的：",paraId:68,tocIndex:32},{value:"高光闪亮程度",paraId:70,tocIndex:33},{value:"凹凸贴图，用于干扰法线。例如",paraId:71,tocIndex:34},{value:"示例",paraId:72,tocIndex:34},{value:"中使用的：",paraId:71,tocIndex:34},{value:"凹凸贴图影响程度。",paraId:73,tocIndex:35},{value:"自定义材质，其中 vertex/fragmentShader 需要指定：",paraId:74,tocIndex:36},{value:"const shaderMaterial = new ShaderMaterial(device, {\n    vertexShader: ``,\n    fragmentShader: ``,\n});\n",paraId:75,tocIndex:36},{value:"考虑到渲染性能，在使用过程中应该尽可能少地创建材质。特别是在可视化场景下，完全可以做到大量图形共享同一个材质：",paraId:76,tocIndex:38},{value:"// 创建共享材质\nconst material = new MeshBasicMaterial();\n\n// 1k 个 Mesh 共享\nfor (let i = 0; i < 1000; i++) {\n    const mesh = new Mesh({\n        style: {\n            // 省略其他样式属性\n            material,\n        },\n    });\n}\n",paraId:77,tocIndex:38},{value:"我们尝试解决以下问题：",paraId:78,tocIndex:39},{value:"一套 Shader 适应不同渲染 API，例如 WebGL 1/2、WebGPU",paraId:79,tocIndex:39},{value:"Shader 开发体验，例如编辑器的高亮、智能提示",paraId:79,tocIndex:39},{value:"模块化，即 Shader chunks 的复用",paraId:79,tocIndex:39},{value:"在 Shader 语言上我们选择 WebGL 2 使用的 GLSL 300，通过运行时简单字符串替换完成对 WebGL 1 使用的 GLSL 100 的兼容。同时使用 Rust 社区的 naga（打包成 wasm 形式）完成在运行时从 GLSL 到 WGSL 的转译，以支持 WebGPU。",paraId:80,tocIndex:40},{value:"例如下面展示了对于 UBO 从 GLSL 300 到 WGSL 的转译：",paraId:81,tocIndex:40},{value:"// GLSL\nlayout(std140) uniform ub_SceneParams {\n  mat4 u_ProjectionMatrix;\n  mat4 u_ViewMatrix;\n  vec3 u_CameraPosition;\n  float u_DevicePixelRatio;\n};\n\n// WGSL\n[[block]]\nstruct ub_SceneParams {\n    u_ProjectionMatrix: mat4x4<f32>;\n    u_ViewMatrix: mat4x4<f32>;\n    u_CameraPosition: vec3<f32>;\n    u_DevicePixelRatio: f32;\n};\n",paraId:82,tocIndex:40},{value:"很多引擎使用模版字符串存放 Shader 代码，例如 Three.js、Clay.gl 等：",paraId:83,tocIndex:41},{value:"// https://github.com/mrdoob/three.js/blob/e1ead8c5c2/src/renderers/shaders/ShaderChunk/alphamap_fragment.glsl.js\nexport default /* glsl */ `\n#ifdef USE_ALPHAMAP\n diffuseColor.a *= texture2D( alphaMap, vUv ).g;\n#endif\n`;\n",paraId:84,tocIndex:41},{value:"好处是无需额外的构建工具 loader/插件，坏处就是丧失了语法高亮，在 Shader 开发时容易犯错。我们希望使用编辑器的高亮以及 Lint，例如配合 VS Code GLSL Lint 插件。因此 shader 需要以 *.glsl/vert/frag 形式存在，使用时以文本形式引入：",paraId:85,tocIndex:41},{value:"// 引入文本字符串\nimport vert from './xxx.vert';\nimport frag from './xxx.frag';\n",paraId:86,tocIndex:41},{value:"可以使用构建工具的插件/ loader 实现，例如：",paraId:87,tocIndex:41},{value:"babel-inline-import",paraId:88,tocIndex:41},{value:"webpack raw-loader",paraId:88,tocIndex:41},{value:"我们希望使用同一个构建工具打 esm / cjs / umd，另外考虑到 wasm，最终选择 rollup-plugin-glslify，并且这个插件还有另一个好处。",paraId:89,tocIndex:41},{value:"如何组织 shader chunks 是一个很麻烦的问题，总有需要复用的代码片段。",paraId:90,tocIndex:42},{value:"Babylon.js 会使用预编译指令，自行完成片段 / 占位符的引入，但这发生在运行时：",paraId:91,tocIndex:42},{value:"#include<clipPlaneFragmentDeclaration>\n\nuniform vec4 color;\n\nvoid main(void) {\n  #include<clipPlaneFragment>\n gbuf_color = color;\n}\n",paraId:92,tocIndex:42},{value:"在构建时完成替换可以省掉 compiler 代码，现成的方案是 glslify，但需要配合构建工具，例如：",paraId:93,tocIndex:42},{value:"webpack ",paraId:94,tocIndex:42},{value:"https://github.com/glslify/glslify-loader",paraId:94,tocIndex:42},{value:"babel ",paraId:94,tocIndex:42},{value:"https://github.com/onnovisser/babel-plugin-glsl",paraId:94,tocIndex:42},{value:"rollup rollup-plugin-glslify 我们选择它",paraId:94,tocIndex:42},{value:"// main.frag\n#pragma glslify: import('./common.glsl')\n\nvoid main() {\n  gbuf_color = vec4(color, 1.0);\n}\n",paraId:95,tocIndex:42},{value:"但问题是会增大包体积，毕竟共用的 chunk 都内联在每个内置 Shader 字符串中了。",paraId:96,tocIndex:42},{value:"参考 stack.gl 建立的一系列 shader components：",paraId:97,tocIndex:42},{value:"https://github.com/glslify/glsl-easings",paraId:97,tocIndex:42},{value:" 我们也提供一个 ",paraId:97,tocIndex:42},{value:"@antv/g-shader-components",paraId:97,tocIndex:42},{value:" 包提供内置的所有 chunks。",paraId:97,tocIndex:42},{value:"Shader 代码中多余的空格、换行、注释最好压缩掉，因为经过上述基于 glslify 的构建流程后，它们都包含在字符串中：",paraId:98,tocIndex:43},{value:"// index.esm.js\nvar vert$1 = '#define GLSLIFY 1\\n#define PI 3.1415926535...';\n",paraId:99,tocIndex:43}]},50485:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(11771);const n=[{value:"在 3D 场景中 Mesh 的描述能力是最强大的，需要配合 ",paraId:0},{value:"Geometry",paraId:1},{value:" 和 ",paraId:0},{value:"Material",paraId:2},{value:" 使用。",paraId:0},{value:"import {\n    MeshPhongMaterial,\n    SphereGeometry,\n    DirectionalLight,\n    Mesh,\n    Plugin as Plugin3D,\n} from '@antv/g-plugin-3d';\n\nconst sphereGeometry = new SphereGeometry();\nconst material = new MeshPhongMaterial({\n    map: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*npAsSLPX4A4AAAAAAAAAAAAAARQnAQ',\n    // 省略其他参数,\n});\n\n// 创建一个 Mesh\nconst sphere = new Mesh({\n    style: {\n        x: 300, // 设置局部坐标系下的位置\n        y: 250,\n        z: 0, // z 轴坐标\n        fill: '#1890FF',\n        opacity: 1,\n        radius: 200,\n        geometry: sphereGeometry,\n        material,\n    },\n});\n// 添加到画布\ncanvas.appendChild(sphere);\n",paraId:3},{value:"我们复用 2D 图形的部分样式属性名。",paraId:4,tocIndex:0},{value:"填充色",paraId:5,tocIndex:1},{value:"透明度",paraId:6,tocIndex:2},{value:"局部坐标系下 Z 轴坐标",paraId:7,tocIndex:3},{value:"和 2D 图形一样，简单推广到 3D 即可。例如平移、缩放、旋转：",paraId:8,tocIndex:4},{value:"mesh.translate(0, 0, 0);\nmesh.setPosition(0, 0, 0);\nmesh.translateLocal(0, 0, 0);\nmesh.setLocalPosition(0, 0, 0);\n\nmesh.scale(1, 1, 1);\nmesh.scaleLocal(1, 1, 1);\nmesh.setLocalScale(1, 1, 1);\n\n// 绕 Y 轴逆时针方向旋转\nmesh.rotate(0, 0.1, 0);\n",paraId:9,tocIndex:4},{value:"轴对齐包围盒也从 2D 的矩形推广到 3D 中的立方体：",paraId:10,tocIndex:5},{value:"const bounds = mesh.getBounds();\n// { center: [0, 0, 0], halfExtents: [100, 100, 100] }\n",paraId:11,tocIndex:5}]},62593:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(89455);const n=[{value:"In addition to describing animations using the ",paraId:0},{value:"Web Animations API",paraId:1},{value:", we also support playback of Lottie formats, for which we provide a player like [lottie-web](",paraId:0},{value:"https://github.com/airbnb/lottie-",paraId:0},{value:" web/) player. Internally we will convert the graphics and Keyframe animations defined there into our ",paraId:0},{value:"basic graphics",paraId:2},{value:" and animation descriptions, while providing simple animation control methods.",paraId:0},{value:"Install player first:",paraId:3,tocIndex:0},{value:"npm install @antv/g-lottie-player --save\n",paraId:4,tocIndex:0},{value:"Then use the ",paraId:5,tocIndex:0},{value:"loadAnimation",paraId:6,tocIndex:0},{value:" method provided by the player to create a ",paraId:5,tocIndex:0},{value:"LottieAnimation",paraId:7,tocIndex:0},{value:" object, passing in the Lottie JSON.",paraId:5,tocIndex:0},{value:"import { loadAnimation } from '@antv/g-lottie-player';\n\nconst ballAnimation = loadAnimation(bouncy_ball, { loop: true });\n",paraId:8,tocIndex:0},{value:"Finally, render to canvas at the right time.",paraId:9,tocIndex:0},{value:"canvas.addEventListener(CanvasEvent.READY, () => {\n    const wrapper = ballAnimation.render(canvas);\n});\n",paraId:10,tocIndex:0},{value:"Reference [lottie-web](",paraId:11,tocIndex:1},{value:"https://github.com/airbnb/lottie-web/blob/6faae912910b2d7be6c5422ef4621f3933c19d60/player/js/animation/",paraId:11,tocIndex:1},{value:" AnimationManager.js#L227) method of the same name for loading Lottie files to create ",paraId:11,tocIndex:1},{value:"LottieAnimation",paraId:12,tocIndex:1},{value:".",paraId:11,tocIndex:1},{value:"The parameters are as follows.",paraId:13,tocIndex:1},{value:"data",paraId:14,tocIndex:1},{value:" Lottie JSON",paraId:14,tocIndex:1},{value:"options",paraId:14,tocIndex:1},{value:" configuration item\n",paraId:14,tocIndex:1},{value:"loop",paraId:15,tocIndex:1},{value:" is of type ",paraId:15,tocIndex:1},{value:"boolean | number",paraId:15,tocIndex:1},{value:". If or not loop is enabled, the default value is ",paraId:15,tocIndex:1},{value:"true",paraId:15,tocIndex:1},{value:" which means infinite loop. When ",paraId:15,tocIndex:1},{value:"number",paraId:15,tocIndex:1},{value:" is passed in, it means the number of loops.",paraId:15,tocIndex:1},{value:"autoplay",paraId:15,tocIndex:1},{value:" is of type ",paraId:15,tocIndex:1},{value:"boolean",paraId:15,tocIndex:1},{value:". The default value is ",paraId:15,tocIndex:1},{value:"false",paraId:15,tocIndex:1},{value:" to start autoplay immediately after loading.",paraId:15,tocIndex:1},{value:"For example, to create an infinitely looping, immediately playable animation.",paraId:16,tocIndex:1},{value:"import { loadAnimation } from '@antv/g-lottie-player';\n\nconst ballAnimation = loadAnimation(bouncy_ball, {\n    loop: true,\n    autoplay: true,\n});\n",paraId:17,tocIndex:1},{value:"This object can be created by ",paraId:18,tocIndex:2},{value:"loadAnimation",paraId:19,tocIndex:2},{value:" to control the animation process.",paraId:18,tocIndex:2},{value:"Renders to ",paraId:20,tocIndex:3},{value:"canvas",paraId:21,tocIndex:3},{value:" and returns a ",paraId:20,tocIndex:3},{value:"Group",paraId:22,tocIndex:3},{value:" as a container, which can subsequently be transformed to.",paraId:20,tocIndex:3},{value:"const wrapper = animation.render(canvas);\n\nwrapper.scale(0.5);\nwrapper.translate(100, 100);\n",paraId:23,tocIndex:3},{value:"The following two parameters are supported to be passed in.",paraId:24,tocIndex:3},{value:"Canvas. This will be added to the canvas under the root node",paraId:25,tocIndex:3},{value:"Any element that has been added to the canvas",paraId:25,tocIndex:3},{value:"It is worth noting that, like animation, it needs to be done ",paraId:26,tocIndex:3},{value:"after canvas initialization is complete",paraId:27,tocIndex:3},{value:".",paraId:26,tocIndex:3},{value:"Start the animation.",paraId:28,tocIndex:4},{value:"animation.play();\n",paraId:29,tocIndex:4},{value:"Pause the animation.",paraId:30,tocIndex:5},{value:"animation.pause();\n",paraId:31,tocIndex:5},{value:"Pause if it is playing and vice versa.",paraId:32,tocIndex:6},{value:"animation.togglePause();\n",paraId:33,tocIndex:6},{value:"Stop the animation.",paraId:34,tocIndex:7},{value:"animation.stop();\n",paraId:35,tocIndex:7},{value:"Jump to the specified moment or frame.",paraId:36,tocIndex:8},{value:"The parameters are as follows.",paraId:37,tocIndex:8},{value:"value",paraId:38,tocIndex:8},{value:" specifies the second moment or frame",paraId:38,tocIndex:8},{value:"isFrame",paraId:38,tocIndex:8},{value:" indicates whether ",paraId:38,tocIndex:8},{value:"value",paraId:38,tocIndex:8},{value:" is passed in as a frame, the default value is ",paraId:38,tocIndex:8},{value:"false",paraId:38,tocIndex:8},{value:".",paraId:38,tocIndex:8},{value:"// Jump to the 2s moment of the timeline\nanimation.goTo(2);\n\n// Jump to frame 10\nanimation.goTo(10, true);\n",paraId:39,tocIndex:8},{value:"Returns the duration, in seconds or frames.",paraId:40,tocIndex:9},{value:"The parameters are as follows.",paraId:41,tocIndex:9},{value:"inFrames",paraId:42,tocIndex:9},{value:" if or not in frames, default is ",paraId:42,tocIndex:9},{value:"false",paraId:42,tocIndex:9},{value:"animation.getDuration(); // 2\nanimation.getDuration(true); // 120\n",paraId:43,tocIndex:9},{value:"The conversion relationship between the two is:",paraId:44,tocIndex:9},{value:"const durationInSeconds = animation.getDuration();\nconst durationInFrames = animation.getDuration(true);\n\ndurationInFrames === animation.fps() * durationInSeconds; // true\n",paraId:45,tocIndex:9},{value:"Start playing the animation from the specified frame range.",paraId:46,tocIndex:10},{value:"The parameters are as follows.",paraId:47,tocIndex:10},{value:"segments",paraId:48,tocIndex:10},{value:" ",paraId:48,tocIndex:10},{value:"[number, number]",paraId:48,tocIndex:10},{value:" Specify the start and end frame range",paraId:48,tocIndex:10},{value:"animation.playSegments([firstFrame, lastFrame]);\n",paraId:49,tocIndex:10},{value:"Controls the playback speed, default is ",paraId:50,tocIndex:11},{value:"1",paraId:50,tocIndex:11},{value:". Greater than ",paraId:50,tocIndex:11},{value:"1",paraId:50,tocIndex:11},{value:" means speed up, less than ",paraId:50,tocIndex:11},{value:"1",paraId:50,tocIndex:11},{value:" means speed down.",paraId:50,tocIndex:11},{value:"// 2x\nanimation.setSpeed(2);\n",paraId:51,tocIndex:11},{value:"1",paraId:52,tocIndex:12},{value:" means forward, ",paraId:52,tocIndex:12},{value:"-1",paraId:52,tocIndex:12},{value:" means reverse. Default forward play.",paraId:52,tocIndex:12},{value:"animation.setSpeed(1);\nanimation.setSpeed(-1);\n",paraId:53,tocIndex:12},{value:"Destroys all internal objects and, of course, terminates the animation at the same time.",paraId:54,tocIndex:13},{value:"animation.destroy();\n",paraId:55,tocIndex:13},{value:"Return to Lottie file size.",paraId:56,tocIndex:14},{value:"animation.size(); // { width: 1080, height: 260 }\n",paraId:57,tocIndex:14},{value:"Returns the version of ",paraId:58,tocIndex:15},{value:"Bodymovin",paraId:58,tocIndex:15},{value:" contained in the Lottie file",paraId:58,tocIndex:15},{value:"animation.version();\n",paraId:59,tocIndex:15},{value:"Support the following ",paraId:60,tocIndex:17},{value:"Shape Layer",paraId:60,tocIndex:17},{value:" Rectangle It will be converted to ",paraId:61,tocIndex:17},{value:"Rect",paraId:62,tocIndex:17},{value:" for rendering. ",paraId:61,tocIndex:17},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#rectangle",paraId:61,tocIndex:17},{value:" Ellipse It will be converted to ",paraId:61,tocIndex:17},{value:"Ellipse",paraId:63,tocIndex:17},{value:" for rendering. ",paraId:61,tocIndex:17},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#ellipse",paraId:61,tocIndex:17},{value:" Path It will be converted to ",paraId:61,tocIndex:17},{value:"Path",paraId:64,tocIndex:17},{value:" for rendering. ",paraId:61,tocIndex:17},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#path",paraId:61,tocIndex:17},{value:" Group It will be converted to ",paraId:61,tocIndex:17},{value:"Group",paraId:65,tocIndex:17},{value:" for rendering. ",paraId:61,tocIndex:17},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#group",paraId:61,tocIndex:17},{value:" PolyStar ",paraId:61,tocIndex:17},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#polystar",paraId:61,tocIndex:17},{value:"https://lottiefiles.github.io/lottie-docs/concepts/#transform",paraId:66,tocIndex:18},{value:"The following features are supported.",paraId:67,tocIndex:18},{value:"anchor",paraId:68,tocIndex:18},{value:" corresponds to the ",paraId:69,tocIndex:18},{value:"a",paraId:69,tocIndex:18},{value:" field",paraId:69,tocIndex:18},{value:"translation",paraId:70,tocIndex:18},{value:" corresponds to the ",paraId:69,tocIndex:18},{value:"p",paraId:69,tocIndex:18},{value:" field",paraId:69,tocIndex:18},{value:"scaling",paraId:71,tocIndex:18},{value:" for the ",paraId:69,tocIndex:18},{value:"s",paraId:69,tocIndex:18},{value:" field",paraId:69,tocIndex:18},{value:"rotation",paraId:72,tocIndex:18},{value:" corresponds to the ",paraId:69,tocIndex:18},{value:"r",paraId:69,tocIndex:18},{value:" field",paraId:69,tocIndex:18},{value:"The following features are not supported at this time.",paraId:73,tocIndex:18},{value:"skew",paraId:74,tocIndex:18},{value:" corresponds to the ",paraId:75,tocIndex:18},{value:"sk",paraId:75,tocIndex:18},{value:" field",paraId:75,tocIndex:18},{value:"skewAxis",paraId:76,tocIndex:18},{value:" corresponds to the ",paraId:75,tocIndex:18},{value:"sa",paraId:75,tocIndex:18},{value:" field",paraId:75,tocIndex:18},{value:"In this ",paraId:77,tocIndex:18},{value:"example",paraId:78,tocIndex:18},{value:", the dark blue is the base rectangle, and we use the red dot as the ",paraId:77,tocIndex:18},{value:"transformOrigin",paraId:79,tocIndex:18},{value:" to rotate it by a certain angle to get the light blue rectangle.",paraId:77,tocIndex:18},{value:"https://lottiefiles.github.io/lottie-docs/concepts/#animated-position",paraId:80,tocIndex:19},{value:"The following style attributes are supported.",paraId:81,tocIndex:20},{value:" Fill",paraId:82,tocIndex:20},{value:" Stroke",paraId:82,tocIndex:20},{value:" Gradients",paraId:82,tocIndex:20},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#fill",paraId:83,tocIndex:21},{value:"Fill color, while supporting the following features.",paraId:84,tocIndex:21},{value:"fillOpacity",paraId:85,tocIndex:21},{value:" corresponds to the ",paraId:86,tocIndex:21},{value:"o",paraId:86,tocIndex:21},{value:" field",paraId:86,tocIndex:21},{value:"fillRule",paraId:87,tocIndex:21},{value:" corresponds to the ",paraId:86,tocIndex:21},{value:"r",paraId:86,tocIndex:21},{value:" field",paraId:86,tocIndex:21},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#stroke",paraId:88,tocIndex:22},{value:"Stroke color, while supporting the following features.",paraId:89,tocIndex:22},{value:"strokeOpacity",paraId:90,tocIndex:22},{value:" corresponds to the ",paraId:91,tocIndex:22},{value:"o",paraId:91,tocIndex:22},{value:" field",paraId:91,tocIndex:22},{value:"strokeWidth",paraId:92,tocIndex:22},{value:" corresponds to the ",paraId:91,tocIndex:22},{value:"w",paraId:91,tocIndex:22},{value:" field",paraId:91,tocIndex:22},{value:"lineCap",paraId:93,tocIndex:22},{value:" corresponds to the ",paraId:91,tocIndex:22},{value:"lc",paraId:91,tocIndex:22},{value:" field",paraId:91,tocIndex:22},{value:"lineJoin",paraId:94,tocIndex:22},{value:" corresponds to the ",paraId:91,tocIndex:22},{value:"lj",paraId:91,tocIndex:22},{value:" field",paraId:91,tocIndex:22},{value:"miterLimit",paraId:95,tocIndex:22},{value:" corresponds to the ",paraId:91,tocIndex:22},{value:"ml",paraId:91,tocIndex:22},{value:" field",paraId:91,tocIndex:22},{value:"lineDash",paraId:96,tocIndex:22},{value:" corresponds to the ",paraId:91,tocIndex:22},{value:"d",paraId:91,tocIndex:22},{value:" field",paraId:91,tocIndex:22},{value:"https://lottiefiles.github.io/lottie-docs/shapes/#gradients",paraId:97,tocIndex:23},{value:"Support ",paraId:98,tocIndex:23},{value:"linear",paraId:99,tocIndex:23},{value:" and ",paraId:98,tocIndex:23},{value:"radial",paraId:100,tocIndex:23},{value:" gradients.",paraId:98,tocIndex:23},{value:"The following features are not supported at this time.",paraId:101,tocIndex:23},{value:"Apply animations to gradients",paraId:102,tocIndex:23},{value:"Highlight length & angle (",paraId:102,tocIndex:23},{value:"h",paraId:102,tocIndex:23},{value:" and ",paraId:102,tocIndex:23},{value:"a",paraId:102,tocIndex:23},{value:" fields)",paraId:102,tocIndex:23},{value:"https://lottiefiles.github.io/lottie-docs/layers/#layers",paraId:103,tocIndex:27},{value:"https://lottiefiles.github.io/lottie-docs/layers/#solid-color-layer",paraId:104,tocIndex:28},{value:"https://lottiefiles.github.io/lottie-docs/layers/#image-layer",paraId:105,tocIndex:29},{value:" ",paraId:105,tocIndex:29},{value:"https://lottiefiles.github.io/lottie-docs/assets/#image",paraId:105,tocIndex:29},{value:"https://lottiefiles.github.io/lottie-docs/layers/#text-layer",paraId:106,tocIndex:30},{value:" ",paraId:106,tocIndex:30},{value:"https://lottiefiles.github.io/lottie-docs/text/",paraId:106,tocIndex:30},{value:"https://lottiefiles.github.io/lottie-docs/layers/#precomposition-layer",paraId:107,tocIndex:31},{value:" ",paraId:107,tocIndex:31},{value:"https://lottiefiles.github.io/lottie-docs/assets/#precomposition",paraId:107,tocIndex:31},{value:"https://lottie-animation-community.github.io/docs/specs/layers/shapes/#merge-paths-property",paraId:108,tocIndex:32},{value:"Internally, it will be converted to ",paraId:109,tocIndex:33},{value:"clipPath",paraId:110,tocIndex:33},{value:" to be applied to the target element and support path animation on it.",paraId:109,tocIndex:33},{value:"Caution.",paraId:111,tocIndex:33},{value:"Limited by the SVG implementation. Currently only a single Clipping Mask is supported, and only the first one will take effect if multiple are declared",paraId:112,tocIndex:33},{value:"Mask Mode Type",paraId:112,tocIndex:33},{value:" only supports the ",paraId:112,tocIndex:33},{value:"Add",paraId:112,tocIndex:33},{value:" operator",paraId:112,tocIndex:33},{value:"https://lottie-animation-community.github.io/docs/specs/layers/common/#clipping-masks",paraId:113,tocIndex:33},{value:"Post-processing effects for Layer are not supported at this time.",paraId:114,tocIndex:34},{value:"https://lottiefiles.github.io/lottie-docs/effects/#layer-effects",paraId:115,tocIndex:34},{value:"Expressions are not supported at this time.",paraId:116,tocIndex:35},{value:"https://lottiefiles.github.io/lottie-docs/expressions/",paraId:117,tocIndex:35}]},10989:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(6177);const n=[{value:"Referring to the ",paraId:0},{value:"Web Animations API",paraId:0},{value:", we add animation capabilities to each DisplayObject.",paraId:0},{value:"Currently we support Keyframe based animations, where the user needs to define a series of keyframes, each of which can contain parameters such as transformation attributes, frame offsets, easing functions, etc. G internally interpolates the values of each attribute at the current time and applies them to the target graphics (as shown below). In addition, the transformation of some special attributes will bring special animation effects, for example:",paraId:1},{value:"Using ",paraId:2},{value:"offsetDistance",paraId:2},{value:" in ",paraId:2},{value:"path animation",paraId:3},{value:"Using ",paraId:2},{value:"lineDashOffset",paraId:2},{value:" in ",paraId:2},{value:"marching ant animation",paraId:4},{value:"Using ",paraId:2},{value:"lineDash",paraId:2},{value:" in ",paraId:2},{value:"stroke animation",paraId:5},{value:"Using ",paraId:2},{value:"path",paraId:2},{value:" in ",paraId:2},{value:"morphing animation",paraId:6},{value:"For transition effects, we currently support:",paraId:7},{value:"Tween, such as ",paraId:8},{value:"linear",paraId:8},{value:", ",paraId:8},{value:"cubic-bezier",paraId:8},{value:" and custom easing function.",paraId:8},{value:"Spring, an effect based on real physical springs.",paraId:8},{value:"Let's start with a Keyframe animation, implementing a ",paraId:9},{value:"ScaleIn",paraId:9},{value:" animation ",paraId:9},{value:"example",paraId:10},{value:".",paraId:9},{value:"const scaleInCenter = circle.animate(\n    [\n        {\n            transform: 'scale(0)',\n        },\n        {\n            transform: 'scale(1)',\n        },\n    ],\n    {\n        duration: 500,\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n        fill: 'both',\n    },\n);\n",paraId:11},{value:"Developers familiar with CSS Transform/Animation will be familiar with it. Its CSS Animation counterpart is:",paraId:12},{value:".scale-in-center {\n    animation: scale-in-center 0.5s cubic-bezier(0.25, 0.46, 0.45, 0.94) both;\n}\n@keyframes scale-in-center {\n    0% {\n        transform: scale(0);\n    }\n    100% {\n        transform: scale(1);\n    }\n}\n",paraId:13},{value:"An animation object usually consists of two parts: a target and a KeyframeEffect animation. The former is specified when it is created with ",paraId:14,tocIndex:0},{value:"object.animate()",paraId:14,tocIndex:0},{value:", and the latter consists of two parts: a set of Keyframe and EffectTiming.",paraId:14,tocIndex:0},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation",paraId:15,tocIndex:0},{value:"We can create an Animation object with ",paraId:16,tocIndex:1},{value:"displayObject.animate()",paraId:16,tocIndex:1},{value:".",paraId:16,tocIndex:1},{value:"const animation = circle.animate(keyframes, options);\n",paraId:17,tocIndex:1},{value:"Note that the target graphic to which the animation effect is applied must first be mounted to the canvas:",paraId:18,tocIndex:1},{value:"// wrong\nconst animation = circle.animate(keyframes, options);\ncanvas.appendChild(circle);\n\n// correct\ncanvas.appendChild(circle);\nconst animation = circle.animate(keyframes, options);\n",paraId:19,tocIndex:1},{value:"KeyframeFormats",paraId:20,tocIndex:2},{value:"The most common is to declare the properties to be transformed in the keyframes, as in the following example to transform the transparency and fill color of the circle.",paraId:21,tocIndex:2},{value:"circle.animate(\n    [\n        {\n            // from\n            opacity: 0,\n            fill: '#fff',\n        },\n        {\n            // to\n            opacity: 1,\n            fill: '#000',\n        },\n    ],\n    2000,\n);\n",paraId:22,tocIndex:2},{value:"The elements in the keyframes array are ",paraId:23,tocIndex:2},{value:"Keyframe",paraId:24,tocIndex:2},{value:".",paraId:23,tocIndex:2},{value:"options",paraId:25,tocIndex:3},{value:" supports two types.",paraId:25,tocIndex:3},{value:"EffectTiming",paraId:26,tocIndex:3},{value:"number",paraId:27,tocIndex:3},{value:" is equivalent to ",paraId:27,tocIndex:3},{value:"{ duration }",paraId:27,tocIndex:3},{value:"Therefore the following two ways of writing are equivalent.",paraId:28,tocIndex:3},{value:"circle.animate(keyframes, {\n    duration: 100,\n});\ncircle.animate(keyframes, 100);\n",paraId:29,tocIndex:3},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/effect",paraId:30,tocIndex:5},{value:"Return ",paraId:31,tocIndex:5},{value:"KeyframeEffect",paraId:32,tocIndex:5},{value:" object. The animation effect can be adjusted later at runtime, e.g. by modifying the easing function, etc.",paraId:31,tocIndex:5},{value:"const effect = animation.effect;\n\neffect.getTiming().ease = 'linear';\n",paraId:33,tocIndex:5},{value:"Get the start time of the animation.",paraId:34,tocIndex:6},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/startTime",paraId:35,tocIndex:6},{value:"Get or set the current time of the animation relative to the timeline.",paraId:36,tocIndex:7},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/currentTime",paraId:37,tocIndex:7},{value:"const currentTime = animation.currentTime;\n\n// Set a new time that will affect the animation effect\nanimation.currentTime = newTime;\n",paraId:38,tocIndex:7},{value:"In this ",paraId:39,tocIndex:7},{value:"example",paraId:40,tocIndex:7},{value:", you can change the properties at any time. Since the single execution time of this animation is 3500ms, and the jogging function is linear, the small circle will return to the position corresponding to the path, and then continue to move.",paraId:39,tocIndex:7},{value:"Returns the running state of the animation. The state is changed when some manual control methods (e.g. ",paraId:41,tocIndex:8},{value:"pause()",paraId:41,tocIndex:8},{value:") are called.",paraId:41,tocIndex:8},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/playState",paraId:42,tocIndex:8},{value:"'idle'",paraId:43,tocIndex:8},{value:" Animation is in an unready state.",paraId:43,tocIndex:8},{value:"'running'",paraId:43,tocIndex:8},{value:" Animation is running.",paraId:43,tocIndex:8},{value:"'paused'",paraId:43,tocIndex:8},{value:" Animation is paused.",paraId:43,tocIndex:8},{value:"'finished'",paraId:43,tocIndex:8},{value:" Animation is finished.",paraId:43,tocIndex:8},{value:"The animation is waiting for some asynchronous task to complete, such as pausing a running animation.",paraId:44,tocIndex:9},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/pending",paraId:45,tocIndex:9},{value:"Returns a Promise that resolves when the animation is ready to start. ",paraId:46,tocIndex:10},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/ready",paraId:46,tocIndex:10},{value:"animation.ready.then(() => {\n    animation.playState; // running\n    canvas.timeline.currentTime;\n});\n",paraId:47,tocIndex:10},{value:"Returns a Promise that resolves at the end of the animation.",paraId:48,tocIndex:11},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/finished",paraId:49,tocIndex:11},{value:"For example, if we want the graph to remove itself after all animations have finished.",paraId:50,tocIndex:11},{value:"Promise.all(circle.getAnimations().map((animation) => animation.finished)).then(\n    () => {\n        return circle.remove();\n    },\n);\n",paraId:51,tocIndex:11},{value:"Or to complete a set of sequential animations, such as having a circle move first to the right and then down, ",paraId:52,tocIndex:11},{value:"example",paraId:53,tocIndex:11},{value:".",paraId:52,tocIndex:11},{value:"(async () => {\n    // 向右移动 100px\n    const moveRight = circle.animate(\n        [\n            {\n                transform: 'translate(0)',\n            },\n            {\n                transform: 'translate(100px)',\n            },\n        ],\n        {\n            duration: 1000,\n            easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n            fill: 'both',\n        },\n    );\n    // 等待动画完成\n    await moveRight.finished;\n\n    // 完成后向下移动\n    const moveDown = circle\n        .animate\n        //... 省略\n        ();\n})();\n",paraId:54,tocIndex:11},{value:"Set the callback function when the animation is finished, similar to ",paraId:55,tocIndex:12},{value:"animationend",paraId:55,tocIndex:12},{value:" event. ",paraId:55,tocIndex:12},{value:"example",paraId:56,tocIndex:12},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/onfinish",paraId:57,tocIndex:12},{value:"animation.onfinish = function (e) {\n    e.target; // animation\n    e.target.playState; // 'finished'\n};\n",paraId:58,tocIndex:12},{value:"The event object in the callback function is ",paraId:59,tocIndex:12},{value:"AnimationPlaybackEvent",paraId:59,tocIndex:12},{value:", which is special in that it cannot be bubbled and cannot call some methods on the object some of the methods on the object, the useful properties are as follows.",paraId:59,tocIndex:12},{value:"target",paraId:60,tocIndex:12},{value:" Returns the animation object.",paraId:60,tocIndex:12},{value:"currentTime",paraId:60,tocIndex:12},{value:"timelineTime",paraId:60,tocIndex:12},{value:"Called for animations that are running, at the end of each frame, when the properties have finished interpolating. It will not be called if the animation is paused, not started or finished. ",paraId:61,tocIndex:13},{value:"example",paraId:62,tocIndex:13},{value:"animation.onframe = function (e) {\n    e.target; // animation\n    e.target.playState; // 'running'\n};\n",paraId:63,tocIndex:13},{value:"The rate of the animation playback, the default value is 1.",paraId:64,tocIndex:14},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/playbackRate",paraId:65,tocIndex:14},{value:"For example, if we want to manually control the running direction of an animation, or reduce the playback rate.",paraId:66,tocIndex:14},{value:"animation.playbackRate = -1;\nanimation.play();\n\n// reduce the playback rate\nanimation.playbackRate *= 0.9;\n\n// accelerate the playback rate\nanimation.playbackRate *= 1.1;\n",paraId:67,tocIndex:14},{value:"The following methods allow you to manually control the running state of the animation, such as pause, restart, end, etc. ",paraId:68,tocIndex:15},{value:"example",paraId:69,tocIndex:15},{value:"Start or resume the animation. When the animation is in the ",paraId:70,tocIndex:16},{value:"finished",paraId:70,tocIndex:16},{value:" state, call it to restart the animation.",paraId:70,tocIndex:16},{value:"animation.play();\nanimation.playState; // 'running'\n",paraId:71,tocIndex:16},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/pause",paraId:72,tocIndex:17},{value:"animation.pause();\nanimation.playState; // 'paused'\n",paraId:73,tocIndex:17},{value:"Adjust the running time of the animation to the end (related to the running direction).",paraId:74,tocIndex:18},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/finish",paraId:75,tocIndex:18},{value:"animation.finish();\nanimation.playState; // 'finished'\n",paraId:76,tocIndex:18},{value:"Clear the animation and set ",paraId:77,tocIndex:19},{value:"startTime",paraId:77,tocIndex:19},{value:" and ",paraId:77,tocIndex:19},{value:"currentTime",paraId:77,tocIndex:19},{value:" to ",paraId:77,tocIndex:19},{value:"null",paraId:77,tocIndex:19},{value:".",paraId:77,tocIndex:19},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/cancel",paraId:78,tocIndex:19},{value:"Flip the animation running direction, the effect is the same as setting playbackRate to -1.",paraId:79,tocIndex:20},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/reverse",paraId:80,tocIndex:20},{value:"Controls the animation run rate, the default rate is 1, ",paraId:81,tocIndex:21},{value:"example",paraId:82,tocIndex:21},{value:".",paraId:81,tocIndex:21},{value:"animation.updatePlaybackRate(2); // accelerate the playback rate\nanimation.updatePlaybackRate(0.5); // reduce the playback rate\nanimation.updatePlaybackRate(-1); // reverse the playback rate\n",paraId:83,tocIndex:21},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/updatePlaybackRate",paraId:84,tocIndex:21},{value:"Animation effect, you can get the timing object corresponding to this effect by ",paraId:85,tocIndex:22},{value:"getTiming()",paraId:85,tocIndex:22},{value:". It consists of two parts: a set of Keyframe and ",paraId:85,tocIndex:22},{value:"EffectTiming",paraId:86,tocIndex:22},{value:".",paraId:85,tocIndex:22},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Animation/effect",paraId:87,tocIndex:22},{value:"Returns the display object currently in animation.",paraId:88,tocIndex:23},{value:"https://developer.mozilla.org/en-US/docs/Web/API/KeyframeEffect/target",paraId:89,tocIndex:23},{value:"const animation = circle.animate({\n    // ...\n});\n\nanimation.effect.target; // circle\n",paraId:90,tocIndex:23},{value:"Return ",paraId:91,tocIndex:24},{value:"EffectTiming",paraId:92,tocIndex:24},{value:" object.",paraId:91,tocIndex:24},{value:"https://developer.mozilla.org/en-US/docs/Web/API/AnimationEffect/getTiming",paraId:93,tocIndex:24},{value:"const timing = animation.effect.getTiming();\ntiming.ease = 'linear';\n",paraId:94,tocIndex:24},{value:"Returns a ",paraId:95,tocIndex:25},{value:"ComputedEffectTiming",paraId:96,tocIndex:25},{value:" object, which differs from ",paraId:95,tocIndex:25},{value:"EffectTiming",paraId:97,tocIndex:25},{value:" in that the former takes some literal quantities of the latter and returns.",paraId:95,tocIndex:25},{value:"duration",paraId:98,tocIndex:25},{value:" Returns 0 when ",paraId:98,tocIndex:25},{value:"duration",paraId:98,tocIndex:25},{value:" is 'auto'.",paraId:98,tocIndex:25},{value:"fill",paraId:98,tocIndex:25},{value:" Returns 'none' if 'auto'.",paraId:98,tocIndex:25},{value:"https://developer.mozilla.org/en-US/docs/Web/API/AnimationEffect/getComputedTiming",paraId:99,tocIndex:25},{value:"Update the ",paraId:100,tocIndex:26},{value:"EffectTiming",paraId:101,tocIndex:26},{value:" attribute, e.g. the following two writeups are equivalent.",paraId:100,tocIndex:26},{value:"const timing = animation.effect.getTiming();\ntiming.ease = 'linear';\n\nanimation.updateTiming({ ease: 'linear' });\n",paraId:102,tocIndex:26},{value:"https://developer.mozilla.org/en-US/docs/Web/API/AnimationEffect/updateTiming",paraId:103,tocIndex:26},{value:"In the opening example, we defined two Keyframes.",paraId:104,tocIndex:27},{value:"[\n  {\n    transform: 'scale(0)', // Start keyframe\n  },\n  {\n    transform: 'scale(1)', // End keyframe\n  }\n],\n",paraId:105,tocIndex:27},{value:"The following attributes are currently supported for transformations, ",paraId:106,tocIndex:28},{value:"example",paraId:107,tocIndex:28},{value:".",paraId:106,tocIndex:28},{value:"name",paraId:108,tocIndex:28},{value:"type",paraId:108,tocIndex:28},{value:"range of values",paraId:108,tocIndex:28},{value:"remarks",paraId:108,tocIndex:28},{value:"transform",paraId:108,tocIndex:28},{value:"string",paraId:108,tocIndex:28},{value:"scale(1, 2)",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"scaleY(1)",paraId:108,tocIndex:28},{value:"和 ",paraId:108,tocIndex:28},{value:"CSS Transform",paraId:108,tocIndex:28},{value:" 保持一致",paraId:108,tocIndex:28},{value:"opacity",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"[0-1]",paraId:108,tocIndex:28},{value:"strokeOpacity",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"[0-1]",paraId:108,tocIndex:28},{value:"fill",paraId:108,tocIndex:28},{value:"string",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"red",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"#fff",paraId:108,tocIndex:28},{value:"stroke",paraId:108,tocIndex:28},{value:"string",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"red",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"#fff",paraId:108,tocIndex:28},{value:"lineWidth",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"1",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"10",paraId:108,tocIndex:28},{value:"r",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"10",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"20",paraId:108,tocIndex:28},{value:"radius of Circle",paraId:108,tocIndex:28},{value:"rx/ry",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"10",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"20",paraId:108,tocIndex:28},{value:"radius of Ellipse",paraId:108,tocIndex:28},{value:"width",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"10",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"20",paraId:108,tocIndex:28},{value:"width of Rect/Image",paraId:108,tocIndex:28},{value:"height",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"10",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"20",paraId:108,tocIndex:28},{value:"height of Rect/Image",paraId:108,tocIndex:28},{value:"x1/y1/x2/y2",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"10",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"20",paraId:108,tocIndex:28},{value:"points of Line",paraId:108,tocIndex:28},{value:"offsetDistance",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"[0-1]",paraId:108,tocIndex:28},{value:"路径偏移，在",paraId:108,tocIndex:28},{value:"路径动画",paraId:109,tocIndex:28},{value:"中使用",paraId:108,tocIndex:28},{value:"lineDash",paraId:108,tocIndex:28},{value:"[number, number]",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"[0, 100]",paraId:108,tocIndex:28},{value:"实线和间隔的长度，在",paraId:108,tocIndex:28},{value:"笔迹动画",paraId:110,tocIndex:28},{value:"中使用",paraId:108,tocIndex:28},{value:"lineDashOffset",paraId:108,tocIndex:28},{value:"number",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"-20",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"0",paraId:108,tocIndex:28},{value:" ",paraId:108,tocIndex:28},{value:"20",paraId:108,tocIndex:28},{value:"设置虚线的偏移量，在",paraId:108,tocIndex:28},{value:"蚂蚁线效果",paraId:111,tocIndex:28},{value:"中使用",paraId:108,tocIndex:28},{value:"path",paraId:108,tocIndex:28},{value:"string",paraId:108,tocIndex:28},{value:"e.g. ",paraId:108,tocIndex:28},{value:"M 100,100 L 200,200",paraId:108,tocIndex:28},{value:"Path 的定义，在",paraId:108,tocIndex:28},{value:"形变动画",paraId:112,tocIndex:28},{value:"中使用",paraId:108,tocIndex:28},{value:"For custom properties, you can ",paraId:113,tocIndex:28},{value:"register them in the style system",paraId:114,tocIndex:28},{value:". In this ",paraId:113,tocIndex:28},{value:"example",paraId:115,tocIndex:28},{value:", we register several different types of custom properties to allow them to support interpolation.",paraId:113,tocIndex:28},{value:"where transform is consistent with ",paraId:116,tocIndex:28},{value:"CSS Transform",paraId:116,tocIndex:28},{value:" and supports the following property values:",paraId:116,tocIndex:28},{value:"Scaling, unitless\n",paraId:117,tocIndex:28},{value:"scale(x, y)",paraId:118,tocIndex:28},{value:"scaleX(x)",paraId:118,tocIndex:28},{value:"scaleY(x)",paraId:118,tocIndex:28},{value:"scaleZ(z)",paraId:118,tocIndex:28},{value:"scale3d(x, y, z)",paraId:118,tocIndex:28},{value:"Panning, 0 can be used without units, unitless is treated as px, the percentage is relative to the current graph enclosing the box\n",paraId:117,tocIndex:28},{value:"translate(0, 0) translate(0, 30px) translate(100%, 100%)",paraId:119,tocIndex:28},{value:"translateX(0)",paraId:119,tocIndex:28},{value:"translateY(0)",paraId:119,tocIndex:28},{value:"translateZ(0)",paraId:119,tocIndex:28},{value:"translate3d(0, 0, 0)",paraId:119,tocIndex:28},{value:"Rotation, support for deg, rad and turn\n",paraId:117,tocIndex:28},{value:"rotate(0.5turn) rotate(30deg) rotate(1rad)",paraId:120,tocIndex:28},{value:"Stretch, support for deg, rad and turn\n",paraId:117,tocIndex:28},{value:"skew(ax, ay)",paraId:121,tocIndex:28},{value:"skewX(a)",paraId:121,tocIndex:28},{value:"skewY(a)",paraId:121,tocIndex:28},{value:"matrix\n",paraId:117,tocIndex:28},{value:"matrix(a,b,c,d,tx,ty) Available from ",paraId:122,tocIndex:28},{value:"CSS matrix definition",paraId:122,tocIndex:28},{value:"matrix3d() Complete matrix definition with 16 elements",paraId:122,tocIndex:28},{value:"none",paraId:117,tocIndex:28},{value:"⚠️ The following values are not supported at this time.",paraId:123,tocIndex:28},{value:"calc()",paraId:124,tocIndex:28},{value:" e.g. ",paraId:124,tocIndex:28},{value:"translate(calc(100% + 10px))",paraId:124,tocIndex:28},{value:"perspective",paraId:124,tocIndex:28},{value:"Offset of the keyframe in the range ",paraId:125,tocIndex:29},{value:"[0-1]",paraId:125,tocIndex:29},{value:".",paraId:125,tocIndex:29},{value:"[{ opacity: 1 }, { opacity: 0.1, offset: 0.7 }, { opacity: 0 }];\n",paraId:126,tocIndex:29},{value:"When not specified, the offset is automatically calculated by the adjacent keyframes, for example, the following 3 keyframes are not specified, the default values are 0 and 1 at one end, and 0.5 is calculated for the middle frame.",paraId:127,tocIndex:29},{value:"[\n  { transform: 'scale(0)' }, // offset 0\n  { transform: 'scale(2)' }, // offset 0.5\n  { transform: 'scale(1)' }, // offset 1\n],\n",paraId:128,tocIndex:29},{value:"The easing function between adjacent keyframes can be specified by ",paraId:129,tocIndex:30},{value:"easing",paraId:129,tocIndex:30},{value:".",paraId:129,tocIndex:30},{value:"circle.animate(\n    [\n        { opacity: 1, easing: 'ease-out' },\n        { opacity: 0.1, easing: 'ease-in' },\n        { opacity: 0 },\n    ],\n    2000,\n);\n",paraId:130,tocIndex:30},{value:"The built-in easing function is described in ",paraId:131,tocIndex:30},{value:"easing",paraId:132,tocIndex:30},{value:"Some common animation effects, such as fadeIn, etc., can be found in ",paraId:133,tocIndex:31},{value:"https://github.com/wellyshen/use-web-animations/tree/master/src/animations",paraId:133,tocIndex:31},{value:"export default {\n    keyframes: [{ opacity: 0 }, { opacity: 1 }],\n    animationOptions: { duration: 1000, fill: 'both' },\n};\n",paraId:134,tocIndex:31},{value:"Example",paraId:135},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming",paraId:136,tocIndex:32},{value:"const timing = animation.effect.getTiming();\n",paraId:137,tocIndex:32},{value:"The delay, in milliseconds, before starting the animation. The default value is 0, so the animation will start immediately.",paraId:138,tocIndex:33},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/delay",paraId:139,tocIndex:33},{value:"type",paraId:140,tocIndex:33},{value:"： ",paraId:140,tocIndex:33},{value:"number",paraId:140,tocIndex:33},{value:"default value",paraId:141,tocIndex:33},{value:"：0",paraId:141,tocIndex:33},{value:"required",paraId:142,tocIndex:33},{value:"：",paraId:142,tocIndex:33},{value:"false",paraId:142,tocIndex:33},{value:"The direction in which the animation runs on the timeline also affects the behavior at the end of each iteration. With this property we can achieve the effect of reciprocal motion.",paraId:143,tocIndex:34},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/direction",paraId:144,tocIndex:34},{value:"type",paraId:145,tocIndex:34},{value:"： ",paraId:145,tocIndex:34},{value:"string",paraId:145,tocIndex:34},{value:"default value",paraId:146,tocIndex:34},{value:"：",paraId:146,tocIndex:34},{value:"normal",paraId:146,tocIndex:34},{value:"required",paraId:147,tocIndex:34},{value:"：",paraId:147,tocIndex:34},{value:"false",paraId:147,tocIndex:34},{value:"The following values can be taken.",paraId:148,tocIndex:34},{value:"'normal'",paraId:149,tocIndex:34},{value:" In each iteration, the animation runs from the start frame to the end frame.",paraId:149,tocIndex:34},{value:"'reverse'",paraId:149,tocIndex:34},{value:" In each iteration, the animation runs from the end frame to the start frame.",paraId:149,tocIndex:34},{value:"'alternate'",paraId:149,tocIndex:34},{value:" Change the direction at the end of each iteration, e.g. first iteration from front to back, second iteration from back to front.",paraId:149,tocIndex:34},{value:"'alternate-reverse'",paraId:149,tocIndex:34},{value:" Change the direction at the end of each iteration, e.g. back to front for the first iteration and front to back for the second iteration.",paraId:149,tocIndex:34},{value:"The duration of the animation, in milliseconds, default is ",paraId:150,tocIndex:35},{value:"auto",paraId:150,tocIndex:35},{value:", same effect as 0.",paraId:150,tocIndex:35},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/duration",paraId:151,tocIndex:35},{value:"type",paraId:152,tocIndex:35},{value:"： ",paraId:152,tocIndex:35},{value:"number | string",paraId:152,tocIndex:35},{value:"default",paraId:153,tocIndex:35},{value:"：",paraId:153,tocIndex:35},{value:"auto",paraId:153,tocIndex:35},{value:"required",paraId:154,tocIndex:35},{value:"：",paraId:154,tocIndex:35},{value:"false",paraId:154,tocIndex:35},{value:"description",paraId:155,tocIndex:35},{value:" Cannot be a negative number",paraId:155,tocIndex:35},{value:"The easing function, which defaults to ",paraId:156,tocIndex:36},{value:"linear",paraId:156,tocIndex:36},{value:", we also have a series of common functions built in. ",paraId:156,tocIndex:36},{value:"example",paraId:157,tocIndex:36},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/easing",paraId:158,tocIndex:36},{value:"type",paraId:159,tocIndex:36},{value:"： ",paraId:159,tocIndex:36},{value:"string",paraId:159,tocIndex:36},{value:"default value",paraId:160,tocIndex:36},{value:"：",paraId:160,tocIndex:36},{value:"linear",paraId:160,tocIndex:36},{value:"required",paraId:161,tocIndex:36},{value:"：",paraId:161,tocIndex:36},{value:"false",paraId:161,tocIndex:36},{value:"支持以下内置缓动函数，来自：",paraId:162,tocIndex:36},{value:"https://easings.net/",paraId:162,tocIndex:36},{value:"constant",paraId:163,tocIndex:36},{value:"accelerate",paraId:163,tocIndex:36},{value:"decelerate",paraId:163,tocIndex:36},{value:"accelerate-decelerate",paraId:163,tocIndex:36},{value:"decelerate-accelerate",paraId:163,tocIndex:36},{value:"linear",paraId:163,tocIndex:36},{value:"ease-in / in",paraId:163,tocIndex:36},{value:"ease-out / out",paraId:163,tocIndex:36},{value:"ease-in-out / in-out",paraId:163,tocIndex:36},{value:"ease-out-in / out-in",paraId:163,tocIndex:36},{value:"ease",paraId:163,tocIndex:36},{value:"in-sine",paraId:163,tocIndex:36},{value:"out-sine",paraId:163,tocIndex:36},{value:"in-out-sine",paraId:163,tocIndex:36},{value:"out-in-sine",paraId:163,tocIndex:36},{value:"steps",paraId:163,tocIndex:36},{value:"in-quad",paraId:163,tocIndex:36},{value:"out-quad",paraId:163,tocIndex:36},{value:"in-out-quad",paraId:163,tocIndex:36},{value:"out-in-quad",paraId:163,tocIndex:36},{value:"step-start",paraId:163,tocIndex:36},{value:"in-cubic",paraId:163,tocIndex:36},{value:"out-cubic",paraId:163,tocIndex:36},{value:"in-out-cubic",paraId:163,tocIndex:36},{value:"out-in-cubic",paraId:163,tocIndex:36},{value:"step-end",paraId:163,tocIndex:36},{value:"in-quart",paraId:163,tocIndex:36},{value:"out-quart",paraId:163,tocIndex:36},{value:"in-out-quart",paraId:163,tocIndex:36},{value:"out-in-quart",paraId:163,tocIndex:36},{value:"in-quint",paraId:163,tocIndex:36},{value:"out-quint",paraId:163,tocIndex:36},{value:"in-out-quint",paraId:163,tocIndex:36},{value:"out-in-quint",paraId:163,tocIndex:36},{value:"in-expo",paraId:163,tocIndex:36},{value:"out-expo",paraId:163,tocIndex:36},{value:"in-out-expo",paraId:163,tocIndex:36},{value:"out-in-expo",paraId:163,tocIndex:36},{value:"in-circ",paraId:163,tocIndex:36},{value:"out-circ",paraId:163,tocIndex:36},{value:"in-out-circ",paraId:163,tocIndex:36},{value:"out-in-circ",paraId:163,tocIndex:36},{value:"in-back",paraId:163,tocIndex:36},{value:"out-back",paraId:163,tocIndex:36},{value:"in-out-back",paraId:163,tocIndex:36},{value:"out-in-back",paraId:163,tocIndex:36},{value:"in-bounce",paraId:163,tocIndex:36},{value:"out-bounce",paraId:163,tocIndex:36},{value:"in-out-bounce",paraId:163,tocIndex:36},{value:"out-in-bounce",paraId:163,tocIndex:36},{value:"in-elastic",paraId:163,tocIndex:36},{value:"out-elastic",paraId:163,tocIndex:36},{value:"in-out-elastic",paraId:163,tocIndex:36},{value:"out-in-elastic",paraId:163,tocIndex:36},{value:"spring / spring-in",paraId:163,tocIndex:36},{value:"spring-out",paraId:163,tocIndex:36},{value:"spring-in-out",paraId:163,tocIndex:36},{value:"spring-out-in",paraId:163,tocIndex:36},{value:"In addition, you can also customize functions like cubic Bezier curves with ",paraId:164,tocIndex:36},{value:"cubic-bezier(<number>, <number>, <number>, <number>)",paraId:164,tocIndex:36},{value:". Some of the above built-in functions are also defined by it, for example ",paraId:164,tocIndex:36},{value:"ease-in-sine = cubic-bezier(0.47, 0, 0.745, 0.715)",paraId:164,tocIndex:36},{value:".",paraId:164,tocIndex:36},{value:"When the above built-in easing functions cannot be satisfied, you can manually pass in a custom function via ",paraId:165,tocIndex:36},{value:"easingFunction",paraId:165,tocIndex:36},{value:".",paraId:165,tocIndex:36},{value:"You can also register custom easing function via ",paraId:166,tocIndex:36},{value:"EasingFunctions",paraId:166,tocIndex:36},{value:" like this:",paraId:166,tocIndex:36},{value:"import { EasingFunctions } from '@antv/g';\n\nEasingFunctions['my-easing'] = (t: number) => t;\n\ncircle.animate([{ opacity: 0 }, { opacity: 1 }], {\n  duration: 500,\n  easing: 'my-easing',\n});\n\n### endDelay\n\nThe delay before the end of the animation, in milliseconds, default value is 0, so the animation will end as soon as it finishes running.\n\nhttps://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/endDelay\n\n**type**： `number`\n\n**default value**：0\n\n**required**：`false`\n\nWe can also set a negative number to bring the animation to an early end.\n\n```js\nconst animation = circle.animate(\n    [{ transform: 'scale(1)' }, { transform: 'scale(2)' }],\n    {\n        duration: 2000,\n        endDelay: -1000, // 动画执行到一半会立刻结束\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n    },\n);\n",paraId:167,tocIndex:36},{value:"This property specifies how the graph will be displayed when the animation is in a non-running state (e.g. before the animation starts, after it ends). The following values are supported.",paraId:168,tocIndex:37},{value:"'auto/none'",paraId:169,tocIndex:37},{value:" default value, This means that the animation will not affect the presentation of the graphics before the first frame starts and after the last frame ends. For example, after the animation finishes the graphics will return to their pre-animation state, and if a delay is set the effect of the first frame will not be applied during the delay.",paraId:169,tocIndex:37},{value:"'forwards'",paraId:169,tocIndex:37},{value:" Stop after the animation is completed and does not return to the initial state.",paraId:169,tocIndex:37},{value:"'backwards'",paraId:169,tocIndex:37},{value:" Apply the first frame effect before the animation starts.",paraId:169,tocIndex:37},{value:"'both'",paraId:169,tocIndex:37},{value:" For the combination of ",paraId:169,tocIndex:37},{value:"'forwards'",paraId:169,tocIndex:37},{value:" and ",paraId:169,tocIndex:37},{value:"'backwards'",paraId:169,tocIndex:37},{value:".",paraId:169,tocIndex:37},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/fill",paraId:170,tocIndex:37},{value:"For example, we want the graph to stop at the end state after the scaling animation finishes.",paraId:171,tocIndex:37},{value:"const animation = circle.animate(\n    [\n        {\n            transform: 'scale(1)',\n            fill: '#1890FF',\n            stroke: '#F04864',\n            opacity: 1,\n        },\n        { transform: 'scale(2)', fill: 'red', stroke: '#1890FF', opacity: 0.8 },\n    ],\n    {\n        duration: 1500,\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n        fill: 'both',\n    },\n);\n",paraId:172,tocIndex:37},{value:"The number of loops, default value is 1, or we can take a decimal number greater than 0. When we want the animation to run forever, we can take ",paraId:173,tocIndex:38},{value:"Infinity",paraId:173,tocIndex:38},{value:".",paraId:173,tocIndex:38},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/iterations",paraId:174,tocIndex:38},{value:"type",paraId:175,tocIndex:38},{value:"： ",paraId:175,tocIndex:38},{value:"number",paraId:175,tocIndex:38},{value:"default value",paraId:176,tocIndex:38},{value:"：1",paraId:176,tocIndex:38},{value:"required",paraId:177,tocIndex:38},{value:"：",paraId:177,tocIndex:38},{value:"false",paraId:177,tocIndex:38},{value:"Where to start the animation, e.g. the animation always starts from 0, set to 0.5 means the animation will start from the middle.",paraId:178,tocIndex:39},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EffectTiming/iterationStart",paraId:179,tocIndex:39},{value:"type",paraId:180,tocIndex:39},{value:"： ",paraId:180,tocIndex:39},{value:"number",paraId:180,tocIndex:39},{value:"default value",paraId:181,tocIndex:39},{value:"：0",paraId:181,tocIndex:39},{value:"required",paraId:182,tocIndex:39},{value:"：",paraId:182,tocIndex:39},{value:"false",paraId:182,tocIndex:39},{value:"Inherits all the properties of ",paraId:183,tocIndex:40},{value:"EffectTiming",paraId:184,tocIndex:40},{value:" and includes some read-only, computed extra properties.",paraId:183,tocIndex:40},{value:"const computedTiming = animation.effect.getComputedTiming();\n",paraId:185,tocIndex:40},{value:"The estimated end time of the animation, which needs to take into account the delay before and after. Calculated as: ",paraId:186,tocIndex:41},{value:"delay",paraId:187,tocIndex:41},{value:" + ",paraId:186,tocIndex:41},{value:"activeDuration",paraId:188,tocIndex:41},{value:" + [endDelay](/en/api/ animation#enddelay).",paraId:186,tocIndex:41},{value:"https://developer.mozilla.org/en-US/docs/Web/API/AnimationEffect/getComputedTiming#return_value",paraId:189,tocIndex:41},{value:"The estimated duration of the animation effect run, in milliseconds. It is calculated as ",paraId:190,tocIndex:42},{value:"duration",paraId:191,tocIndex:42},{value:" * ",paraId:190,tocIndex:42},{value:"iterations",paraId:192,tocIndex:42},{value:"https://developer.mozilla.org/en-US/docs/Web/API/AnimationEffect/getComputedTiming#return_value",paraId:193,tocIndex:42},{value:"Same as ",paraId:194,tocIndex:43},{value:"currentTime",paraId:195,tocIndex:43},{value:", in milliseconds.",paraId:194,tocIndex:43},{value:"Returns the progress within the current iteration, in the range ",paraId:196,tocIndex:44},{value:"[0-1]",paraId:196,tocIndex:44},{value:". Returns null when the animation is not running.",paraId:196,tocIndex:44},{value:"In this ",paraId:197,tocIndex:44},{value:"example",paraId:198,tocIndex:44},{value:", we print the progress value in the ",paraId:197,tocIndex:44},{value:"onframe",paraId:199,tocIndex:44},{value:" callback function at the end of each frame.",paraId:197,tocIndex:44},{value:"animation.onframe = (e) => {\n    console.log(e.target.effect.getComputedTiming().progress);\n};\n",paraId:200,tocIndex:44},{value:"Returns the number of times the animation is currently looped, starting from 0. Returns null when the animation is not running.",paraId:201,tocIndex:45},{value:"The familiar easing function (aka Tween) is an animation effect based on the current runtime, but even if you can customize the jogging function, there are still some animation effects that cannot be implemented. For example, the now widely used Spring effect can be seen in the ",paraId:202,tocIndex:46},{value:"React Spring Visualizer",paraId:202,tocIndex:46},{value:" which does not rely solely on the current runtime, but is an effect based on physical spring properties (self-weight, friction, etc.).",paraId:202,tocIndex:46},{value:"Therefore, in some popular animation libraries, there is often more than one type of transition, such as ",paraId:203,tocIndex:46},{value:"Framer Motion",paraId:203,tocIndex:46},{value:", which supports Spring.",paraId:203,tocIndex:46},{value:"<motion.div animate={{ rotate: 180 }} transition={{ type: 'spring' }} />\n",paraId:204,tocIndex:46},{value:"There are also libraries like ",paraId:205,tocIndex:46},{value:"https://react-spring.io/",paraId:205,tocIndex:46},{value:".",paraId:205,tocIndex:46},{value:"https://blog.maximeheckel.com/posts/the-physics-behind-spring-animations",paraId:206,tocIndex:46},{value:"So how do you implement this non-jogging effect using CSS Animation or WAAPI? This issue has been discussed in the W3C for a long time: ",paraId:207,tocIndex:46},{value:"https://github.com/w3c/csswg-drafts/issues/229",paraId:207,tocIndex:46},{value:". We currently have the spring family of transform effects built in, but do not provide configuration of the spring parameters yet [example](/en/examples/animation## easing).",paraId:207,tocIndex:46},{value:"const animation = image.animate(\n    [{ transform: 'rotate(0)' }, { transform: 'rotate(360deg)' }],\n    {\n        duration: 1500,\n        iterations: Infinity,\n        easing: 'spring',\n    },\n);\n",paraId:208,tocIndex:46},{value:"Moving graphics along a path is a common requirement, and is accomplished in CSS via ",paraId:209,tocIndex:47},{value:"MotionPath",paraId:209,tocIndex:47},{value:".",paraId:209,tocIndex:47},{value:"#motion-demo {\n    animation: move 3000ms infinite alternate ease-in-out;\n    offset-path: path('M20,20 C20,100 200,0 200,100');\n}\n@keyframes move {\n    0% {\n        offset-distance: 0%;\n    }\n    100% {\n        offset-distance: 100%;\n    }\n}\n",paraId:210,tocIndex:47},{value:"First create a motion path by offsetPath, currently support ",paraId:211,tocIndex:47},{value:"Line",paraId:212,tocIndex:47},{value:" ",paraId:211,tocIndex:47},{value:"Path",paraId:213,tocIndex:47},{value:" and ",paraId:211,tocIndex:47},{value:"Polyline",paraId:214,tocIndex:47},{value:". The effect is then achieved by transforming the offsetDistance (in the range ",paraId:211,tocIndex:47},{value:"[0-1]",paraId:211,tocIndex:47},{value:") to.",paraId:211,tocIndex:47},{value:"const circle = new Circle({\n    style: {\n        offsetPath: new Line({\n            // Create motion tracks\n            style: {\n                // There is no need to set other drawing properties that are not related to trajectories\n                x1: 100,\n                y1: 100,\n                x2: 300,\n                y2: 100,\n            },\n        }),\n        r: 10,\n    },\n});\n\ncircle.animate([{ offsetDistance: 0 }, { offsetDistance: 1 }], {\n    duration: 3000,\n    easing: 'ease-in-out',\n    iterations: Infinity,\n});\n",paraId:215,tocIndex:47},{value:"Example",paraId:216,tocIndex:47},{value:".",paraId:217,tocIndex:47},{value:'The common lasso tool in PS is an "Marching Ant" effect.',paraId:218,tocIndex:48},{value:"The ",paraId:219,tocIndex:48},{value:"lineDashOffset",paraId:220,tocIndex:48},{value:" property is used to set the offset of the dashed line, which can be transformed to achieve the effect.",paraId:219,tocIndex:48},{value:"const circle = new Circle({\n    style: {\n        lineDash: [10, 10],\n    },\n});\ncircle.animate([{ lineDashOffset: -20 }, { lineDashOffset: 0 }], {\n    duration: 500,\n    iterations: Infinity,\n});\n",paraId:221,tocIndex:48},{value:"Example",paraId:222,tocIndex:48},{value:".",paraId:223,tocIndex:48},{value:"A common animation effect is to show the stroke from nothing to something. The ",paraId:224,tocIndex:49},{value:"lineDash",paraId:225,tocIndex:49},{value:" attribute specifies the length of the solid line and interval of the stroke, and the initial state of the stroke, ",paraId:224,tocIndex:49},{value:"nothing', can be represented by",paraId:224,tocIndex:49},{value:"[0, length]",paraId:224,tocIndex:49},{value:", while the full state can be represented by",paraId:224,tocIndex:49},{value:"[length, 0]`. The length of the stroke can be obtained by graphical methods, such as Path's ",paraId:224,tocIndex:49},{value:"getTotalLength",paraId:226,tocIndex:49},{value:" method.",paraId:224,tocIndex:49},{value:"const length = path.getTotalLength();\npath.animate([{ lineDash: [0, length] }, { lineDash: [length, 0] }], {\n    duration: 3500,\n    easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n    iterations: Infinity,\n    direction: 'alternate',\n});\n",paraId:227,tocIndex:49},{value:"Example",paraId:228,tocIndex:49},{value:".",paraId:229,tocIndex:49},{value:"Examples of morping animation can be found in many SVG-related libraries, such as",paraId:230,tocIndex:50},{value:"Paper.js",paraId:231,tocIndex:50},{value:"Kute.js",paraId:231,tocIndex:50},{value:" provides ",paraId:231,tocIndex:50},{value:"Morph",paraId:231,tocIndex:50},{value:" and ",paraId:231,tocIndex:50},{value:"CubicMorph",paraId:231,tocIndex:50},{value:".",paraId:231,tocIndex:50},{value:"Snap.svg",paraId:231,tocIndex:50},{value:"GreenSocks provides ",paraId:231,tocIndex:50},{value:"MorphSVGPlugin",paraId:231,tocIndex:50},{value:"The above partial library will require that the path definitions before and after the transformation contain the same segments, otherwise interpolation is not possible.",paraId:232,tocIndex:50},{value:"G refers to ",paraId:233,tocIndex:50},{value:"CubicMorph",paraId:233,tocIndex:50},{value:" in Kute.js, and first transforms each part of the Path definition into a third-order Bezier curve, and then uses the easy segmentation property of the third-order Bezier curve to normalize the paths before and after the transformation to the same number of segments. The paths are normalized to the same number of segments, and finally the control points in each segment are interpolated to achieve the animation effect.",paraId:233,tocIndex:50},{value:"const path1 = 'M 0,40 ...';\nconst path2 = [\n    ['M', 100, 100],\n    ['L', 200, 200],\n];\n\npath.animate([{ path: path1 }, { path: path2 }], {\n    duration: 2500,\n    easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n    iterations: Infinity,\n    direction: 'alternate',\n});\n",paraId:234,tocIndex:50},{value:"Example",paraId:235,tocIndex:50},{value:".",paraId:236,tocIndex:50},{value:"Since only the path attribute can be transformed, for other base shapes such as Circle, Rect, Line, we provide the tool method ",paraId:237,tocIndex:51},{value:"convertToPath",paraId:238,tocIndex:51},{value:" for conversion.",paraId:237,tocIndex:51},{value:"import { Circle, convertToPath } from '@antv/g';\n\nconst circle = new Circle({\n    style: {\n        cx: 50,\n        cy: 50,\n        r: 50,\n    },\n});\nconst circlePath = convertToPath(circle); // get path definition\n\npath.animate([{ path: originalPath }, { path: circlePath }], {\n    duration: 2500,\n});\n",paraId:239,tocIndex:51},{value:"The base graphics that currently support conversion paths are: ",paraId:240,tocIndex:51},{value:"Circle",paraId:241,tocIndex:51},{value:" ",paraId:240,tocIndex:51},{value:"Ellipse",paraId:242,tocIndex:51},{value:" ",paraId:240,tocIndex:51},{value:"Rect",paraId:243,tocIndex:51},{value:" ",paraId:240,tocIndex:51},{value:"Line",paraId:244,tocIndex:51},{value:" ",paraId:240,tocIndex:51},{value:"Polyline",paraId:245,tocIndex:51},{value:" ",paraId:240,tocIndex:51},{value:"Polygon",paraId:246,tocIndex:51},{value:" ",paraId:240,tocIndex:51},{value:"Path",paraId:247,tocIndex:51},{value:".",paraId:240,tocIndex:51},{value:"Example",paraId:248},{value:"Note that the transformation of these base shapes affects the final generated path string. For example, the original path of the following pentagram is too large and can be scaled and animated.",paraId:249},{value:"const starPath = new Path({\n    style: {\n        path: 'M301.113,12.011l99.25,179.996l201.864,38.778L461.706,380.808l25.508,203.958l-186.101-87.287L115.01,584.766l25.507-203.958L0,230.785l201.86-38.778L301.113,12.011',\n    },\n});\nstarPath.scale(0.2); // do scaling first\nconst pathString = convertToPath(starPath); // then do conversion\n",paraId:250},{value:"We do not support more than two sets of keyframes for the time being in the shape change animation, e.g.",paraId:251,tocIndex:52},{value:"path.animate(\n    [\n        // wrong. use 3 keyframes\n        { path: path1 },\n        { path: path2 },\n        { path: path3 },\n    ],\n    {\n        duration: 2500,\n    },\n);\n",paraId:252,tocIndex:52},{value:"For continuous changes between multiple paths, it can be split into multiple Animations, e.g.",paraId:253,tocIndex:52},{value:"const animation1 = path.animate([{ path: path1 }, { path: path2 }], {\n    duration: 1250,\n    fill: 'both',\n});\n\nanimation1.finished.then(() => {\n    path.animate([{ path: path2 }, { path: path3 }], {\n        duration: 1250,\n        fill: 'both',\n    });\n});\n",paraId:254,tocIndex:52},{value:"Support for WebGL Transform Feedback-based GPU animations in ",paraId:255,tocIndex:53},{value:"g-webgl",paraId:255,tocIndex:53},{value:".",paraId:255,tocIndex:53}]},8840:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(6730);const n=[{value:"You can refer to the ",paraId:0},{value:"<circle>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" draws a circle with a center of ",paraId:1},{value:"[100, 100]",paraId:1},{value:" and a radius of ",paraId:1},{value:"100",paraId:1},{value:".",paraId:1},{value:"const circle = new Circle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 100,\n    },\n});\n",paraId:3},{value:"Inherits ",paraId:4,tocIndex:0},{value:"style property",paraId:5,tocIndex:0},{value:" from ",paraId:4,tocIndex:0},{value:"DisplayObject",paraId:6,tocIndex:0},{value:".",paraId:4,tocIndex:0},{value:"The default value is ",paraId:7,tocIndex:1},{value:"[0.5, 0.5]",paraId:7,tocIndex:1},{value:". For details, see ",paraId:7,tocIndex:1},{value:"DisplayObject's anchor",paraId:8,tocIndex:1},{value:".",paraId:7,tocIndex:1},{value:"The default value is ",paraId:9,tocIndex:2},{value:"center",paraId:9,tocIndex:2},{value:". For details, see ",paraId:9,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:10,tocIndex:2},{value:".",paraId:9,tocIndex:2},{value:"The x-axis coordinates of the center of the circle in the local coordinate system.",paraId:11,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/cx",paraId:12,tocIndex:4},{value:"Initial value",paraId:13,tocIndex:4},{value:"Applicable elements",paraId:14,tocIndex:4},{value:"Inheritable",paraId:15,tocIndex:4},{value:"Animatable",paraId:14,tocIndex:4},{value:"Computed value",paraId:16,tocIndex:4},{value:"'0'",paraId:14,tocIndex:4},{value:"-",paraId:14,tocIndex:4},{value:"no",paraId:14,tocIndex:4},{value:"yes",paraId:14,tocIndex:4},{value:"<percentage>",paraId:17,tocIndex:4},{value:" ",paraId:14,tocIndex:4},{value:"<length>",paraId:18,tocIndex:4},{value:"The y-axis coordinates of the center of the circle in the local coordinate system.",paraId:19,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/cy",paraId:20,tocIndex:5},{value:"Initial value",paraId:21,tocIndex:5},{value:"Applicable elements",paraId:22,tocIndex:5},{value:"Inheritable",paraId:23,tocIndex:5},{value:"Animatable",paraId:22,tocIndex:5},{value:"Computed value",paraId:24,tocIndex:5},{value:"'0'",paraId:22,tocIndex:5},{value:"-",paraId:22,tocIndex:5},{value:"no",paraId:22,tocIndex:5},{value:"yes",paraId:22,tocIndex:5},{value:"<percentage>",paraId:25,tocIndex:5},{value:" ",paraId:22,tocIndex:5},{value:"<length>",paraId:26,tocIndex:5},{value:"The radius of the circle.",paraId:27,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/r",paraId:28,tocIndex:6},{value:"Initial value",paraId:29,tocIndex:6},{value:"Applicable elements",paraId:30,tocIndex:6},{value:"Inheritable",paraId:31,tocIndex:6},{value:"Animatable",paraId:30,tocIndex:6},{value:"Computed value",paraId:32,tocIndex:6},{value:"'0'",paraId:30,tocIndex:6},{value:"-",paraId:30,tocIndex:6},{value:"no",paraId:30,tocIndex:6},{value:"yes",paraId:30,tocIndex:6},{value:"<percentage>",paraId:33,tocIndex:6},{value:" ",paraId:30,tocIndex:6},{value:"<length>",paraId:34,tocIndex:6}]},46683:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(47213);const n=[{value:"First, you need to clarify some concepts, such as bounding boxes, coordinates, anchor points, transform centers, etc. Understanding them helps to better use the specific API. Understanding them helps to better use the specific API.",paraId:0},{value:"In ",paraId:1,tocIndex:0},{value:"scene graph",paraId:2,tocIndex:0},{value:" we learned that it is possible to construct parent-child relationships between graphs, and that such parent-child relationships can sometimes be counter-intuitive, for example adding a child node text (",paraId:1,tocIndex:0},{value:"Text",paraId:3,tocIndex:0},{value:") to a line (",paraId:1,tocIndex:0},{value:"Line",paraId:4,tocIndex:0},{value:").",paraId:1,tocIndex:0},{value:"line.appendChild(text);\n",paraId:5,tocIndex:0},{value:"But essentially this hierarchy just defines a parent-child relationship that is taken into account when computing the transformation. For example, we don't need to move the line and the text separately anymore, based on this parent-child relationship, we can just move the line and the text will follow it. During the transformation, the position of the text relative to the line remains unchanged, i.e., the coordinates of the text in the local coordinate system of the parent line remain unchanged.",paraId:6,tocIndex:0},{value:"To simplify the calculation, we need to wrap the figure in a regular geometry, usually using [axis-aligned bounding boxes](",paraId:7,tocIndex:1},{value:"https://developer.mozilla.org/zh-CN/docs/Games/Techniques/3D_collision_detection#axis-",paraId:7,tocIndex:1},{value:" aligned_bounding_boxes%EF%BC%88aabb%E5%8C%85%E5%9B%B4%E7%9B%92%EF%BC%89) (Axis Aligned Bounding Box), which is a non-rotating cube, and the following figure from",paraId:7,tocIndex:1},{value:"https://developer.mozilla.org/zh-CN/docs/Games/Techniques/3D_collision_detection#axis-aligned_bounding_boxes%EF%BC%88aabb%E5%8C%85%E5%9B%B4%E7%9B%92%EF%BC%89",paraId:8,tocIndex:1},{value:"We use the following definitions.",paraId:9,tocIndex:1},{value:"interface AABB {\n    center: [number, number, number]; // 中心坐标\n    halfExtents: [number, number, number]; // 长宽高的一半\n    min: [number, number, number]; // 左上角坐标\n    max: [number, number, number]; // 右下角坐标\n}\n",paraId:10,tocIndex:1},{value:"AABB boxes have different meanings in different situations. Let's first look at what a wraparound box represents for a single figure. The figure below shows a circle with a radius of 100 and a border width of 20. For better illustration we have set the border to be translucent and it also has a shadow effect.",paraId:11,tocIndex:1},{value:"For the user, it is often desirable to use the geometric definition of the shape, e.g. the size of the circle is ",paraId:12,tocIndex:1},{value:"100 * 100",paraId:12,tocIndex:1},{value:", and we don't want the circle to be picked up even if the mouse slides over the shaded area.",paraId:12,tocIndex:1},{value:"And for rendering pipelines, these style properties obviously need to be taken into account, e.g.",paraId:13,tocIndex:1},{value:'Correctly erasing the drawn area in the dirty rectangle rendering will result in a poorly erased "shadow" once the increase in the size of the enclosing box due to the shadow is not taken into account',paraId:14,tocIndex:1},{value:"Culling plug-ins also needs to be considered, for example a drawing should not be rejected even if only the shaded part appears in the viewport",paraId:14,tocIndex:1},{value:"It is easy to define geometric enclosing boxes based on different types of graphs.",paraId:15,tocIndex:1},{value:"Geometry Bounds",paraId:16,tocIndex:1},{value:"。Determined only by the geometric definition of the figure, disregard most of the drawing properties(like radius of ",paraId:16,tocIndex:1},{value:"Circle",paraId:17,tocIndex:1},{value:" , width/height of ",paraId:16,tocIndex:1},{value:"Rect",paraId:18,tocIndex:1},{value:", path definition of ",paraId:16,tocIndex:1},{value:"Path",paraId:19,tocIndex:1},{value:") and transformation. We can use ",paraId:16,tocIndex:1},{value:"getGeometryBounds",paraId:20,tocIndex:1},{value:" to get them.",paraId:16,tocIndex:1},{value:"Once a node has child nodes, it should be considered in the calculation of the enclosing box. For example, if we want to rotate it as a whole, we need to find the center of the enclosing box as the center of rotation. Therefore, the following enclosing boxes are considered for the hierarchy.",paraId:21,tocIndex:1},{value:"Bounds",paraId:22,tocIndex:1},{value:"。It is calculated in the world coordinate system and obtained by merging the Geometry Bounds of itself and all its children. Users usually use this wrapping box most often. We can use ",paraId:22,tocIndex:1},{value:"getBounds",paraId:23,tocIndex:1},{value:" to get them.",paraId:22,tocIndex:1},{value:"Local Bounds",paraId:22,tocIndex:1},{value:"。The only difference with Bounds is that it is calculated in the local coordinate system of the parent node. We can use ",paraId:22,tocIndex:1},{value:"getLocalBounds",paraId:24,tocIndex:1},{value:" to get them.",paraId:22,tocIndex:1},{value:"Render Bounds",paraId:22,tocIndex:1},{value:"。Calculated in the world coordinate system, based on Bounds, influenced by some rendering properties, such as border width, shadows, some filters, etc., while merging the Render Bounds of all child nodes. We can use ",paraId:22,tocIndex:1},{value:"getRenderBounds",paraId:25,tocIndex:1},{value:" to get them.",paraId:22,tocIndex:1},{value:"In the figure below, ul1 has two word nodes, li1 and li2, which are not considered in the calculation of its own Geometry Bounds, but are needed in the calculation of Bounds. Since ul1 also has shadows, its Render Bounds are one turn larger.",paraId:26,tocIndex:1},{value:"How should the anchor point (origin) of a graph be defined? We can define it based on Geometry Bounds, with the value range ",paraId:27,tocIndex:2},{value:"[0, 0] ~ [1, 1]",paraId:27,tocIndex:2},{value:", where ",paraId:27,tocIndex:2},{value:"[0, 0]",paraId:27,tocIndex:2},{value:" represents the upper left corner of Geometry Bounds and ",paraId:27,tocIndex:2},{value:"[1, 1]",paraId:27,tocIndex:2},{value:" represents the lower right corner. And the default anchor points for different shapes due to different geometry definitions are as follows.",paraId:27,tocIndex:2},{value:"The center of ",paraId:28,tocIndex:2},{value:"Circle",paraId:29,tocIndex:2},{value:" and ",paraId:28,tocIndex:2},{value:"Ellipse",paraId:30,tocIndex:2},{value:" is ",paraId:28,tocIndex:2},{value:"[0.5, 0.5]",paraId:28,tocIndex:2},{value:"The top left corner of ",paraId:28,tocIndex:2},{value:"Rect",paraId:31,tocIndex:2},{value:", ",paraId:28,tocIndex:2},{value:"Image",paraId:32,tocIndex:2},{value:", ",paraId:28,tocIndex:2},{value:"Line",paraId:33,tocIndex:2},{value:", ",paraId:28,tocIndex:2},{value:"Polyline",paraId:34,tocIndex:2},{value:", ",paraId:28,tocIndex:2},{value:"Polygon",paraId:35,tocIndex:2},{value:" and ",paraId:28,tocIndex:2},{value:"Path",paraId:36,tocIndex:2},{value:" is ",paraId:28,tocIndex:2},{value:"[0, 0]",paraId:28,tocIndex:2},{value:".",paraId:28,tocIndex:2},{value:"We should always use ",paraId:28,tocIndex:2},{value:"textBaseline",paraId:37,tocIndex:2},{value:" and ",paraId:28,tocIndex:2},{value:"textAlign",paraId:38,tocIndex:2},{value:" to set the anchor of ",paraId:28,tocIndex:2},{value:"Text",paraId:39,tocIndex:2},{value:".",paraId:28,tocIndex:2},{value:"Since ",paraId:28,tocIndex:2},{value:"Group",paraId:40,tocIndex:2},{value:" has no geometry bounds, so its anchor is ",paraId:28,tocIndex:2},{value:"[0, 0]",paraId:28,tocIndex:2},{value:".",paraId:28,tocIndex:2},{value:"Sometimes we want to change the definition of the origin of a base graph, for example by defining the anchor of Rect as the center instead of the top left corner, ",paraId:41,tocIndex:2},{value:"example",paraId:42,tocIndex:2},{value:"：",paraId:41,tocIndex:2},{value:"rect.style.anchor = [0.5, 0.5];\n",paraId:43,tocIndex:2},{value:'Does that anchor point change affect the coordinates of the drawing in the local/world coordinate system? The answer is no. We just put the origin of the graph in these coordinates, and no matter how the definition of the origin is changed, the "location" coordinates remain unchanged.',paraId:44,tocIndex:2},{value:"rect.getPosition(); // [200, 200]\nrect.style.anchor = [0.5, 0.5];\nrect.getPosition(); // [200, 200]\n",paraId:45,tocIndex:2},{value:"When scaling or rotating a drawing, you need to specify a transformation center. For example, if you use ",paraId:46,tocIndex:3},{value:"scale(2)",paraId:46,tocIndex:3},{value:" as the center of a circle, you will get a completely different result than if you use the upper left corner of the Geometry Bounds of a circle as the center of the transformation. In a library like ",paraId:46,tocIndex:3},{value:"gl-matrix",paraId:46,tocIndex:3},{value:", the RTS transformation matrix is usually obtained by specifying the transformation center.",paraId:46,tocIndex:3},{value:"mat4.fromRotationTranslationScaleOrigin();\n",paraId:47,tocIndex:3},{value:"In some scenarios, it is easier to use some literal or percentage definitions. CSS, for example, provides the ",paraId:48,tocIndex:3},{value:"transform-origin",paraId:48,tocIndex:3},{value:" property, which is defined exactly relative to Bounds. The image below is from: ",paraId:48,tocIndex:3},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/transform-origin",paraId:48,tocIndex:3},{value:".",paraId:48,tocIndex:3},{value:'When we want to achieve "rotation around the center", we only need to use literal amounts or percentages, so that we can avoid having to do Bounds fetching.',paraId:49,tocIndex:3},{value:"group.style.transformOrigin = 'center';\ngroup.style.transformOrigin = 'center center';\ngroup.style.transformOrigin = '50% 50%';\n",paraId:50,tocIndex:3}]},11541:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(7968);const n=[{value:"DisplayObject is the base class of all graph like ",paraId:0},{value:"Group",paraId:1},{value:", ",paraId:0},{value:"Circle",paraId:2},{value:", ",paraId:0},{value:"Text",paraId:3},{value:" etc.",paraId:0},{value:"We tried to make it as compatible as possible with ",paraId:4},{value:"DOM Element",paraId:4},{value:", which in addition to reducing learning costs, allows us to take advantage of the existing Web ecosystem by disguising ourselves as a DOM Element, e.g.",paraId:4},{value:"Using CSS selectors for ",paraId:5},{value:"advanced queries",paraId:6},{value:".",paraId:5},{value:"Using Hammer.js for ",paraId:5},{value:"gesture",paraId:7},{value:"Using Interact.js for ",paraId:5},{value:"Drag'n'Drop and Resize",paraId:8},{value:"Taking over D3's rendering implementation",paraId:9},{value:"Taking over Observable Plot's rendering implementation",paraId:10},{value:"Element",paraId:11},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/id",paraId:12,tocIndex:1},{value:"Globally unique identifier, can be queried by [getElementById](/en/api/display-object#advanced query).",paraId:13,tocIndex:1},{value:"const circle = new Circle({\n    id: 'my-circle-id',\n    style: {\n        r: 10,\n    },\n});\ncircle.id; // 'my-circle-id'\ncanvas.getElementById('my-circle-id'); // circle\n",paraId:14,tocIndex:1},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Document/getElementsByName",paraId:15,tocIndex:2},{value:"Graph name, not required to be globally unique, can be queried by [getElementsByName](/en/api/display-object#advanced query).",paraId:16,tocIndex:2},{value:"const circle = new Circle({\n    name: 'my-circle-name',\n    style: {\n        r: 10,\n    },\n});\ncircle.name; // 'my-circle-name'\ncanvas.getElementsByName('my-circle-name'); // [circle]\n",paraId:17,tocIndex:2},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/className",paraId:18,tocIndex:3},{value:"The class name owned by the graphic, which can be used to get/set the class name of the graphic. It can be queried later using [getElementsByClassName](/en/api/display-object#advanced query).",paraId:19,tocIndex:3},{value:"const circle = new Circle({\n    className: 'my-circle-classname',\n    style: {\n        r: 10,\n    },\n});\ncircle.className; // 'my-circle-classname'\ncanvas.getElementsByClassName('my-circle-classname'); // [circle]\n",paraId:20,tocIndex:3},{value:"You can use spaces to separate multiple class names, and then use ",paraId:21,tocIndex:3},{value:"classList",paraId:22,tocIndex:3},{value:" read-only attribute to get a list of class names.",paraId:21,tocIndex:3},{value:"circle.className = 'c1 c2';\ncircle.classList; // ['c1', 'c2']\n",paraId:23,tocIndex:3},{value:"Not specifying a class name will return the empty string.",paraId:24,tocIndex:3},{value:"const group = new Group();\ngroup.className; // ''\n",paraId:25,tocIndex:3},{value:"Finally, you can also use ",paraId:26,tocIndex:3},{value:"class",paraId:26,tocIndex:3},{value:" as an alias when setting.",paraId:26,tocIndex:3},{value:"const group = new Group({\n    class: 'my-classname',\n    // className: 'my-classname'\n});\n\ngroup.setAttribute('class', 'my-classname');\n\n// wrong, class is the kept keywords\ngroup.class;\n",paraId:27,tocIndex:3},{value:"Whether to support responding to ",paraId:28,tocIndex:4},{value:"events",paraId:29,tocIndex:4},{value:", default is ",paraId:28,tocIndex:4},{value:"true",paraId:28,tocIndex:4},{value:". Can be turned off on some graphics that do not need to support interaction.",paraId:28,tocIndex:4},{value:"For example, we don't want the following circle to respond to the mouse ",paraId:30,tocIndex:4},{value:"mouseenter/leave",paraId:30,tocIndex:4},{value:" event, ",paraId:30,tocIndex:4},{value:"example",paraId:31,tocIndex:4},{value:"const circle = new Circle({\n    interactive: false,\n    style: {\n        r: 100,\n    },\n});\n\n// or\ncircle.interactive = false;\n",paraId:32,tocIndex:4},{value:"It is recommended to use the ",paraId:33,tocIndex:4},{value:"pointerEvents",paraId:34,tocIndex:4},{value:" attribute, so the above prohibited interactions are equivalent to",paraId:33,tocIndex:4},{value:"circle.style.pointerEvents = 'none';\n",paraId:35,tocIndex:4},{value:"The drawing properties are set by ",paraId:36,tocIndex:5},{value:"style",paraId:36,tocIndex:5},{value:" and usually contain ",paraId:36,tocIndex:5},{value:"generic properties",paraId:36,tocIndex:5},{value:" such as fill color, transparency, etc. Different types of shapes also have their own ",paraId:36,tocIndex:5},{value:"additional properties",paraId:36,tocIndex:5},{value:", for example, in the following rounded rectangle, the fill color ",paraId:36,tocIndex:5},{value:"fill",paraId:36,tocIndex:5},{value:" and stroke color ",paraId:36,tocIndex:5},{value:"stroke",paraId:36,tocIndex:5},{value:" are generic properties, while the top-left vertex position ",paraId:36,tocIndex:5},{value:"(x, y)",paraId:36,tocIndex:5},{value:", the size ",paraId:36,tocIndex:5},{value:"width/height",paraId:36,tocIndex:5},{value:" and the radius ",paraId:36,tocIndex:5},{value:"radius",paraId:36,tocIndex:5},{value:" of the rectangle are additional properties.",paraId:36,tocIndex:5},{value:"const rect = new Rect({\n    style: {\n        // or using attrs\n        x: 200,\n        y: 100,\n        fill: '#1890FF',\n        stroke: '#F04864',\n        lineWidth: 4,\n        width: 300,\n        height: 200,\n        radius: 8,\n    },\n});\n",paraId:37,tocIndex:5},{value:"Property names can also be hyphenated, so the following writeups are fully equivalent, see ",paraId:38,tocIndex:5},{value:"get/set property values",paraId:39,tocIndex:5},{value:" for full usage.",paraId:38,tocIndex:5},{value:"const rect = new Rect({\n    'line-width': 4,\n    // lineWidth: 4,\n});\n\nrect.style.lineWidth = 4;\nrect.style['line-width'] = 4;\nrect.style.setProperty('lineWidth', 4);\nrect.style.setProperty('line-width', 4);\n",paraId:40,tocIndex:5},{value:"The initial position of the drawing in the local coordinate system is described by different properties depending on the type of drawing, and can be reset later by ",paraId:41,tocIndex:6},{value:"setLocalPosition",paraId:42,tocIndex:6},{value:".",paraId:41,tocIndex:6},{value:"const circle = new Cirle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 100,\n    },\n});\ncircle.getLocalPosition(); // [0, 0]\n",paraId:43,tocIndex:6},{value:"We provide shortcuts for transformations in local coordinate systems, while keeping in line with ",paraId:44,tocIndex:7},{value:"CSS Transform",paraId:44,tocIndex:7},{value:", supporting the following ",paraId:44,tocIndex:7},{value:"transform-function transformations function",paraId:44,tocIndex:7},{value:".",paraId:44,tocIndex:7},{value:"Scaling\n",paraId:45,tocIndex:7},{value:"scale(x, y)",paraId:46,tocIndex:7},{value:"scaleX(x)",paraId:46,tocIndex:7},{value:"scaleY(x)",paraId:46,tocIndex:7},{value:"scaleZ(z)",paraId:46,tocIndex:7},{value:"scale3d(x, y, z)",paraId:46,tocIndex:7},{value:"Translation, 0 can be used without units, unitless is treated as px, the percentage is relative to the current graph bounding box\n",paraId:45,tocIndex:7},{value:"translate(0, 0) translate(0, 30px) translate(100%, 100%)",paraId:47,tocIndex:7},{value:"translateX(0)",paraId:47,tocIndex:7},{value:"translateY(0)",paraId:47,tocIndex:7},{value:"translateZ(0)",paraId:47,tocIndex:7},{value:"translate3d(0, 0, 0)",paraId:47,tocIndex:7},{value:"Rotation, support for deg rad turn, these angular units\n",paraId:45,tocIndex:7},{value:"rotate(0.5turn) rotate(30deg) rotate(1rad)",paraId:48,tocIndex:7},{value:"Stretch, support deg rad turn these angular units\n",paraId:45,tocIndex:7},{value:"skew(ax, ay)",paraId:49,tocIndex:7},{value:"skewX(a)",paraId:49,tocIndex:7},{value:"skewY(a)",paraId:49,tocIndex:7},{value:"Matrix\n",paraId:45,tocIndex:7},{value:"matrix()",paraId:50,tocIndex:7},{value:"matrix3d()",paraId:50,tocIndex:7},{value:"none",paraId:45,tocIndex:7},{value:"Initial value",paraId:51,tocIndex:7},{value:"Applicable elements",paraId:52,tocIndex:7},{value:"Inheritable",paraId:53,tocIndex:7},{value:"Animatable",paraId:52,tocIndex:7},{value:"Computed value",paraId:54,tocIndex:7},{value:"'none'",paraId:52,tocIndex:7},{value:"all",paraId:52,tocIndex:7},{value:"no",paraId:52,tocIndex:7},{value:"yes",paraId:52,tocIndex:7},{value:"<transform>",paraId:52,tocIndex:7},{value:"Since the transformation is performed in a local coordinate system, the following write-ups are visually consistent.",paraId:55,tocIndex:7},{value:"// Using transform\nconst circle = new Circle({\n    style: {\n        transform: 'translate(100px, 100px)',\n        r: 100,\n    },\n});\n\n// or set cx/cy directly\nconst circle = new Circle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 100,\n    },\n});\n\n// or using transform functions\nconst circle = new Circle({\n    style: {\n        r: 100,\n    },\n});\ncircle.translateLocal(100, 100);\n",paraId:56,tocIndex:7},{value:"Rotation and scaling centers, also called transform origin, are defined relative to Bounds.",paraId:57,tocIndex:8},{value:"Similar to CSS ",paraId:58,tocIndex:8},{value:"transform-origin",paraId:58,tocIndex:8},{value:", the following string writing is supported, separated by spaces.",paraId:58,tocIndex:8},{value:"One value\n",paraId:59,tocIndex:8},{value:"Length in px, e.g. 10px",paraId:60,tocIndex:8},{value:"Length in %, e.g. 50%",paraId:60,tocIndex:8},{value:"The keywords left, center, right, top, bottom are expressed as percentages, e.g. left equals 0%, center equals 50%.",paraId:60,tocIndex:8},{value:"Two values\n",paraId:59,tocIndex:8},{value:"The first is the length in px or %, or one of the left, center, or right keywords",paraId:61,tocIndex:8},{value:"The second is the length in px or %, or one of the top, center, or bottom keywords",paraId:61,tocIndex:8},{value:"Therefore the following write-ups are equivalent.",paraId:62,tocIndex:8},{value:"// r = 100\ncircle.style.transformOrigin = 'left';\ncircle.style.transformOrigin = 'left center'; // AABB horizontal left edge, vertical midpoint\ncircle.style.transformOrigin = '0 50%'; // The distance to the left edge of the AABB is 0 horizontally and 50% height from the top vertically\ncircle.style.transformOrigin = '0 100px'; // The distance to the left edge of the AABB is 0 horizontally and 100px vertically from the top\n",paraId:63,tocIndex:8},{value:"⚠️ Writing with three values is not supported at the moment.",paraId:64,tocIndex:8},{value:"Initial value",paraId:65,tocIndex:8},{value:"Applicable elements",paraId:66,tocIndex:8},{value:"Inheritable",paraId:67,tocIndex:8},{value:"Animatable",paraId:66,tocIndex:8},{value:"Computed value",paraId:68,tocIndex:8},{value:"-",paraId:66,tocIndex:8},{value:"all",paraId:66,tocIndex:8},{value:"no",paraId:66,tocIndex:8},{value:"no",paraId:66,tocIndex:8},{value:"<transform-origin>",paraId:66,tocIndex:8},{value:"The overall transparency of the graph, with values in the range ",paraId:69,tocIndex:10},{value:"[0, 1]",paraId:69,tocIndex:10},{value:", supports both ",paraId:69,tocIndex:10},{value:"number",paraId:69,tocIndex:10},{value:" and ",paraId:69,tocIndex:10},{value:"string",paraId:69,tocIndex:10},{value:" types, so the following two ways of writing it are equivalent.",paraId:69,tocIndex:10},{value:"circle.style.opacity = 0.5;\ncircle.style.opacity = '0.5';\n",paraId:70,tocIndex:10},{value:"Initial value",paraId:71,tocIndex:10},{value:"Applicable elements",paraId:72,tocIndex:10},{value:"Inheritable",paraId:73,tocIndex:10},{value:"Animatable",paraId:72,tocIndex:10},{value:"Computed value",paraId:74,tocIndex:10},{value:"'1'",paraId:72,tocIndex:10},{value:"all",paraId:72,tocIndex:10},{value:"no",paraId:72,tocIndex:10},{value:"yes",paraId:72,tocIndex:10},{value:"<number>",paraId:75,tocIndex:10},{value:"The fill color transparency, in the range ",paraId:76,tocIndex:11},{value:"[0, 1]",paraId:76,tocIndex:11},{value:", supports both ",paraId:76,tocIndex:11},{value:"number",paraId:76,tocIndex:11},{value:" and ",paraId:76,tocIndex:11},{value:"string",paraId:76,tocIndex:11},{value:" types, so the following two ways of writing are equivalent.",paraId:76,tocIndex:11},{value:"circle.style.fillOpacity = 0.5;\ncircle.style.fillOpacity = '0.5';\n",paraId:77,tocIndex:11},{value:"Initial value",paraId:78,tocIndex:11},{value:"Applicable elements",paraId:79,tocIndex:11},{value:"Inheritable",paraId:80,tocIndex:11},{value:"Animatable",paraId:79,tocIndex:11},{value:"Computed",paraId:81,tocIndex:11},{value:"'1'",paraId:79,tocIndex:11},{value:"all",paraId:79,tocIndex:11},{value:"yes",paraId:79,tocIndex:11},{value:"yes",paraId:79,tocIndex:11},{value:"<number>",paraId:82,tocIndex:11},{value:"Fill color, supports ",paraId:83,tocIndex:12},{value:"string",paraId:83,tocIndex:12},{value:" type, see ",paraId:83,tocIndex:12},{value:"<paint>",paraId:84,tocIndex:12},{value:"：",paraId:83,tocIndex:12},{value:"circle.style.fill = 'red';\ncircle.style.fill = 'rgb(255, 0, 0)';\n",paraId:85,tocIndex:12},{value:"Initial value",paraId:86,tocIndex:12},{value:"Applicable elements",paraId:87,tocIndex:12},{value:"Inheritable",paraId:88,tocIndex:12},{value:"Animatable",paraId:87,tocIndex:12},{value:"Computed value",paraId:89,tocIndex:12},{value:"'none'",paraId:87,tocIndex:12},{value:"all",paraId:87,tocIndex:12},{value:"no",paraId:87,tocIndex:12},{value:"yes",paraId:87,tocIndex:12},{value:"<paint>",paraId:90,tocIndex:12},{value:"This attribute is a presentation attribute defining the algorithm to use to determine the inside part of a shape.",paraId:91,tocIndex:13},{value:"'nonzero'",paraId:92,tocIndex:13},{value:" Default ",paraId:92,tocIndex:13},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/fill-rule#nonzero",paraId:92,tocIndex:13},{value:"'evenodd'",paraId:92,tocIndex:13},{value:" ",paraId:92,tocIndex:13},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/fill-rule#evenodd",paraId:92,tocIndex:13},{value:"This ",paraId:93,tocIndex:13},{value:"example",paraId:94,tocIndex:13},{value:" shows the fill effects of ",paraId:93,tocIndex:13},{value:"'nonzero'",paraId:93,tocIndex:13},{value:" and ",paraId:93,tocIndex:13},{value:"'evenodd'",paraId:93,tocIndex:13},{value:" in order.",paraId:93,tocIndex:13},{value:"Stroke transparency, which takes values in the range ",paraId:95,tocIndex:15},{value:"[0, 1]",paraId:95,tocIndex:15},{value:", supports both ",paraId:95,tocIndex:15},{value:"number",paraId:95,tocIndex:15},{value:" and ",paraId:95,tocIndex:15},{value:"string",paraId:95,tocIndex:15},{value:" types, so the following two ways of writing it are equivalent.",paraId:95,tocIndex:15},{value:"circle.style.strokeOpacity = 0.5;\ncircle.style.strokeOpacity = '0.5';\n",paraId:96,tocIndex:15},{value:"Initial value",paraId:97,tocIndex:15},{value:"Applicable elements",paraId:98,tocIndex:15},{value:"Inheritable",paraId:99,tocIndex:15},{value:"Animatable",paraId:98,tocIndex:15},{value:"Computed value",paraId:100,tocIndex:15},{value:"'1'",paraId:98,tocIndex:15},{value:"all",paraId:98,tocIndex:15},{value:"yes",paraId:98,tocIndex:15},{value:"yes",paraId:98,tocIndex:15},{value:"<number>",paraId:101,tocIndex:15},{value:"Stroke color, supports ",paraId:102,tocIndex:16},{value:"string",paraId:102,tocIndex:16},{value:" type, see ",paraId:102,tocIndex:16},{value:"<paint>",paraId:103,tocIndex:16},{value:"：",paraId:102,tocIndex:16},{value:"circle.style.stroke = 'red';\ncircle.style.stroke = 'rgb(255, 0, 0)';\n",paraId:104,tocIndex:16},{value:"Initial value",paraId:105,tocIndex:16},{value:"Applicable elements",paraId:106,tocIndex:16},{value:"Inheritable",paraId:107,tocIndex:16},{value:"Animatable",paraId:106,tocIndex:16},{value:"Computed value",paraId:108,tocIndex:16},{value:"'none'",paraId:106,tocIndex:16},{value:"all",paraId:106,tocIndex:16},{value:"no",paraId:106,tocIndex:16},{value:"yes",paraId:106,tocIndex:16},{value:"<paint>",paraId:109,tocIndex:16},{value:"The width of the stroke. Unlike the familiar ",paraId:110,tocIndex:17},{value:"CSS box model",paraId:110,tocIndex:17},{value:", half of the width of the border is inside the graphic and half is outside the graphic. For example, the width of the enclosing box for the circle below is: ",paraId:110,tocIndex:17},{value:"r + lineWidth / 2 = 110",paraId:110,tocIndex:17},{value:"supports ",paraId:111,tocIndex:17},{value:"number",paraId:111,tocIndex:17},{value:" and ",paraId:111,tocIndex:17},{value:"string",paraId:111,tocIndex:17},{value:" types, the former defaulting to length values in ",paraId:111,tocIndex:17},{value:"px",paraId:111,tocIndex:17},{value:", with the following writing equivalents.",paraId:111,tocIndex:17},{value:"circle.style.lineWidth = 1;\ncircle.style.lineWidth = '1';\ncircle.style.lineWidth = '1px';\n",paraId:112,tocIndex:17},{value:"Initial value",paraId:113,tocIndex:17},{value:"Applicable elements",paraId:114,tocIndex:17},{value:"Inheritable",paraId:115,tocIndex:17},{value:"Animatable",paraId:114,tocIndex:17},{value:"Computed value",paraId:116,tocIndex:17},{value:"'1'",paraId:114,tocIndex:17},{value:"all",paraId:114,tocIndex:17},{value:"yes",paraId:114,tocIndex:17},{value:"yes",paraId:114,tocIndex:17},{value:"<percentage>",paraId:117,tocIndex:17},{value:" ",paraId:114,tocIndex:17},{value:"<length>",paraId:118,tocIndex:17},{value:"Endpoint style, supporting the following values.",paraId:119,tocIndex:18},{value:"'butt' Default value. The end of the line segment ends in a square.",paraId:120,tocIndex:18},{value:"'round' The line segment ends in a circle.",paraId:120,tocIndex:18},{value:"'square' The line segment ends in a square, but adds a rectangular area with the same width as the line segment and half the height of the line segment's thickness.",paraId:120,tocIndex:18},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D/lineCap",paraId:121,tocIndex:18},{value:"Supporting the following values.",paraId:122,tocIndex:19},{value:"'miter' Default. An additional diamond-shaped area is formed by extending the outer edges of the connected sections so that they intersect at a point. The effect of this setting can be seen with the ",paraId:123,tocIndex:19},{value:"miterLimit",paraId:124,tocIndex:19},{value:" property.",paraId:123,tocIndex:19},{value:"'round' Draws the shape of the corner by filling an additional, circular sector with the center of the circle at the end of the connected section. The radius of the rounded corner is the width of the line segment.",paraId:123,tocIndex:19},{value:"'bevel' An additional triangular-base area is filled in at the end of the connected sections, each with its own separate rectangular corner.",paraId:123,tocIndex:19},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D/lineJoin",paraId:125,tocIndex:19},{value:"The default value for SVG and Canvas2D is different, the former is 4 and the latter is 10. We set ",paraId:126,tocIndex:20},{value:"Path",paraId:127,tocIndex:20},{value:" ",paraId:126,tocIndex:20},{value:"Polyline",paraId:128,tocIndex:20},{value:" ",paraId:126,tocIndex:20},{value:"Polygon",paraId:129,tocIndex:20},{value:" to 4 and the rest to 10. api/basic/polygon) These three graphs are set to 4, and the rest are set to 10.",paraId:126,tocIndex:20},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D/miterLimit",paraId:130,tocIndex:20},{value:"Use ",paraId:131,tocIndex:21},{value:"number[]",paraId:131,tocIndex:21},{value:" to describe the alternate line segments and spacing. Reference can be made to: ",paraId:131,tocIndex:21},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D/setLineDash",paraId:131,tocIndex:21},{value:"Currently only the form ",paraId:132,tocIndex:21},{value:"[dash, gap]",paraId:132,tocIndex:21},{value:" is supported, if there is only one element in the array, i.e. ",paraId:132,tocIndex:21},{value:"[dash]",paraId:132,tocIndex:21},{value:" is equivalent to ",paraId:132,tocIndex:21},{value:"[dash, dash]",paraId:132,tocIndex:21},{value:".",paraId:132,tocIndex:21},{value:"Applying animation to it can achieve ",paraId:133,tocIndex:21},{value:"handwriting animation effect",paraId:134,tocIndex:21},{value:".",paraId:133,tocIndex:21},{value:"Initial value",paraId:135,tocIndex:21},{value:"Applicable elements",paraId:136,tocIndex:21},{value:"Inheritable",paraId:137,tocIndex:21},{value:"Animatable",paraId:136,tocIndex:21},{value:"Computed value",paraId:138,tocIndex:21},{value:"-",paraId:136,tocIndex:21},{value:"all",paraId:136,tocIndex:21},{value:"yes",paraId:136,tocIndex:21},{value:"yes",paraId:136,tocIndex:21},{value:"Dashed line offset, type ",paraId:139,tocIndex:22},{value:"number",paraId:139,tocIndex:22},{value:", transform it to achieve ",paraId:139,tocIndex:22},{value:"marching ants animation",paraId:140,tocIndex:22},{value:"Initial value",paraId:141,tocIndex:22},{value:"Applicable elements",paraId:142,tocIndex:22},{value:"Inheritable",paraId:143,tocIndex:22},{value:"Animatable",paraId:142,tocIndex:22},{value:"Computed value",paraId:144,tocIndex:22},{value:"'0'",paraId:142,tocIndex:22},{value:"all",paraId:142,tocIndex:22},{value:"yes",paraId:142,tocIndex:22},{value:"yes",paraId:142,tocIndex:22},{value:"<percentage>",paraId:145,tocIndex:22},{value:" ",paraId:142,tocIndex:22},{value:"<length>",paraId:146,tocIndex:22},{value:"Add shadow effect at the bottom of the shape, support configuring shadow color, blur radius and horizontal/vertical offset distance. ",paraId:147,tocIndex:23},{value:"example",paraId:148,tocIndex:23},{value:".",paraId:147,tocIndex:23},{value:"Shadows do not affect the graph's ",paraId:149,tocIndex:23},{value:"Geometry Bounds",paraId:150,tocIndex:23},{value:", e.g. in the following figure, after adding a shadow to a circle with a radius of 100, the geometry wrapping box size remains the same.",paraId:149,tocIndex:23},{value:"circle.getBounds(); // { halfExtents: [100, 100] }\ncircle.style.shadowBlur = 20;\ncircle.getBounds(); // { halfExtents: [100, 100] }\n",paraId:151,tocIndex:23},{value:"Of course outer shadows increase the ",paraId:152,tocIndex:23},{value:"Render Bounds",paraId:153,tocIndex:23},{value:", inner shadows do not.",paraId:152,tocIndex:23},{value:"Finally, shadows can have a very big impact on rendering performance.",paraId:154,tocIndex:23},{value:"We currently support two kinds of shadow.",paraId:155,tocIndex:24},{value:"'outer'",paraId:156,tocIndex:24},{value:" Outer Shading, which is also the default value for this property. The shadow appears on the outside of the drawing fill or stroke.",paraId:156,tocIndex:24},{value:"'inner'",paraId:156,tocIndex:24},{value:" Internal shading. As the name implies the shadows are inside the graph, as shown in the figure below.",paraId:156,tocIndex:24},{value:"Shade color, supports ",paraId:157,tocIndex:25},{value:"string",paraId:157,tocIndex:25},{value:" type, for example ",paraId:157,tocIndex:25},{value:"'#1890FF'",paraId:157,tocIndex:25},{value:". Gradient or pattern writing is not supported.",paraId:157,tocIndex:25},{value:"Initial value",paraId:158,tocIndex:25},{value:"Applicable elements",paraId:159,tocIndex:25},{value:"Inheritable",paraId:160,tocIndex:25},{value:"Animatable",paraId:159,tocIndex:25},{value:"Computed value",paraId:161,tocIndex:25},{value:"-",paraId:159,tocIndex:25},{value:"all",paraId:159,tocIndex:25},{value:"no",paraId:159,tocIndex:25},{value:"yes",paraId:159,tocIndex:25},{value:"<color>",paraId:162,tocIndex:25},{value:"The blurring degree of the shading effect, ",paraId:163,tocIndex:26},{value:"number",paraId:163,tocIndex:26},{value:" type, negative numbers are not allowed. Larger means more blurred, 0 means no blurring effect.",paraId:163,tocIndex:26},{value:"Initial value",paraId:164,tocIndex:26},{value:"Applicable elements",paraId:165,tocIndex:26},{value:"Inheritable",paraId:166,tocIndex:26},{value:"Animatable",paraId:165,tocIndex:26},{value:"Computed value",paraId:167,tocIndex:26},{value:"-",paraId:165,tocIndex:26},{value:"all",paraId:165,tocIndex:26},{value:"no",paraId:165,tocIndex:26},{value:"yes",paraId:165,tocIndex:26},{value:"<number>",paraId:168,tocIndex:26},{value:"Horizontal offset, supports ",paraId:169,tocIndex:27},{value:"number",paraId:169,tocIndex:27},{value:" or ",paraId:169,tocIndex:27},{value:"string",paraId:169,tocIndex:27},{value:" types, e.g. negative numbers move shadows to the left, positive numbers to the right.",paraId:169,tocIndex:27},{value:"Initial value",paraId:170,tocIndex:27},{value:"Applicable elements",paraId:171,tocIndex:27},{value:"Inheritable",paraId:172,tocIndex:27},{value:"Animatable",paraId:171,tocIndex:27},{value:"Computed value",paraId:173,tocIndex:27},{value:"-",paraId:171,tocIndex:27},{value:"all",paraId:171,tocIndex:27},{value:"no",paraId:171,tocIndex:27},{value:"yes",paraId:171,tocIndex:27},{value:"<percentage>",paraId:174,tocIndex:27},{value:" ",paraId:171,tocIndex:27},{value:"<length>",paraId:175,tocIndex:27},{value:"Vertical offset, e.g. a negative number moves the shadow up, a positive number down.",paraId:176,tocIndex:28},{value:"Initial value",paraId:177,tocIndex:28},{value:"Applicable elements",paraId:178,tocIndex:28},{value:"Inheritable",paraId:179,tocIndex:28},{value:"Animatable",paraId:178,tocIndex:28},{value:"Computed value",paraId:180,tocIndex:28},{value:"-",paraId:178,tocIndex:28},{value:"all",paraId:178,tocIndex:28},{value:"no",paraId:178,tocIndex:28},{value:"yes",paraId:178,tocIndex:28},{value:"<percentage>",paraId:181,tocIndex:28},{value:" ",paraId:178,tocIndex:28},{value:"<length>",paraId:182,tocIndex:28},{value:"Filters can perform some processing on the generated image, such as blurring, highlighting, boosting contrast, etc. The following implementations are available on the web side.",paraId:183,tocIndex:29},{value:"CSS Filter: ",paraId:184,tocIndex:29},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/filter",paraId:184,tocIndex:29},{value:"Canvas Filter: ",paraId:184,tocIndex:29},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D/filter",paraId:184,tocIndex:29},{value:"SVG Filter: ",paraId:184,tocIndex:29},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Element/filter",paraId:184,tocIndex:29},{value:"Post Processing in WebGL.",paraId:184,tocIndex:29},{value:"Referring to the CSS Filter syntax, we support applying one or more filter effects to a shape, ",paraId:185,tocIndex:29},{value:"example",paraId:186,tocIndex:29},{value:".",paraId:185,tocIndex:29},{value:"circle.style.filter = 'blur(5px)';\ncircle.style.filter = 'blur(5px) brightness(0.4)'; // Stackable\n",paraId:187,tocIndex:29},{value:"Filters can currently be used in the g-canvas/svg/webgl renderer with the following caveats.",paraId:188,tocIndex:29},{value:"Due to poor Canvas Filter support, mainly ",paraId:189,tocIndex:29},{value:"Safari does not support",paraId:189,tocIndex:29},{value:", filters are not displayed properly in Safari using g-canvas",paraId:189,tocIndex:29},{value:"g-canvas and g-svg differ slightly in some filter effects",paraId:189,tocIndex:29},{value:"Can be applied to all base graphs and Groups",paraId:189,tocIndex:29},{value:"This property does not support animation at this time",paraId:189,tocIndex:29},{value:"Applies a Gaussian blur to the input image. where radius defines the standard deviation value of the Gaussian function, or how many pixels on the screen blend into each other so that larger values will produce more blur, with a default value of 0. This parameter can be specified as a CSS length, but does not accept percentage values.",paraId:190,tocIndex:30},{value:"As with shadows, blurring also does not affect the size of the geometry bounds for graphics.",paraId:191,tocIndex:30},{value:"circle.style.filter = 'blur(5px)';\n",paraId:192,tocIndex:30},{value:"The following figure shows the blurring effect of 2px 4px and 10px in order, ",paraId:193,tocIndex:30},{value:"example",paraId:194,tocIndex:30},{value:".",paraId:193,tocIndex:30},{value:"Applies a linear multiplier to the input image to make it lighter or darker, with a default value of 1. A value of 0% will create an all-black image. A value of 100% will leave the input unchanged. Other values are linear multipliers of the effect. Values greater than 100% provide brighter results.",paraId:195,tocIndex:31},{value:"circle.style.filter = 'brightness(2)';\ncircle.style.filter = 'brightness(200%)';\n",paraId:196,tocIndex:31},{value:"The following figure shows the bright effects of 0 100% and 200% in order, ",paraId:197,tocIndex:31},{value:"example",paraId:198,tocIndex:31},{value:".",paraId:197,tocIndex:31},{value:"To display the shadows under the image, you can set the shadow color, offset and blur effect by passing in the following parameters in order.",paraId:199,tocIndex:32},{value:"offset-x Describes the horizontal offset distance of the shadow in px",paraId:200,tocIndex:32},{value:"offset-y Describes the vertical offset distance of the shadow in px",paraId:200,tocIndex:32},{value:"blur-radius The larger the value, the more ambiguous it is, in px, no negative numbers allowed",paraId:200,tocIndex:32},{value:"color",paraId:200,tocIndex:32},{value:"The shading does not affect the size of the geometry bounding box of the graph.",paraId:201,tocIndex:32},{value:"circle.style.filter = 'drop-shadow(16px 16px 10px black)';\n",paraId:202,tocIndex:32},{value:"The following figure shows the effect of the above configuration in turn, ",paraId:203,tocIndex:32},{value:"example",paraId:204,tocIndex:32},{value:".",paraId:203,tocIndex:32},{value:"Adjusts the contrast of the image. When the value is 0%, the image becomes completely black. When the value is 100%, the image does not change at all.",paraId:205,tocIndex:33},{value:"circle.style.filter = 'contrast(2)';\ncircle.style.filter = 'contrast(200%)';\n",paraId:206,tocIndex:33},{value:"The following figure shows the contrast effect of 0, 1 and 10 in order，",paraId:207,tocIndex:33},{value:"example",paraId:208,tocIndex:33},{value:".",paraId:207,tocIndex:33},{value:"Converts the image to a gray picture. When the value is 100%, the image turns completely gray. When the value is 0%, the image does not change at all.",paraId:209,tocIndex:34},{value:"circle.style.filter = 'grayscale(1)';\ncircle.style.filter = 'grayscale(100%)';\n",paraId:210,tocIndex:34},{value:"The following figure shows the grayscale effect of 0 50% and 100% in order, ",paraId:211,tocIndex:34},{value:"example",paraId:212,tocIndex:34},{value:".",paraId:211,tocIndex:34},{value:"Saturation is applied to the image. When the value is 0%, the image is not saturated at all. When the value is 100%, there is no change in the image.",paraId:213,tocIndex:35},{value:"circle.style.filter = 'saturate(1)';\ncircle.style.filter = 'saturate(100%)';\n",paraId:214,tocIndex:35},{value:"The following figure shows the saturation effect at 0 50% and 100% in order, ",paraId:215,tocIndex:35},{value:"example",paraId:216,tocIndex:35},{value:".",paraId:215,tocIndex:35},{value:"Applies sepia processing to the image (nostalgic style). When the value is 100%, the image becomes completely sepia. When the value is 0%, the image does not change at all.",paraId:217,tocIndex:36},{value:"circle.style.filter = 'sepia(1)';\ncircle.style.filter = 'sepia(100%)';\n",paraId:218,tocIndex:36},{value:"The following figure shows the results of 0 50% and 100% processing in order, ",paraId:219,tocIndex:36},{value:"example",paraId:220,tocIndex:36},{value:".",paraId:219,tocIndex:36},{value:"Applying hue rotation to the input image sets the value of the color ring angle at which the image will be adjusted. The image does not change when the value is 0deg.",paraId:221,tocIndex:37},{value:"circle.style.filter = 'hue-rotate(30deg)';\ncircle.style.filter = 'hue-rotate(180deg)';\n",paraId:222,tocIndex:37},{value:"The following figure shows the effect of 0, 90deg and 180deg processing in turn, ",paraId:223,tocIndex:37},{value:"example",paraId:224,tocIndex:37},{value:".",paraId:223,tocIndex:37},{value:"Inverts the color of the input image. amount defines the percentage of conversion, 100% means complete inversion, 0% means no change in the image.",paraId:225,tocIndex:38},{value:"circle.style.filter = 'invert(1)';\ncircle.style.filter = 'invert(100%)';\n",paraId:226,tocIndex:38},{value:"The following figure shows in turn the effect of 0, 50% and 100% inversions, ",paraId:227,tocIndex:38},{value:"example",paraId:228,tocIndex:38},{value:".",paraId:227,tocIndex:38},{value:"Similar to CSS's ",paraId:229,tocIndex:39},{value:"z-index",paraId:229,tocIndex:39},{value:" property, used to control the rendering order, it needs to be noted that",paraId:229,tocIndex:39},{value:"Only affects the rendering order, and does not change the node structure in the scene graph.",paraId:230,tocIndex:39},{value:"Effective only in the current context.",paraId:230,tocIndex:39},{value:"The default display order is the order in which the scenes are added, with those added later on top of the previously added elements.",paraId:230,tocIndex:39},{value:"Initial value",paraId:231,tocIndex:39},{value:"Applicable elements",paraId:232,tocIndex:39},{value:"Inheritable",paraId:233,tocIndex:39},{value:"Animatable",paraId:232,tocIndex:39},{value:"Computed value",paraId:234,tocIndex:39},{value:"'0'",paraId:232,tocIndex:39},{value:"all",paraId:232,tocIndex:39},{value:"no",paraId:232,tocIndex:39},{value:"no",paraId:232,tocIndex:39},{value:"<number>",paraId:235,tocIndex:39},{value:"For example, in the scene below, li2 is displayed on top of li1 by default because li2 was added to the canvas after li1. If you want to change this display order, you can modify the zIndex of li1:",paraId:236,tocIndex:39},{value:"// ul1 -> li1\n//     -> li2\n// ul2 -> li3\n\nli1.style.zIndex = 1; // li1 在 li2 之上\n",paraId:237,tocIndex:39},{value:"For example, even though li2 has a much larger zIndex than ul2, it can only be under ul2 because ul1 is smaller than ul2, ",paraId:238,tocIndex:39},{value:"example",paraId:239,tocIndex:39},{value:"For compatibility with older versions, we also provide the following methods:",paraId:240,tocIndex:39},{value:"name",paraId:241,tocIndex:39},{value:"parameters",paraId:241,tocIndex:39},{value:"return value",paraId:241,tocIndex:39},{value:"remarks",paraId:241,tocIndex:39},{value:"setZIndex",paraId:241,tocIndex:39},{value:"number",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"toFront",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"toBack",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"-",paraId:241,tocIndex:39},{value:"const group = new Group();\n\ngroup.setZIndex(100);\n// or group.setAttribute('zIndex', 100);\n// or group.style.zIndex = 100;\n",paraId:242,tocIndex:39},{value:"To control the visibility of the graph, see. ",paraId:243,tocIndex:40},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/visibility",paraId:243,tocIndex:40},{value:"For compatibility with older versions, the following methods are also provided.",paraId:244,tocIndex:40},{value:"name",paraId:245,tocIndex:40},{value:"parameters",paraId:245,tocIndex:40},{value:"return value",paraId:245,tocIndex:40},{value:"remarks",paraId:245,tocIndex:40},{value:"hide",paraId:245,tocIndex:40},{value:"-",paraId:245,tocIndex:40},{value:"-",paraId:245,tocIndex:40},{value:"-",paraId:245,tocIndex:40},{value:"show",paraId:245,tocIndex:40},{value:"-",paraId:245,tocIndex:40},{value:"-",paraId:245,tocIndex:40},{value:"-",paraId:245,tocIndex:40},{value:"Therefore the following write-ups are equivalent.",paraId:246,tocIndex:40},{value:"const group = new Group();\n\ngroup.style.visibility = 'hidden';\n// or group.setAttribute('visibility', 'hidden');\n// or group.hide();\n\ngroup.style.visibility = 'visible';\n// or group.setAttribute('visibility', 'visible');\n// or group.show();\n",paraId:247,tocIndex:40},{value:"Initial value",paraId:248,tocIndex:40},{value:"Applicable elements",paraId:249,tocIndex:40},{value:"Inheritable",paraId:250,tocIndex:40},{value:"Animatable",paraId:249,tocIndex:40},{value:"Computed value",paraId:251,tocIndex:40},{value:"'visible'",paraId:249,tocIndex:40},{value:"all",paraId:249,tocIndex:40},{value:"yes",paraId:249,tocIndex:40},{value:"no",paraId:249,tocIndex:40},{value:"<keywords>",paraId:252,tocIndex:40},{value:"There are two points to note about visibility.",paraId:253,tocIndex:40},{value:"Hidden graphics can still be picked up, so use ",paraId:254,tocIndex:40},{value:"pointerEvents",paraId:255,tocIndex:40},{value:"Hidden elements still need to participate in enclosing box operations, i.e. they still occupy space. If you want to remove the element completely, you should use ",paraId:254,tocIndex:40},{value:"removeChild",paraId:256,tocIndex:40},{value:"Use clipping to create a displayable region of an element, with the parts inside the region shown and the parts outside the region hidden. See CSS's ",paraId:257,tocIndex:41},{value:"clip-path",paraId:257,tocIndex:41},{value:". The value of this property can be any shape, such as Circle, Rect, etc. The same clipping region can be shared by multiple shapes. Finally, the crop region also affects the pickup area of the shapes, ",paraId:257,tocIndex:41},{value:"example",paraId:258,tocIndex:41},{value:".",paraId:257,tocIndex:41},{value:"For example, if we want to create a picture that is cropped into a circle, so that the cropping area is just in the center of the picture (size 200 * 200), we can set the world coordinates of the circle in the cropping area to ",paraId:259,tocIndex:41},{value:"[100, 100]",paraId:259,tocIndex:41},{value:". ",paraId:259,tocIndex:41},{value:"example",paraId:260,tocIndex:41},{value:".",paraId:259,tocIndex:41},{value:"const image = new Image({\n    style: {\n        x: 0,\n        y: 0,\n        width: 200,\n        height: 200,\n        clipPath: new Circle({\n            style: {\n                cx: 100,\n                cy: 100,\n                r: 50,\n            },\n        }),\n    },\n});\n",paraId:261,tocIndex:41},{value:"It is also possible to set the cropping area after creating the drawing, so the above writeup is equivalent to:",paraId:262,tocIndex:41},{value:"const image = new Image({\n    style: {\n        //...\n    },\n});\n\nimage.style.clipPath = new Circle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 50,\n    },\n});\n// or\nimage.setClip(\n    new Circle({\n        style: {\n            cx: 100,\n            cy: 100,\n            r: 50,\n        },\n    }),\n);\n",paraId:263,tocIndex:41},{value:"When we want to clear the cropping area, we can set it to ",paraId:264,tocIndex:41},{value:"null",paraId:264,tocIndex:41},{value:".",paraId:264,tocIndex:41},{value:"image.style.clipPath = null;\n// or\nimage.setClip(null);\n",paraId:265,tocIndex:41},{value:"The crop area graphic itself is also supported to modify the property, and affected by it, the cropped graphic will be redrawn immediately. For example, with ",paraId:266,tocIndex:42},{value:"animation system",paraId:267,tocIndex:42},{value:" we can transform the cropped area graphic to achieve the following effect, ",paraId:266,tocIndex:42},{value:"example",paraId:268,tocIndex:42},{value:".",paraId:266,tocIndex:42},{value:"// Apply animation to clipped areas\nclipPathCircle.animate(\n    [{ transform: 'scale(1)' }, { transform: 'scale(1.2)' }],\n    {\n        duration: 1500,\n        iterations: Infinity,\n    },\n);\n",paraId:269,tocIndex:42},{value:"We do not yet support composite clipped areas, such as custom graphics and Group.",paraId:270,tocIndex:42},{value:"In ",paraId:271,tocIndex:43},{value:"path-animation",paraId:272,tocIndex:43},{value:", we can use ",paraId:271,tocIndex:43},{value:"offsetPath",paraId:271,tocIndex:43},{value:" to specify the trajectory of a drawing, applying a transformation to the ",paraId:271,tocIndex:43},{value:"offsetDistance",paraId:271,tocIndex:43},{value:" property.",paraId:271,tocIndex:43},{value:"const circle = new Circle({\n    style: {\n        offsetPath: new Line({\n            style: {\n                // There is no need to set other drawing properties that are not related to trajectories\n                x1: 100,\n                y1: 100,\n                x2: 300,\n                y2: 100,\n            },\n        }),\n        r: 10,\n    },\n});\n\nconst animation = circle.animate(\n    [{ offsetDistance: 0 }, { offsetDistance: 1 }],\n    {\n        duration: 3000,\n        easing: 'ease-in-out',\n        iterations: Infinity,\n    },\n);\n",paraId:273,tocIndex:43},{value:"Specify path trajectory, currently support ",paraId:274,tocIndex:44},{value:"Line",paraId:275,tocIndex:44},{value:" ",paraId:274,tocIndex:44},{value:"Path",paraId:276,tocIndex:44},{value:" and ",paraId:274,tocIndex:44},{value:"Polyline",paraId:277,tocIndex:44},{value:" these three graphics.",paraId:274,tocIndex:44},{value:"The distance to travel from the start of the path, in the range of ",paraId:278,tocIndex:45},{value:"[0-1]",paraId:278,tocIndex:45},{value:", where 0 is the start of the path and 1 is the end.",paraId:278,tocIndex:45},{value:"Initial value",paraId:279,tocIndex:45},{value:"Applicable elements",paraId:280,tocIndex:45},{value:"Inheritable",paraId:281,tocIndex:45},{value:"Animatable",paraId:280,tocIndex:45},{value:"Computed value",paraId:282,tocIndex:45},{value:"'0'",paraId:280,tocIndex:45},{value:"all",paraId:280,tocIndex:45},{value:"no",paraId:280,tocIndex:45},{value:"yes",paraId:280,tocIndex:45},{value:"<number>",paraId:283,tocIndex:45},{value:"We can change the style of a graphic when the mouse hovers over it, by modifying the CSS style of the container.",paraId:284,tocIndex:46},{value:"The values supported by the ",paraId:285,tocIndex:46},{value:"cursor",paraId:285,tocIndex:46},{value:" property can be found at ",paraId:285,tocIndex:46},{value:"https://developer.mozilla.org/zh-CN/docs/Web/CSS/cursor",paraId:285,tocIndex:46},{value:"const circle = new Circle({\n    style: {\n        //...\n        cursor: 'pointer',\n    },\n});\n",paraId:286,tocIndex:46},{value:"We can set how the graph responds to interaction events, such as displaying the mouse style when hitting a pickup, or increasing the pickup area.",paraId:287,tocIndex:47},{value:"To set how the graph responds to interaction events, see. ",paraId:288,tocIndex:48},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/pointer-events",paraId:288,tocIndex:48},{value:"简而言之，",paraId:289,tocIndex:48},{value:"fill",paraId:290,tocIndex:48},{value:" ",paraId:289,tocIndex:48},{value:"stroke",paraId:291,tocIndex:48},{value:" 和 ",paraId:289,tocIndex:48},{value:"visibility",paraId:292,tocIndex:48},{value:" 都可以独立或组合影响拾取判定行为。目前支持以下关键词：",paraId:289,tocIndex:48},{value:"'auto'",paraId:293,tocIndex:48},{value:" Default value, equivalent to ",paraId:293,tocIndex:48},{value:"'visiblepainted'",paraId:293,tocIndex:48},{value:".",paraId:293,tocIndex:48},{value:"'none'",paraId:293,tocIndex:48},{value:" Will never be the target of a response event.",paraId:293,tocIndex:48},{value:"'visiblepainted'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"visibility",paraId:294,tocIndex:48},{value:" takes ",paraId:295,tocIndex:48},{value:"'visible'",paraId:295,tocIndex:48},{value:" which means the graph is visible.",paraId:295,tocIndex:48},{value:"Trigger while ",paraId:295,tocIndex:48},{value:"fill",paraId:296,tocIndex:48},{value:" takes a value other than ",paraId:295,tocIndex:48},{value:"'none'",paraId:295,tocIndex:48},{value:" in the graphics fill area. Or ",paraId:295,tocIndex:48},{value:"stroke",paraId:297,tocIndex:48},{value:" takes a value other than ",paraId:295,tocIndex:48},{value:"'none'",paraId:295,tocIndex:48},{value:" when triggered in the drawing stroke area.",paraId:295,tocIndex:48},{value:"'visiblefill'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"visibility",paraId:298,tocIndex:48},{value:" takes ",paraId:299,tocIndex:48},{value:"'visible'",paraId:299,tocIndex:48},{value:" which means the graph is visible an not affected by the value of ",paraId:299,tocIndex:48},{value:"fill",paraId:300,tocIndex:48},{value:".",paraId:299,tocIndex:48},{value:"'visiblestroke'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"visibility",paraId:301,tocIndex:48},{value:" takes ",paraId:302,tocIndex:48},{value:"'visible'",paraId:302,tocIndex:48},{value:" which means the graph is visible an not affected by the value of ",paraId:302,tocIndex:48},{value:"stroke",paraId:303,tocIndex:48},{value:".",paraId:302,tocIndex:48},{value:"'visible'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"visibility",paraId:304,tocIndex:48},{value:" takes ",paraId:305,tocIndex:48},{value:"'visible'",paraId:305,tocIndex:48},{value:".",paraId:305,tocIndex:48},{value:"Triggered in drawing fill or stroke area, not affected by ",paraId:305,tocIndex:48},{value:"fill",paraId:306,tocIndex:48},{value:" and ",paraId:305,tocIndex:48},{value:"stroke",paraId:307,tocIndex:48},{value:" values.",paraId:305,tocIndex:48},{value:"'painted'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"Trigger while ",paraId:308,tocIndex:48},{value:"fill",paraId:309,tocIndex:48},{value:" takes a value other than ",paraId:308,tocIndex:48},{value:"'none'",paraId:308,tocIndex:48},{value:" in the graphics fill area. Or ",paraId:308,tocIndex:48},{value:"stroke",paraId:310,tocIndex:48},{value:" takes a value other than ",paraId:308,tocIndex:48},{value:"'none'",paraId:308,tocIndex:48},{value:" when the drawing stroke area is triggered. Not affected by the value of ",paraId:308,tocIndex:48},{value:"visibility",paraId:311,tocIndex:48},{value:".",paraId:308,tocIndex:48},{value:"'fill'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"Triggered in graphics fill area, not affected by ",paraId:312,tocIndex:48},{value:"fill",paraId:313,tocIndex:48},{value:" and ",paraId:312,tocIndex:48},{value:"visibility",paraId:314,tocIndex:48},{value:" values.",paraId:312,tocIndex:48},{value:"'stroke'",paraId:293,tocIndex:48},{value:" The following conditions are met before the event is responded to.\n",paraId:293,tocIndex:48},{value:"Triggered in graphics fill area, not affected by ",paraId:315,tocIndex:48},{value:"stroke",paraId:316,tocIndex:48},{value:" and ",paraId:315,tocIndex:48},{value:"visibility",paraId:317,tocIndex:48},{value:" values.",paraId:315,tocIndex:48},{value:"'all'",paraId:293,tocIndex:48},{value:" The events are responded to whenever the fill and stroke areas of the drawing are entered. So it will not be affected by ",paraId:293,tocIndex:48},{value:"fill",paraId:318,tocIndex:48},{value:" ",paraId:293,tocIndex:48},{value:"stroke",paraId:319,tocIndex:48},{value:" [visibility](/en/api/ basic/display-object#visibility) is affected by the value of",paraId:293,tocIndex:48},{value:"In this ",paraId:320,tocIndex:48},{value:"example",paraId:321,tocIndex:48},{value:", we set the property to ",paraId:320,tocIndex:48},{value:"stroke",paraId:320,tocIndex:48},{value:", so the filled area will not respond to events.",paraId:320,tocIndex:48},{value:"In this ",paraId:322,tocIndex:48},{value:"example",paraId:323,tocIndex:48},{value:", we can easily control the interactivity based on the inheritance mechanism.",paraId:322,tocIndex:48},{value:"// The entire canvas does not respond to interaction events\ncanvas.document.documentElement.style.pointerEvents = 'none';\n",paraId:324,tocIndex:48},{value:"Initial value",paraId:325,tocIndex:48},{value:"Applicable elements",paraId:326,tocIndex:48},{value:"Inheritable",paraId:327,tocIndex:48},{value:"Animatable",paraId:326,tocIndex:48},{value:"Computed value",paraId:328,tocIndex:48},{value:"'auto'",paraId:326,tocIndex:48},{value:"all",paraId:326,tocIndex:48},{value:"yes",paraId:326,tocIndex:48},{value:"no",paraId:326,tocIndex:48},{value:"<keywords>",paraId:329,tocIndex:48},{value:"When ",paraId:330,tocIndex:49},{value:"lineWidth",paraId:331,tocIndex:49},{value:' is small, the interactable area becomes smaller, sometimes we want to increase this area to make the "thin line" easier to be picked up. Note that this property does not affect the rendering effect.',paraId:330,tocIndex:49},{value:"In the ",paraId:332,tocIndex:49},{value:"example",paraId:333,tocIndex:49},{value:" below, we set this property to ",paraId:332,tocIndex:49},{value:"50",paraId:332,tocIndex:49},{value:", so that the line width is equal to ",paraId:332,tocIndex:49},{value:"50 + the original line width",paraId:332,tocIndex:49},{value:" when picking up, making it easier to pick up when close:",paraId:332,tocIndex:49},{value:"\n ",paraId:334},{value:"line.style.increasedLineWidthForHitTesting = 50;\n",paraId:335,tocIndex:49},{value:"Also like ",paraId:336,tocIndex:49},{value:"lineWidth",paraId:337,tocIndex:49},{value:", this property also extends to the sides, and in the image below the unfilled ",paraId:336,tocIndex:49},{value:"Path",paraId:338,tocIndex:49},{value:" internal pickup area has been enlarged.",paraId:336,tocIndex:49},{value:"Initial value",paraId:339,tocIndex:49},{value:"Applicable elements",paraId:340,tocIndex:49},{value:"Inheritable",paraId:341,tocIndex:49},{value:"Animatable",paraId:340,tocIndex:49},{value:"Computed value",paraId:342,tocIndex:49},{value:"'0'",paraId:340,tocIndex:49},{value:"all",paraId:340,tocIndex:49},{value:"no",paraId:340,tocIndex:49},{value:"no",paraId:340,tocIndex:49},{value:"<percentage>",paraId:343,tocIndex:49},{value:" ",paraId:340,tocIndex:49},{value:"<length>",paraId:344,tocIndex:49},{value:"We offer a range of transformation methods.",paraId:345,tocIndex:50},{value:"For translation operations, we provide APIs for moving absolute/relative distances in local/world coordinate systems.",paraId:346,tocIndex:51},{value:"method name",paraId:347,tocIndex:51},{value:"parameters",paraId:347,tocIndex:51},{value:"return value",paraId:347,tocIndex:51},{value:"remarks",paraId:347,tocIndex:51},{value:"translate",paraId:347,tocIndex:51},{value:"[number, number]",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number, number",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number",paraId:347,tocIndex:51},{value:"-",paraId:347,tocIndex:51},{value:"Move relative to current position in ",paraId:347,tocIndex:51},{value:"world coordinate system",paraId:347,tocIndex:51},{value:"translateLocal",paraId:347,tocIndex:51},{value:"[number, number]",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number, number",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number",paraId:347,tocIndex:51},{value:"-",paraId:347,tocIndex:51},{value:"Move relative to current position in ",paraId:347,tocIndex:51},{value:"local coordinate system",paraId:347,tocIndex:51},{value:"setPosition",paraId:347,tocIndex:51},{value:"[number, number]",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number, number",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number",paraId:347,tocIndex:51},{value:"-",paraId:347,tocIndex:51},{value:"Sets the position in the ",paraId:347,tocIndex:51},{value:"world coordinate system",paraId:347,tocIndex:51},{value:".",paraId:347,tocIndex:51},{value:"setLocalPosition",paraId:347,tocIndex:51},{value:"[number, number]",paraId:347,tocIndex:51},{value:" or ",paraId:347,tocIndex:51},{value:"number, number",paraId:347,tocIndex:51},{value:"or ",paraId:347,tocIndex:51},{value:"number",paraId:347,tocIndex:51},{value:"-",paraId:347,tocIndex:51},{value:"Set the position under the ",paraId:347,tocIndex:51},{value:"local coordinate system",paraId:347,tocIndex:51},{value:"getPosition",paraId:347,tocIndex:51},{value:"-",paraId:347,tocIndex:51},{value:"[number, number]",paraId:347,tocIndex:51},{value:"Get the position in the ",paraId:347,tocIndex:51},{value:"world coordinate system",paraId:347,tocIndex:51},{value:"getLocalPosition",paraId:347,tocIndex:51},{value:"-",paraId:347,tocIndex:51},{value:"[number, number]",paraId:347,tocIndex:51},{value:"Get the position in the ",paraId:347,tocIndex:51},{value:"local coordinate system",paraId:347,tocIndex:51},{value:"translate/translateLocal/setPosition/setLocalPosition",paraId:348,tocIndex:51},{value:" supports the following input forms, where if you want to modify only the X-axis direction, you can pass only one number.",paraId:348,tocIndex:51},{value:"circle.translate([100, 0]); // [number, number]\ncircle.translate(100, 0); // number, number\ncircle.translate(100); // number\n",paraId:349,tocIndex:51},{value:"Unlike panning, we can't provide a method like ",paraId:350,tocIndex:52},{value:"setScale",paraId:350,tocIndex:52},{value:" to set scaling in the world coordinate system, so scaling in the global coordinate system is read-only, which in Unity is called ",paraId:350,tocIndex:52},{value:"lossyScale",paraId:350,tocIndex:52},{value:"。",paraId:350,tocIndex:52},{value:"method name",paraId:351,tocIndex:52},{value:"parameters",paraId:351,tocIndex:52},{value:"return value",paraId:351,tocIndex:52},{value:"remarks",paraId:351,tocIndex:52},{value:"scaleLocal",paraId:351,tocIndex:52},{value:"[number, number]",paraId:351,tocIndex:52},{value:" or ",paraId:351,tocIndex:52},{value:"number, number",paraId:351,tocIndex:52},{value:" or",paraId:351,tocIndex:52},{value:"number",paraId:351,tocIndex:52},{value:"-",paraId:351,tocIndex:52},{value:"Continued scaling with respect to the current scale in ",paraId:351,tocIndex:52},{value:"local coordinate system",paraId:351,tocIndex:52},{value:"setLocalScale",paraId:351,tocIndex:52},{value:"[number, number]",paraId:351,tocIndex:52},{value:" or ",paraId:351,tocIndex:52},{value:"number, number",paraId:351,tocIndex:52},{value:" or ",paraId:351,tocIndex:52},{value:"number",paraId:351,tocIndex:52},{value:"-",paraId:351,tocIndex:52},{value:"Set the scaling in ",paraId:351,tocIndex:52},{value:"local coordinate system",paraId:351,tocIndex:52},{value:"getScale",paraId:351,tocIndex:52},{value:"-",paraId:351,tocIndex:52},{value:"[number, number]",paraId:351,tocIndex:52},{value:"Get the scaling in ",paraId:351,tocIndex:52},{value:"world coordinate system",paraId:351,tocIndex:52},{value:"getLocalScale",paraId:351,tocIndex:52},{value:"-",paraId:351,tocIndex:52},{value:"[number, number]",paraId:351,tocIndex:52},{value:"Get the scaling in ",paraId:351,tocIndex:52},{value:"local coordinate system",paraId:351,tocIndex:52},{value:"scaleLocal/setLocalScale",paraId:352,tocIndex:52},{value:" supports the following input forms, where only one number can be passed if the horizontal/vertical scaling is equal.",paraId:352,tocIndex:52},{value:"circle.scaleLocal([2, 2]); // [number, number]\ncircle.scaleLocal(2, 2); // number, number\ncircle.scaleLocal(2); // number\n",paraId:353,tocIndex:52},{value:"If you want to flip along the X / Y axis, you can pass in a negative value, e.g. flip along the Y axis.",paraId:354,tocIndex:52},{value:"circle.setLocalScale(-1, 1);\n",paraId:355,tocIndex:52},{value:"In 3D scenes, rotations can be represented by matrices, axis angles, Euler angles and quaternions, which are interconvertible with each other. Although, considering future scalability, we use quaternions in the G internal implementation.",paraId:356,tocIndex:53},{value:"method name",paraId:357,tocIndex:53},{value:"parameters",paraId:357,tocIndex:53},{value:"return value",paraId:357,tocIndex:53},{value:"remarks",paraId:357,tocIndex:53},{value:"rotateLocal",paraId:357,tocIndex:53},{value:"number",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"In the ",paraId:357,tocIndex:53},{value:"local coordinate system",paraId:357,tocIndex:53},{value:", rotate by a certain Eulerian angle, clockwise positive, in ",paraId:357,tocIndex:53},{value:"degree",paraId:357,tocIndex:53},{value:"rotate",paraId:357,tocIndex:53},{value:"number",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"In ",paraId:357,tocIndex:53},{value:"world coordinate system",paraId:357,tocIndex:53},{value:", rotate by a certain Eulerian angle",paraId:357,tocIndex:53},{value:"setEulerAngles",paraId:357,tocIndex:53},{value:"number",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"In ",paraId:357,tocIndex:53},{value:"world coordinate system",paraId:357,tocIndex:53},{value:", rotate by a certain Eulerian angle",paraId:357,tocIndex:53},{value:"setLocalEulerAngles",paraId:357,tocIndex:53},{value:"number",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"Set the Euler angles in the ",paraId:357,tocIndex:53},{value:"local coordinate system",paraId:357,tocIndex:53},{value:".",paraId:357,tocIndex:53},{value:"setLocalRotation",paraId:357,tocIndex:53},{value:"quat",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"Sets the number of quaternions in the ",paraId:357,tocIndex:53},{value:"local coordinate system",paraId:357,tocIndex:53},{value:".",paraId:357,tocIndex:53},{value:"setRotation",paraId:357,tocIndex:53},{value:"quat",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"Sets the number of quaternions in the ",paraId:357,tocIndex:53},{value:"world coordinate system",paraId:357,tocIndex:53},{value:".",paraId:357,tocIndex:53},{value:"getEulerAngles",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"number",paraId:357,tocIndex:53},{value:"Get the Euler angles in ",paraId:357,tocIndex:53},{value:"world coordinate system",paraId:357,tocIndex:53},{value:"getLocalEulerAngles",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"number",paraId:357,tocIndex:53},{value:"Get the Euler angles in ",paraId:357,tocIndex:53},{value:"local coordinate system",paraId:357,tocIndex:53},{value:"getLocalRotation",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"quat",paraId:357,tocIndex:53},{value:"Get the quaternion in ",paraId:357,tocIndex:53},{value:"local coordinate system",paraId:357,tocIndex:53},{value:"getRotation",paraId:357,tocIndex:53},{value:"-",paraId:357,tocIndex:53},{value:"quat",paraId:357,tocIndex:53},{value:"Get the quaternion in ",paraId:357,tocIndex:53},{value:"world coordinate system",paraId:357,tocIndex:53},{value:"In 2D scenes, stretching can be performed to distort each point on an element in a certain direction at a certain angle. See ",paraId:358,tocIndex:54},{value:"CSS eponymous transform function",paraId:358,tocIndex:54},{value:".",paraId:358,tocIndex:54},{value:"method name",paraId:359,tocIndex:54},{value:"parameters",paraId:359,tocIndex:54},{value:"return values",paraId:359,tocIndex:54},{value:"remarks",paraId:359,tocIndex:54},{value:"setLocalSkew",paraId:359,tocIndex:54},{value:"vec2",paraId:359,tocIndex:54},{value:"-",paraId:359,tocIndex:54},{value:"The angle in ",paraId:359,tocIndex:54},{value:"rad",paraId:359,tocIndex:54},{value:" that distorts the element along the horizontal/vertical coordinates in the ",paraId:359,tocIndex:54},{value:"local coordinate system",paraId:359,tocIndex:54},{value:".",paraId:359,tocIndex:54},{value:"getLocalSkew",paraId:359,tocIndex:54},{value:"-",paraId:359,tocIndex:54},{value:"vec2",paraId:359,tocIndex:54},{value:"Gets the distortion angle in ",paraId:359,tocIndex:54},{value:"rad",paraId:359,tocIndex:54},{value:" under the ",paraId:359,tocIndex:54},{value:"local coordinate system",paraId:359,tocIndex:54},{value:".",paraId:359,tocIndex:54},{value:"Using the ",paraId:360,tocIndex:55},{value:"transformOrigin",paraId:361,tocIndex:55},{value:" property, you can also use ",paraId:360,tocIndex:55},{value:"setOrigin",paraId:360,tocIndex:55},{value:".",paraId:360,tocIndex:55},{value:"method name",paraId:362,tocIndex:55},{value:"parameters",paraId:362,tocIndex:55},{value:"return value",paraId:362,tocIndex:55},{value:"remarks",paraId:362,tocIndex:55},{value:"setOrigin",paraId:362,tocIndex:55},{value:"[number, number]",paraId:362,tocIndex:55},{value:" or ",paraId:362,tocIndex:55},{value:"[number, number, number]",paraId:362,tocIndex:55},{value:" or ",paraId:362,tocIndex:55},{value:"number, number",paraId:362,tocIndex:55},{value:" or ",paraId:362,tocIndex:55},{value:"number, number, number",paraId:362,tocIndex:55},{value:"-",paraId:362,tocIndex:55},{value:"Set the scaling and rotation center in the local coordinate system.",paraId:362,tocIndex:55},{value:"getOrigin",paraId:362,tocIndex:55},{value:"[number, number, number]",paraId:362,tocIndex:55},{value:"-",paraId:362,tocIndex:55},{value:"Get the scaling and rotation center in the local coordinate system.",paraId:362,tocIndex:55},{value:"Set the center of scaling and rotation in the local coordinate system, ",paraId:363,tocIndex:55},{value:"example",paraId:364,tocIndex:55},{value:".",paraId:363,tocIndex:55},{value:"The default value is ",paraId:365,tocIndex:55},{value:"[0, 0]",paraId:365,tocIndex:55},{value:".",paraId:365,tocIndex:55},{value:"In the following example, we have placed a circle with a radius of 100 at ",paraId:366,tocIndex:55},{value:"[100, 100]",paraId:366,tocIndex:55},{value:".",paraId:366,tocIndex:55},{value:"const circle = new Circle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 100,\n    },\n});\n",paraId:367,tocIndex:55},{value:"If we want the circle to be scaled with the center of the circle as the center of transformation, and it is the enclosing box that changes.",paraId:368,tocIndex:55},{value:"circle.setOrigin(100, 100);\ncircle.scale(0.5);\ncircle.getBounds(); // { center: [100, 100], halfExtents: [50, 50] }\n",paraId:369,tocIndex:55},{value:"But if we want the circle to be scaled by its own upper left corner of the bounding box:",paraId:370,tocIndex:55},{value:"circle.setOrigin(0, 0);\ncircle.scale(0.5);\ncircle.getBounds(); // { center: [50, 50], halfExtents: [50, 50] }\n",paraId:371,tocIndex:55},{value:"In the following ",paraId:372,tocIndex:55},{value:"example",paraId:373,tocIndex:55},{value:", we have created a rectangle whose default anchor point is the upper left corner of the enclosing box in the local coordinate system. If we want it to rotate at the center of the enclosing box, we need to set the transformation center to be offset by half the length and width relative to the anchor point, i.e., ",paraId:372,tocIndex:55},{value:"[150, 100]",paraId:372,tocIndex:55},{value:".",paraId:372,tocIndex:55},{value:"const rect = new Rect({\n    id: 'rect',\n    style: {\n        width: 300,\n        height: 200,\n    },\n});\nrect.setOrigin(150, 100); // Set the rotation and scaling center to the center point of its own bounding box\n",paraId:374,tocIndex:55},{value:"For example, if we want to modify the transformation center of a circle to the upper left corner instead of the center of the circle, we can do so.",paraId:375,tocIndex:55},{value:"const circle = new Circle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 100,\n    },\n});\n\ncircle.setOrigin(0, 0);\n// or\ncircle.style.transformOrigin = 'left top';\n// or\ncircle.style.transformOrigin = '0px 0px';\n// or\ncircle.style.transformOrigin = '0% 0%';\n",paraId:376,tocIndex:55},{value:"The difference between the two is that origin is defined relative to the anchor point, while transformOrigin is defined relative to the bounding box.",paraId:377,tocIndex:55},{value:"Based on different ",paraId:378,tocIndex:56},{value:"bounding box definitions",paraId:379,tocIndex:56},{value:", we provide the following methods to obtain them.",paraId:378,tocIndex:56},{value:"Gets the geometric bouding box of the base drawing, which is independent of other drawing properties (e.g. ",paraId:380,tocIndex:57},{value:"lineWidth",paraId:381,tocIndex:57},{value:", ",paraId:380,tocIndex:57},{value:"filter",paraId:382,tocIndex:57},{value:", ",paraId:380,tocIndex:57},{value:"shadowBlur",paraId:383,tocIndex:57},{value:", etc.), except for defining the required style properties (e.g. r for Circle, width/height for Rect).",paraId:380,tocIndex:57},{value:"const circle = new Circle({\n    style: {\n        cx: 100, // Coordinates in the local coordinate system do not affect Geometry Bounds\n        cy: 100, // Coordinates in the local coordinate system do not affect Geometry Bounds\n        r: 100,\n        lineWidth: 20, // Style properties do not affect Geometry Bounds\n        shadowBlur: 10, // Style properties do not affect Geometry Bounds\n    },\n});\ncircle.getGeometryBounds(); // { center: [0, 0], halfExtents: [100, 100] }\n",paraId:384,tocIndex:57},{value:"Group returns null because there is no geometry definition.",paraId:385,tocIndex:57},{value:"const group = new Group();\ngroup.getGeometryBounds(); // null\n",paraId:386,tocIndex:57},{value:"This should be the most common way of calculating the Geometry Bounds of itself and its children in the world coordinate system.",paraId:387,tocIndex:58},{value:"const circle = new Circle({\n    style: {\n        cx: 100, // Applying transformations in the world coordinate system\n        cy: 100,\n        r: 100,\n    },\n});\ncircle.getBounds(); // { center: [100, 100], halfExtents: [100, 100] }\n",paraId:388,tocIndex:58},{value:"Merge the Render Bounds of itself and its children in the world coordinate system, based on the Geometry Bounds, affected by the following style properties: ",paraId:389,tocIndex:59},{value:"lineWidth",paraId:390,tocIndex:59},{value:", ",paraId:389,tocIndex:59},{value:"filter",paraId:391,tocIndex:59},{value:", ",paraId:389,tocIndex:59},{value:"shadowBlur",paraId:392,tocIndex:59},{value:", etc.",paraId:389,tocIndex:59},{value:"const circle = new Circle({\n    style: {\n        cx: 100, // Applying transformations in the world coordinate system\n        cy: 100,\n        r: 100,\n        lineWidth: 20,\n    },\n});\n// r + lineWidth / 2\ncircle.getRenderBounds(); // { center: [100, 100], halfExtents: [110, 110] }\n",paraId:393,tocIndex:59},{value:"The only difference in getBounds is that it is calculated under the local coordinate system of the parent node.",paraId:394,tocIndex:60},{value:"Compatible with ",paraId:395,tocIndex:61},{value:"SVG method of the same name",paraId:395,tocIndex:61},{value:", the calculation is equivalent to getBounds, except that the return value type is different, the latter returns AABB. This method returns a ",paraId:395,tocIndex:61},{value:"DOMRect",paraId:395,tocIndex:61},{value:".",paraId:395,tocIndex:61},{value:"interface DOMRect {\n  top: number;\n  left: number;\n  right: number;\n  bottom: number;\n  width: number;\n  height: number;\n}\n",paraId:396,tocIndex:61},{value:"Get the Geometry Bounds in the browser coordinate system, apply the transformation in the world coordinate system, and then add the offset of the canvas relative to the browser.",paraId:397,tocIndex:62},{value:"In the scene graph, we need to construct parent-child relationships, get parent-child nodes quickly, and sometimes query the list of nodes of a certain type in the subtree. Based on the inheritance relationship, each DisplayObject has ",paraId:398,tocIndex:63},{value:"Node",paraId:399,tocIndex:63},{value:" and ",paraId:398,tocIndex:63},{value:"Element",paraId:400,tocIndex:63},{value:" capabilities.",paraId:398,tocIndex:63},{value:"method/property name",paraId:401,tocIndex:64},{value:"method/property",paraId:401,tocIndex:64},{value:"return value",paraId:401,tocIndex:64},{value:"remarks",paraId:401,tocIndex:64},{value:"parentNode",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject | null",paraId:401,tocIndex:64},{value:"Parent node (if any)",paraId:401,tocIndex:64},{value:"parentElement",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject | null",paraId:401,tocIndex:64},{value:"Parent node (if any)",paraId:401,tocIndex:64},{value:"childNodes",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject[]",paraId:401,tocIndex:64},{value:"Child Node List",paraId:401,tocIndex:64},{value:"children",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject[]",paraId:401,tocIndex:64},{value:"Child Node List",paraId:401,tocIndex:64},{value:"firstChild",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject | null",paraId:401,tocIndex:64},{value:"Returns the first node in the list of child nodes (if any)",paraId:401,tocIndex:64},{value:"lastChild",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject | null",paraId:401,tocIndex:64},{value:"Returns the last node in the list of child nodes (if any)",paraId:401,tocIndex:64},{value:"nextSibling",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject | null",paraId:401,tocIndex:64},{value:"Return the next sibling node (if any)",paraId:401,tocIndex:64},{value:"previousSibling",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"DisplayObject | null",paraId:401,tocIndex:64},{value:"Return the previous sibling node (if any)",paraId:401,tocIndex:64},{value:"contains",paraId:401,tocIndex:64},{value:"method",paraId:401,tocIndex:64},{value:"boolean",paraId:401,tocIndex:64},{value:"Whether the subtree contains a node (entry)",paraId:401,tocIndex:64},{value:"getRootNode",paraId:401,tocIndex:64},{value:"method",paraId:401,tocIndex:64},{value:"Node",paraId:401,tocIndex:64},{value:"Returns the root node of the current node",paraId:401,tocIndex:64},{value:"ownerDocument",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"Document",paraId:401,tocIndex:64},{value:"Back to the canvas entrance Document",paraId:401,tocIndex:64},{value:"isConnected",paraId:401,tocIndex:64},{value:"property",paraId:401,tocIndex:64},{value:"boolean",paraId:401,tocIndex:64},{value:"Whether the node is added to the canvas",paraId:401,tocIndex:64},{value:"Referring to the CSS selector, we provide the following query that looks at the ",paraId:402,tocIndex:65},{value:"entire subtree",paraId:402,tocIndex:65},{value:" of the current node, and not just the direct list of children, but all descendant nodes.",paraId:402,tocIndex:65},{value:"method name",paraId:403,tocIndex:65},{value:"parameters",paraId:403,tocIndex:65},{value:"return value",paraId:403,tocIndex:65},{value:"remarks",paraId:403,tocIndex:65},{value:"getElementById",paraId:403,tocIndex:65},{value:"(id: string)",paraId:403,tocIndex:65},{value:"DisplayObject | null",paraId:403,tocIndex:65},{value:"Query child nodes by ",paraId:403,tocIndex:65},{value:"id",paraId:403,tocIndex:65},{value:"getElementsByName",paraId:403,tocIndex:65},{value:"(name: string)",paraId:403,tocIndex:65},{value:"DisplayObject[]",paraId:403,tocIndex:65},{value:"Query the list of child nodes by ",paraId:403,tocIndex:65},{value:"name",paraId:403,tocIndex:65},{value:"getElementsByClassName",paraId:403,tocIndex:65},{value:"(className: string)",paraId:403,tocIndex:65},{value:"DisplayObject[]",paraId:403,tocIndex:65},{value:"Query the list of child nodes by ",paraId:403,tocIndex:65},{value:"className",paraId:403,tocIndex:65},{value:"getElementsByTagName",paraId:403,tocIndex:65},{value:"(tagName: string)",paraId:403,tocIndex:65},{value:"DisplayObject[]",paraId:403,tocIndex:65},{value:"Query the list of child nodes by ",paraId:403,tocIndex:65},{value:"tagName",paraId:403,tocIndex:65},{value:"querySelector",paraId:403,tocIndex:65},{value:"(selector: string)",paraId:403,tocIndex:65},{value:"DisplayObject \\｜ null",paraId:403,tocIndex:65},{value:"Query the first child node that satisfies the condition",paraId:403,tocIndex:65},{value:"querySelectorAll",paraId:403,tocIndex:65},{value:"(selector: string)",paraId:403,tocIndex:65},{value:"DisplayObject[]",paraId:403,tocIndex:65},{value:"Query the list of all child nodes that satisfy the condition",paraId:403,tocIndex:65},{value:"find",paraId:403,tocIndex:65},{value:"(filter: Function)",paraId:403,tocIndex:65},{value:"DisplayObject \\｜ null",paraId:403,tocIndex:65},{value:"Query the first child node that satisfies the condition",paraId:403,tocIndex:65},{value:"findAll",paraId:403,tocIndex:65},{value:"(filter: Function)",paraId:403,tocIndex:65},{value:"DisplayObject[]",paraId:403,tocIndex:65},{value:"Query the list of all child nodes that satisfy the condition",paraId:403,tocIndex:65},{value:"We demonstrate how to use these query methods using the above example of the solar system.",paraId:404,tocIndex:65},{value:"solarSystem.getElementsByName('sun');\n// sun\n\nsolarSystem.getElementsByTagName('circle');\nsolarSystem.getElementsByTagName(Shape.CIRCLE);\n// [sun, earth, moon]\n\nsolarSystem.querySelector('[name=sun]');\n// sun\n\nsolarSystem.querySelectorAll('[r=25]');\n// [moon]\n",paraId:405,tocIndex:65},{value:"Sometimes the query criteria are not well described by CSS selectors, so you can use custom query methods: find/findAll. they can be compared to querySelector/querySelectorAll. the difference is that the former requires passing in a filter, for example the following is equivalent.",paraId:406,tocIndex:65},{value:"solarSystem.querySelector('[name=sun]');\nsolarSystem.find((element) => element.name === 'sun');\n\nsolarSystem.querySelectorAll('[r=25]');\nsolarSystem.findAll((element) => element.style.r === 25);\n",paraId:407,tocIndex:65},{value:"The following add/remove node capabilities come from the inherited ",paraId:408,tocIndex:66},{value:"Element",paraId:409,tocIndex:66},{value:" base class.",paraId:408,tocIndex:66},{value:"method name",paraId:410,tocIndex:66},{value:"parameters",paraId:410,tocIndex:66},{value:"return value",paraId:410,tocIndex:66},{value:"remarks",paraId:410,tocIndex:66},{value:"appendChild",paraId:410,tocIndex:66},{value:"child: DisplayObject",paraId:410,tocIndex:66},{value:"DisplayObject",paraId:410,tocIndex:66},{value:"Adds a child node and returns the added node",paraId:410,tocIndex:66},{value:"insertBefore",paraId:410,tocIndex:66},{value:"child: DisplayObject",paraId:410,tocIndex:66},{value:" or ",paraId:410,tocIndex:66},{value:"reference?: DisplayObject",paraId:410,tocIndex:66},{value:"DisplayObject",paraId:410,tocIndex:66},{value:"Add a child node, before some child node (if any), and return the added node",paraId:410,tocIndex:66},{value:"append",paraId:410,tocIndex:66},{value:"...nodes: DisplayObject[]",paraId:410,tocIndex:66},{value:"Add a group of nodes in bulk at the end of the child node list of the current node",paraId:410,tocIndex:66},{value:"prepend",paraId:410,tocIndex:66},{value:"...nodes: DisplayObject[]",paraId:410,tocIndex:66},{value:"Add a group of nodes in bulk to the head of the current node's child node list",paraId:410,tocIndex:66},{value:"after",paraId:410,tocIndex:66},{value:"...nodes: DisplayObject[]",paraId:410,tocIndex:66},{value:"Add some sibling nodes in bulk after the current node",paraId:410,tocIndex:66},{value:"before",paraId:410,tocIndex:66},{value:"...nodes: DisplayObject[]",paraId:410,tocIndex:66},{value:"Add some sibling nodes in bulk before the current node",paraId:410,tocIndex:66},{value:"removeChild",paraId:410,tocIndex:66},{value:"child: DisplayObject",paraId:410,tocIndex:66},{value:"DisplayObject",paraId:410,tocIndex:66},{value:"Delete the child node and return the node that was deleted.",paraId:410,tocIndex:66},{value:"removeChildren",paraId:410,tocIndex:66},{value:"Delete and destroy all child nodes.",paraId:410,tocIndex:66},{value:"remove",paraId:410,tocIndex:66},{value:"destroy = true",paraId:410,tocIndex:66},{value:"DisplayObject",paraId:410,tocIndex:66},{value:"Remove itself from the parent node (if any), ",paraId:410,tocIndex:66},{value:"destroy",paraId:410,tocIndex:66},{value:" indicates whether to destroy",paraId:410,tocIndex:66},{value:"replaceChild",paraId:410,tocIndex:66},{value:"child: DisplayObject",paraId:410,tocIndex:66},{value:"DisplayObject",paraId:410,tocIndex:66},{value:"Replace a child node of the current node with the specified node, and return the replaced node",paraId:410,tocIndex:66},{value:"replaceWith",paraId:410,tocIndex:66},{value:"...nodes: DisplayObject[]",paraId:410,tocIndex:66},{value:"In the list of children of the parent node, replace the node with the list of nodes passed in",paraId:410,tocIndex:66},{value:"replaceChildren",paraId:410,tocIndex:66},{value:"...nodes: DisplayObject[]",paraId:410,tocIndex:66},{value:"Replace all children of the node. If no parameters are passed, all children of the node will be cleared",paraId:410,tocIndex:66},{value:"There are two ways to remove a child node from a parent node and destroy it.",paraId:411,tocIndex:66},{value:"// parent -> child\nparent.removeChild(child);\n\n// or\nchild.remove();\n",paraId:412,tocIndex:66},{value:"There are three ways to delete all child nodes.",paraId:413,tocIndex:66},{value:"parent.removeChildren();\n\n// or\n[...parent.children].forEach((child) => parent.removeChild(child));\n[...parent.children].forEach((child) => child.remove());\n\n// or\nparent.replaceChildren();\n",paraId:414,tocIndex:66},{value:"The following points are noted when adding/removing nodes.",paraId:415,tocIndex:66},{value:"The ChildInserted and Inserted events are triggered sequentially when a node is added.",paraId:416,tocIndex:66},{value:"Removed and ChildRemoved events will be triggered sequentially, and ",paraId:416,tocIndex:66},{value:"destroy",paraId:417,tocIndex:66},{value:" will be called by default to destroy itself. If the node is only temporarily removed from the scene graph and may be added back later, you can use ",paraId:416,tocIndex:66},{value:"remove(false)",paraId:416,tocIndex:66},{value:".",paraId:416,tocIndex:66},{value:"The method signature is ",paraId:418,tocIndex:67},{value:"cloneNode(deep?: boolean): this",paraId:418,tocIndex:67},{value:", with optional arguments for whether a deep copy is needed, and returns the new node obtained by cloning.",paraId:418,tocIndex:67},{value:"In the following example, we create a circle, set its radius and position. The new node is copied with the same style properties and position.",paraId:419,tocIndex:67},{value:"circle.style.r = 20;\ncircle.setPosition(10, 20);\n\nconst clonedCircle = circle.cloneNode();\nclonedCircle instanceof Circle; // true\nclonedCircle.style.r; // 20\nclonedCircle.getPosition(); // [10, 20]\n",paraId:420,tocIndex:67},{value:"Caveats:",paraId:421,tocIndex:67},{value:"Deep copy support, i.e. itself and the whole subtree",paraId:422,tocIndex:67},{value:"The cloned node does not retain the parent-child relationship of the original node and needs to be added to the canvas using ",paraId:422,tocIndex:67},{value:"appendChild",paraId:422,tocIndex:67},{value:" before it will be rendered",paraId:422,tocIndex:67},{value:"Consistent with the ",paraId:422,tocIndex:67},{value:"DOM API",paraId:422,tocIndex:67},{value:", event listeners on the original drawing are not copied",paraId:422,tocIndex:67},{value:"In this ",paraId:423,tocIndex:67},{value:"example",paraId:424,tocIndex:67},{value:", we demonstrate the above features.",paraId:423,tocIndex:67},{value:"The style properties of the original node can be changed at any time, and the copy obtained will be up-to-date, and the new node will also need to be added to the scene graph before it will be rendered",paraId:425,tocIndex:67},{value:"However, since no event listeners will be copied, only the original node can be dragged",paraId:425,tocIndex:67},{value:"In non-deep copy mode, Text (Drag me Text) is not copied as a child of Circle",paraId:425,tocIndex:67},{value:"method name",paraId:426,tocIndex:68},{value:"parameters",paraId:426,tocIndex:68},{value:"return values",paraId:426,tocIndex:68},{value:"remarks",paraId:426,tocIndex:68},{value:"getAttribute",paraId:426,tocIndex:68},{value:"(name: string)",paraId:426,tocIndex:68},{value:"null | any",paraId:426,tocIndex:68},{value:"Get attribute value based on attribute name",paraId:426,tocIndex:68},{value:"setAttribute",paraId:426,tocIndex:68},{value:"(name: string, value: any)",paraId:426,tocIndex:68},{value:"-",paraId:426,tocIndex:68},{value:"Set attribute value",paraId:426,tocIndex:68},{value:"⚠️ Compatible with the old ",paraId:427,tocIndex:68},{value:"attr(name: string, value?: any)",paraId:427,tocIndex:68},{value:", get and set attribute values.",paraId:427,tocIndex:68},{value:"⚠️ Compatible with ",paraId:428,tocIndex:68},{value:"HTMLElement Style",paraId:428,tocIndex:68},{value:":",paraId:428,tocIndex:68},{value:"style.",paraId:429,tocIndex:68},{value:"getPropertyValue",paraId:429,tocIndex:68},{value:"style.",paraId:429,tocIndex:68},{value:"setProperty",paraId:429,tocIndex:68},{value:"style.",paraId:429,tocIndex:68},{value:"removeProperty",paraId:429,tocIndex:68},{value:"The following usage equivalents.",paraId:430,tocIndex:68},{value:"const circle = new Circle({\n    style: {\n        // or using attrs\n        r: 10,\n        fill: 'red',\n    },\n});\n\n// get attribute value\ncircle.getAttribute('fill'); // red\ncircle.attr('fill'); // red\ncircle.style.fill; // red\ncircle.style.getPropertyValue('fill');\n\n// set attribute value\ncircle.setAttribute('r', 20);\ncircle.attr('r', 20);\ncircle.style.r = 20;\ncircle.style.setProperty('r', 20);\n",paraId:431,tocIndex:68},{value:"Some properties such as ",paraId:432,tocIndex:69},{value:"Rect",paraId:433,tocIndex:69},{value:" support units for width / height, if you want to get the ",paraId:432,tocIndex:69},{value:"calculated value",paraId:434,tocIndex:69},{value:", you can use ",paraId:432,tocIndex:69},{value:"parsedStyle",paraId:432,tocIndex:69},{value:".",paraId:432,tocIndex:69},{value:"rect.style.width = '100px';\nrect.parsedStyle.width; // CSSUnitValue { unit: 'px', value: 100 }\n",paraId:435,tocIndex:69},{value:"Note that currently, when using ",paraId:436,tocIndex:69},{value:"animation",paraId:437,tocIndex:69},{value:", we also convert the values of the attributes to be interpolated, so if you want to get the absolute values in px, you need to use ",paraId:436,tocIndex:69},{value:"parsedStyle",paraId:436,tocIndex:69},{value:" ",paraId:436,tocIndex:69},{value:"example",paraId:438,tocIndex:69},{value:".",paraId:436,tocIndex:69},{value:"animation.onframe = () => {\n    rect.style.width; // '100px'\n    rect.parsedStyle.width; // CSSUnitValue { unit: 'px', value: 100 }\n};\n",paraId:439,tocIndex:69},{value:"Calling ",paraId:440,tocIndex:70},{value:"destroy()",paraId:440,tocIndex:70},{value:" will destroy the node. Destroyed nodes will not be added to the canvas rendering again. The ",paraId:440,tocIndex:70},{value:"destroyed",paraId:441,tocIndex:70},{value:" attribute allows you to determine if a node has been destroyed.",paraId:440,tocIndex:70},{value:"circle.destroy();\n",paraId:442,tocIndex:70},{value:"When this method is invoked, the following actions are performed in sequence.",paraId:443,tocIndex:70},{value:"Trigger Destroy event",paraId:444,tocIndex:70},{value:"Call ",paraId:444,tocIndex:70},{value:"remove()",paraId:444,tocIndex:70},{value:" to remove itself from the scene graph, so it will trigger the Removed and ChildRemoved events",paraId:444,tocIndex:70},{value:"Remove all event listeners and animations on this node",paraId:444,tocIndex:70},{value:"Set the ",paraId:444,tocIndex:70},{value:"destroyed",paraId:445,tocIndex:70},{value:" flag to true",paraId:444,tocIndex:70},{value:"The following properties allow you to determine the current state of the drawing, such as whether it has been added to the canvas, whether it has been destroyed, etc.",paraId:446,tocIndex:71},{value:"用于判断一个图形是否已经被加入到画布中。",paraId:447,tocIndex:72},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/isConnected",paraId:448,tocIndex:72},{value:"circle.isConnected; // false\ncanvas.appendChild(circle); // add to canvas\ncircle.isConnected; // true\n",paraId:449,tocIndex:72},{value:"Used to determine if a drawing has been added to the canvas.",paraId:450,tocIndex:73},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Node/ownerDocument",paraId:451,tocIndex:73},{value:"circle.ownerDocument; // null\ncanvas.appendChild(circle); // add to canvas\ncircle.ownerDocument; // canvas.document\n",paraId:452,tocIndex:73},{value:"Used to determine if a graph has been destroyed.",paraId:453,tocIndex:74},{value:"By calling ",paraId:454,tocIndex:74},{value:"destroy()",paraId:454,tocIndex:74},{value:" to actively destroy itself, or the parent node by ",paraId:454,tocIndex:74},{value:"destroyChildren()",paraId:454,tocIndex:74},{value:" to actively remove and destroy all children, etc.",paraId:454,tocIndex:74},{value:"circle.destroyed; // false\ncircle.destroy();\ncircle.destroyed; // true\n",paraId:455,tocIndex:74},{value:"In the ",paraId:456,tocIndex:75},{value:"event system",paraId:457,tocIndex:75},{value:", we can add event listeners to nodes added to the canvas using a DOM Event API-like approach.",paraId:456,tocIndex:75},{value:"In addition to interactive events such as click and mouseenter, we also provide a series of built-in node lifecycle events, such as listening for node additions and deletions, which also have full propagation paths (bubbling, capturing), ",paraId:458,tocIndex:75},{value:"example",paraId:459,tocIndex:75},{value:".",paraId:458,tocIndex:75},{value:"import { ElementEvent, MutationEvent } from '@antv/g';\n\nchild.on(ElementEvent.INSERTED, (e: MutationEvent) => {\n  e.target; // child\n  e.relatedNode; // parent\n});\nchild.on(ElementEvent.REMOVED, (e) => {\n  e.target; // child\n  e.relatedNode; // parent\n});\nchild.on(ElementEvent.ATTR_MODIFIED, (e) => {\n  e.target; // child\n  e.attrName;\n  e.prevValue;\n  e.newValue;\n});\n\nparent.appendChild(child);\n",paraId:460,tocIndex:75},{value:"We currently support the following scenario map related events.",paraId:461,tocIndex:75},{value:"INSERTED",paraId:462,tocIndex:75},{value:" Triggered when added as a child node",paraId:462,tocIndex:75},{value:"REMOVED",paraId:462,tocIndex:75},{value:" Triggered when removed as a child node",paraId:462,tocIndex:75},{value:"MOUNTED",paraId:462,tocIndex:75},{value:" Triggered when first entering the canvas",paraId:462,tocIndex:75},{value:"UNMOUNTED",paraId:462,tocIndex:75},{value:" Triggered when removed from the canvas",paraId:462,tocIndex:75},{value:"ATTR_MODIFIED",paraId:462,tocIndex:75},{value:" Triggered when modifying properties",paraId:462,tocIndex:75},{value:"DESTROY",paraId:462,tocIndex:75},{value:" Triggered on destruction",paraId:462,tocIndex:75},{value:"Referring to the Web Animations API, you can use animate to complete the keyframe animation, the following is a ScaleIn animation effect.",paraId:463,tocIndex:76},{value:"circle.animate(\n    [\n        {\n            transform: 'scale(0)',\n        },\n        {\n            transform: 'scale(1)',\n        },\n    ],\n    {\n        duration: 500,\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n        iterations: Infinity,\n    },\n);\n",paraId:464,tocIndex:76},{value:"See ",paraId:465,tocIndex:76},{value:"animation system",paraId:466,tocIndex:76},{value:" for more details on usage.",paraId:465,tocIndex:76},{value:"https://developer.mozilla.org/en-US/docs/Learn/HTML/Howto/Use_data_attributes",paraId:467,tocIndex:77},{value:"data-*",paraId:468,tocIndex:77},{value:" attributes allow us to store extra information on standard.",paraId:468,tocIndex:77},{value:"group.dataset.type = 'a';\ngroup.getAttribute('data-type'); // 'a'\n",paraId:469,tocIndex:77},{value:"It should be noted that the part after the ",paraId:470,tocIndex:77},{value:"data-",paraId:470,tocIndex:77},{value:" prefix needs to use camel case when accessing through ",paraId:470,tocIndex:77},{value:"dataset",paraId:470,tocIndex:77},{value:":",paraId:470,tocIndex:77},{value:"group.setAttribute('data-a-b-c');\ngroup.dataset.aBC;\n\n// Wrong\ngroup.dataset.abc;\ngroup.dataset.abC;\n",paraId:471,tocIndex:77}]},94573:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(18947);const n=[{value:"You can refer to the ",paraId:0},{value:"<ellipse>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" draws an ellipse with a center of ",paraId:1},{value:"[100, 100]",paraId:1},{value:" and a radius of ",paraId:1},{value:"100",paraId:1},{value:".",paraId:1},{value:"const ellipse = new Ellipse({\n    style: {\n        cx: 100,\n        cy: 100,\n        rx: 100,\n        ry: 100,\n    },\n});\n",paraId:3},{value:"Inherits ",paraId:4,tocIndex:0},{value:"style property",paraId:5,tocIndex:0},{value:" from ",paraId:4,tocIndex:0},{value:"DisplayObject",paraId:6,tocIndex:0},{value:".",paraId:4,tocIndex:0},{value:"The default value is ",paraId:7,tocIndex:1},{value:"[0.5, 0.5]",paraId:7,tocIndex:1},{value:". For details, see ",paraId:7,tocIndex:1},{value:"DisplayObject's anchor",paraId:8,tocIndex:1},{value:".",paraId:7,tocIndex:1},{value:"The default value is ",paraId:9,tocIndex:2},{value:"center",paraId:9,tocIndex:2},{value:". For details, see ",paraId:9,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:10,tocIndex:2},{value:".",paraId:9,tocIndex:2},{value:"The x-axis coordinates of the center of the circle in the local coordinate system.",paraId:11,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/cx",paraId:12,tocIndex:4},{value:"Initial value",paraId:13,tocIndex:4},{value:"Applicable elements",paraId:14,tocIndex:4},{value:"Inheritable",paraId:15,tocIndex:4},{value:"Animatable",paraId:14,tocIndex:4},{value:"Computed value",paraId:16,tocIndex:4},{value:"'0'",paraId:14,tocIndex:4},{value:"-",paraId:14,tocIndex:4},{value:"no",paraId:14,tocIndex:4},{value:"yes",paraId:14,tocIndex:4},{value:"<percentage>",paraId:17,tocIndex:4},{value:" ",paraId:14,tocIndex:4},{value:"<length>",paraId:18,tocIndex:4},{value:"The y-axis coordinates of the center of the circle in the local coordinate system.",paraId:19,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/cy",paraId:20,tocIndex:5},{value:"Initial value",paraId:21,tocIndex:5},{value:"Applicable elements",paraId:22,tocIndex:5},{value:"Inheritable",paraId:23,tocIndex:5},{value:"Animatable",paraId:22,tocIndex:5},{value:"Computed value",paraId:24,tocIndex:5},{value:"'0'",paraId:22,tocIndex:5},{value:"-",paraId:22,tocIndex:5},{value:"no",paraId:22,tocIndex:5},{value:"yes",paraId:22,tocIndex:5},{value:"<percentage>",paraId:25,tocIndex:5},{value:" ",paraId:22,tocIndex:5},{value:"<length>",paraId:26,tocIndex:5},{value:"Horizontal radius of the ellipse",paraId:27,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/rx",paraId:28,tocIndex:6},{value:"Initial value",paraId:29,tocIndex:6},{value:"Applicable elements",paraId:30,tocIndex:6},{value:"Inheritable",paraId:31,tocIndex:6},{value:"Animatable",paraId:30,tocIndex:6},{value:"Computed value",paraId:32,tocIndex:6},{value:"'0'",paraId:30,tocIndex:6},{value:"-",paraId:30,tocIndex:6},{value:"no",paraId:30,tocIndex:6},{value:"yes",paraId:30,tocIndex:6},{value:"<percentage>",paraId:33,tocIndex:6},{value:" ",paraId:30,tocIndex:6},{value:"<length>",paraId:34,tocIndex:6},{value:"The vertical radius of the ellipse",paraId:35,tocIndex:7},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/ry",paraId:36,tocIndex:7},{value:"Initial value",paraId:37,tocIndex:7},{value:"Applicable elements",paraId:38,tocIndex:7},{value:"Inheritable",paraId:39,tocIndex:7},{value:"Animatable",paraId:38,tocIndex:7},{value:"Computed value",paraId:40,tocIndex:7},{value:"'0'",paraId:38,tocIndex:7},{value:"-",paraId:38,tocIndex:7},{value:"no",paraId:38,tocIndex:7},{value:"yes",paraId:38,tocIndex:7},{value:"<percentage>",paraId:41,tocIndex:7},{value:" ",paraId:38,tocIndex:7},{value:"<length>",paraId:42,tocIndex:7}]},54198:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(65788);const n=[{value:'While we support adding child nodes to all base graphs to express hierarchical relationships, sometimes there is a need for a "container" like concept that has no entity of its own and only holds other child elements. For example, in the typical solar system example, the solar orbit and the Earth\'s orbit are created using a Group.',paraId:0},{value:"Although Group does not have drawing properties, it has all the general capabilities of ",paraId:1},{value:"DisplayObject",paraId:2},{value:". For example, querying child nodes, transformations, getting bounding boxes, etc.",paraId:1},{value:"group.appendChild(circle);\ngroup.getBounds(); // circle's bounds\n\n// transform\ngroup.translate(100, 0);\n\n// query\ngroup.getElementsByTagName('circle'); // [circle]\n",paraId:3},{value:"DisplayObject",paraId:4,tocIndex:0}]},13687:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(30030);const n=[{value:"Sometimes we need to add some HUDs to the canvas, e.g. Tooltip. In this case, the HTML + CSS presentation has the following advantages over using basic graphics.",paraId:0},{value:"Many native HTML components are difficult to draw, such as some input components: ",paraId:1},{value:"<input>",paraId:1},{value:", ",paraId:1},{value:"<select>",paraId:1},{value:" etc.",paraId:1},{value:"Some of the HTML native features are difficult to implement, for example, text cannot be selected after drawing it using ",paraId:1},{value:"g-canvas/webgl",paraId:1},{value:", while it can be if it is displayed in HTML, the following image shows the text selection effect, ",paraId:1},{value:"example",paraId:2},{value:".",paraId:1},{value:"HTML content and width are required, where HTML content can be a string or HTMLElement.",paraId:3},{value:"const html = new HTML({\n    style: {\n        x: 0,\n        y: 0,\n        width: 100,\n        height: 100,\n        innerHTML: '<h1>This is Title</h1>',\n    },\n});\ncanvas.appendChild(html);\n",paraId:4},{value:"The reason why you must specify the width and height (or at least the initial width and height) is that the ",paraId:5},{value:"<foreignObject>",paraId:5},{value:" element of the SVG must be specified or it will not be displayed. .",paraId:5},{value:"In the implementation ",paraId:6,tocIndex:0},{value:"g-canvas/webgl",paraId:6,tocIndex:0},{value:" wraps the HTML content in ",paraId:6,tocIndex:0},{value:"<div>",paraId:6,tocIndex:0},{value:", placing it inside the container as a sibling node of ",paraId:6,tocIndex:0},{value:"<canvas>",paraId:6,tocIndex:0},{value:". And in ",paraId:6,tocIndex:0},{value:"g-svg",paraId:6,tocIndex:0},{value:" the content is wrapped using ",paraId:6,tocIndex:0},{value:"<foreignObject>",paraId:6,tocIndex:0},{value:".",paraId:6,tocIndex:0},{value:'// the DOM in g-canvas/webgl\n<div id="container">\n    <canvas></canvas>\n    <div name="容器元素">\n        \x3c!-- content --\x3e\n    </div>\n</div>\n\n// the DOM in g-svg\n<div id="container">\n    <svg>\n        <foreignObject name="容器元素">\n            \x3c!-- content --\x3e\n        </foreignObject>\n    </svg>\n</div>\n',paraId:7,tocIndex:0},{value:"DisplayObject",paraId:8,tocIndex:1},{value:"Where ",paraId:9,tocIndex:1},{value:"id",paraId:10,tocIndex:1},{value:", ",paraId:9,tocIndex:1},{value:"name",paraId:11,tocIndex:1},{value:", [className](/en/api/basic/ display-object#classname) are applied to the container element if passed in, so there are two ways to get to the container element.",paraId:9,tocIndex:1},{value:"Get it through a DOM API like ",paraId:12,tocIndex:1},{value:"getElementById",paraId:12,tocIndex:1},{value:"using ",paraId:12,tocIndex:1},{value:"getDomElement()",paraId:13,tocIndex:1},{value:"Other style attributes are applied via CSS.",paraId:14,tocIndex:1},{value:"Corresponds to the CSS ",paraId:15,tocIndex:2},{value:"background",paraId:15,tocIndex:2},{value:" property.",paraId:15,tocIndex:2},{value:"Corresponds to the CSS ",paraId:16,tocIndex:3},{value:"border-color",paraId:16,tocIndex:3},{value:" property.",paraId:16,tocIndex:3},{value:"Corresponds to the CSS ",paraId:17,tocIndex:4},{value:"border-width",paraId:17,tocIndex:4},{value:" property.",paraId:17,tocIndex:4},{value:"Corresponds to the CSS ",paraId:18,tocIndex:5},{value:"border-style",paraId:18,tocIndex:5},{value:" property.",paraId:18,tocIndex:5},{value:"Use the ",paraId:19,tocIndex:5},{value:"dashed",paraId:19,tocIndex:5},{value:" value, but there is no precise control over the length of ",paraId:19,tocIndex:5},{value:"dash",paraId:19,tocIndex:5},{value:" and ",paraId:19,tocIndex:5},{value:"gap",paraId:19,tocIndex:5},{value:".",paraId:19,tocIndex:5},{value:"Corresponds to the CSS ",paraId:20,tocIndex:6},{value:"opacity",paraId:20,tocIndex:6},{value:" property.",paraId:20,tocIndex:6},{value:"Corresponds to the CSS ",paraId:21,tocIndex:7},{value:"visibility",paraId:21,tocIndex:7},{value:" property.",paraId:21,tocIndex:7},{value:"Corresponds to the CSS ",paraId:22,tocIndex:8},{value:"pointer-events",paraId:22,tocIndex:8},{value:" property.",paraId:22,tocIndex:8},{value:"When we implement a requirement like tooltip, we can have mouse events penetrate it, ",paraId:23,tocIndex:8},{value:"example",paraId:24,tocIndex:8},{value:".",paraId:23,tocIndex:8},{value:"const tooltip = new HTML({\n    style: {\n        x: 0,\n        y: 0,\n        innerHTML: 'Tooltip',\n        fill: 'white',\n        stroke: 'black',\n        lineWidth: 6,\n        width: 100,\n        height: 30,\n        pointerEvents: 'none', // Let the event penetrate it\n        visibility: 'hidden',\n    },\n});\n",paraId:25,tocIndex:8},{value:"Corresponds to the ",paraId:26,tocIndex:9},{value:"transform",paraId:26,tocIndex:9},{value:" property.",paraId:26,tocIndex:9},{value:"Use to generate the matrix string form in the global coordinate system.",paraId:27,tocIndex:9},{value:"Corresponds to the ",paraId:28,tocIndex:10},{value:"transform-origin",paraId:28,tocIndex:10},{value:" property.",paraId:28,tocIndex:10},{value:"The x-axis coordinate of the top-left vertex of the container in the local coordinate system.",paraId:29,tocIndex:12},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/x",paraId:30,tocIndex:12},{value:"Initial value",paraId:31,tocIndex:12},{value:"Applicable elements",paraId:32,tocIndex:12},{value:"Inheritable",paraId:33,tocIndex:12},{value:"Animatable",paraId:32,tocIndex:12},{value:"Computed value",paraId:34,tocIndex:12},{value:"'0'",paraId:32,tocIndex:12},{value:"-",paraId:32,tocIndex:12},{value:"no",paraId:32,tocIndex:12},{value:"yes",paraId:32,tocIndex:12},{value:"<percentage>",paraId:35,tocIndex:12},{value:" ",paraId:32,tocIndex:12},{value:"<length>",paraId:36,tocIndex:12},{value:"The y-axis coordinate of the top-left vertex of the container in the local coordinate system.",paraId:37,tocIndex:13},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/y",paraId:38,tocIndex:13},{value:"Initial value",paraId:39,tocIndex:13},{value:"Applicable elements",paraId:40,tocIndex:13},{value:"Inheritable",paraId:41,tocIndex:13},{value:"Animatable",paraId:40,tocIndex:13},{value:"Computed value",paraId:42,tocIndex:13},{value:"'0'",paraId:40,tocIndex:13},{value:"-",paraId:40,tocIndex:13},{value:"no",paraId:40,tocIndex:13},{value:"yes",paraId:40,tocIndex:13},{value:"<percentage>",paraId:43,tocIndex:13},{value:" ",paraId:40,tocIndex:13},{value:"<length>",paraId:44,tocIndex:13},{value:"HTML content, either as a string or as an HTMLElement.",paraId:45,tocIndex:14},{value:"| ",paraId:46,tocIndex:14},{value:"Initial value",paraId:47,tocIndex:14},{value:" | Applicable elements | ",paraId:46,tocIndex:14},{value:"Inheritable",paraId:48,tocIndex:14},{value:" | Animatable | ",paraId:46,tocIndex:14},{value:"Computed value",paraId:49,tocIndex:14},{value:" |\n| --- | --- | --- | --- | --- | --- |\n| - | - | no | no | ",paraId:46,tocIndex:14},{value:"string | HTMLElement",paraId:46,tocIndex:14},{value:" |",paraId:46,tocIndex:14},{value:"const html = new HTML({\n    style: {\n        width: 100,\n        height: 100,\n        innerHTML: '<h1>This is Title</h1>',\n        // innerHTML: 'content',\n        // innerHTML: document.createElement('div'),\n    },\n});\n\nhtml.style.innerHTML = '<h1>This is Title</h1>';\n",paraId:50,tocIndex:14},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/width",paraId:51,tocIndex:15},{value:"Initial value",paraId:52,tocIndex:15},{value:"Applicable elements",paraId:53,tocIndex:15},{value:"Inheritable",paraId:54,tocIndex:15},{value:"Animatable",paraId:53,tocIndex:15},{value:"Computed value",paraId:55,tocIndex:15},{value:"'auto'",paraId:53,tocIndex:15},{value:"-",paraId:53,tocIndex:15},{value:"no",paraId:53,tocIndex:15},{value:"yes",paraId:53,tocIndex:15},{value:"<percentage>",paraId:56,tocIndex:15},{value:" ",paraId:53,tocIndex:15},{value:"<length>",paraId:57,tocIndex:15},{value:"Initial value",paraId:58,tocIndex:16},{value:"Applicable elements",paraId:59,tocIndex:16},{value:"Inheritable",paraId:60,tocIndex:16},{value:"Animatable",paraId:59,tocIndex:16},{value:"Computed value",paraId:61,tocIndex:16},{value:"'auto'",paraId:59,tocIndex:16},{value:"-",paraId:59,tocIndex:16},{value:"no",paraId:59,tocIndex:16},{value:"yes",paraId:59,tocIndex:16},{value:"<percentage>",paraId:62,tocIndex:16},{value:" ",paraId:59,tocIndex:16},{value:"<length>",paraId:63,tocIndex:16},{value:"CSS properties will be passthrough and applied directly to the style of the DOM container. In the following ",paraId:64,tocIndex:17},{value:"example",paraId:65,tocIndex:17},{value:", CSS attributes such as ",paraId:64,tocIndex:17},{value:"fontSize",paraId:64,tocIndex:17},{value:" ",paraId:64,tocIndex:17},{value:"textAlign",paraId:64,tocIndex:17},{value:" ",paraId:64,tocIndex:17},{value:"color",paraId:64,tocIndex:17},{value:" will be directly reflected in the style:",paraId:64,tocIndex:17},{value:"const html = new HTML({\n    style: {\n        x: 200,\n        y: 100,\n        width: 200,\n        height: 200,\n        innerHTML: 'p1',\n        // The followin will override the CSS properties.\n        fontSize: '20px',\n        textAlign: 'center',\n        color: 'red',\n    },\n});\n",paraId:66,tocIndex:17},{value:"Gets the container element, e.g. ",paraId:67,tocIndex:19},{value:"<div>",paraId:67,tocIndex:19},{value:" in ",paraId:67,tocIndex:19},{value:"g-canvas/webgl",paraId:67,tocIndex:19},{value:", and ",paraId:67,tocIndex:19},{value:"<foreignObject>",paraId:67,tocIndex:19},{value:" in ",paraId:67,tocIndex:19},{value:"g-svg",paraId:67,tocIndex:19},{value:".",paraId:67,tocIndex:19},{value:"// g-canvas/webgl\nconst $div = html.getDomElement(); // HTMLDivElement\n\n// g-svg\nconst $foreignObject = html.getDomElement(); // <foreignObject>\n",paraId:68,tocIndex:19},{value:"Most of the scenegraph capabilities are available on HTML, such as ",paraId:69,tocIndex:22},{value:"transform operations",paraId:70,tocIndex:22},{value:".",paraId:69,tocIndex:22},{value:"html.translate(100, 0); // 平移\nhtml.scale(2); // 缩放\nhtml.rotate(30); // 旋转\n",paraId:71,tocIndex:22},{value:"When getting the enclosing box, we will use the native DOM API ",paraId:72,tocIndex:22},{value:"getBoundingClientRect",paraId:72,tocIndex:22},{value:", so calling it before the first call before the rendering is done will give incorrect results.",paraId:72,tocIndex:22},{value:"For HTML elements, it does not make much sense to add other base graphics as its child elements. In this case, you can use ",paraId:73,tocIndex:23},{value:"getDomElement",paraId:74,tocIndex:23},{value:" to get the container element and then perform subsequent DOM operations, such as adding child nodes.",paraId:73,tocIndex:23},{value:"const $div = document.createElement('div');\n\n// wrong\nhtml.appendChild($div);\n\n// correct\nhtml.getDomElement().appendChild($div);\n",paraId:75,tocIndex:23},{value:"The hidden displays all work properly.",paraId:76,tocIndex:24},{value:"html.show();\nhtml.style.visibility = 'visible';\n\nhtml.hide();\nhtml.style.visibility = 'hidden';\n",paraId:77,tocIndex:24},{value:"However, when specifying the rendering order by ",paraId:78,tocIndex:24},{value:"z-index",paraId:79,tocIndex:24},{value:", it is limited by the specific implementation and only works between individual HTML contents. In the following example, html1 cannot be displayed between circle1 and circle2.",paraId:78,tocIndex:24},{value:"// 在 <canvas> 中渲染的两个 circle\ncircle1.style.zIndex = 1;\ncircle2.style.zIndex = 3;\n\nhtml1.style.zIndex = 2;\nhtml2.style.zIndex = 100;\n",paraId:80,tocIndex:24},{value:"Since ",paraId:81,tocIndex:25},{value:"foreignObject",paraId:81,tocIndex:25},{value:" requires a specified width and height to be rendered, it can also be modified after being specified at creation time.",paraId:81,tocIndex:25},{value:"html.style.width = 100;\nhtml.style.height = 100;\n",paraId:82,tocIndex:25},{value:"Currently, all other basic graphics animations are redrawn after interpolation by Keyframe. For HTML graphics, the ideal situation is obviously to use CSS Animation directly.",paraId:83,tocIndex:26}]},9641:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(59243);const n=[{value:"You can refer to the ",paraId:0},{value:"<image>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" defines an image with a top-left vertex position of ",paraId:1},{value:"(200, 100)",paraId:1},{value:".",paraId:1},{value:"const image = new Image({\n    style: {\n        x: 200,\n        y: 100,\n        width: 200,\n        height: 200,\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n    },\n});\n",paraId:3},{value:"Usually we are used to centering on the image, which can be modified by the anchor ",paraId:4},{value:"anchor",paraId:5},{value:".",paraId:4},{value:"const image = new Image({\n    style: {\n        //...\n        anchor: [0.5, 0.5],\n    },\n});\n",paraId:6},{value:"If you encounter performance issues with large images, try turning on the ",paraId:7},{value:"enableLargeImageOptimization",paraId:8},{value:" configuration.",paraId:7},{value:"Inherits ",paraId:9,tocIndex:0},{value:"style property",paraId:10,tocIndex:0},{value:" from ",paraId:9,tocIndex:0},{value:"DisplayObject",paraId:11,tocIndex:0},{value:".",paraId:9,tocIndex:0},{value:"The default value is ",paraId:12,tocIndex:1},{value:"[0, 0]",paraId:12,tocIndex:1},{value:". For details, see ",paraId:12,tocIndex:1},{value:"DisplayObject's anchor",paraId:13,tocIndex:1},{value:".",paraId:12,tocIndex:1},{value:"The default value is ",paraId:14,tocIndex:2},{value:"left top",paraId:14,tocIndex:2},{value:". For details, see ",paraId:14,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:15,tocIndex:2},{value:".",paraId:14,tocIndex:2},{value:"The x-axis coordinates of the top-left vertex of the image in the local coordinate system.",paraId:16,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/x",paraId:17,tocIndex:4},{value:"Initial value",paraId:18,tocIndex:4},{value:"Applicable elements",paraId:19,tocIndex:4},{value:"Inheritable",paraId:20,tocIndex:4},{value:"Animatable",paraId:19,tocIndex:4},{value:"Computed value",paraId:21,tocIndex:4},{value:"'0'",paraId:19,tocIndex:4},{value:"-",paraId:19,tocIndex:4},{value:"no",paraId:19,tocIndex:4},{value:"yes",paraId:19,tocIndex:4},{value:"<percentage>",paraId:22,tocIndex:4},{value:" ",paraId:19,tocIndex:4},{value:"<length>",paraId:23,tocIndex:4},{value:"The y-axis coordinates of the top-left vertex of the image in the local coordinate system.",paraId:24,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/y",paraId:25,tocIndex:5},{value:"Initial value",paraId:26,tocIndex:5},{value:"Applicable elements",paraId:27,tocIndex:5},{value:"Inheritable",paraId:28,tocIndex:5},{value:"Animatable",paraId:27,tocIndex:5},{value:"Computed value",paraId:29,tocIndex:5},{value:"'0'",paraId:27,tocIndex:5},{value:"-",paraId:27,tocIndex:5},{value:"no",paraId:27,tocIndex:5},{value:"yes",paraId:27,tocIndex:5},{value:"<percentage>",paraId:30,tocIndex:5},{value:" ",paraId:27,tocIndex:5},{value:"<length>",paraId:31,tocIndex:5},{value:"Image sources, supports the following types:",paraId:32,tocIndex:6},{value:"string",paraId:33,tocIndex:6},{value:" Image address string, displayed after successful loading",paraId:33,tocIndex:6},{value:"HTMLImageElement",paraId:33,tocIndex:6},{value:" Create your own ",paraId:33,tocIndex:6},{value:"Image",paraId:33,tocIndex:6},{value:" object to create a G Image in the ",paraId:33,tocIndex:6},{value:"onload",paraId:33,tocIndex:6},{value:" callback, as shown in the following example.",paraId:33,tocIndex:6},{value:"import { Image as GImage, Canvas } from '@antv/g';\n\nlet image;\nconst img = new Image();\n\nimg.src =\n    'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ';\nimg.crossOrigin = 'Anonymous';\nimg.onload = () => {\n    image = new GImage({\n        style: {\n            x: 200,\n            y: 100,\n            width: 200,\n            height: 200,\n            src: img,\n        },\n    });\n    canvas.appendChild(image);\n};\n",paraId:34,tocIndex:6},{value:"Image width.",paraId:35,tocIndex:7},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/width",paraId:36,tocIndex:7},{value:"Initial value",paraId:37,tocIndex:7},{value:"Applicable elements",paraId:38,tocIndex:7},{value:"Inheritable",paraId:39,tocIndex:7},{value:"Animatable",paraId:38,tocIndex:7},{value:"Computed value",paraId:40,tocIndex:7},{value:"'0'",paraId:38,tocIndex:7},{value:"-",paraId:38,tocIndex:7},{value:"no",paraId:38,tocIndex:7},{value:"yes",paraId:38,tocIndex:7},{value:"<percentage>",paraId:41,tocIndex:7},{value:" ",paraId:38,tocIndex:7},{value:"<length>",paraId:42,tocIndex:7},{value:"Image height.",paraId:43,tocIndex:8},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/height",paraId:44,tocIndex:8},{value:"Initial value",paraId:45,tocIndex:8},{value:"Applicable elements",paraId:46,tocIndex:8},{value:"Inheritable",paraId:47,tocIndex:8},{value:"Animatable",paraId:46,tocIndex:8},{value:"Computed value",paraId:48,tocIndex:8},{value:"'0'",paraId:46,tocIndex:8},{value:"-",paraId:46,tocIndex:8},{value:"no",paraId:46,tocIndex:8},{value:"yes",paraId:46,tocIndex:8},{value:"<percentage>",paraId:49,tocIndex:8},{value:" ",paraId:46,tocIndex:8},{value:"<length>",paraId:50,tocIndex:8},{value:"Whether to keep aspect ratio, when enabled we can only provide height or width, the missing item will be calculated according to raw ratio. ",paraId:51,tocIndex:9},{value:"Example",paraId:52,tocIndex:9},{value:"const image = new Image({\n    style: {\n        width: 200,\n        keepAspectRatio: true,\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n    },\n});\n",paraId:53,tocIndex:9},{value:"Whether or not to always face the camera in 3D scenes, defaults to ",paraId:54,tocIndex:10},{value:"false",paraId:54,tocIndex:10},{value:', also known as the "billboard effect".',paraId:54,tocIndex:10},{value:"In ",paraId:55,tocIndex:10},{value:"example",paraId:56,tocIndex:10},{value:", the image is rendered compressed when the camera is rotated without being turned on:",paraId:55,tocIndex:10},{value:"Turning it on doesn't change the position of the image, but it will always face the camera. This is in line with what is usually required for 2D graphics like text in 3D scenes:",paraId:57,tocIndex:10},{value:"Rotation angle in billboard mode, clockwise in radians.",paraId:58,tocIndex:11},{value:"In ",paraId:59,tocIndex:11},{value:"example",paraId:60,tocIndex:11},{value:", we add a rotation angle to the image:",paraId:59,tocIndex:11},{value:"image.style.isBillboard = true;\nimage.style.billboardRotation = Math.PI / 8;\n",paraId:61,tocIndex:11},{value:'Whether or not to apply size attenuation in perspective projection. This option can be turned on if you want to keep the size consistent regardless of depth, following the "near big, far small" visual effect in perspective projection.',paraId:62,tocIndex:12},{value:"In ",paraId:63,tocIndex:12},{value:"example",paraId:64,tocIndex:12},{value:", we enable size attenuation for image:",paraId:63,tocIndex:12},{value:"image.style.isSizeAttenuation = true;\n",paraId:65,tocIndex:12}]},20845:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(27234);const n=[{value:"You can refer to the ",paraId:0},{value:"<line>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" defines a line with two endpoints ",paraId:1},{value:"[200, 100]",paraId:1},{value:" and ",paraId:1},{value:"[400, 100]",paraId:1},{value:", a line width of 2, and a dashed line.",paraId:1},{value:"const line1 = new Line({\n    style: {\n        x1: 200,\n        y1: 100,\n        x2: 400,\n        y2: 100,\n        stroke: '#1890FF',\n        lineWidth: 2,\n        lineDash: [10, 10],\n    },\n});\n",paraId:3},{value:"For a straight line, the default anchor point is defined at the top left vertex of the enclosing box, where the two endpoint coordinates ",paraId:4},{value:"[x1, y1]",paraId:4},{value:" ",paraId:4},{value:"[x2, y2]",paraId:4},{value:" are defined under the local coordinate system, so if you get the coordinates of the line in the local coordinate system at this point, you will get the coordinates of ",paraId:4},{value:"[x1, y1]",paraId:4},{value:", i.e. ",paraId:4},{value:"[200, 100]",paraId:4},{value:".",paraId:4},{value:"line1.getLocalPosition(); // [200, 100]\n",paraId:5},{value:"For the above line as ",paraId:6},{value:"(200, 100)",paraId:6},{value:". When we want to move this line 100 distance to the right along the X-axis, we can do three things:",paraId:6},{value:"Use ",paraId:7},{value:"translate",paraId:8},{value:" to translate a relative distance in the world coordinate system",paraId:7},{value:"Use ",paraId:7},{value:"setPosition",paraId:9},{value:" to set the absolute coordinates in the world coordinate system",paraId:7},{value:"Directly modify the x1/x2 property in the line definition",paraId:7},{value:"// 平移相对距离，此时 x1/x2 不变\nline1.translate(100, 0);\n// 或者，直接设置锚点位置\nline1.setPosition(200 + 100, 0);\n// 或者，直接移动两个端点\nline1.style.x1 = 200 + 100;\nline1.style.x2 = 400 + 100;\n",paraId:10},{value:"If you want to change the default anchor position, you can do so by using the ",paraId:11},{value:"anchor",paraId:11},{value:" property, for example, by using the midpoint of the line as the anchor point, where the coordinates in the line's local coordinate system remain the same, but the anchor point is moved to ",paraId:11},{value:"[200, 100]",paraId:11},{value:", so the display will change.",paraId:11},{value:"line.style.anchor = [0.5, 0.5];\nline.getLocalPosition(); // [200, 100]\n",paraId:12},{value:"Inherits ",paraId:13,tocIndex:0},{value:"style property",paraId:14,tocIndex:0},{value:" from ",paraId:13,tocIndex:0},{value:"DisplayObject",paraId:15,tocIndex:0},{value:".",paraId:13,tocIndex:0},{value:"The default value is ",paraId:16,tocIndex:1},{value:"[0, 0]",paraId:16,tocIndex:1},{value:". For details, see ",paraId:16,tocIndex:1},{value:"DisplayObject's anchor",paraId:17,tocIndex:1},{value:".",paraId:16,tocIndex:1},{value:"The default value is ",paraId:18,tocIndex:2},{value:"left top",paraId:18,tocIndex:2},{value:". For details, see ",paraId:18,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:19,tocIndex:2},{value:".",paraId:18,tocIndex:2},{value:"Default value is ",paraId:20,tocIndex:3},{value:"'1'",paraId:20,tocIndex:3},{value:". See ",paraId:20,tocIndex:3},{value:"DisplayObject's lineWidth",paraId:21,tocIndex:3},{value:" for details.",paraId:20,tocIndex:3},{value:"The x-axis coordinate of the first endpoint in the local coordinate system.",paraId:22,tocIndex:5},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/x1",paraId:23,tocIndex:5},{value:"Initial value",paraId:24,tocIndex:5},{value:"Applicable elements",paraId:25,tocIndex:5},{value:"Inheritable",paraId:26,tocIndex:5},{value:"Animatable",paraId:25,tocIndex:5},{value:"Computed value",paraId:27,tocIndex:5},{value:"'0'",paraId:25,tocIndex:5},{value:"-",paraId:25,tocIndex:5},{value:"no",paraId:25,tocIndex:5},{value:"yes",paraId:25,tocIndex:5},{value:"<percentage>",paraId:28,tocIndex:5},{value:" ",paraId:25,tocIndex:5},{value:"<length>",paraId:29,tocIndex:5},{value:"The y-axis coordinate of the first endpoint in the local coordinate system.",paraId:30,tocIndex:6},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/y1",paraId:31,tocIndex:6},{value:"Initial value",paraId:32,tocIndex:6},{value:"Applicable elements",paraId:33,tocIndex:6},{value:"Inheritable",paraId:34,tocIndex:6},{value:"Animatable",paraId:33,tocIndex:6},{value:"Computed value",paraId:35,tocIndex:6},{value:"'0'",paraId:33,tocIndex:6},{value:"-",paraId:33,tocIndex:6},{value:"no",paraId:33,tocIndex:6},{value:"yes",paraId:33,tocIndex:6},{value:"<percentage>",paraId:36,tocIndex:6},{value:" ",paraId:33,tocIndex:6},{value:"<length>",paraId:37,tocIndex:6},{value:"The z-axis coordinate of the first endpoint in the local coordinate system.",paraId:38,tocIndex:7},{value:"Initial value",paraId:39,tocIndex:7},{value:"Applicable elements",paraId:40,tocIndex:7},{value:"Inheritable",paraId:41,tocIndex:7},{value:"Animatable",paraId:40,tocIndex:7},{value:"Computed value",paraId:42,tocIndex:7},{value:"'0'",paraId:40,tocIndex:7},{value:"-",paraId:40,tocIndex:7},{value:"no",paraId:40,tocIndex:7},{value:"yes",paraId:40,tocIndex:7},{value:"<percentage>",paraId:43,tocIndex:7},{value:" ",paraId:40,tocIndex:7},{value:"<length>",paraId:44,tocIndex:7},{value:"The x-axis coordinate of the second endpoint in the local coordinate system.",paraId:45,tocIndex:8},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/x2",paraId:46,tocIndex:8},{value:"Initial value",paraId:47,tocIndex:8},{value:"Applicable elements",paraId:48,tocIndex:8},{value:"Inheritable",paraId:49,tocIndex:8},{value:"Animatable",paraId:48,tocIndex:8},{value:"Computed value",paraId:50,tocIndex:8},{value:"'0'",paraId:48,tocIndex:8},{value:"-",paraId:48,tocIndex:8},{value:"no",paraId:48,tocIndex:8},{value:"yes",paraId:48,tocIndex:8},{value:"<percentage>",paraId:51,tocIndex:8},{value:" ",paraId:48,tocIndex:8},{value:"<length>",paraId:52,tocIndex:8},{value:"The y-axis coordinate of the second endpoint in the local coordinate system.",paraId:53,tocIndex:9},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/y2",paraId:54,tocIndex:9},{value:"Initial value",paraId:55,tocIndex:9},{value:"Applicable elements",paraId:56,tocIndex:9},{value:"Inheritable",paraId:57,tocIndex:9},{value:"Animatable",paraId:56,tocIndex:9},{value:"Computed value",paraId:58,tocIndex:9},{value:"'0'",paraId:56,tocIndex:9},{value:"-",paraId:56,tocIndex:9},{value:"no",paraId:56,tocIndex:9},{value:"yes",paraId:56,tocIndex:9},{value:"<percentage>",paraId:59,tocIndex:9},{value:" ",paraId:56,tocIndex:9},{value:"<length>",paraId:60,tocIndex:9},{value:"The z-axis coordinate of the second endpoint in the local coordinate system.",paraId:61,tocIndex:10},{value:"Initial value",paraId:62,tocIndex:10},{value:"Applicable elements",paraId:63,tocIndex:10},{value:"Inheritable",paraId:64,tocIndex:10},{value:"Animatable",paraId:63,tocIndex:10},{value:"Computed value",paraId:65,tocIndex:10},{value:"'0'",paraId:63,tocIndex:10},{value:"-",paraId:63,tocIndex:10},{value:"no",paraId:63,tocIndex:10},{value:"yes",paraId:63,tocIndex:10},{value:"<percentage>",paraId:66,tocIndex:10},{value:" ",paraId:63,tocIndex:10},{value:"<length>",paraId:67,tocIndex:10},{value:"Effective in 3D scenes, always facing the screen, so the line width is not affected by the perspective projection image. The default value is ",paraId:68,tocIndex:11},{value:"false",paraId:68,tocIndex:11},{value:". ",paraId:68,tocIndex:11},{value:"example",paraId:69,tocIndex:11},{value:"You can refer to the ",paraId:70,tocIndex:12},{value:"attribute of the same name",paraId:70,tocIndex:12},{value:" of SVG.",paraId:70,tocIndex:12},{value:'Add a marker graphic to the "start point" of the line, where the "start point" is the endpoint defined by ',paraId:71,tocIndex:12},{value:"x1/y1",paraId:72,tocIndex:12},{value:".",paraId:71,tocIndex:12},{value:"In the following ",paraId:73,tocIndex:12},{value:"example",paraId:74,tocIndex:12},{value:", we first created an arrow using ",paraId:73,tocIndex:12},{value:"Path",paraId:75,tocIndex:12},{value:" and then added it to the start of the line with this property.",paraId:73,tocIndex:12},{value:"// Create a marker graphic\nconst arrowMarker = new Path({\n    style: {\n        path: 'M 10,10 L -10,0 L 10,-10 Z',\n        stroke: '#1890FF',\n        anchor: '0.5 0.5',\n        transformOrigin: 'center',\n    },\n});\n\nconst arrowLine = new Line({\n    style: {\n        x1: 200,\n        y1: 250,\n        x2: 400,\n        y2: 250,\n        stroke: '#1890FF',\n        lineWidth: 2,\n        markerStart: arrowMarker, // Placement on the \"start point\" of the line\n    },\n});\n",paraId:76,tocIndex:12},{value:"The marker graphic can be any graphic, and we will place it in the right place and adjust the orientation. When the definition of a line is changed, it will be adjusted automatically as well.",paraId:77,tocIndex:12},{value:"Of course you can also manually adjust its ",paraId:78,tocIndex:12},{value:"anchor",paraId:79,tocIndex:12},{value:", ",paraId:78,tocIndex:12},{value:"transformOrigin",paraId:80,tocIndex:12},{value:" and ",paraId:78,tocIndex:12},{value:"transform",paraId:81,tocIndex:12},{value:", for example in this ",paraId:78,tocIndex:12},{value:"example",paraId:82,tocIndex:12},{value:" we rotate ",paraId:78,tocIndex:12},{value:"Image",paraId:83,tocIndex:12},{value:" as a marker graphic, manually rotated by 90 degrees.",paraId:78,tocIndex:12},{value:"const imageMarker = new Image({\n    style: {\n        width: 50,\n        height: 50,\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n        anchor: [0.5, 0.5],\n        transformOrigin: 'center',\n        transform: 'rotate(90deg)',\n    },\n});\n",paraId:84,tocIndex:12},{value:"If you want to unset the marker graphic, you can set it to null or the empty string.",paraId:85,tocIndex:12},{value:"line.style.markerStart = null;\n",paraId:86,tocIndex:12},{value:"The relationship between the line and the marker graph in the implementation is parent-child.",paraId:87,tocIndex:12},{value:"Line\n  -> Path(#markerStart)\n  -> Path(#markerEnd)\n",paraId:88,tocIndex:12},{value:"This can also be found using ",paraId:89,tocIndex:12},{value:"childNodes",paraId:90,tocIndex:12},{value:".",paraId:89,tocIndex:12},{value:"line.style.markerStart = arrowHead;\nline.childNodes; // [Path]\n",paraId:91,tocIndex:12},{value:'The "start point" and "end point" can be set to the same marker graph, and internally it will first use [cloneNode](/en/api/builtin-objects/node## clonenode) to generate a new graph. So once we specify a marker graph, subsequent attempts to modify its properties cannot operate on the original graph, but need to be obtained by ',paraId:92,tocIndex:12},{value:"childNodes",paraId:93,tocIndex:12},{value:".",paraId:92,tocIndex:12},{value:"line.style.markerStart = arrowhead;\nline.style.markerEnd = arrowhead;\n\n// wrong\narrowhead.style.stroke = 'red';\n\n// correct!\nline.childNodes[0].style.stroke = 'red';\n",paraId:94,tocIndex:12},{value:'Add a marker graphic to the "endpoint" of the line, where "endpoint" is the endpoint defined by ',paraId:95,tocIndex:13},{value:"x2/y2",paraId:96,tocIndex:13},{value:".",paraId:95,tocIndex:13},{value:"You can refer to the ",paraId:97,tocIndex:13},{value:"attribute of the same name",paraId:97,tocIndex:13},{value:" of SVG.",paraId:97,tocIndex:13},{value:"Sometimes we want to adjust the position of the marker shape, so we provide the option to increase the offset along the line by a certain amount, positive offset inward and negative offset outward.",paraId:98,tocIndex:14},{value:"In ",paraId:99,tocIndex:14},{value:"example",paraId:100,tocIndex:14},{value:', we manipulate this property to give the line a "stretch effect".',paraId:99,tocIndex:14},{value:"It is worth noting that while the offset will make the line change visually, it does not affect the ",paraId:101,tocIndex:14},{value:"x1/y1/x2/y2",paraId:102,tocIndex:14},{value:" values of these attributes.",paraId:101,tocIndex:14},{value:"In ",paraId:103,tocIndex:14},{value:"example",paraId:104,tocIndex:14},{value:", the endpoints of the line coincide with the center of the circle at both ends, but to avoid the arrows coinciding with the nodes at both ends, they need to be indented a certain distance inward.",paraId:103,tocIndex:14},{value:"Initial value",paraId:105,tocIndex:14},{value:"Applicable elements",paraId:106,tocIndex:14},{value:"Inheritable",paraId:107,tocIndex:14},{value:"Animatable",paraId:106,tocIndex:14},{value:"Computed value",paraId:108,tocIndex:14},{value:"'0'",paraId:106,tocIndex:14},{value:"-",paraId:106,tocIndex:14},{value:"no",paraId:106,tocIndex:14},{value:"yes",paraId:106,tocIndex:14},{value:"<length>",paraId:109,tocIndex:14},{value:'Adjusts the position of the marker graphic at the "end point".',paraId:110,tocIndex:15},{value:"Initial value",paraId:111,tocIndex:15},{value:"Applicable elements",paraId:112,tocIndex:15},{value:"Inheritable",paraId:113,tocIndex:15},{value:"Animatable",paraId:112,tocIndex:15},{value:"Computed value",paraId:114,tocIndex:15},{value:"'0'",paraId:112,tocIndex:15},{value:"-",paraId:112,tocIndex:15},{value:"no",paraId:112,tocIndex:15},{value:"yes",paraId:112,tocIndex:15},{value:"<length>",paraId:115,tocIndex:15},{value:"Get the length of the line.",paraId:116,tocIndex:17},{value:"https://developer.mozilla.org/en-US/docs/Web/API/SVGGeometryElement/getTotalLength",paraId:117,tocIndex:17},{value:"line.getTotalLength(); // 200\n",paraId:118,tocIndex:17},{value:"Returns the point along the path at a given distance, controlled by a second optional parameter in the local or world coordinate system.",paraId:119,tocIndex:18},{value:"The parameters are as follows.",paraId:120,tocIndex:18},{value:"distance",paraId:121,tocIndex:18},{value:" mandatory, the distance value",paraId:121,tocIndex:18},{value:"inWorldSpace",paraId:121,tocIndex:18},{value:" optional, indicates if the distance is calculated in the world coordinate system. The default value is ",paraId:121,tocIndex:18},{value:"false",paraId:121,tocIndex:18},{value:".",paraId:121,tocIndex:18},{value:"where ",paraId:122,tocIndex:18},{value:"Point",paraId:122,tocIndex:18},{value:" has the format:",paraId:122,tocIndex:18},{value:"export type Point = {\n    x: number;\n    y: number;\n};\n",paraId:123,tocIndex:18},{value:"https://developer.mozilla.org/en-US/docs/Web/API/SVGGeometryElement/getPointAtLength",paraId:124,tocIndex:18},{value:"For example, to obtain the coordinates of a point in the local coordinate system on a line at a distance of 100 from the starting point.",paraId:125,tocIndex:18},{value:"line.getPointAtLength(100); // Point {x: 300, y: 100}\n",paraId:126,tocIndex:18},{value:"Get the coordinates of the point on the line in the local or world coordinate system according to the length scale (in the range ",paraId:127,tocIndex:19},{value:"[0-1]",paraId:127,tocIndex:19},{value:").",paraId:127,tocIndex:19},{value:"The parameters are as follows.",paraId:128,tocIndex:19},{value:"ratio",paraId:129,tocIndex:19},{value:" mandatory, the length ratio",paraId:129,tocIndex:19},{value:"inWorldSpace",paraId:129,tocIndex:19},{value:" optional, if or not it is calculated in the world coordinate system. The default value is ",paraId:129,tocIndex:19},{value:"false",paraId:129,tocIndex:19},{value:".",paraId:129,tocIndex:19},{value:"For example, to get the midpoint of the line defined above.",paraId:130,tocIndex:19},{value:"line.getPoint(0.5); // Point {x: 300, y: 100}\n",paraId:131,tocIndex:19},{value:"Requires use with ",paraId:132,tocIndex:20},{value:"g-webgl",paraId:133,tocIndex:20},{value:" renderer and ",paraId:132,tocIndex:20},{value:"g-plugin-3d",paraId:134,tocIndex:20},{value:" plug-in.",paraId:132,tocIndex:20},{value:"Extending endpoint coordinates to 3D.",paraId:135,tocIndex:20},{value:"new Line({\n    style: {\n        x1: 200,\n        y1: 100,\n        z1: 0, // Z 轴坐标\n        x2: 400,\n        y2: 100,\n        z2: 100, // Z 轴坐标\n    },\n});\n",paraId:136,tocIndex:20},{value:"2D lines are guaranteed to have a consistent width under orthogonal projection, but not under perspective projection. In some 3D scenes where the line width needs to be consistent at all times, you can turn on ",paraId:137,tocIndex:20},{value:"isBillboard",paraId:138,tocIndex:20},{value:", ",paraId:137,tocIndex:20},{value:"example",paraId:139,tocIndex:20}]},23457:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(62464);const n=[{value:"Use Path to define lines, dashes, arcs, Bezier curves, etc. The path contains a set of commands and arguments with different semantics, which can be found at: ",paraId:0},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Tutorial/Paths",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" defines a line from ",paraId:1},{value:"[100, 100]",paraId:1},{value:" to ",paraId:1},{value:"[200, 200]",paraId:1},{value:" in the local coordinate system.",paraId:1},{value:"const line = new Path({\n    style: {\n        path: [\n            ['M', 100, 100],\n            ['L', 200, 200],\n        ],\n        stroke: '#F04864',\n    },\n});\n",paraId:3},{value:"Inherits ",paraId:4,tocIndex:0},{value:"style property",paraId:5,tocIndex:0},{value:" from ",paraId:4,tocIndex:0},{value:"DisplayObject",paraId:6,tocIndex:0},{value:".",paraId:4,tocIndex:0},{value:"The default anchor definition is the top-left corner of the enclosing box, which can be changed by ",paraId:7,tocIndex:0},{value:"anchor",paraId:8,tocIndex:0},{value:".",paraId:7,tocIndex:0},{value:"On this point we refer to the actual performance of SVG, the following figure as an example we defined a segment of arc with ",paraId:9,tocIndex:0},{value:"[100, 100]",paraId:9,tocIndex:0},{value:" as the starting point, obviously its top left corner of the enclosing box vertex is not ",paraId:9,tocIndex:0},{value:"[0, 0]",paraId:9,tocIndex:0},{value:" or ",paraId:9,tocIndex:0},{value:"[100, 100]",paraId:9,tocIndex:0},{value:", but needs to be calculated according to the real shape of the path, we will use this calculation as the default anchor position, but also the coordinates of the local coordinate system: ",paraId:9,tocIndex:0},{value:"[0, 0]",paraId:9,tocIndex:0},{value:".",paraId:9,tocIndex:0},{value:"And let's say this linear path ",paraId:10,tocIndex:0},{value:"[['M', 100, 100], ['L', 200, 200]]",paraId:10,tocIndex:0},{value:' has a "location" of ',paraId:10,tocIndex:0},{value:"[100, 100]",paraId:10,tocIndex:0},{value:" in the local coordinate system.",paraId:10,tocIndex:0},{value:"const line = new Path({\n    style: {\n        path: [\n            ['M', 100, 100],\n            ['L', 200, 200],\n        ],\n        stroke: '#F04864',\n    },\n});\n\nline.getLocalPosition(); // [100, 100];\nline.getBounds(); // 包围盒 { min: [100, 100], max: [200, 200] }\nline.translateLocal(100, 0); // 沿 X 轴平移\n",paraId:11,tocIndex:0},{value:"The default value is ",paraId:12,tocIndex:1},{value:"[0, 0]",paraId:12,tocIndex:1},{value:". For details, see ",paraId:12,tocIndex:1},{value:"DisplayObject's anchor",paraId:13,tocIndex:1},{value:".",paraId:12,tocIndex:1},{value:"The default value is ",paraId:14,tocIndex:2},{value:"left top",paraId:14,tocIndex:2},{value:". For details, see ",paraId:14,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:15,tocIndex:2},{value:".",paraId:14,tocIndex:2},{value:"Default value is ",paraId:16,tocIndex:3},{value:"'1'",paraId:16,tocIndex:3},{value:". See ",paraId:16,tocIndex:3},{value:"DisplayObject's lineWidth",paraId:17,tocIndex:3},{value:" for details.",paraId:16,tocIndex:3},{value:"Default value is ",paraId:18,tocIndex:4},{value:"'4'",paraId:18,tocIndex:4},{value:". See ",paraId:18,tocIndex:4},{value:"DisplayObject's miterLimit",paraId:19,tocIndex:4},{value:"Effective in 3D scenes, always facing the screen, so the line width is not affected by the perspective projection image. The default value is ",paraId:20,tocIndex:5},{value:"false",paraId:20,tocIndex:5},{value:".",paraId:20,tocIndex:5},{value:'When isBillboard is enabled, whether or not to apply size attenuation in perspective projection. This option can be turned on if you want to keep the size consistent regardless of depth, following the "near big, far small" visual effect in perspective projection.',paraId:21,tocIndex:6},{value:"Paths, both ",paraId:22,tocIndex:8},{value:"string",paraId:22,tocIndex:8},{value:" and ",paraId:22,tocIndex:8},{value:"Array",paraId:22,tocIndex:8},{value:" forms are supported, see ",paraId:22,tocIndex:8},{value:"SVG path",paraId:22,tocIndex:8},{value:".",paraId:22,tocIndex:8},{value:"String form: ",paraId:23,tocIndex:8},{value:"M 100,100 L 200,200",paraId:23,tocIndex:8},{value:"Array form: ",paraId:23,tocIndex:8},{value:"[ [ 'M', 100, 100 ], [ 'L', 200, 200 ]]",paraId:23,tocIndex:8},{value:"https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/path",paraId:24,tocIndex:8},{value:"Alias for the ",paraId:25,tocIndex:9},{value:"path",paraId:26,tocIndex:9},{value:" attribute, consistent with the ",paraId:25,tocIndex:9},{value:"<path>",paraId:25,tocIndex:9},{value:" naming in SVG.",paraId:25,tocIndex:9},{value:"Since Path can be closed by ",paraId:27,tocIndex:10},{value:"Z",paraId:27,tocIndex:10},{value:' command, the definition of "start point" differs in two cases.',paraId:27,tocIndex:10},{value:"If it is not closed, you can refer to the ",paraId:28,tocIndex:10},{value:"markerStart",paraId:29,tocIndex:10},{value:" attribute of ",paraId:28,tocIndex:10},{value:"Polyline",paraId:30,tocIndex:10},{value:".",paraId:28,tocIndex:10},{value:"If it is closed, you can refer to the ",paraId:28,tocIndex:10},{value:"markerStart",paraId:31,tocIndex:10},{value:" property of ",paraId:28,tocIndex:10},{value:"Polygon",paraId:32,tocIndex:10},{value:".",paraId:28,tocIndex:10},{value:'For example, in the following figure, where markerStart and markerEnd are also specified as "arrows", the effect of an unclosed path is shown on the left, and the effect of a closed path is shown on the right.',paraId:33,tocIndex:10},{value:"In this ",paraId:34,tocIndex:10},{value:"example",paraId:35,tocIndex:10},{value:", we have placed an arrow at the beginning of the Path.",paraId:34,tocIndex:10},{value:"const arrowMarker = new Path({\n    style: {\n        path: 'M 10,10 L -10,0 L 10,-10 Z',\n        stroke: '#1890FF',\n        anchor: '0.5 0.5',\n        transformOrigin: 'center',\n    },\n});\n\npath.style.markerStart = arrowMarker;\n",paraId:36,tocIndex:10},{value:"See the ",paraId:37,tocIndex:11},{value:"markerEnd",paraId:38,tocIndex:11},{value:" attribute of ",paraId:37,tocIndex:11},{value:"Polyline",paraId:39,tocIndex:11},{value:".",paraId:37,tocIndex:11},{value:"Since Path can be closed by the ",paraId:40,tocIndex:11},{value:"Z",paraId:40,tocIndex:11},{value:' command, the definition of the "end point" differs in two cases.',paraId:40,tocIndex:11},{value:"If it is not closed, you can refer to the ",paraId:41,tocIndex:11},{value:"markerEnd",paraId:42,tocIndex:11},{value:" attribute of ",paraId:41,tocIndex:11},{value:"Polyline",paraId:43,tocIndex:11},{value:".",paraId:41,tocIndex:11},{value:"If closed, see the ",paraId:41,tocIndex:11},{value:"markerEnd",paraId:44,tocIndex:11},{value:" property of ",paraId:41,tocIndex:11},{value:"Polygon",paraId:45,tocIndex:11},{value:".",paraId:41,tocIndex:11},{value:"In this ",paraId:46,tocIndex:11},{value:"example",paraId:47,tocIndex:11},{value:", we have placed an image at the termination point of the polygon.",paraId:46,tocIndex:11},{value:"const imageMarker = new Image({\n    style: {\n        width: 50,\n        height: 50,\n        anchor: [0.5, 0.5],\n        transformOrigin: 'center',\n        transform: 'rotate(90deg)',\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n    },\n});\n\npath.style.markerEnd = imageMarker;\n",paraId:48,tocIndex:11},{value:"You can refer to SVG's ",paraId:49,tocIndex:12},{value:"attribute of the same name",paraId:49,tocIndex:12},{value:".",paraId:49,tocIndex:12},{value:'Place marker graphics on each vertex of the path except for the "start" and "end" points. In the internal implementation, these vertices are actually control points for the third-order Bessel curve, since we convert some of the commands in the path to C commands.',paraId:50,tocIndex:12},{value:"For example, in the following figure, a ",paraId:51,tocIndex:12},{value:"Circle",paraId:52,tocIndex:12},{value:" is placed on each vertex of the path except the first and last.",paraId:51,tocIndex:12},{value:"const circleMarker = new Circle({\n    style: {\n        r: 10,\n        stroke: '#1890FF',\n    },\n});\n\npath.style.markerMid = circleMarker;\n",paraId:53,tocIndex:12},{value:"See the ",paraId:54,tocIndex:13},{value:"markerStartOffset",paraId:55,tocIndex:13},{value:" property of ",paraId:54,tocIndex:13},{value:"Polyline",paraId:56,tocIndex:13},{value:". marker will move along the tangent of the first segment in the path. The marker will be moved in the direction of the first segment of the path, and the body path will be lengthened or shortened accordingly.",paraId:54,tocIndex:13},{value:"See the ",paraId:57,tocIndex:13},{value:"markerStartOffset",paraId:58,tocIndex:13},{value:" property of ",paraId:57,tocIndex:13},{value:"Polyline",paraId:59,tocIndex:13},{value:'. marker will move along the tangent of the first section of the path. The marker will move in the direction of the tangent of the first segment in the path, and the body path will be extended or shortened accordingly. Note that the stretching distance of the body path is also limited, and when it exceeds the length of the first segment, a "bend" effect will occur, as shown in the following figure.',paraId:57,tocIndex:13},{value:'This property is therefore suitable for "fine-tuning", rather than drastically changing the path definition.',paraId:60,tocIndex:13},{value:"Initial value",paraId:61,tocIndex:13},{value:"Applicable elements",paraId:62,tocIndex:13},{value:"Inheritable",paraId:63,tocIndex:13},{value:"Animatable",paraId:62,tocIndex:13},{value:"Computed value",paraId:64,tocIndex:13},{value:"'0'",paraId:62,tocIndex:13},{value:"-",paraId:62,tocIndex:13},{value:"no",paraId:62,tocIndex:13},{value:"yes",paraId:62,tocIndex:13},{value:"<length>",paraId:65,tocIndex:13},{value:"See the ",paraId:66,tocIndex:14},{value:"markerEndOffset",paraId:67,tocIndex:14},{value:" property of ",paraId:66,tocIndex:14},{value:"Polyline",paraId:68,tocIndex:14},{value:". marker will move along the tangent direction of the last section of the path. The marker will move in the direction of the tangent of the last section of the path, and the body path will be extended or shortened accordingly.",paraId:66,tocIndex:14},{value:"Initial value",paraId:69,tocIndex:14},{value:"Applicable elements",paraId:70,tocIndex:14},{value:"Inheritable",paraId:71,tocIndex:14},{value:"Animatable",paraId:70,tocIndex:14},{value:"Computed value",paraId:72,tocIndex:14},{value:"'0'",paraId:70,tocIndex:14},{value:"-",paraId:70,tocIndex:14},{value:"no",paraId:70,tocIndex:14},{value:"yes",paraId:70,tocIndex:14},{value:"<length>",paraId:73,tocIndex:14},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/SVGGeometryElement/getTotalLength",paraId:74,tocIndex:16},{value:"For example, get the length of the following line.",paraId:75,tocIndex:16},{value:"const path = new Path({\n    style: {\n        path: [\n            ['M', 100, 100],\n            ['L', 100, 200],\n        ],\n        stroke: '#F04864',\n    },\n});\n\npath.getTotalLength(); // 100\n",paraId:76,tocIndex:16},{value:"If it is an illegal path, return 0.",paraId:77,tocIndex:16},{value:"const path = new Path({\n    style: {\n        path: [['XXXX', 100, 100]],\n        stroke: '#F04864',\n    },\n});\n\npath.getTotalLength(); // 0\n",paraId:78,tocIndex:16},{value:"Get the coordinates of the point on the line in the local or world coordinate system according to the length scale (in the range ",paraId:79,tocIndex:17},{value:"[0-1]",paraId:79,tocIndex:17},{value:").",paraId:79,tocIndex:17},{value:"The parameters are as follows.",paraId:80,tocIndex:17},{value:"ratio",paraId:81,tocIndex:17},{value:" mandatory, the length ratio",paraId:81,tocIndex:17},{value:"inWorldSpace",paraId:81,tocIndex:17},{value:" optional, if or not it is calculated in the world coordinate system. The default value is ",paraId:81,tocIndex:17},{value:"false",paraId:81,tocIndex:17},{value:".",paraId:81,tocIndex:17},{value:"where ",paraId:82,tocIndex:17},{value:"Point",paraId:82,tocIndex:17},{value:" has the format :",paraId:82,tocIndex:17},{value:"export type Point = {\n    x: number;\n    y: number;\n};\n",paraId:83,tocIndex:17},{value:"For example, get the coordinates of the midpoint of the following line.",paraId:84,tocIndex:17},{value:"const path = new Path({\n    style: {\n        path: [\n            ['M', 100, 100],\n            ['L', 100, 200],\n        ],\n        stroke: '#F04864',\n    },\n});\n\npath.getPoint(0.5); // Point {x: 100, y: 150}\n",paraId:85,tocIndex:17},{value:"It is worth noting that if the value range ",paraId:86,tocIndex:17},{value:"[0-1]",paraId:86,tocIndex:17},{value:" is exceeded, the coordinates of the point at the beginning and end of the path will be returned. For illegal paths, the method returns ",paraId:86,tocIndex:17},{value:"Point {x: NaN, y: NaN}",paraId:86,tocIndex:17},{value:".",paraId:86,tocIndex:17},{value:"Also the transformations applied on the original path, in the local coordinate system, will be applied to the returned points. For example, in this ",paraId:87,tocIndex:17},{value:"example",paraId:88,tocIndex:17},{value:", the path itself is translated and scaled by.",paraId:87,tocIndex:17},{value:"Returns the point along the path at a given distance, controlled by a second optional parameter in the local or world coordinate system.",paraId:89,tocIndex:18},{value:"The parameters are as follows.",paraId:90,tocIndex:18},{value:"distance",paraId:91,tocIndex:18},{value:" mandatory, the distance value",paraId:91,tocIndex:18},{value:"inWorldSpace",paraId:91,tocIndex:18},{value:" optional, indicates if the distance is calculated in the world coordinate system. The default value is ",paraId:91,tocIndex:18},{value:"false",paraId:91,tocIndex:18},{value:".",paraId:91,tocIndex:18},{value:"https://developer.mozilla.org/en-US/docs/Web/API/SVGGeometryElement/getPointAtLength",paraId:92,tocIndex:18},{value:"path.getPointAtLength(100); // Point {x: 300, y: 100}\n",paraId:93,tocIndex:18},{value:"Get the tangent vector of the starting point, shaped as : ",paraId:94,tocIndex:19},{value:"[[10, 10], [20, 20]]",paraId:94,tocIndex:19},{value:"Get the tangent vector of the ending point, shaped as : ",paraId:95,tocIndex:20},{value:"[[10, 10], [20, 20]]",paraId:95,tocIndex:20}]},63306:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(96249);const n=[{value:"You can refer to the ",paraId:0},{value:"<polygon>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" defines a polygon.",paraId:1},{value:"const polygon = new Polygon({\n    style: {\n        points: [\n            [0, 0],\n            [100, 0],\n            [100, 100],\n            [0, 100],\n        ],\n        stroke: '#1890FF',\n        lineWidth: 2,\n    },\n});\n",paraId:3},{value:"Inherits ",paraId:4,tocIndex:0},{value:"style property",paraId:5,tocIndex:0},{value:" from ",paraId:4,tocIndex:0},{value:"DisplayObject",paraId:6,tocIndex:0},{value:".",paraId:4,tocIndex:0},{value:"The default value is ",paraId:7,tocIndex:1},{value:"[0, 0]",paraId:7,tocIndex:1},{value:". For details, see ",paraId:7,tocIndex:1},{value:"DisplayObject's anchor",paraId:8,tocIndex:1},{value:".",paraId:7,tocIndex:1},{value:"The default value is ",paraId:9,tocIndex:2},{value:"left top",paraId:9,tocIndex:2},{value:". For details, see ",paraId:9,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:10,tocIndex:2},{value:".",paraId:9,tocIndex:2},{value:"Default value is ",paraId:11,tocIndex:3},{value:"'1'",paraId:11,tocIndex:3},{value:". See ",paraId:11,tocIndex:3},{value:"DisplayObject's lineWidth",paraId:12,tocIndex:3},{value:" for details.",paraId:11,tocIndex:3},{value:"Default value is ",paraId:13,tocIndex:4},{value:"'4'",paraId:13,tocIndex:4},{value:". See ",paraId:13,tocIndex:4},{value:"DisplayObject's miterLimit",paraId:14,tocIndex:4},{value:"The following two writing methods are supported.",paraId:15,tocIndex:6},{value:"[number, number][]",paraId:16,tocIndex:6},{value:" an array of points",paraId:16,tocIndex:6},{value:"string",paraId:16,tocIndex:6},{value:" points are separated by spaces, e.g., ",paraId:16,tocIndex:6},{value:"'100,10 250,150 200,110'",paraId:16,tocIndex:6},{value:"Thus the following two ways of writing are equivalent.",paraId:17,tocIndex:6},{value:"polygon.style.points = '100,10 250,150 200,110';\npolygon.style.points = [\n    [100, 10],\n    [250, 150],\n    [200, 110],\n];\n",paraId:18,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/points",paraId:19,tocIndex:6},{value:"See ",paraId:20,tocIndex:7},{value:"markerStart",paraId:21,tocIndex:7},{value:" property of ",paraId:20,tocIndex:7},{value:"Polyline",paraId:22,tocIndex:7},{value:".",paraId:20,tocIndex:7},{value:"But unlike Polyline, since polygons are ",paraId:23,tocIndex:7},{value:"closed",paraId:23,tocIndex:7},{value:', the positions of the "start" and "end" points coincide exactly, as determined by the first point in ',paraId:23,tocIndex:7},{value:"points",paraId:24,tocIndex:7},{value:". This is also consistent with the native SVG implementation, and the following figure shows the overlap effect after defining both markerStart and markerEnd.",paraId:23,tocIndex:7},{value:"In this ",paraId:25,tocIndex:7},{value:"example",paraId:26,tocIndex:7},{value:", we have placed an arrow at the start of the polygon.",paraId:25,tocIndex:7},{value:"const arrowMarker = new Path({\n    style: {\n        path: 'M 10,10 L -10,0 L 10,-10 Z',\n        stroke: '#1890FF',\n        anchor: '0.5 0.5',\n        transformOrigin: 'center',\n    },\n});\n\npolygon.style.markerStart = arrowMarker;\n",paraId:27,tocIndex:7},{value:"See ",paraId:28,tocIndex:8},{value:"markerEnd",paraId:29,tocIndex:8},{value:" property of ",paraId:28,tocIndex:8},{value:"Polyline",paraId:30,tocIndex:8},{value:".",paraId:28,tocIndex:8},{value:"However, unlike Polyline, since polygons are ",paraId:31,tocIndex:8},{value:"closed",paraId:31,tocIndex:8},{value:', the positions of the "start point" and "end point" coincide exactly. The "end point" is determined by the first point in ',paraId:31,tocIndex:8},{value:"points",paraId:32,tocIndex:8},{value:".",paraId:31,tocIndex:8},{value:"In this ",paraId:33,tocIndex:8},{value:"example",paraId:34,tocIndex:8},{value:", we have placed a picture at the termination point of the polygon.",paraId:33,tocIndex:8},{value:"const imageMarker = new Image({\n    style: {\n        width: 50,\n        height: 50,\n        anchor: [0.5, 0.5],\n        transformOrigin: 'center',\n        transform: 'rotate(90deg)',\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n    },\n});\n\npolygon.style.markerEnd = imageMarker;\n",paraId:35,tocIndex:8},{value:"You can refer to the ",paraId:36,tocIndex:9},{value:"attribute of the same name",paraId:36,tocIndex:9},{value:" of SVG.",paraId:36,tocIndex:9},{value:'Place markers on each vertex of the polygon except for the "start" and "end" points.',paraId:37,tocIndex:9},{value:"For example, in the following figure, a ",paraId:38,tocIndex:9},{value:"Circle",paraId:39,tocIndex:9},{value:" is placed on each vertex of the polygon except for the beginning and end.",paraId:38,tocIndex:9},{value:"const circleMarker = new Circle({\n    style: {\n        r: 10,\n        stroke: '#1890FF',\n    },\n});\n\npolygon.style.markerMid = circleMarker;\n",paraId:40,tocIndex:9},{value:"See the ",paraId:41,tocIndex:10},{value:"markerStartOffset",paraId:42,tocIndex:10},{value:" property of ",paraId:41,tocIndex:10},{value:"Polyline",paraId:43,tocIndex:10},{value:".",paraId:41,tocIndex:10},{value:"Moving the marker graphic in the direction of the first line segment of the polygon will change the shape of the original polygon at the same time.",paraId:44,tocIndex:10},{value:"Initial value",paraId:45,tocIndex:10},{value:"Applicable elements",paraId:46,tocIndex:10},{value:"Inheritable",paraId:47,tocIndex:10},{value:"Animatable",paraId:46,tocIndex:10},{value:"Computed value",paraId:48,tocIndex:10},{value:"'0'",paraId:46,tocIndex:10},{value:"-",paraId:46,tocIndex:10},{value:"no",paraId:46,tocIndex:10},{value:"yes",paraId:46,tocIndex:10},{value:"<length>",paraId:49,tocIndex:10},{value:"See the ",paraId:50,tocIndex:11},{value:"markerEndOffset",paraId:51,tocIndex:11},{value:" property of ",paraId:50,tocIndex:11},{value:"Polyline",paraId:52,tocIndex:11},{value:".",paraId:50,tocIndex:11},{value:"Initial value",paraId:53,tocIndex:11},{value:"Applicable elements",paraId:54,tocIndex:11},{value:"Inheritable",paraId:55,tocIndex:11},{value:"Animatable",paraId:54,tocIndex:11},{value:"Computed value",paraId:56,tocIndex:11},{value:"'0'",paraId:54,tocIndex:11},{value:"-",paraId:54,tocIndex:11},{value:"no",paraId:54,tocIndex:11},{value:"yes",paraId:54,tocIndex:11},{value:"<length>",paraId:57,tocIndex:11}]},20525:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(56666);const n=[{value:"You can refer to the ",paraId:0},{value:"<polyline>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" defines a polyline with the following endpoints in order",paraId:1},{value:"const polyline = new Polyline({\n    style: {\n        points: [\n            [50, 50],\n            [100, 50],\n            [100, 100],\n            [150, 100],\n            [150, 150],\n            [200, 150],\n            [200, 200],\n            [250, 200],\n            [250, 250],\n            [300, 250],\n            [300, 300],\n            [350, 300],\n            [350, 350],\n            [400, 350],\n            [400, 400],\n            [450, 400],\n        ],\n        stroke: '#1890FF',\n        lineWidth: 2,\n    },\n});\n",paraId:3},{value:"For the line, the default anchor point is defined at the top left vertex of the enclosing box, where the coordinates of each endpoint are defined in the local coordinate system. So if we get the coordinates of the above line in the local coordinate system, we will get the coordinates of the upper left corner of the enclosing box, which also happens to be the coordinates of the first vertex, i.e. ",paraId:4},{value:"[50, 50]",paraId:4},{value:".",paraId:4},{value:"polyline.getLocalPosition(); // [50, 50]\n",paraId:5},{value:"Inherits ",paraId:6,tocIndex:0},{value:"style property",paraId:7,tocIndex:0},{value:" from ",paraId:6,tocIndex:0},{value:"DisplayObject",paraId:8,tocIndex:0},{value:".",paraId:6,tocIndex:0},{value:"The default value is ",paraId:9,tocIndex:1},{value:"[0, 0]",paraId:9,tocIndex:1},{value:". For details, see ",paraId:9,tocIndex:1},{value:"DisplayObject's anchor",paraId:10,tocIndex:1},{value:".",paraId:9,tocIndex:1},{value:"The default value is ",paraId:11,tocIndex:2},{value:"left top",paraId:11,tocIndex:2},{value:". For details, see ",paraId:11,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:12,tocIndex:2},{value:".",paraId:11,tocIndex:2},{value:"Default value is ",paraId:13,tocIndex:3},{value:"'1'",paraId:13,tocIndex:3},{value:". See ",paraId:13,tocIndex:3},{value:"DisplayObject's lineWidth",paraId:14,tocIndex:3},{value:" for details.",paraId:13,tocIndex:3},{value:"Default value is ",paraId:15,tocIndex:4},{value:"'4'",paraId:15,tocIndex:4},{value:". See ",paraId:15,tocIndex:4},{value:"DisplayObject's miterLimit",paraId:16,tocIndex:4},{value:"The following two writing methods are supported.",paraId:17,tocIndex:6},{value:"[number, number][]",paraId:18,tocIndex:6},{value:" an array of points",paraId:18,tocIndex:6},{value:"string",paraId:18,tocIndex:6},{value:" points are separated by spaces, e.g., ",paraId:18,tocIndex:6},{value:"'100,10 250,150 200,110'",paraId:18,tocIndex:6},{value:"Thus the following two ways of writing are equivalent.",paraId:19,tocIndex:6},{value:"polyline.style.points = '100,10 250,150 200,110';\npolyline.style.points = [\n    [100, 10],\n    [250, 150],\n    [200, 110],\n];\n",paraId:20,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/points",paraId:21,tocIndex:6},{value:"See the ",paraId:22,tocIndex:7},{value:"markerStart",paraId:23,tocIndex:7},{value:" property of ",paraId:22,tocIndex:7},{value:"Line",paraId:24,tocIndex:7},{value:".",paraId:22,tocIndex:7},{value:'The "start point" is determined by the first point in ',paraId:25,tocIndex:7},{value:"points",paraId:26,tocIndex:7},{value:".",paraId:25,tocIndex:7},{value:"In this ",paraId:27,tocIndex:7},{value:"example",paraId:28,tocIndex:7},{value:", we have placed an arrow at the start of the line.",paraId:27,tocIndex:7},{value:"const arrowMarker = new Path({\n    style: {\n        path: 'M 10,10 L -10,0 L 10,-10 Z',\n        stroke: '#1890FF',\n        anchor: '0.5 0.5',\n        transformOrigin: 'center',\n    },\n});\n\npolyline.style.markerStart = arrowMarker;\n",paraId:29,tocIndex:7},{value:"See the ",paraId:30,tocIndex:8},{value:"markerEnd",paraId:31,tocIndex:8},{value:" attribute of ",paraId:30,tocIndex:8},{value:"Line",paraId:32,tocIndex:8},{value:".",paraId:30,tocIndex:8},{value:'The "end point" is determined by the last point in ',paraId:33,tocIndex:8},{value:"points",paraId:34,tocIndex:8},{value:".",paraId:33,tocIndex:8},{value:"In this ",paraId:35,tocIndex:8},{value:"example",paraId:36,tocIndex:8},{value:", we have placed an image at the termination point of the line.",paraId:35,tocIndex:8},{value:"const imageMarker = new Image({\n    style: {\n        width: 50,\n        height: 50,\n        anchor: [0.5, 0.5],\n        transformOrigin: 'center',\n        transform: 'rotate(90deg)',\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n    },\n});\n\npolyline.style.markerEnd = imageMarker;\n",paraId:37,tocIndex:8},{value:"You can refer to the SVG's ",paraId:38,tocIndex:9},{value:"attribute of the same name",paraId:38,tocIndex:9},{value:".",paraId:38,tocIndex:9},{value:'Place markers on each vertex of the line except for the "start" and "end" points.',paraId:39,tocIndex:9},{value:"For example, in the following figure, a [Circle] (/en/api/basic/circle) is placed on each vertex of the line except for the beginning and end.",paraId:40,tocIndex:9},{value:"const circleMarker = new Circle({\n    style: {\n        r: 10,\n        stroke: '#1890FF',\n    },\n});\n\npolyline.style.markerMid = circleMarker;\n",paraId:41,tocIndex:9},{value:"You can refer to the ",paraId:42,tocIndex:10},{value:"markerStartOffset",paraId:43,tocIndex:10},{value:" property of ",paraId:42,tocIndex:10},{value:"Line",paraId:44,tocIndex:10},{value:".",paraId:42,tocIndex:10},{value:"Moves the marker graphic in the direction of the first line segment of the fold. Note that if the offset distance exceeds the length of the original line segment, it will extend in the opposite direction.",paraId:45,tocIndex:10},{value:"Initial value",paraId:46,tocIndex:10},{value:"Applicable elements",paraId:47,tocIndex:10},{value:"Inheritable",paraId:48,tocIndex:10},{value:"Animatable",paraId:47,tocIndex:10},{value:"Computed value",paraId:49,tocIndex:10},{value:"'0'",paraId:47,tocIndex:10},{value:"-",paraId:47,tocIndex:10},{value:"no",paraId:47,tocIndex:10},{value:"yes",paraId:47,tocIndex:10},{value:"<length>",paraId:50,tocIndex:10},{value:"You can refer to the ",paraId:51,tocIndex:11},{value:"markerEndOffset",paraId:52,tocIndex:11},{value:" property of ",paraId:51,tocIndex:11},{value:"Line",paraId:53,tocIndex:11},{value:".",paraId:51,tocIndex:11},{value:"Moves the marker graphic in the direction of the last line segment of the fold. Note that if the offset distance exceeds the length of the original line segment, it will extend in the opposite direction. In this ",paraId:54,tocIndex:11},{value:"example",paraId:55,tocIndex:11},{value:", we use this property to move the marker graphic.",paraId:54,tocIndex:11},{value:"Initial value",paraId:56,tocIndex:11},{value:"Applicable elements",paraId:57,tocIndex:11},{value:"Inheritable",paraId:58,tocIndex:11},{value:"Animatable",paraId:57,tocIndex:11},{value:"Computed value",paraId:59,tocIndex:11},{value:"'0'",paraId:57,tocIndex:11},{value:"-",paraId:57,tocIndex:11},{value:"no",paraId:57,tocIndex:11},{value:"yes",paraId:57,tocIndex:11},{value:"<length>",paraId:60,tocIndex:11},{value:"Effective in 3D scenes, always facing the screen, so the line width is not affected by the perspective projection image. The default value is ",paraId:61,tocIndex:12},{value:"false",paraId:61,tocIndex:12},{value:".",paraId:61,tocIndex:12},{value:"Get the length of the polyline.",paraId:62,tocIndex:14},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/SVGGeometryElement/getTotalLength",paraId:63,tocIndex:14},{value:"Get the coordinates of the point on the line in the local or world coordinate system according to the length scale (in the range ",paraId:64,tocIndex:15},{value:"[0-1]",paraId:64,tocIndex:15},{value:").",paraId:64,tocIndex:15},{value:"The parameters are as follows.",paraId:65,tocIndex:15},{value:"ratio",paraId:66,tocIndex:15},{value:" mandatory, the length ratio",paraId:66,tocIndex:15},{value:"inWorldSpace",paraId:66,tocIndex:15},{value:" optional, if or not it is calculated in the world coordinate system. The default value is ",paraId:66,tocIndex:15},{value:"false",paraId:66,tocIndex:15},{value:".",paraId:66,tocIndex:15},{value:"where ",paraId:67,tocIndex:15},{value:"Point",paraId:67,tocIndex:15},{value:" has the format :",paraId:67,tocIndex:15},{value:"export type Point = {\n    x: number;\n    y: number;\n};\n",paraId:68,tocIndex:15},{value:"Returns the point along the path at a given distance, controlled by a second optional parameter in the local or world coordinate system.",paraId:69,tocIndex:16},{value:"The parameters are as follows.",paraId:70,tocIndex:16},{value:"distance",paraId:71,tocIndex:16},{value:" mandatory, the distance value",paraId:71,tocIndex:16},{value:"inWorldSpace",paraId:71,tocIndex:16},{value:" optional, indicates if the distance is calculated in the world coordinate system. The default value is ",paraId:71,tocIndex:16},{value:"false",paraId:71,tocIndex:16},{value:".",paraId:71,tocIndex:16},{value:"https://developer.mozilla.org/en-US/docs/Web/API/SVGGeometryElement/getPointAtLength",paraId:72,tocIndex:16},{value:"polyline.getPointAtLength(100); // Point {x: 300, y: 100}\n",paraId:73,tocIndex:16},{value:"Get the tangent vector of the starting point, shaped as : ",paraId:74,tocIndex:17},{value:"[[10, 10], [20, 20]]",paraId:74,tocIndex:17},{value:"Get the tangent vector of the ending point, shaped as : ",paraId:75,tocIndex:18},{value:"[[10, 10], [20, 20]]",paraId:75,tocIndex:18},{value:"Same as Line, Polyline can also be defined under 3D space:",paraId:76,tocIndex:19},{value:"const polyline = new Polyline({\n    style: {\n        stroke: '#1890FF',\n        lineWidth: 10,\n        lineCap: 'round',\n        lineJoin: 'round',\n        points: [\n            [50, 50, 0],\n            [100, 50, 100],\n            [100, 100, 0],\n            [150, 100, 100],\n            [150, 150, 0],\n            [200, 150, 0],\n            [200, 200, 0],\n            [250, 200, 0],\n        ],\n    },\n});\n",paraId:77,tocIndex:19},{value:"Example",paraId:78}]},39933:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(28463);const n=[{value:"You can refer to the ",paraId:0},{value:"<rect>",paraId:0},{value:" element of SVG.",paraId:0},{value:"The following ",paraId:1},{value:"example",paraId:2},{value:" defines a rounded rectangle with the top left vertex at ",paraId:1},{value:"(200, 100)",paraId:1},{value:".",paraId:1},{value:"const rect = new Rect({\n    style: {\n        x: 200,\n        y: 100,\n        width: 300,\n        height: 200,\n        fill: '#1890FF',\n        stroke: '#F04864',\n        lineWidth: 4,\n        radius: 8,\n    },\n});\n",paraId:3},{value:"Inherits ",paraId:4,tocIndex:0},{value:"style property",paraId:5,tocIndex:0},{value:" from ",paraId:4,tocIndex:0},{value:"DisplayObject",paraId:6,tocIndex:0},{value:".",paraId:4,tocIndex:0},{value:"The default value is ",paraId:7,tocIndex:1},{value:"[0, 0]",paraId:7,tocIndex:1},{value:". For details, see ",paraId:7,tocIndex:1},{value:"DisplayObject's anchor",paraId:8,tocIndex:1},{value:".",paraId:7,tocIndex:1},{value:"The default value is ",paraId:9,tocIndex:2},{value:"left top",paraId:9,tocIndex:2},{value:". For details, see ",paraId:9,tocIndex:2},{value:"DisplayObject's transformOrigin",paraId:10,tocIndex:2},{value:".",paraId:9,tocIndex:2},{value:"The x-axis coordinate of the top-left vertex of the rectangle in the local coordinate system.",paraId:11,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/x",paraId:12,tocIndex:4},{value:"Initial value",paraId:13,tocIndex:4},{value:"Applicable elements",paraId:14,tocIndex:4},{value:"Inheritable",paraId:15,tocIndex:4},{value:"Animatable",paraId:14,tocIndex:4},{value:"Computed value",paraId:16,tocIndex:4},{value:"'0'",paraId:14,tocIndex:4},{value:"-",paraId:14,tocIndex:4},{value:"no",paraId:14,tocIndex:4},{value:"yes",paraId:14,tocIndex:4},{value:"<percentage>",paraId:17,tocIndex:4},{value:" ",paraId:14,tocIndex:4},{value:"<length>",paraId:18,tocIndex:4},{value:"The y-axis coordinate of the top-left vertex of the rectangle in the local coordinate system.",paraId:19,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/y",paraId:20,tocIndex:5},{value:"Initial value",paraId:21,tocIndex:5},{value:"Applicable elements",paraId:22,tocIndex:5},{value:"Inheritable",paraId:23,tocIndex:5},{value:"Animatable",paraId:22,tocIndex:5},{value:"Computed value",paraId:24,tocIndex:5},{value:"'0'",paraId:22,tocIndex:5},{value:"-",paraId:22,tocIndex:5},{value:"no",paraId:22,tocIndex:5},{value:"yes",paraId:22,tocIndex:5},{value:"<percentage>",paraId:25,tocIndex:5},{value:" ",paraId:22,tocIndex:5},{value:"<length>",paraId:26,tocIndex:5},{value:"The width of the rectangle. Supports taking ",paraId:27,tocIndex:6},{value:"negative numbers",paraId:27,tocIndex:6},{value:" with the effect of reversing along the Y-axis, ",paraId:27,tocIndex:6},{value:"example",paraId:28,tocIndex:6},{value:".",paraId:27,tocIndex:6},{value:"This is consistent with the Canvas2D API, ",paraId:29,tocIndex:6},{value:"see",paraId:29,tocIndex:6},{value:". In the SVG spec, it is noted that the ",paraId:29,tocIndex:6},{value:"<rect>",paraId:29,tocIndex:6},{value:" width and height attribute is not displayed when it is negative, for example, in Chrome this results in the following error: ",paraId:29,tocIndex:6},{value:'Error: <rect> attribute height: A negative value is not valid. ("-100")',paraId:29,tocIndex:6},{value:"：",paraId:29,tocIndex:6},{value:"The width and height properties define the overall width and height of the rectangle. A negative value for either property is illegal and must be ignored as a parsing error. A computed value of zero for either dimension disables rendering of the element.",paraId:30,tocIndex:6},{value:"We circumvent this problem by using ",paraId:31,tocIndex:6},{value:"<path>",paraId:31,tocIndex:6},{value:" instead of ",paraId:31,tocIndex:6},{value:"<rect>",paraId:31,tocIndex:6},{value:" for drawing in ",paraId:31,tocIndex:6},{value:"g-svg",paraId:32,tocIndex:6},{value:".",paraId:31,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/width",paraId:33,tocIndex:6},{value:"Initial value",paraId:34,tocIndex:6},{value:"Applicable elements",paraId:35,tocIndex:6},{value:"Inheritable",paraId:36,tocIndex:6},{value:"Animatable",paraId:35,tocIndex:6},{value:"Computed value",paraId:37,tocIndex:6},{value:"'0'",paraId:35,tocIndex:6},{value:"-",paraId:35,tocIndex:6},{value:"no",paraId:35,tocIndex:6},{value:"yes",paraId:35,tocIndex:6},{value:"<percentage>",paraId:38,tocIndex:6},{value:" ",paraId:35,tocIndex:6},{value:"<length>",paraId:39,tocIndex:6},{value:"The height of the rectangle. Supports taking ",paraId:40,tocIndex:7},{value:"negative numbers",paraId:40,tocIndex:7},{value:" with the effect of reversing along the X-axis, ",paraId:40,tocIndex:7},{value:"example",paraId:41,tocIndex:7},{value:".",paraId:40,tocIndex:7},{value:"https://developer.mozilla.org/zh-CN/docs/Web/SVG/Attribute/height",paraId:42,tocIndex:7},{value:"Initial value",paraId:43,tocIndex:7},{value:"Applicable elements",paraId:44,tocIndex:7},{value:"Inheritable",paraId:45,tocIndex:7},{value:"Animatable",paraId:44,tocIndex:7},{value:"Computed value",paraId:46,tocIndex:7},{value:"'0'",paraId:44,tocIndex:7},{value:"-",paraId:44,tocIndex:7},{value:"no",paraId:44,tocIndex:7},{value:"yes",paraId:44,tocIndex:7},{value:"<percentage>",paraId:47,tocIndex:7},{value:" ",paraId:44,tocIndex:7},{value:"<length>",paraId:48,tocIndex:7},{value:"Corner radius, unlike SVG ",paraId:49,tocIndex:8},{value:"<rect>",paraId:49,tocIndex:8},{value:" which only supports ",paraId:49,tocIndex:8},{value:"cx/cy",paraId:49,tocIndex:8},{value:" uniform settings, here you can specify the radius of each of the four corners, ",paraId:49,tocIndex:8},{value:"example",paraId:50,tocIndex:8},{value:".",paraId:49,tocIndex:8},{value:"rect.style.radius = [0, 4, 8, 16];\nrect.style.radius = '0 4px 8px 16px';\n",paraId:51,tocIndex:8},{value:"The following values are supported, set in the order of top left, top right, bottom right, bottom left.",paraId:52,tocIndex:8},{value:"number",paraId:53,tocIndex:8},{value:" Uniform setting of four rounded corner radii",paraId:53,tocIndex:8},{value:"number[]",paraId:53,tocIndex:8},{value:" Setting the four corner radii separately will make up the default fraction of.\n",paraId:53,tocIndex:8},{value:"[ 1 ]",paraId:54,tocIndex:8},{value:" equals ",paraId:54,tocIndex:8},{value:"[ 1, 1, 1, 1 ]",paraId:54,tocIndex:8},{value:"[ 1, 2 ]",paraId:54,tocIndex:8},{value:" equals ",paraId:54,tocIndex:8},{value:"[ 1, 2, 1, 2 ]",paraId:54,tocIndex:8},{value:"[ 1, 2, 3 ]",paraId:54,tocIndex:8},{value:" equals ",paraId:54,tocIndex:8},{value:"[ 1, 2, 3, 2 ]",paraId:54,tocIndex:8},{value:"[ 1, 2, 3, 4 ]",paraId:54,tocIndex:8},{value:"string",paraId:53,tocIndex:8},{value:" Similar to the CSS ",paraId:53,tocIndex:8},{value:"padding",paraId:53,tocIndex:8},{value:" property, using spaces to separate",paraId:53,tocIndex:8},{value:"When actually drawn, the maximum value of the radius of the rounded corners is limited to half the maximum value of the width and height of the rectangle.",paraId:55,tocIndex:8},{value:"const [tlr, trr, brr, blr] = radius.map((r) =>\n    clamp(\n        r.value,\n        0,\n        Math.min(Math.abs(width.value) / 2, Math.abs(height.value) / 2),\n    ),\n);\n",paraId:56,tocIndex:8},{value:"Initial value",paraId:57,tocIndex:8},{value:"Applicable elements",paraId:58,tocIndex:8},{value:"Inheritable",paraId:59,tocIndex:8},{value:"Animatable",paraId:58,tocIndex:8},{value:"Computed value",paraId:60,tocIndex:8},{value:"'0'",paraId:58,tocIndex:8},{value:"-",paraId:58,tocIndex:8},{value:"no",paraId:58,tocIndex:8},{value:"yes",paraId:58,tocIndex:8},{value:"<percentage>",paraId:61,tocIndex:8},{value:" ",paraId:58,tocIndex:8},{value:"<length>",paraId:62,tocIndex:8}]},47261:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(81581);const n=[{value:"Provides simple single/multi-line text layout capabilities, with single-line support for horizontal alignment and character spacing; multi-line support for explicit line breaks as well as automatic line breaks and vertical alignment.",paraId:0},{value:"The following properties can be adjusted in this ",paraId:1},{value:"example",paraId:2},{value:".",paraId:1},{value:"DisplayObject",paraId:3,tocIndex:0},{value:"The position of a text/text block is described by a text anchor point around which it adjusts itself through properties such as ",paraId:4,tocIndex:0},{value:"textBaseline",paraId:4,tocIndex:0},{value:" (single/multi-line), ",paraId:4,tocIndex:0},{value:"textAlign",paraId:4,tocIndex:0},{value:" (multi-line), etc.",paraId:4,tocIndex:0},{value:"Text content, which can contain line breaks, e.g. ",paraId:5,tocIndex:1},{value:'"test text \\n another line"',paraId:5,tocIndex:1},{value:"Initial value",paraId:6,tocIndex:1},{value:"Applicable elements",paraId:7,tocIndex:1},{value:"Inheritable",paraId:8,tocIndex:1},{value:"Animatable",paraId:7,tocIndex:1},{value:"Computed value",paraId:9,tocIndex:1},{value:"''",paraId:7,tocIndex:1},{value:"-",paraId:7,tocIndex:1},{value:"no",paraId:7,tocIndex:1},{value:"no",paraId:7,tocIndex:1},{value:"<string>",paraId:10,tocIndex:1},{value:"Consistent with ",paraId:11,tocIndex:2},{value:"CSS text-transform",paraId:11,tocIndex:2},{value:", the following enumeration values are supported for text content transformation.",paraId:11,tocIndex:2},{value:"'capitalize'",paraId:12,tocIndex:2},{value:"'uppercase'",paraId:12,tocIndex:2},{value:"'lowercase'",paraId:12,tocIndex:2},{value:"'none'",paraId:12,tocIndex:2},{value:" default value",paraId:12,tocIndex:2},{value:"Initial value",paraId:13,tocIndex:2},{value:"Applicable elements",paraId:14,tocIndex:2},{value:"Inheritable",paraId:15,tocIndex:2},{value:"Animatable",paraId:14,tocIndex:2},{value:"Computed value",paraId:16,tocIndex:2},{value:"'none'",paraId:14,tocIndex:2},{value:"-",paraId:14,tocIndex:2},{value:"no",paraId:14,tocIndex:2},{value:"no",paraId:14,tocIndex:2},{value:"<keywords>",paraId:17,tocIndex:2},{value:"Corresponds to the ",paraId:18,tocIndex:3},{value:"SVG dx / dy attribute",paraId:18,tocIndex:3},{value:" to add offsets in the horizontal and vertical directions.",paraId:18,tocIndex:3},{value:"Both ",paraId:19,tocIndex:3},{value:"px",paraId:19,tocIndex:3},{value:" and ",paraId:19,tocIndex:3},{value:"em",paraId:19,tocIndex:3},{value:" units are supported, and the default ",paraId:19,tocIndex:3},{value:"px",paraId:19,tocIndex:3},{value:" unit when using the ",paraId:19,tocIndex:3},{value:"number",paraId:19,tocIndex:3},{value:" type.",paraId:19,tocIndex:3},{value:"{\n    dx: 10;\n    dx: '10px';\n    dx: '0.5em';\n}\n",paraId:20,tocIndex:3},{value:"Initial value",paraId:21,tocIndex:3},{value:"Applicable elements",paraId:22,tocIndex:3},{value:"Inheritable",paraId:23,tocIndex:3},{value:"Animatable",paraId:22,tocIndex:3},{value:"Computed value",paraId:24,tocIndex:3},{value:"'0'",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"no",paraId:22,tocIndex:3},{value:"yes",paraId:22,tocIndex:3},{value:"<percentage>",paraId:25,tocIndex:3},{value:" ",paraId:22,tocIndex:3},{value:"<length>",paraId:26,tocIndex:3},{value:"Whether or not to always face the camera in 3D scenes, defaults to ",paraId:27,tocIndex:4},{value:"false",paraId:27,tocIndex:4},{value:', also known as the "billboard effect".',paraId:27,tocIndex:4},{value:"In ",paraId:28,tocIndex:4},{value:"example",paraId:29,tocIndex:4},{value:", the text is rendered compressed when the camera is rotated without being turned on:",paraId:28,tocIndex:4},{value:"Turning it on doesn't change the position of the text, but it will always face the camera. This is in line with what is usually required for 2D graphics like text in 3D scenes:",paraId:30,tocIndex:4},{value:"Rotation angle in billboard mode, clockwise in radians.",paraId:31,tocIndex:5},{value:"In ",paraId:32,tocIndex:5},{value:"example",paraId:33,tocIndex:5},{value:", we add a rotation angle to the text:",paraId:32,tocIndex:5},{value:"label.style.isBillboard = true;\nlabel.style.billboardRotation = Math.PI / 8;\n",paraId:34,tocIndex:5},{value:'Whether or not to apply size attenuation in perspective projection. This option can be turned on if you want to keep the size consistent regardless of depth, following the "near big, far small" visual effect in perspective projection.',paraId:35,tocIndex:6},{value:"In ",paraId:36,tocIndex:6},{value:"example",paraId:37,tocIndex:6},{value:", we enable size attenuation for text:",paraId:36,tocIndex:6},{value:"label.style.isSizeAttenuation = true;\n",paraId:38,tocIndex:6},{value:"Font type, e.g. ",paraId:39,tocIndex:8},{value:"'PingFang SC'",paraId:39,tocIndex:8},{value:" ",paraId:39,tocIndex:8},{value:"'Microsoft Yahei'",paraId:39,tocIndex:8},{value:"Corresponds to the ",paraId:40,tocIndex:8},{value:"CSS font-family",paraId:40,tocIndex:8},{value:".",paraId:40,tocIndex:8},{value:"Initial value",paraId:41,tocIndex:8},{value:"Applicable elements",paraId:42,tocIndex:8},{value:"Inheritable",paraId:43,tocIndex:8},{value:"Animatable",paraId:42,tocIndex:8},{value:"Computed value",paraId:44,tocIndex:8},{value:"''",paraId:42,tocIndex:8},{value:"-",paraId:42,tocIndex:8},{value:"yes",paraId:42,tocIndex:8},{value:"no",paraId:42,tocIndex:8},{value:"<keywords>",paraId:45,tocIndex:8},{value:"Corresponds to the ",paraId:46,tocIndex:9},{value:"CSS font-size",paraId:46,tocIndex:9},{value:".",paraId:46,tocIndex:9},{value:"Initial value",paraId:47,tocIndex:9},{value:"Applicable elements",paraId:48,tocIndex:9},{value:"Inheritable",paraId:49,tocIndex:9},{value:"Animatable",paraId:48,tocIndex:9},{value:"Computed value",paraId:50,tocIndex:9},{value:"'16px'",paraId:48,tocIndex:9},{value:"-",paraId:48,tocIndex:9},{value:"yes",paraId:48,tocIndex:9},{value:"yes",paraId:48,tocIndex:9},{value:"<percentage>",paraId:51,tocIndex:9},{value:" ",paraId:48,tocIndex:9},{value:"<length>",paraId:52,tocIndex:9},{value:"Corresponds to the ",paraId:53,tocIndex:10},{value:"CSS font-weight",paraId:53,tocIndex:10},{value:".",paraId:53,tocIndex:10},{value:"'normal'",paraId:54,tocIndex:10},{value:" Normal font weight. Same as 400.",paraId:54,tocIndex:10},{value:"'bold'",paraId:54,tocIndex:10},{value:" Bold font weight. Same as 700.",paraId:54,tocIndex:10},{value:"'bolder'",paraId:54,tocIndex:10},{value:"'lighter'",paraId:54,tocIndex:10},{value:"number",paraId:54,tocIndex:10},{value:" A number value between 1 and 1000.",paraId:54,tocIndex:10},{value:"Initial value",paraId:55,tocIndex:10},{value:"Applicable elements",paraId:56,tocIndex:10},{value:"Inheritable",paraId:57,tocIndex:10},{value:"Animatable",paraId:56,tocIndex:10},{value:"Computed value",paraId:58,tocIndex:10},{value:"'normal'",paraId:56,tocIndex:10},{value:"-",paraId:56,tocIndex:10},{value:"yes",paraId:56,tocIndex:10},{value:"no",paraId:56,tocIndex:10},{value:"<keywords>",paraId:59,tocIndex:10},{value:"Corresponds to the ",paraId:60,tocIndex:11},{value:"CSS font-style",paraId:60,tocIndex:11},{value:".",paraId:60,tocIndex:11},{value:"Font style, for example, the image below shows the tilted ",paraId:61,tocIndex:11},{value:"italic",paraId:61,tocIndex:11},{value:" effect.",paraId:61,tocIndex:11},{value:"Initial value",paraId:62,tocIndex:11},{value:"Applicable elements",paraId:63,tocIndex:11},{value:"Inheritable",paraId:64,tocIndex:11},{value:"Animatable",paraId:63,tocIndex:11},{value:"Computed value",paraId:65,tocIndex:11},{value:"'normal'",paraId:63,tocIndex:11},{value:"-",paraId:63,tocIndex:11},{value:"yes",paraId:63,tocIndex:11},{value:"no",paraId:63,tocIndex:11},{value:"<keywords>",paraId:66,tocIndex:11},{value:"Corresponds to the ",paraId:67,tocIndex:12},{value:"CSS font-variant",paraId:67,tocIndex:12},{value:".",paraId:67,tocIndex:12},{value:"Font style, for example, the following image is the ",paraId:68,tocIndex:12},{value:"small-cap",paraId:68,tocIndex:12},{value:" effect.",paraId:68,tocIndex:12},{value:"Initial value",paraId:69,tocIndex:12},{value:"Applicable elements",paraId:70,tocIndex:12},{value:"Inheritable",paraId:71,tocIndex:12},{value:"Animatable",paraId:70,tocIndex:12},{value:"Computed value",paraId:72,tocIndex:12},{value:"'normal'",paraId:70,tocIndex:12},{value:"-",paraId:70,tocIndex:12},{value:"yes",paraId:70,tocIndex:12},{value:"no",paraId:70,tocIndex:12},{value:"<keywords>",paraId:73,tocIndex:12},{value:"Corresponds to the ",paraId:74,tocIndex:14},{value:"Canvas textBaseline",paraId:74,tocIndex:14},{value:".",paraId:74,tocIndex:14},{value:"Alignment in the vertical direction is achieved by ",paraId:75,tocIndex:14},{value:"textBaseline",paraId:75,tocIndex:14},{value:", and the following figure shows the effect of alignment with different values.",paraId:75,tocIndex:14},{value:"Using the current position of the text as the anchor point, the following figure shows the effect of ",paraId:76,tocIndex:14},{value:"top",paraId:76,tocIndex:14},{value:", ",paraId:76,tocIndex:14},{value:"middle",paraId:76,tocIndex:14},{value:" and ",paraId:76,tocIndex:14},{value:"bottom",paraId:76,tocIndex:14},{value:" in turn. In addition to single line also applies to multi-line text blocks.",paraId:76,tocIndex:14},{value:"Initial value",paraId:77,tocIndex:14},{value:"Applicable elements",paraId:78,tocIndex:14},{value:"Inheritable",paraId:79,tocIndex:14},{value:"Animatable",paraId:78,tocIndex:14},{value:"Computed value",paraId:80,tocIndex:14},{value:"'alphabetic'",paraId:78,tocIndex:14},{value:"-",paraId:78,tocIndex:14},{value:"yes",paraId:78,tocIndex:14},{value:"no",paraId:78,tocIndex:14},{value:"<keywords>",paraId:81,tocIndex:14},{value:"Corresponds to the ",paraId:82,tocIndex:15},{value:"Canvas letterSpacing",paraId:82,tocIndex:15},{value:".",paraId:82,tocIndex:15},{value:"Initial value",paraId:83,tocIndex:15},{value:"Applicable elements",paraId:84,tocIndex:15},{value:"Inheritable",paraId:85,tocIndex:15},{value:"Animatable",paraId:84,tocIndex:15},{value:"Computed value",paraId:86,tocIndex:15},{value:"'0'",paraId:84,tocIndex:15},{value:"-",paraId:84,tocIndex:15},{value:"yes",paraId:84,tocIndex:15},{value:"no",paraId:84,tocIndex:15},{value:"<percentage>",paraId:87,tocIndex:15},{value:" ",paraId:84,tocIndex:15},{value:"<length>",paraId:88,tocIndex:15},{value:"Line feeds occur in the following two cases:",paraId:89,tocIndex:16},{value:"Line breaks in text",paraId:90,tocIndex:16},{value:"When ",paraId:90,tocIndex:16},{value:"wordWrap",paraId:90,tocIndex:16},{value:" is turned on, the part beyond ",paraId:90,tocIndex:16},{value:"wordWrapWidth",paraId:90,tocIndex:16},{value:" will be automatically line wrapped, similar to ",paraId:90,tocIndex:16},{value:"word-break",paraId:90,tocIndex:16},{value:" in CSS.",paraId:90,tocIndex:16},{value:"Therefore, both cases need to be considered when parsing raw text. However, when dealing with CJK (Chinese/Japanese/Korean) characters, their special language specification needs to be taken into account. In fact, the CSS ",paraId:91,tocIndex:16},{value:"word-break",paraId:91,tocIndex:16},{value:" also provides a value that takes into account the CJK case.",paraId:91,tocIndex:16},{value:"Corresponds to the ",paraId:92,tocIndex:17},{value:"CSS text-align",paraId:92,tocIndex:17},{value:".",paraId:92,tocIndex:17},{value:"In multi-line text, each line can be horizontally aligned with an anchor",paraId:93,tocIndex:17},{value:"'start'",paraId:94,tocIndex:17},{value:"'center'",paraId:94,tocIndex:17},{value:"'end'",paraId:94,tocIndex:17},{value:"'left'",paraId:94,tocIndex:17},{value:" Same as ",paraId:94,tocIndex:17},{value:"'start'",paraId:94,tocIndex:17},{value:".",paraId:94,tocIndex:17},{value:"'right'",paraId:94,tocIndex:17},{value:" Same as ",paraId:94,tocIndex:17},{value:"'end'",paraId:94,tocIndex:17},{value:".",paraId:94,tocIndex:17},{value:"The following figure shows the effect of ",paraId:95,tocIndex:17},{value:"left",paraId:95,tocIndex:17},{value:", ",paraId:95,tocIndex:17},{value:"center",paraId:95,tocIndex:17},{value:" and ",paraId:95,tocIndex:17},{value:"right",paraId:95,tocIndex:17},{value:" in that order:",paraId:95,tocIndex:17},{value:"Initial value",paraId:96,tocIndex:17},{value:"Applicable elements",paraId:97,tocIndex:17},{value:"Inheritable",paraId:98,tocIndex:17},{value:"Animatable",paraId:97,tocIndex:17},{value:"Computed value",paraId:99,tocIndex:17},{value:"'left'",paraId:97,tocIndex:17},{value:"-",paraId:97,tocIndex:17},{value:"yes",paraId:97,tocIndex:17},{value:"no",paraId:97,tocIndex:17},{value:"<keywords>",paraId:100,tocIndex:17},{value:"Whether to turn on automatic line feed, default value is ",paraId:101,tocIndex:18},{value:"false",paraId:101,tocIndex:18},{value:".",paraId:101,tocIndex:18},{value:"When ",paraId:102,tocIndex:19},{value:"wordWrap",paraId:102,tocIndex:19},{value:" is turned on, the line will break beyond that width.",paraId:102,tocIndex:19},{value:"Initial value",paraId:103,tocIndex:19},{value:"Applicable elements",paraId:104,tocIndex:19},{value:"Inheritable",paraId:105,tocIndex:19},{value:"Animatable",paraId:104,tocIndex:19},{value:"Computed value",paraId:106,tocIndex:19},{value:"'0'",paraId:104,tocIndex:19},{value:"-",paraId:104,tocIndex:19},{value:"yes",paraId:104,tocIndex:19},{value:"no",paraId:104,tocIndex:19},{value:"<length>",paraId:107,tocIndex:19},{value:"Used to determine how to prompt the user for the presence of hidden text overflow content, such as direct cropping, appending an ellipsis or a custom string. Need to be used with ",paraId:108,tocIndex:20},{value:"wordWrap",paraId:109,tocIndex:20},{value:", ",paraId:108,tocIndex:20},{value:"wordWrapWidth",paraId:110,tocIndex:20},{value:" and [maxLines](/en/api/ basic/text#maxlines) are used together.",paraId:108,tocIndex:20},{value:"Corresponds to the ",paraId:111,tocIndex:20},{value:"CSS text-overflow",paraId:111,tocIndex:20},{value:".",paraId:111,tocIndex:20},{value:"The following values are supported.",paraId:112,tocIndex:20},{value:"'clip'",paraId:113,tocIndex:20},{value:" truncates the text directly",paraId:113,tocIndex:20},{value:"'ellipsis'",paraId:113,tocIndex:20},{value:" uses ",paraId:113,tocIndex:20},{value:"...",paraId:113,tocIndex:20},{value:" to indicate the truncated text",paraId:113,tocIndex:20},{value:"Custom strings, using it to indicate the truncated text",paraId:113,tocIndex:20},{value:"Caution.",paraId:114,tocIndex:20},{value:"'clip'",paraId:115,tocIndex:20},{value:" and ",paraId:115,tocIndex:20},{value:"'ellipsis'",paraId:115,tocIndex:20},{value:" are reserved words, so custom strings cannot use them.",paraId:115,tocIndex:20},{value:"If the length of custom text exceeds ",paraId:115,tocIndex:20},{value:"wordWrapWidth",paraId:116,tocIndex:20},{value:", it will be truncated directly, and the effect is the same as ",paraId:115,tocIndex:20},{value:"'clip'",paraId:115,tocIndex:20},{value:".",paraId:115,tocIndex:20},{value:"The truncation only affects the visual effect, the original text content ",paraId:115,tocIndex:20},{value:"text",paraId:117,tocIndex:20},{value:" is not affected",paraId:115,tocIndex:20},{value:"Initial value",paraId:118,tocIndex:20},{value:"Applicable elements",paraId:119,tocIndex:20},{value:"Inheritable",paraId:120,tocIndex:20},{value:"Animatable",paraId:119,tocIndex:20},{value:"Computed value",paraId:121,tocIndex:20},{value:"'clip'",paraId:119,tocIndex:20},{value:"-",paraId:119,tocIndex:20},{value:"no",paraId:119,tocIndex:20},{value:"no",paraId:119,tocIndex:20},{value:"<keywords>",paraId:122,tocIndex:20},{value:"Max lines, text overflow will be truncated, need to use with ",paraId:123,tocIndex:21},{value:"wordWrap",paraId:124,tocIndex:21},{value:", ",paraId:123,tocIndex:21},{value:"wordWrapWidth",paraId:125,tocIndex:21},{value:" and ",paraId:123,tocIndex:21},{value:"textOverflow",paraId:126,tocIndex:21},{value:" are used together.",paraId:123,tocIndex:21},{value:"The following figure shows limiting text to be displayed on one line and truncated with an ellipsis after it is exceeded.",paraId:127,tocIndex:21},{value:"Initial value",paraId:128,tocIndex:21},{value:"Applicable elements",paraId:129,tocIndex:21},{value:"Inheritable",paraId:130,tocIndex:21},{value:"Animatable",paraId:129,tocIndex:21},{value:"Computed value",paraId:131,tocIndex:21},{value:"'Infinity'",paraId:129,tocIndex:21},{value:"-",paraId:129,tocIndex:21},{value:"no",paraId:129,tocIndex:21},{value:"no",paraId:129,tocIndex:21},{value:"<number>",paraId:132,tocIndex:21},{value:"Corresponds to the ",paraId:133,tocIndex:22},{value:"CSS line-height",paraId:133,tocIndex:22},{value:".",paraId:133,tocIndex:22},{value:"Initial value",paraId:134,tocIndex:22},{value:"Applicable elements",paraId:135,tocIndex:22},{value:"Inheritable",paraId:136,tocIndex:22},{value:"Animatable",paraId:135,tocIndex:22},{value:"Computed value",paraId:137,tocIndex:22},{value:"'0'",paraId:135,tocIndex:22},{value:"-",paraId:135,tocIndex:22},{value:"no",paraId:135,tocIndex:22},{value:"yes",paraId:135,tocIndex:22},{value:"<length>",paraId:138,tocIndex:22},{value:"Initial value",paraId:139,tocIndex:23},{value:"Applicable elements",paraId:140,tocIndex:23},{value:"Inheritable",paraId:141,tocIndex:23},{value:"Animatable",paraId:140,tocIndex:23},{value:"Computed value",paraId:142,tocIndex:23},{value:"'0'",paraId:140,tocIndex:23},{value:"-",paraId:140,tocIndex:23},{value:"no",paraId:140,tocIndex:23},{value:"no",paraId:140,tocIndex:23},{value:"<length>",paraId:143,tocIndex:23},{value:"6.1.28",paraId:144,tocIndex:23},{value:"Text decoration is controlled by the following four properties, consistent with CSS ",paraId:145,tocIndex:24},{value:"text-decoration",paraId:145,tocIndex:24},{value:".",paraId:145,tocIndex:24},{value:"Decoration line type, consistent with ",paraId:146,tocIndex:25},{value:"CSS text-decoration-line",paraId:146,tocIndex:25},{value:".",paraId:146,tocIndex:25},{value:"The following values are supported:",paraId:147,tocIndex:25},{value:"'none'",paraId:148,tocIndex:25},{value:" No decoration line, default value",paraId:148,tocIndex:25},{value:"'underline'",paraId:148,tocIndex:25},{value:" Underline",paraId:148,tocIndex:25},{value:"'overline'",paraId:148,tocIndex:25},{value:" Overline",paraId:148,tocIndex:25},{value:"'line-through'",paraId:148,tocIndex:25},{value:" Line through",paraId:148,tocIndex:25},{value:"'underline overline'",paraId:148,tocIndex:25},{value:" Both underline and overline",paraId:148,tocIndex:25},{value:"The following properties can be adjusted in this ",paraId:149,tocIndex:25},{value:"example",paraId:150,tocIndex:25},{value:".",paraId:149,tocIndex:25},{value:"Initial value",paraId:151,tocIndex:25},{value:"Applicable elements",paraId:152,tocIndex:25},{value:"Inheritable",paraId:153,tocIndex:25},{value:"Animatable",paraId:152,tocIndex:25},{value:"Computed value",paraId:154,tocIndex:25},{value:"'none'",paraId:152,tocIndex:25},{value:"-",paraId:152,tocIndex:25},{value:"no",paraId:152,tocIndex:25},{value:"no",paraId:152,tocIndex:25},{value:"<keywords>",paraId:155,tocIndex:25},{value:"Decoration line style, consistent with ",paraId:156,tocIndex:26},{value:"CSS text-decoration-style",paraId:156,tocIndex:26},{value:".",paraId:156,tocIndex:26},{value:"The following values are supported:",paraId:157,tocIndex:26},{value:"'solid'",paraId:158,tocIndex:26},{value:" Solid line, default value",paraId:158,tocIndex:26},{value:"'double'",paraId:158,tocIndex:26},{value:" Double line",paraId:158,tocIndex:26},{value:"'dotted'",paraId:158,tocIndex:26},{value:" Dotted line",paraId:158,tocIndex:26},{value:"'dashed'",paraId:158,tocIndex:26},{value:" Dashed line",paraId:158,tocIndex:26},{value:"'wavy'",paraId:158,tocIndex:26},{value:" Wavy line",paraId:158,tocIndex:26},{value:"Initial value",paraId:159,tocIndex:26},{value:"Applicable elements",paraId:160,tocIndex:26},{value:"Inheritable",paraId:161,tocIndex:26},{value:"Animatable",paraId:160,tocIndex:26},{value:"Computed value",paraId:162,tocIndex:26},{value:"'solid'",paraId:160,tocIndex:26},{value:"-",paraId:160,tocIndex:26},{value:"no",paraId:160,tocIndex:26},{value:"no",paraId:160,tocIndex:26},{value:"<keywords>",paraId:163,tocIndex:26},{value:"Decoration line color, consistent with ",paraId:164,tocIndex:27},{value:"CSS text-decoration-color",paraId:164,tocIndex:27},{value:".",paraId:164,tocIndex:27},{value:"Supports all color formats supported by CSS, for example:",paraId:165,tocIndex:27},{value:"Keywords: ",paraId:166,tocIndex:27},{value:"'red'",paraId:166,tocIndex:27},{value:" ",paraId:166,tocIndex:27},{value:"'blue'",paraId:166,tocIndex:27},{value:"Hex: ",paraId:166,tocIndex:27},{value:"'#FF0000'",paraId:166,tocIndex:27},{value:"RGB: ",paraId:166,tocIndex:27},{value:"'rgb(255, 0, 0)'",paraId:166,tocIndex:27},{value:"RGBA: ",paraId:166,tocIndex:27},{value:"'rgba(255, 0, 0, 1)'",paraId:166,tocIndex:27},{value:"Initial value",paraId:167,tocIndex:27},{value:"Applicable elements",paraId:168,tocIndex:27},{value:"Inheritable",paraId:169,tocIndex:27},{value:"Animatable",paraId:168,tocIndex:27},{value:"Computed value",paraId:170,tocIndex:27},{value:"'currentcolor'",paraId:168,tocIndex:27},{value:"-",paraId:168,tocIndex:27},{value:"no",paraId:168,tocIndex:27},{value:"no",paraId:168,tocIndex:27},{value:"<color>",paraId:171,tocIndex:27},{value:"Decoration line thickness, consistent with ",paraId:172,tocIndex:28},{value:"CSS text-decoration-thickness",paraId:172,tocIndex:28},{value:".",paraId:172,tocIndex:28},{value:"Supports number type, representing pixel value. For example:",paraId:173,tocIndex:28},{value:"1",paraId:174,tocIndex:28},{value:" 1 pixel thickness",paraId:174,tocIndex:28},{value:"3",paraId:174,tocIndex:28},{value:" 3 pixel thickness",paraId:174,tocIndex:28},{value:"Initial value",paraId:175,tocIndex:28},{value:"Applicable elements",paraId:176,tocIndex:28},{value:"Inheritable",paraId:177,tocIndex:28},{value:"Animatable",paraId:176,tocIndex:28},{value:"Computed value",paraId:178,tocIndex:28},{value:"1",paraId:176,tocIndex:28},{value:"-",paraId:176,tocIndex:28},{value:"no",paraId:176,tocIndex:28},{value:"no",paraId:176,tocIndex:28},{value:"<length>",paraId:179,tocIndex:28},{value:"Get the bounding box for each line of text, e.g.:",paraId:180,tocIndex:30},{value:"text.getLineBoundingRects(); // Rectangle[]\n",paraId:181,tocIndex:30},{value:"where the enclosing box structure is as follows, where x/y is relative to the local coordinate system of the text:",paraId:182,tocIndex:30},{value:"interface Rectangle {\n    x: number;\n    y: number;\n    width: number;\n    height: number;\n}\n",paraId:183,tocIndex:30},{value:"In ",paraId:184,tocIndex:30},{value:"example",paraId:185,tocIndex:30},{value:", we draw the bounding box for each line of the multi-line text, and we can implement advanced text features such as underline and strikethrough based on the bounding box information:",paraId:184,tocIndex:30},{value:"text.getLineBoundingRects().forEach(({ x, y, width, height }) => {\n    const block = new Rect({\n        style: {\n            x,\n            y,\n            width,\n            height,\n            stroke: 'black',\n            lineWidth: 2,\n        },\n    });\n    text.appendChild(block);\n});\n",paraId:186,tocIndex:30},{value:"Used to determine if there is overflow content. Useful for Tooltip-like components to determine if the full text needs to be displayed.",paraId:187,tocIndex:31},{value:"text.isOverflowing(); // true\n",paraId:188,tocIndex:31},{value:"Note that the presence of a line break does not necessarily mean that there is overflow. For example, in the following figure, even though ",paraId:189,tocIndex:31},{value:"maxLines",paraId:189,tocIndex:31},{value:" and ",paraId:189,tocIndex:31},{value:"wordWrapWidth",paraId:189,tocIndex:31},{value:" are set, there is no content overflow and the method returns ",paraId:189,tocIndex:31},{value:"false",paraId:189,tocIndex:31},{value:".",paraId:189,tocIndex:31},{value:"And only if the content does overflow, i.e. the ",paraId:190,tocIndex:31},{value:"textOverflow",paraId:191,tocIndex:31},{value:" attribute does take effect (whatever its value is), will it return ",paraId:190,tocIndex:31},{value:"true",paraId:190,tocIndex:31},{value:".",paraId:190,tocIndex:31},{value:"In addition to the system default fonts, sometimes we want to load third-party fonts.",paraId:192,tocIndex:32},{value:"In this case, you can use ",paraId:193,tocIndex:32},{value:"Web Font Loader",paraId:193,tocIndex:32},{value:", which is created in the ",paraId:193,tocIndex:32},{value:"active",paraId:193,tocIndex:32},{value:" callback function when it is loaded successfully, ",paraId:193,tocIndex:32},{value:"example",paraId:194,tocIndex:32},{value:":",paraId:193,tocIndex:32},{value:"import WebFont from 'webfontloader';\n\nWebFont.load({\n    google: {\n        families: ['Gaegu'],\n    },\n    active: () => {\n        const text = new Text({\n            style: {\n                x: 100,\n                y: 100,\n                fontFamily: 'Gaegu',\n                text: 'Almost before we knew it, we had left the ground.',\n                fontSize: 30,\n                fill: '#1890FF',\n                stroke: '#F04864',\n                lineWidth: 5,\n            },\n        });\n        canvas.appendChild(text);\n    },\n});\n",paraId:195,tocIndex:32},{value:"CanvasKit provides ",paraId:196,tocIndex:33},{value:"enhanced paragraph drawing capabilities",paraId:197,tocIndex:33},{value:". We've integrated them into our ",paraId:196,tocIndex:33},{value:"g-canvaskit",paraId:198,tocIndex:33},{value:" renderer.",paraId:196,tocIndex:33},{value:"Since many properties of Text are inheritable, this means that if their values are not explicitly passed in, the correct inherited value can only be obtained after adding the document, so as to calculate an accurate bounding box. If you really want to get the size of the bounding box before adding the document, for example, to get the exact bounding box immediately after instantiation, you need to manually pass in their values:",paraId:199,tocIndex:35},{value:"const text = new Text({\n    style: {\n        text: 'abcde',\n    },\n});\ntext.getBounds(); // Wrong empty bounding box.\n\ntext.attr({\n    fontSize: '16px',\n    fontFamily: 'sans-serif',\n    fontWeight: 'normal',\n    fontVariant: 'normal',\n    fontStyle: 'normal',\n    textAlign: 'start',\n    textBaseline: 'alphabetic',\n    lineWidth: 0,\n});\ntext.getBounds(); // Right bounding box.\n",paraId:200,tocIndex:35}]},99995:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(17223);const n=[{value:"The following inheritance relationships exist in G.",paraId:0},{value:"Document -> Node -> EventTarget",paraId:1},{value:"We can analogize ",paraId:2},{value:"Document",paraId:2},{value:" to ",paraId:2},{value:"window.document",paraId:2},{value:" in the browser environment, e.g. in a browser.",paraId:2},{value:"It has a reference to ",paraId:3},{value:"window",paraId:3},{value:" ",paraId:3},{value:"defaultView",paraId:4},{value:"Access ",paraId:3},{value:"<html>",paraId:3},{value:" elements via ",paraId:3},{value:"documentElement",paraId:5},{value:"Nodes can be queried by a series of methods, such as ",paraId:3},{value:"getElementById",paraId:6},{value:"Create an element by ",paraId:3},{value:"createElement",paraId:7},{value:"We have implemented the above browser-provided API as much as possible.",paraId:8},{value:"Node",paraId:9},{value:"implements ",paraId:10,tocIndex:2},{value:"Node.nodeName",paraId:11,tocIndex:2},{value:", which returns ",paraId:10,tocIndex:2},{value:"'document'",paraId:10,tocIndex:2},{value:" and can be used in event handlers to quickly determine the target, e.g. when clicking on a blank area of the canvas.",paraId:10,tocIndex:2},{value:"canvas.addEventListener('click', (e) => {\n    e.target; // Document\n\n    if (e.target.nodeName === 'document') {\n        //...\n    }\n});\n",paraId:12,tocIndex:2},{value:"Point to the ",paraId:13,tocIndex:3},{value:"canvas",paraId:14,tocIndex:3},{value:", e.g.",paraId:13,tocIndex:3},{value:"canvas.document.defaultView; // canvas\n",paraId:15,tocIndex:3},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Document/defaultView",paraId:16,tocIndex:3},{value:"Returns the root node in the scene graph. When creating a canvas, ",paraId:17,tocIndex:4},{value:"Group",paraId:18,tocIndex:4},{value:" is used by default to create a.",paraId:17,tocIndex:4},{value:"canvas.document.documentElement; // Group\ncanvas.document.documentElement.getBounds(); // Get the whole scene bounding box\n",paraId:19,tocIndex:4},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Document/documentElement",paraId:20,tocIndex:4},{value:"The default timeline, used in the animation system.",paraId:21,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/timeline",paraId:22,tocIndex:5},{value:"Return null.",paraId:23,tocIndex:6},{value:"Since it inherits from ",paraId:24,tocIndex:7},{value:"Node",paraId:25,tocIndex:7},{value:", it obviously has event binding capabilities.",paraId:24,tocIndex:7},{value:"canvas.document.addEventListener('click', () => {});\n",paraId:26,tocIndex:7},{value:"However, some of the methods, especially the node operations, differ from Node.",paraId:27,tocIndex:7},{value:"Although it inherits from ",paraId:28,tocIndex:8},{value:"Node",paraId:29,tocIndex:8},{value:", some node manipulation methods cannot be called on the Document, just as calling ",paraId:28,tocIndex:8},{value:"document.appendChild",paraId:28,tocIndex:8},{value:" in the browser returns the following error.",paraId:28,tocIndex:8},{value:"Uncaught DOMException: Failed to execute 'appendChild' on 'Node': Only one element on document allowed.\n",paraId:30,tocIndex:8},{value:"The following node query methods are equivalent to executing on ",paraId:31,tocIndex:9},{value:"document.documentElement",paraId:32,tocIndex:9},{value:".",paraId:31,tocIndex:9},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/getElementById",paraId:33,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/getElementsByName",paraId:34,tocIndex:11},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/getElementsByClassName",paraId:35,tocIndex:12},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/getElementsByTagName",paraId:36,tocIndex:13},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/querySelector",paraId:37,tocIndex:14},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/querySelectorAll",paraId:38,tocIndex:15},{value:"Usually we recommend using ",paraId:39,tocIndex:16},{value:"new Circle()",paraId:39,tocIndex:16},{value:" to create built-in or custom graphics, but we also provide something like the DOM [CustomElementRegistry](",paraId:39,tocIndex:16},{value:"https://developer.mozilla.org/en-US/docs/Web/API/",paraId:39,tocIndex:16},{value:" CustomElementRegistry) API to create a completed registered graph using ",paraId:39,tocIndex:16},{value:"document.createElement",paraId:40,tocIndex:16},{value:", so the following writeup is equivalent.",paraId:39,tocIndex:16},{value:"import { Shape, Circle } from '@antv/g';\n\nconst circle = canvas.document.createElement(Shape.CIRCLE, {\n    style: { r: 100 },\n});\n\n// or\nconst circle = new Circle({ style: { r: 100 } });\n",paraId:41,tocIndex:16},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Document/createElement",paraId:42,tocIndex:16},{value:"The current implementation is the same as ",paraId:43,tocIndex:17},{value:"createElement",paraId:44,tocIndex:17},{value:".",paraId:43,tocIndex:17},{value:"When we want to know how many shapes are stacked on a certain point in the canvas, we can do the pickup by API way, besides the interactive events.",paraId:45,tocIndex:18},{value:"This method accepts a set of ",paraId:46,tocIndex:18},{value:"x, y",paraId:46,tocIndex:18},{value:" coordinates (under ",paraId:46,tocIndex:18},{value:"Canvas coordinate system",paraId:47,tocIndex:18},{value:", if you want to use coordinates under other coordinate system, please use [conversion method](/en/api/canvas#conversion method)) as parameters and returns the pickup result.",paraId:46,tocIndex:18},{value:"In the following ",paraId:48,tocIndex:18},{value:"example",paraId:49,tocIndex:18},{value:", we place a ",paraId:48,tocIndex:18},{value:"Circle",paraId:50,tocIndex:18},{value:" with radius ",paraId:48,tocIndex:18},{value:"100, 100",paraId:48,tocIndex:18},{value:" under ",paraId:48,tocIndex:18},{value:"Canvas coordinate system",paraId:51,tocIndex:18},{value:". en/docs/api/basic/circle), which will be returned when picked up at the red dot.",paraId:48,tocIndex:18},{value:"const topMostElement = await canvas.document.elementFromPoint(20, 100); // circle1\n\nawait canvas.document.elementFromPoint(0, 0); // canvas.document.documentElement\n",paraId:52,tocIndex:18},{value:"There are three points to note.",paraId:53,tocIndex:18},{value:"Unlike the synchronous API provided by the browser, this method is ",paraId:54,tocIndex:18},{value:"asynchronous",paraId:54,tocIndex:18},{value:" because some renderer implementations (e.g. ",paraId:54,tocIndex:18},{value:"g-webgl",paraId:54,tocIndex:18},{value:") need to be picked up via the GPU.",paraId:54,tocIndex:18},{value:"when only the topmost graph of the point hit is needed, ",paraId:54,tocIndex:18},{value:"elementFromPoint",paraId:54,tocIndex:18},{value:" should be used instead of ",paraId:54,tocIndex:18},{value:"elementsFromPoint",paraId:54,tocIndex:18},{value:", as the former is faster than the latter in most scenarios",paraId:54,tocIndex:18},{value:"The pickup decision follows the following rules.\n",paraId:54,tocIndex:18},{value:"Out of canvas viewport range (considering camera, not necessarily equal to canvas range) returns null.",paraId:55,tocIndex:18},{value:"The ",paraId:55,tocIndex:18},{value:"interactive",paraId:56,tocIndex:18},{value:" attribute",paraId:55,tocIndex:18},{value:"of the graph affects",paraId:55,tocIndex:18},{value:"pickup. Non-interactive graphics cannot be picked up. 3.",paraId:55,tocIndex:18},{value:"The ",paraId:55,tocIndex:18},{value:"visibility",paraId:57,tocIndex:18},{value:" attribute",paraId:55,tocIndex:18},{value:"of a drawing affects",paraId:55,tocIndex:18},{value:"pickup. Invisible shapes cannot be picked up. 4.",paraId:55,tocIndex:18},{value:"The ",paraId:55,tocIndex:18},{value:"opacity",paraId:58,tocIndex:18},{value:" attribute",paraId:55,tocIndex:18},{value:"of a drawing does not affect",paraId:55,tocIndex:18},{value:"pickup. Even if the graphic is completely transparent, it will still be picked up.",paraId:55,tocIndex:18},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Document/elementFromPoint",paraId:59,tocIndex:18},{value:"When there are multiple graphs stacked on the target point, this method returns them sorted by ",paraId:60,tocIndex:19},{value:"z-index",paraId:61,tocIndex:19},{value:", with the first element of the result being the topmost graph.",paraId:60,tocIndex:19},{value:"This method also accepts a set of ",paraId:62,tocIndex:19},{value:"x, y",paraId:62,tocIndex:19},{value:" coordinates as arguments.",paraId:62,tocIndex:19},{value:"In the following ",paraId:63,tocIndex:19},{value:"example",paraId:64,tocIndex:19},{value:", circle2 is on top of circle1, so picking both in the overlapping region appears in the result array, and circle2 comes first.",paraId:63,tocIndex:19},{value:"const elements = await canvas.document.elementsFromPoint(150, 150); // [circle2, circle1, document.documentElement]\n",paraId:65,tocIndex:19},{value:"Caveats.",paraId:66,tocIndex:19},{value:"The difference between this return result and ",paraId:67,tocIndex:19},{value:"composedPath()",paraId:68,tocIndex:19},{value:" on the event object is that the latter appends ",paraId:67,tocIndex:19},{value:"Document",paraId:69,tocIndex:19},{value:" and ",paraId:67,tocIndex:19},{value:"Canvas",paraId:70,tocIndex:19},{value:" objects, while the former only goes to ",paraId:67,tocIndex:19},{value:"Canvas root",paraId:71,tocIndex:19},{value:". 2.",paraId:67,tocIndex:19},{value:"Return an empty array beyond the canvas viewport range.",paraId:67,tocIndex:19},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Document/elementsFromPoint",paraId:72,tocIndex:19},{value:"Area queries, especially boundingbox-based detection, are particularly useful in scenarios such as",paraId:73,tocIndex:20},{value:"Dirty rectangle rendering for determining the affected area",paraId:74,tocIndex:20},{value:"Rectangle swiping for batch selection of graphics",paraId:74,tocIndex:20},{value:"This type of wraparound box-based detection does not need to be too precise, and is fast with spatial indexing like internal RBush.",paraId:75,tocIndex:20},{value:"This method is synchronous and accepts the enclosing box description ",paraId:76,tocIndex:20},{value:"minX, minY, maxX, maxY",paraId:76,tocIndex:20},{value:" coordinates (under ",paraId:76,tocIndex:20},{value:"Canvas coordinate system",paraId:77,tocIndex:20},{value:").",paraId:76,tocIndex:20},{value:"const elements = document.elementsFromBBox(minX, minY, maxX, maxY);\n",paraId:78,tocIndex:20},{value:"Caveats.",paraId:79,tocIndex:20},{value:"will consider ",paraId:80,tocIndex:20},{value:"visibility",paraId:81,tocIndex:20},{value:" and ",paraId:80,tocIndex:20},{value:"pointer-events",paraId:82,tocIndex:20},{value:" attributes",paraId:80,tocIndex:20},{value:"no need to consider GPU-based picking implementations like WebGL / WebGPU, synchronous methods",paraId:80,tocIndex:20},{value:"the returned array of elements is sorted by the actual rendering order",paraId:80,tocIndex:20},{value:"The synchronized version of ",paraId:83,tocIndex:21},{value:"elementFromPoint",paraId:84,tocIndex:21},{value:", it is worth noting that not all ",paraId:83,tocIndex:21},{value:"renderers",paraId:85,tocIndex:21},{value:" will implement this method, currently only ",paraId:83,tocIndex:21},{value:"g-canvas",paraId:86,tocIndex:21},{value:", ",paraId:83,tocIndex:21},{value:"g-svg",paraId:87,tocIndex:21},{value:" and ",paraId:83,tocIndex:21},{value:"g-canvaskit",paraId:88,tocIndex:21},{value:" provide the corresponding implementations.",paraId:83,tocIndex:21},{value:"const element = canvas.document.elementFromPoint(0, 0); // canvas.document.documentElement\n",paraId:89,tocIndex:21},{value:"The synchronized version of ",paraId:90,tocIndex:22},{value:"elementsFromPoint",paraId:91,tocIndex:22},{value:", it is worth noting that not all ",paraId:90,tocIndex:22},{value:"renderers",paraId:92,tocIndex:22},{value:" will implement this method, currently only ",paraId:90,tocIndex:22},{value:"g-canvas",paraId:93,tocIndex:22},{value:", ",paraId:90,tocIndex:22},{value:"g-svg",paraId:94,tocIndex:22},{value:" and [g-canvaskit](/en/api/renderer/ canvaskit) provide the corresponding implementations.",paraId:90,tocIndex:22},{value:"const elements = canvas.document.elementsFromPoint(150, 150); // [circle2, circle1, document.documentElement]\n",paraId:95,tocIndex:22}]},6442:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(72199);const n=[{value:"The following inheritance relationships exist in G.",paraId:0},{value:"DisplayObject -> Element -> Node -> EventTarget",paraId:1},{value:"Node",paraId:2},{value:"Unique in the scenario map, which can be subsequently queried by ",paraId:3,tocIndex:2},{value:"getElementById",paraId:3,tocIndex:2},{value:".",paraId:3,tocIndex:2},{value:"const circle = new Circle({\n    id: 'my-id',\n    style: { r: 10 },\n});\n\ncircle.id; // 'my-id';\n",paraId:4,tocIndex:2},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/id",paraId:5,tocIndex:2},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/name",paraId:6,tocIndex:3},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/className",paraId:7,tocIndex:4},{value:"Read-only property that returns a list of class names.",paraId:8,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/classList",paraId:9,tocIndex:5},{value:"circle.className = 'c1 c2';\ncircle.classList; // ['c1', 'c2']\n",paraId:10,tocIndex:5},{value:"Read-only, returns style attributes, e.g.",paraId:11,tocIndex:6},{value:"const circle = new Circle({ style: { r: 10 } });\n\ncircle.attributes.r; // 10;\n",paraId:12,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/attributes",paraId:13,tocIndex:6},{value:"Returns a list of child elements, equivalent to Node.childNodes.",paraId:14,tocIndex:7},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/children",paraId:15,tocIndex:7},{value:"Return the length of the list of child elements.",paraId:16,tocIndex:8},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/childElementCount",paraId:17,tocIndex:8},{value:"Equals ",paraId:18,tocIndex:9},{value:"Node.firstChild",paraId:19,tocIndex:9},{value:".",paraId:18,tocIndex:9},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/firstElementChild",paraId:20,tocIndex:9},{value:"Equals ",paraId:21,tocIndex:10},{value:"Node.lastChild",paraId:22,tocIndex:10},{value:".",paraId:21,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/lastElementChild",paraId:23,tocIndex:10},{value:"Since border is not supported at the moment, it always returns 0.",paraId:24,tocIndex:11},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/clientTop",paraId:25,tocIndex:11},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/getAttributeNames",paraId:26,tocIndex:13},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/getAttribute",paraId:27,tocIndex:14},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/removeAttribute",paraId:28,tocIndex:15},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/setAttribute",paraId:29,tocIndex:16},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/hasAttribute",paraId:30,tocIndex:17},{value:"Returns the enclosing box in the browser coordinate system, regardless of child elements.",paraId:31,tocIndex:18},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/getBoundingClientRect",paraId:32,tocIndex:18},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/getClientRects",paraId:33,tocIndex:19},{value:"Get the parsed style Map of ",paraId:34,tocIndex:20},{value:"style system",paraId:35,tocIndex:20},{value:", e.g.",paraId:34,tocIndex:20},{value:"const circle = new Circle({\n  style: {\n    r: 100,\n    fill: '#f00',\n  },\n});\n\n/**\n * user-defined values\n */\nexpect(circle.getAttribute('r')).toBe(100);\nexpect(circle.getAttribute('fill')).toBe('#f00');\n\n/**\n * computed values\n */\nconst styleMap = circle.computedStyleMap();\nexpect((styleMap.get('r') as CSSUnitValue).equals(CSS.px(100))).to.be.true;\nconst fill = styleMap.get('fill') as CSSRGB;\nexpect(fill.r).toBe(255);\nexpect(fill.g).toBe(0);\nexpect(fill.b).toBe(0);\nexpect(fill.alpha).toBe(1);\n",paraId:36,tocIndex:20},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/computedStyleMap",paraId:37,tocIndex:20},{value:"Destroying itself will remove all event listeners and stop the ongoing animation.",paraId:38,tocIndex:21},{value:"Whether or not to match the selector string",paraId:39,tocIndex:23},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/matches",paraId:40,tocIndex:23},{value:"Add a group of nodes in bulk at the end of the child node list of the current node.",paraId:41,tocIndex:32},{value:"parent.appendChild(child1);\nparent.appendChild(child2); // parent -> [child1, child2]\nparent.append(child3, child34); // parent -> [child1, child2, child3, child4]\n",paraId:42,tocIndex:32},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/append",paraId:43,tocIndex:32},{value:"Add a group of nodes in bulk to the head of the current node's child node list.",paraId:44,tocIndex:33},{value:"parent.appendChild(child1);\nparent.appendChild(child2); // parent -> [child1, child2]\nparent.prepend(child3, child34); // parent -> [child3, child4, child1, child2]\n",paraId:45,tocIndex:33},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/prepend",paraId:46,tocIndex:33},{value:"Add some sibling nodes in bulk after the current node, e.g. add a batch at once.",paraId:47,tocIndex:34},{value:"circle.after(sibling1, sibling2); // [circle, sibling1, sibling2]\n",paraId:48,tocIndex:34},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/after",paraId:49,tocIndex:34},{value:"Add some sibling nodes in bulk before the current node, e.g. add a batch at once.",paraId:50,tocIndex:35},{value:"circle.before(sibling1, sibling2); // [sibling1, sibling2, circle]\n",paraId:51,tocIndex:35},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/before",paraId:52,tocIndex:35},{value:"Remove itself from the scene graph.",paraId:53,tocIndex:36},{value:"circle.remove();\n",paraId:54,tocIndex:36},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/remove",paraId:55,tocIndex:36},{value:"Remove all child nodes from the scene graph.",paraId:56,tocIndex:37},{value:"parent.removeChildren();\n",paraId:57,tocIndex:37},{value:"In the list of children of the parent node, replace the node with the list of nodes passed in.",paraId:58,tocIndex:38},{value:"parent.appendChild(child1);\nparent.appendChild(child2); // parent -> [child1, child2]\nchild1.replaceWith(node1, node2); // parent -> [node1, node2, child2]\n",paraId:59,tocIndex:38},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/replaceWith",paraId:60,tocIndex:38},{value:"Replace all children of the node. If no parameters are passed, all children of the node are cleared and destroyed.",paraId:61,tocIndex:39},{value:"parent.replaceChildren(child1, child2);\nparent.replaceChildren(); // 清空\n",paraId:62,tocIndex:39},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/replaceChildren",paraId:63,tocIndex:39},{value:"Returns a list of animation objects applied to the current element, see ",paraId:64,tocIndex:40},{value:"animation system",paraId:65,tocIndex:40},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Element/getAnimations",paraId:66,tocIndex:40},{value:"Apply Keyframe animation, see ",paraId:67,tocIndex:41},{value:"animation system",paraId:68,tocIndex:41},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/animate",paraId:69,tocIndex:41}]},10308:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(30160);const n=[{value:"Similar to ",paraId:0},{value:"EventTarget",paraId:0},{value:" in the DOM API, this object provides the ability to bind/unbind events.",paraId:0},{value:"The following inheritance relationships exist in G, so the high-level objects ",paraId:1},{value:"Canvas",paraId:2},{value:", ",paraId:1},{value:"Document",paraId:3},{value:", ",paraId:1},{value:"DisplayObject",paraId:4},{value:" all have event management capabilities.",paraId:1},{value:"Canvas -> EventTarget",paraId:5},{value:"Document -> Node -> EventTarget",paraId:5},{value:"DisplayObject -> Element -> Node -> EventTarget",paraId:5},{value:"Specific API can be found in ",paraId:6},{value:"event system",paraId:7},{value:".",paraId:6},{value:"Bind event: ",paraId:8},{value:"addEventListener",paraId:9},{value:"Unbind event: ",paraId:8},{value:"removeEventListener",paraId:10},{value:"Trigger custom events: ",paraId:8},{value:"dispatchEvent",paraId:11},{value:"Remove all event listeners ",paraId:8},{value:"removeAllEventListeners",paraId:12}]},56525:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(37094);const n=[{value:"在 DOM API 中，当我们想感知 DOM 树节点的修改，例如新节点加入、属性值变更，可以使用 ",paraId:0},{value:"MutationObserver",paraId:0},{value:"。",paraId:0},{value:"在 G 中我们同样实现了这个 API，用来监听场景图中的变化。",paraId:1},{value:"创建一个 MutationObserver 需要传入一个 callback：",paraId:2,tocIndex:0},{value:"const group1 = new Group();\nconst group2 = new Group();\nconst group3 = new Group();\ncanvas.appendChild(group1);\n\n// 创建一个 MutationObserver\nconst observer = new MutationObserver(() => {});\n\n// 开始监听\nobserver.observe(group1, { childList: true });\n\n// 操作场景图\ngroup1.appendChild(group2);\ngroup1.appendChild(group3);\n\n// 获取变更记录\nconst records = observer.takeRecords();\n\n// 断开监听\nobserver.disconnect();\n",paraId:3,tocIndex:0},{value:"监听场景图中一个节点的变化，可以通过配置选择监听单个节点或者全部子孙节点。",paraId:4,tocIndex:1},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MutationObserver/observe",paraId:5,tocIndex:1},{value:"mutationObserver.observe(target[, options])\n",paraId:6,tocIndex:1},{value:"options",paraId:7,tocIndex:1},{value:" 为可选项，类型为 ",paraId:7,tocIndex:1},{value:"MutationObserverInit",paraId:7,tocIndex:1},{value:" 配置如下：",paraId:7,tocIndex:1},{value:"childList",paraId:8,tocIndex:1},{value:" 设为 true 以监视目标节点（如果 subtree 为 true，则包含子孙节点）添加或删除新的子节点。默认值为 false。",paraId:8,tocIndex:1},{value:"subtree",paraId:8,tocIndex:1},{value:" 设为 true 以将监视范围扩展至目标节点整个节点树中的所有节点。MutationObserverInit 的其他值也会作用于此子树下的所有节点，而不仅仅只作用于目标节点。默认值为 false。",paraId:8,tocIndex:1},{value:"attributes",paraId:8,tocIndex:1},{value:" 设为 true 以观察受监视元素的属性值变更。默认值为 false。",paraId:8,tocIndex:1},{value:"attributeOldValue",paraId:8,tocIndex:1},{value:" 当监视节点的属性改动时，将此属性设为 true 将记录任何有改动的属性的上一个值。",paraId:8,tocIndex:1},{value:"attributeFilter",paraId:8,tocIndex:1},{value:" 要监视的特定属性名称的数组。如果未包含此属性，则对所有属性的更改都会触发变动通知。无默认值。",paraId:8,tocIndex:1},{value:"断开监听。",paraId:9,tocIndex:2},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MutationObserver/disconnect",paraId:10,tocIndex:2},{value:"获取变更记录。",paraId:11,tocIndex:3},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MutationObserver/takeRecords",paraId:12,tocIndex:3},{value:"在下面的例子中，我们监听父节点的变化，当加入两个子节点后获取到两条变更记录：",paraId:13,tocIndex:3},{value:"const group1 = new Group();\nconst group2 = new Group();\nconst group3 = new Group();\ncanvas.appendChild(group1);\n\n// 创建一个 MutationObserver\nconst observer = new MutationObserver(() => {});\n\n// 开始监听 group1 上的变更\nobserver.observe(group1, { childList: true });\n\n// 操作场景图\ngroup1.appendChild(group2);\ngroup1.appendChild(group3);\n\n// 获取变更记录\nconst records = observer.takeRecords();\n// 包含两条记录\nexpect(records.length).to.eqls(2);\nexpect(records[0].type).to.eqls('childList');\nexpect(records[0].target).to.eqls(group1);\nexpect(records[0].addedNodes.length).to.eqls(1);\nexpect(records[0].addedNodes[0]).to.eqls(group2);\n\nexpect(records[1].type).to.eqls('childList');\nexpect(records[1].target).to.eqls(group1);\nexpect(records[1].addedNodes.length).to.eqls(1);\nexpect(records[1].addedNodes[0]).to.eqls(group3);\nexpect(records[1].previousSibling).to.eqls(group2);\n",paraId:14,tocIndex:3}]},74948:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(15533);const n=[{value:"Similar to ",paraId:0},{value:"Node",paraId:0},{value:" in the DOM API, this object provides part of the scene graph capabilities, such as node addition, deletion, etc.",paraId:0},{value:"The following inheritance relationships exist in G.",paraId:1},{value:"Document -> Node -> EventTarget",paraId:2},{value:"DisplayObject -> Element -> Node -> EventTarget",paraId:2},{value:"EventTarget",paraId:3},{value:"Read-only, returns the node name, e.g.",paraId:4,tocIndex:2},{value:"circle.nodeName; // 'circle'\nrect.nodeName; // 'rect'\n",paraId:5,tocIndex:2},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/nodeName",paraId:6,tocIndex:2},{value:"G The built-in graphic names are as follows.",paraId:7,tocIndex:2},{value:"export enum Shape {\n  GROUP = 'g',\n  CIRCLE = 'circle',\n  ELLIPSE = 'ellipse',\n  IMAGE = 'image',\n  RECT = 'rect',\n  LINE = 'line',\n  POLYLINE = 'polyline',\n  POLYGON = 'polygon',\n  TEXT = 'text',\n  PATH = 'path',\n  HTML = 'html',\n  MESH = 'mesh'\n}\n",paraId:8,tocIndex:2},{value:"Read-only, return node string, default is null.",paraId:9,tocIndex:3},{value:"Text",paraId:10,tocIndex:3},{value:" will return text string.",paraId:9,tocIndex:3},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/nodeValue",paraId:11,tocIndex:3},{value:"const group = new Group();\ngroup.nodeValue; // null\n\nconst text = new Text({ style: { text: 'test' } });\ntext.nodeValue; // 'test'\n",paraId:12,tocIndex:3},{value:"Read-only, whether it is added to the canvas, e.g.",paraId:13,tocIndex:4},{value:"circle.isConnected; // false\ncanvas.appendChild(circle); // 加入到画布中\ncircle.isConnected; // true\n",paraId:14,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/isConnected",paraId:15,tocIndex:4},{value:"Read-only, pointing to the entry ",paraId:16,tocIndex:5},{value:"Document",paraId:17,tocIndex:5},{value:" of the canvas. Returns null if not yet added to the canvas, e.g.",paraId:16,tocIndex:5},{value:"circle.ownerDocument; // null\ncanvas.appendChild(circle); // 加入到画布中\ncircle.ownerDocument; // canvas.document\n",paraId:18,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/ownerDocument",paraId:19,tocIndex:5},{value:"Read-only, returns the parent node of the current node.",paraId:20,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/parentNode",paraId:21,tocIndex:6},{value:"Read-only, same as parentNode in the current implementation.",paraId:22,tocIndex:7},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/parentElement",paraId:23,tocIndex:7},{value:"Read-only, returns the list of child nodes of the current node.",paraId:24,tocIndex:8},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/childNodes",paraId:25,tocIndex:8},{value:"Read-only, returns the first child of the current node, or null if there are no children.",paraId:26,tocIndex:9},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/firstChild",paraId:27,tocIndex:9},{value:"Read-only, returns the last child of the current node, or null if there are no children.",paraId:28,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/lastChild",paraId:29,tocIndex:10},{value:"Read-only, returns the next sibling of the current node, or null if none.",paraId:30,tocIndex:11},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/nextSibling",paraId:31,tocIndex:11},{value:"Read-only, returns the previous sibling of the current node, or null if there is none.",paraId:32,tocIndex:12},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/previousSibling",paraId:33,tocIndex:12},{value:"Read/write property to get or set the text content of the node. The default returns the empty string, ",paraId:34,tocIndex:13},{value:"Text",paraId:35,tocIndex:13},{value:" will return the text string.",paraId:34,tocIndex:13},{value:"When reading, this method recursively computes the sub-nodes and returns the final stitched string as.",paraId:36,tocIndex:13},{value:"const group = new Group();\ngroup.textContent; // ''\n\nconst text = new Text({ style: { text: 'test' } });\ngroup.appendChild(text);\n\ntext.textContent; // 'test'\ngroup.textContent; // 'test'\n",paraId:37,tocIndex:13},{value:"When setting, all children of this node will be removed first, if the node is ",paraId:38,tocIndex:13},{value:"Text",paraId:39,tocIndex:13},{value:", the text content will be modified directly; if the node is not ",paraId:38,tocIndex:13},{value:"Text",paraId:40,tocIndex:13},{value:", a ",paraId:38,tocIndex:13},{value:"Text",paraId:41,tocIndex:13},{value:" will be created as a child node and the text content will be set.",paraId:38,tocIndex:13},{value:"const text = new Text({ style: { text: 'test' } });\ntext.textContent = 'changed';\n\n// create a Text & insertChild\ngroup.textContent = 'changed';\ngroup.childNodes; // [Text]\n",paraId:42,tocIndex:13},{value:"Adds a node to the end of the child node list of the specified parent node. If the node is already in the scene graph, it will be removed from its original position and then added to the new position.",paraId:43,tocIndex:15},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/appendChild",paraId:44,tocIndex:15},{value:"The method signature is ",paraId:45,tocIndex:16},{value:"cloneNode(deep?: boolean): this",paraId:45,tocIndex:16},{value:", with optional arguments for whether a deep copy is needed, and returns the new node obtained by cloning.",paraId:45,tocIndex:16},{value:"In the following example, we create a circle, set its radius and position. The new node is copied with the same style properties and position.",paraId:46,tocIndex:16},{value:"circle.style.r = 20;\ncircle.setPosition(10, 20);\n\nconst clonedCircle = circle.cloneNode();\nclonedCircle instanceof Circle; // true\nclonedCircle.style.r; // 20\nclonedCircle.getPosition(); // [10, 20]\n",paraId:47,tocIndex:16},{value:"Caveats.",paraId:48,tocIndex:16},{value:"Deep copy support, i.e. itself and the whole subtree",paraId:49,tocIndex:16},{value:"Cloned new nodes do not retain the parent-child relationship of the original node, and need to be added to the canvas using ",paraId:49,tocIndex:16},{value:"appendChild",paraId:49,tocIndex:16},{value:" before they will be rendered",paraId:49,tocIndex:16},{value:"Consistent with the ",paraId:49,tocIndex:16},{value:"DOM API",paraId:49,tocIndex:16},{value:", event listeners on the original graph are not copied",paraId:49,tocIndex:16},{value:"In this ",paraId:50,tocIndex:16},{value:"example",paraId:51,tocIndex:16},{value:", we demonstrate the above features.",paraId:50,tocIndex:16},{value:"The style properties of the original node can be changed at any time, the copy will be up-to-date, and the new node will also need to be added to the scene graph before it will be rendered",paraId:52,tocIndex:16},{value:"However, since no event listeners are copied, only the original node can be dragged and dropped",paraId:52,tocIndex:16},{value:"In non-deep copy mode, Text (Drag me Text) is not copied as a child of Circle.",paraId:52,tocIndex:16},{value:"Determine if the incoming node is a descendant of this node.",paraId:53,tocIndex:17},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/contains",paraId:54,tocIndex:17},{value:"Returns the root node of the current node. If it has already been added to the canvas, it returns canvas.document For example",paraId:55,tocIndex:18},{value:"circle.getRootNode(); // circle\ncanvas.appendChild(circle);\ncircle.getRootNode(); // canvas.document\n",paraId:56,tocIndex:18},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/getRootNode",paraId:57,tocIndex:18},{value:"Returns the ancestor node at the specified level, e.g.",paraId:58,tocIndex:19},{value:"circle.getAncestor(2); // circle.parentNode.parentNode\n",paraId:59,tocIndex:19},{value:"If the lookup goes beyond the root node, null is returned.",paraId:60,tocIndex:19},{value:"circle.getAncestor(100); // null\n",paraId:61,tocIndex:19},{value:"If or not there are child nodes.",paraId:62,tocIndex:20},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/hasChildNodes",paraId:63,tocIndex:20},{value:"The full method signature is:",paraId:64,tocIndex:21},{value:"insertBefore(child: Node, reference?: Node): Node\n",paraId:65,tocIndex:21},{value:"Inserts a child node with the specified parent node before the reference node. If the given child node is a reference to an existing node in the document, insertBefore() will move it from its current position to the new position (it is not necessary to remove the node from its parent before attaching it to another node).",paraId:66,tocIndex:21},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/insertBefore",paraId:67,tocIndex:21},{value:"The full method signature is:",paraId:68,tocIndex:22},{value:"removeChild(child: Node, destroy?: boolean): Node\n",paraId:69,tocIndex:22},{value:"Deletes a child node, finally returns the deleted child node.",paraId:70,tocIndex:22},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/removeChild",paraId:71,tocIndex:22},{value:"Replaces a child node of the current node with the specified node, and returns the replaced node.",paraId:72,tocIndex:23},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/replaceChild",paraId:73,tocIndex:23},{value:"Determines if two nodes are equal.",paraId:74,tocIndex:24},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Node/isEqualNode",paraId:75,tocIndex:24},{value:"Compare the positions of the two nodes in the scene graph.",paraId:76,tocIndex:25},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Node/compareDocumentPosition",paraId:77,tocIndex:25},{value:"For example, comparing itself will return 0.",paraId:78,tocIndex:25},{value:"const group1 = new Element();\nexpect(group1.compareDocumentPosition(group1)).to.eqls(0);\n",paraId:79,tocIndex:25},{value:"Comparison with another node with no common ancestor.",paraId:80,tocIndex:25},{value:"const group1 = new Element();\nconst group2 = new Element();\nexpect(group1.compareDocumentPosition(group2)).to.eqls(\n    Node.DOCUMENT_POSITION_DISCONNECTED |\n        Node.DOCUMENT_POSITION_IMPLEMENTATION_SPECIFIC |\n        Node.DOCUMENT_POSITION_PRECEDING,\n);\n",paraId:81,tocIndex:25},{value:"Parent-child nodes.",paraId:82,tocIndex:25},{value:"group1.appendChild(group2);\nexpect(group1.compareDocumentPosition(group2)).to.eqls(\n    Node.DOCUMENT_POSITION_CONTAINED_BY | Node.DOCUMENT_POSITION_FOLLOWING,\n);\nexpect(group2.compareDocumentPosition(group1)).to.eqls(\n    Node.DOCUMENT_POSITION_CONTAINS | Node.DOCUMENT_POSITION_PRECEDING,\n);\n",paraId:83,tocIndex:25},{value:"Sibling Nodes.",paraId:84,tocIndex:25},{value:"// 1 -> 2\n// 1 -> 4\ngroup1.appendChild(group2);\ngroup1.appendChild(group4);\nexpect(group2.compareDocumentPosition(group4)).to.eqls(\n    Node.DOCUMENT_POSITION_PRECEDING,\n);\nexpect(group4.compareDocumentPosition(group2)).to.eqls(\n    Node.DOCUMENT_POSITION_FOLLOWING,\n);\n",paraId:85,tocIndex:25},{value:"The enumeration values are as follows.",paraId:86,tocIndex:25},{value:"static DOCUMENT_POSITION_DISCONNECTED = 1;\nstatic DOCUMENT_POSITION_PRECEDING = 2;\nstatic DOCUMENT_POSITION_FOLLOWING = 4;\nstatic DOCUMENT_POSITION_CONTAINS = 8;\nstatic DOCUMENT_POSITION_CONTAINED_BY = 16;\nstatic DOCUMENT_POSITION_IMPLEMENTATION_SPECIFIC = 32;\n",paraId:87,tocIndex:25}]},4274:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(45786);const n=[{value:"We provide a range of tool methods for use with the core as well as plug-ins, such as:",paraId:0},{value:"import { convertToPath } from '@antv/g';\n",paraId:1},{value:"It mainly involves the conversion between different angle units.",paraId:2,tocIndex:0},{value:"Angle conversion to radians.",paraId:3,tocIndex:1},{value:"deg2rad(deg: number): number;\n",paraId:4,tocIndex:1},{value:"Radians conversion to angle.",paraId:5,tocIndex:2},{value:"rad2deg(rad: number): number;\n",paraId:6,tocIndex:2},{value:"Angle conversion to turn.",paraId:7,tocIndex:3},{value:"deg2turn(deg: number): number;\n",paraId:8,tocIndex:3},{value:"Turn conversion to angle.",paraId:9,tocIndex:4},{value:"turn2deg(turn: number): number;\n",paraId:10,tocIndex:4},{value:"In the vast majority of cases, we can use the graphics' own transformation capabilities, which are implemented internally via ",paraId:11,tocIndex:5},{value:"gl-matrix",paraId:11,tocIndex:5},{value:".",paraId:11,tocIndex:5},{value:"Decompose the 3x3 transformation matrix to obtain translation, scaling and rotation angles.",paraId:12,tocIndex:6},{value:"https://www.w3.org/TR/css-transforms-1/#decomposing-a-2d-matrix",paraId:13,tocIndex:6},{value:"const [tx, ty, scalingX, scalingY, angle] = decompose(mat3);\n",paraId:14,tocIndex:6},{value:"Get the Euler angles from ",paraId:15,tocIndex:7},{value:"quat",paraId:15,tocIndex:7},{value:" or ",paraId:15,tocIndex:7},{value:"mat4",paraId:15,tocIndex:7},{value:". The method signature is as follows.",paraId:15,tocIndex:7},{value:"getEuler(out: vec3, quat: quat | mat4): vec3\n",paraId:16,tocIndex:7},{value:"来自：",paraId:17,tocIndex:7},{value:"https://github.com/toji/gl-matrix/issues/329",paraId:17,tocIndex:7},{value:"Create ",paraId:18,tocIndex:8},{value:"vec3",paraId:18,tocIndex:8},{value:" that accepts multiple types of arguments. The method signature is as follows.",paraId:18,tocIndex:8},{value:"createVec3(x: number | vec2 | vec3 | vec4, y: number = 0, z: number = 0): vec3;\n",paraId:19,tocIndex:8},{value:"Most calculations involving paths rely on ",paraId:20,tocIndex:9},{value:"@antv/util",paraId:20,tocIndex:9},{value:".",paraId:20,tocIndex:9},{value:"Morph animation",paraId:21,tocIndex:10},{value:" is implemented by interpolating the ",paraId:22,tocIndex:10},{value:"path/d",paraId:23,tocIndex:10},{value:" property of ",paraId:22,tocIndex:10},{value:"Path",paraId:24,tocIndex:10},{value:".",paraId:22,tocIndex:10},{value:"The method signature is as follows.",paraId:25,tocIndex:10},{value:"convertToPath(\n    object: Circle | Ellipse | Rect | Line | Polyline | Polygon | Path,\n    transform = object.getLocalTransform()\n): string;\n",paraId:26,tocIndex:10},{value:"This method supports the following base graphics, not ",paraId:27,tocIndex:10},{value:"Group",paraId:28,tocIndex:10},{value:" or other custom graphics.",paraId:27,tocIndex:10},{value:"Circle",paraId:29,tocIndex:10},{value:"Ellipse",paraId:30,tocIndex:10},{value:"Rect",paraId:31,tocIndex:10},{value:"Line",paraId:32,tocIndex:10},{value:"Polyline",paraId:33,tocIndex:10},{value:"Polygon",paraId:34,tocIndex:10},{value:"Path",paraId:35,tocIndex:10},{value:"The result of the transformation is a third-order Bezier curve in the form of a string, which is easy to split, and the paths before and after the transformation are normalized to the same number of segments, and finally the control points in each segment are interpolated to achieve the animation effect.",paraId:36,tocIndex:10},{value:"The transformation process will consider the transformation of the input graphics in the local coordinate system (declarative transformation using ",paraId:37,tocIndex:10},{value:"transform",paraId:38,tocIndex:10},{value:" or [imperative transformation method](/en/api/basic/display- object#transform operation)), so the generated path definition already contains transformation information and you can create ",paraId:37,tocIndex:10},{value:"Path",paraId:39,tocIndex:10},{value:" directly based on that path definition. ",paraId:37,tocIndex:10},{value:"Example",paraId:40,tocIndex:10},{value:".",paraId:37,tocIndex:10},{value:"const circle = new Circle({\n    style: {\n        cx: 100,\n        cy: 100,\n        r: 100,\n        transform: 'translate(20px, 20px)', // Declarative transformations\n    },\n});\n// Apply a transformation to the source graph, imperative\ncircle.translate(100, 0);\ncircle.scale(0.5);\n\n// Convert to a path that already contains all the transformation information\nconst pathStr = convertToPath(circle);\n\n// Create new graphics\nconst circlePath = new Path({\n    style: {\n        d: pathStr,\n        fill: 'red',\n    },\n});\n\n// The following transformations are no longer required\n// circlePath.translate(100, 0);\n",paraId:41,tocIndex:10},{value:"In some cases it is not necessary to consider the transformation in the local coordinate system, and the second parameter can be passed as ",paraId:42,tocIndex:10},{value:"mat4.identity()",paraId:42,tocIndex:10},{value:".",paraId:42,tocIndex:10}]},96572:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(20606);const n=[{value:"The three axes of the camera in the camera coordinate system are ",paraId:0},{value:"uvn",paraId:0},{value:".",paraId:0},{value:"The camera movements we describe later are actually movement and rotation along these three axes.",paraId:1},{value:"The following picture is from Television Production Handbook p.97. The cameras used in the early years of television were moved by tracks.",paraId:2},{value:"Disregarding the crane and tongue movements, which rely on the rocker, the translations and rotations along the three uvn axes can be summarized as follows.",paraId:3},{value:"Action",paraId:4},{value:"Camera Position",paraId:4},{value:"FocalPoint",paraId:4},{value:"u",paraId:4},{value:"v",paraId:4},{value:"n",paraId:4},{value:"dolly",paraId:4},{value:"pan",paraId:4},{value:"pedestal",paraId:4},{value:"pan",paraId:4},{value:"truck",paraId:4},{value:"pan",paraId:4},{value:"cant",paraId:4},{value:"Center of Rotation",paraId:4},{value:"rotate",paraId:4},{value:"pan",paraId:4},{value:"Center of Rotation",paraId:4},{value:"rotate",paraId:4},{value:"tilt",paraId:4},{value:"Center of Rotation",paraId:4},{value:"rotate",paraId:4},{value:"arc",paraId:4},{value:"Center of Rotation",paraId:4},{value:"rotate",paraId:4},{value:"Naturally, depending on the camera type, the same camera action is implemented differently. Let's take ",paraId:5},{value:"dolly",paraId:6},{value:" action as an example, it's also an action to move the camera position forward and backward, for ",paraId:5},{value:"Orbiting",paraId:7},{value:" / ",paraId:5},{value:"Exploring",paraId:8},{value:" mode the point of view remains the same. In ",paraId:5},{value:"Tracking",paraId:9},{value:" mode, the point of view is adjusted.",paraId:5},{value:"Pans the camera along the u / v axis, i.e., horizontally and vertically.",paraId:10,tocIndex:0},{value:"The method signature is as follows.",paraId:11,tocIndex:0},{value:"pan(tx: number, ty: number)\n",paraId:12,tocIndex:0},{value:"Parameters:",paraId:13,tocIndex:0},{value:"tx",paraId:14,tocIndex:0},{value:" Positive translation along u-axis",paraId:14,tocIndex:0},{value:"ty",paraId:14,tocIndex:0},{value:" Positive translation along v-axis",paraId:14,tocIndex:0},{value:"In this ",paraId:15,tocIndex:0},{value:"example",paraId:16,tocIndex:0},{value:", the following action will cause the object originally at the point of view to be displayed in the upper left corner.",paraId:15,tocIndex:0},{value:"camera.pan(200, 200);\n",paraId:17,tocIndex:0},{value:"In ",paraId:18,tocIndex:0},{value:"g-plugin-control",paraId:19,tocIndex:0},{value:" we respond to the mouse panning event by calling this method.",paraId:18,tocIndex:0},{value:"Move the camera along the n-axis. Fix the viewpoint and change the camera position to change the view distance. It will keep the view distance between ",paraId:20,tocIndex:1},{value:"minDistance",paraId:21,tocIndex:1},{value:" and ",paraId:20,tocIndex:1},{value:"maxDistance",paraId:22,tocIndex:1},{value:".",paraId:20,tocIndex:1},{value:"The method signature is as follows.",paraId:23,tocIndex:1},{value:"dolly(value: number)\n",paraId:24,tocIndex:1},{value:"Parameters:",paraId:25,tocIndex:1},{value:"value",paraId:26,tocIndex:1},{value:" 以 ",paraId:26,tocIndex:1},{value:"dollyingStep",paraId:26,tocIndex:1},{value:" 为单位，正向远离视点，负向靠近",paraId:26,tocIndex:1},{value:"Example:",paraId:27,tocIndex:1},{value:"camera.dolly(10); // Away from the point of view\ncamera.dolly(-10); // Close to the point of view\n",paraId:28,tocIndex:1},{value:"The effect in the pivot projection is as follows. In ",paraId:29,tocIndex:1},{value:"g-plugin-control",paraId:30,tocIndex:1},{value:" we respond to the mouse wheel event by calling this method.",paraId:29,tocIndex:1},{value:"Rotate by camera azimuth, counterclockwise is positive.",paraId:31,tocIndex:2},{value:"The method signature is as follows.",paraId:32,tocIndex:2},{value:"rotate(azimuth: number, elevation: number, roll: number)\n",paraId:33,tocIndex:2},{value:'2D scenes only need to specify rolls, e.g. for the camera to "tilt its head".',paraId:34,tocIndex:2},{value:"camera.rotate(0, 0, 30);\n",paraId:35,tocIndex:2}]},93083:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(79047);const n=[{value:"We can record the current position and viewpoint of the camera and save it as a Landmark, and then when the camera parameters change, you can switch to any of the previously saved Landmark at any time, with a smooth switching animation, similar to the camera pan arm on a real set, also called ",paraId:0},{value:"flyTo",paraId:0},{value:" in some applications (e.g. ",paraId:0},{value:"Mapbox in application",paraId:0},{value:"), ",paraId:0},{value:"example",paraId:1},{value:".",paraId:0},{value:"Create a Landmark with the following parameters.",paraId:2,tocIndex:0},{value:"markName",paraId:3,tocIndex:0},{value:"options Camera parameters, including.\n",paraId:3,tocIndex:0},{value:"position",paraId:4,tocIndex:0},{value:" The position of the camera in the world coordinate system, taking the type reference ",paraId:4,tocIndex:0},{value:"setPosition",paraId:5,tocIndex:0},{value:"focalPoint",paraId:4,tocIndex:0},{value:" Viewpoint in the world coordinate system, reference to the value type ",paraId:4,tocIndex:0},{value:"setFocalPoint",paraId:6,tocIndex:0},{value:"roll",paraId:4,tocIndex:0},{value:" Rotation angle, take the value type reference ",paraId:4,tocIndex:0},{value:"setRoll",paraId:7,tocIndex:0},{value:"zoom",paraId:4,tocIndex:0},{value:" Zoom scaling, take the value type reference ",paraId:4,tocIndex:0},{value:"setZoom",paraId:8,tocIndex:0},{value:"camera.createLandmark('mark1', {\n    position: [300, 250, 400],\n    focalPoint: [300, 250, 0],\n});\ncamera.createLandmark('mark2', {\n    position: [300, 600, 500],\n    focalPoint: [300, 250, 0],\n});\ncamera.createLandmark('mark3', {\n    position: [0, 250, 800],\n    focalPoint: [300, 250, 0],\n    roll: 30,\n});\n",paraId:9,tocIndex:0},{value:"Switching to a previously saved Landmark works in both 2D and 3D scenes, ",paraId:10,tocIndex:1},{value:"example",paraId:11,tocIndex:1},{value:".",paraId:10,tocIndex:1},{value:"camera.gotoLandmark('mark1', { duration: 300, easing: 'ease-in' });\n// or\ncamera.gotoLandmark(landmark, { duration: 300, easing: 'ease-in' });\n",paraId:12,tocIndex:1},{value:"The list of parameters is as follows.",paraId:13,tocIndex:1},{value:"markName",paraId:14,tocIndex:1},{value:"options Camera parameters, including.\n",paraId:14,tocIndex:1},{value:"duration",paraId:15,tocIndex:1},{value:" Duration of the animation in ",paraId:15,tocIndex:1},{value:"ms",paraId:15,tocIndex:1},{value:", default value is ",paraId:15,tocIndex:1},{value:"100",paraId:15,tocIndex:1},{value:".",paraId:15,tocIndex:1},{value:"easing",paraId:15,tocIndex:1},{value:" Easing function, default value is ",paraId:15,tocIndex:1},{value:"linear",paraId:15,tocIndex:1},{value:". Consistent with the animation system ",paraId:15,tocIndex:1},{value:"built-in effects",paraId:16,tocIndex:1},{value:"easingFunction",paraId:15,tocIndex:1},{value:" Custom easing function, when the built-in easing function can not meet the requirements, you can ",paraId:15,tocIndex:1},{value:"custom",paraId:17,tocIndex:1},{value:"onfinish",paraId:15,tocIndex:1},{value:" Callback function at the end of the animation",paraId:15,tocIndex:1},{value:"As with the ",paraId:18,tocIndex:1},{value:"options",paraId:19,tocIndex:1},{value:" parameter in the animation system, passing ",paraId:18,tocIndex:1},{value:"number",paraId:18,tocIndex:1},{value:" is equivalent to setting ",paraId:18,tocIndex:1},{value:"duration",paraId:18,tocIndex:1},{value:".",paraId:18,tocIndex:1},{value:"camera.gotoLandmark('mark1', { duration: 300 });\ncamera.gotoLandmark('mark1', 300);\n",paraId:20,tocIndex:1},{value:"It is important to note that if another camera animation is called before the end of one, the animation in progress will be cancelled immediately.",paraId:21,tocIndex:1}]},36266:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(94211);const n=[{value:"The camera describes the angle from which we view the world. The viewpoint and camera position all affect the final image. When creating the ",paraId:0},{value:"Canvas",paraId:1},{value:" canvas, there is already a built-in camera that uses orthogonal projection by default. So we don't need to create it manually, we can get it as follows.",paraId:0},{value:"const camera = canvas.getCamera();\n",paraId:2},{value:"By manipulating the camera we can easily achieve many effects, such as panning and zooming the entire canvas. This will be a big improvement in rendering performance.",paraId:3},{value:"The camera currently supports the following features.",paraId:4},{value:"Two projection modes: Orthographic ",paraId:5},{value:"Orthogonal",paraId:6},{value:" and Perspective ",paraId:5},{value:"Perspective",paraId:7},{value:", the former is used by default.",paraId:5},{value:"Three camera types: ",paraId:5},{value:"Exploring",paraId:8},{value:", ",paraId:5},{value:"Orbiting",paraId:9},{value:" and ",paraId:5},{value:"Tracking",paraId:10},{value:", Exploring is used by default.",paraId:5},{value:"Camera action. For example ",paraId:5},{value:"pan",paraId:11},{value:", ",paraId:5},{value:"dolly",paraId:12},{value:", ",paraId:5},{value:"rotate",paraId:13},{value:"Customize ",paraId:5},{value:"camera animation",paraId:14},{value:" to create/save the current camera state as a Landmark and smoothly switch between multiple Landmarks.",paraId:5},{value:'The orthogonal projection (left) is commonly used in CAD software and strategy games (Sims). The perspective projection (right) follows our perception of "large near and small far".',paraId:15,tocIndex:0},{value:"We offer the above two projection modes.",paraId:16,tocIndex:0},{value:"enum CameraProjectionMode {\n  ORTHOGRAPHIC,\n  PERSPECTIVE,\n}\n",paraId:17,tocIndex:0},{value:"We use ",paraId:18,tocIndex:1},{value:"CameraProjectionMode.ORTHOGRAPHIC",paraId:18,tocIndex:1},{value:" by default.",paraId:18,tocIndex:1},{value:"canvas.getCamera().getProjectionMode(); // CameraProjectionMode.ORTHOGRAPHIC\n",paraId:19,tocIndex:1},{value:"In 2D scenes the orthogonal projection is used, so this is the default projection mode of G. In 3D scenes, sometimes we need to switch to perspective projection, so we provide the following two APIs to set the projection mode.",paraId:20,tocIndex:1},{value:"Set the camera projection mode to orthogonal projection ",paraId:21,tocIndex:2},{value:"CameraProjectionMode.ORTHOGRAPHIC",paraId:21,tocIndex:2},{value:"The method signature is as follows.",paraId:22,tocIndex:2},{value:"setOrthographic(left: number, right: number,\n                top: number, bottom: number,\n                near: number, far: number)\n",paraId:23,tocIndex:2},{value:"The list of parameters is as follows.",paraId:24,tocIndex:2},{value:"left",paraId:25,tocIndex:2},{value:" Maximum distance in the negative direction of x-axis",paraId:25,tocIndex:2},{value:"right",paraId:25,tocIndex:2},{value:" Maximum distance in the forward direction of x-axis",paraId:25,tocIndex:2},{value:"top",paraId:25,tocIndex:2},{value:" Maximum distance in the forward direction of y-axis",paraId:25,tocIndex:2},{value:"bottom",paraId:25,tocIndex:2},{value:" Maximum distance in the negative direction of y-axis",paraId:25,tocIndex:2},{value:"near",paraId:25,tocIndex:2},{value:" Near plane",paraId:25,tocIndex:2},{value:"far",paraId:25,tocIndex:2},{value:" Far plane",paraId:25,tocIndex:2},{value:"The default camera settings for G are as follows, where ",paraId:26,tocIndex:2},{value:"width/height",paraId:26,tocIndex:2},{value:" is the size of ",paraId:26,tocIndex:2},{value:"Canvas",paraId:27,tocIndex:2},{value:" and ",paraId:26,tocIndex:2},{value:"usage example",paraId:28,tocIndex:2},{value:".",paraId:26,tocIndex:2},{value:"const camera = new Camera()\n    .setPosition(width / 2, height / 2, 500)\n    .setFocalPoint(width / 2, height / 2, 0)\n    .setOrthographic(width / -2, width / 2, height / 2, height / -2, 0.1, 1000);\n",paraId:29,tocIndex:2},{value:"Set the camera projection mode to Perspective Projection ",paraId:30,tocIndex:3},{value:"CameraProjectionMode.PERSPECTIVE",paraId:30,tocIndex:3},{value:"The method signature is as follows.",paraId:31,tocIndex:3},{value:"setPerspective(near: number, far: number, fov: number, aspect: number)\n",paraId:32,tocIndex:3},{value:"Parameters:",paraId:33,tocIndex:3},{value:"near",paraId:34,tocIndex:3},{value:" Near plane",paraId:34,tocIndex:3},{value:"far",paraId:34,tocIndex:3},{value:" Far plane",paraId:34,tocIndex:3},{value:"fov",paraId:34,tocIndex:3},{value:" Viewing angle, larger means more objects in the scene can be accommodated",paraId:34,tocIndex:3},{value:"aspect",paraId:34,tocIndex:3},{value:" Width-to-Height Ratio",paraId:34,tocIndex:3},{value:"Example",paraId:35,tocIndex:3},{value:"：",paraId:36,tocIndex:3},{value:"camera\n    .setPosition(300, 100, 500)\n    .setFocalPoint(300, 250, 0)\n    .setPerspective(0.1, 1000, 75, 600 / 500);\n",paraId:37,tocIndex:3},{value:"In 2D scenes, if we want to move around the scene, we usually use panning and zooming. In 3D scenes different camera types will bring different visual effects.",paraId:38,tocIndex:4},{value:"The image on the left is a fixed point of view, moving the camera position to observe the scene, mostly seen in model observation. On the right, the camera position is fixed and the viewpoint is adjusted to observe all objects in the scene.",paraId:39,tocIndex:4},{value:"We offer three types.",paraId:40,tocIndex:4},{value:"export enum CameraType {\n  ORBITING,\n  EXPLORING,\n  TRACKING,\n}\n\n",paraId:41,tocIndex:4},{value:"With ",paraId:42,tocIndex:4},{value:"g-plugin-control",paraId:43,tocIndex:4},{value:" you can interact with mouse panning and zooming, ",paraId:42,tocIndex:4},{value:"example",paraId:44,tocIndex:4},{value:".",paraId:42,tocIndex:4},{value:"Fixes the viewpoint ",paraId:45,tocIndex:5},{value:"focalPoint",paraId:45,tocIndex:5},{value:" and changes the camera position ",paraId:45,tocIndex:5},{value:"position",paraId:45,tocIndex:5},{value:". Commonly used in scenarios like CAD viewing models, but not across the north and south poles.",paraId:45,tocIndex:5},{value:"Called ",paraId:46,tocIndex:5},{value:"OrbitControls",paraId:46,tocIndex:5},{value:" in Three.js.",paraId:46,tocIndex:5},{value:"In this ",paraId:47,tocIndex:5},{value:"example",paraId:48,tocIndex:5},{value:", we control the camera by mouse panning to complete the ",paraId:47,tocIndex:5},{value:"pan",paraId:49,tocIndex:5},{value:' action, as if we were "rotating" the scene around a fixed viewpoint.',paraId:47,tocIndex:5},{value:"Similar to ",paraId:50,tocIndex:6},{value:"Orbiting",paraId:50,tocIndex:6},{value:" mode, also fixed viewpoint ",paraId:50,tocIndex:6},{value:"focalPoint",paraId:50,tocIndex:6},{value:", but can span North and South poles.",paraId:50,tocIndex:6},{value:"G's ",paraId:51,tocIndex:6},{value:"Default Camera",paraId:51,tocIndex:6},{value:" has this mode selected.",paraId:51,tocIndex:6},{value:"Called ",paraId:52,tocIndex:6},{value:"TrackballControls",paraId:52,tocIndex:6},{value:" in Three.js.",paraId:52,tocIndex:6},{value:"In this ",paraId:53,tocIndex:6},{value:"example",paraId:54,tocIndex:6},{value:", we control the camera via mouse panning to complete the ",paraId:53,tocIndex:6},{value:"pan",paraId:55,tocIndex:6},{value:' action, allowing the camera to "rotate" around a fixed point of view.',paraId:53,tocIndex:6},{value:"The fixed camera position ",paraId:56,tocIndex:7},{value:"position",paraId:56,tocIndex:7},{value:" rotates around it, so the viewpoint ",paraId:56,tocIndex:7},{value:"focalPoint",paraId:56,tocIndex:7},{value:" position will change.",paraId:56,tocIndex:7},{value:"Called ",paraId:57,tocIndex:7},{value:"FirstPersonControls",paraId:57,tocIndex:7},{value:" in Three.js.",paraId:57,tocIndex:7},{value:"At any time, you can switch between these three modes.",paraId:58,tocIndex:8},{value:"camera.setType(CameraType.Tracking);\n",paraId:59,tocIndex:8}]},34594:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(87262);const n=[{value:"We provide the following methods to obtain or modify the camera position, viewpoint and other common camera parameters.",paraId:0},{value:"The picture below shows the camera ",paraId:1},{value:"position",paraId:1},{value:" and the ",paraId:1},{value:"focalPoint",paraId:1},{value:":",paraId:1},{value:"Get the position of the camera in the world coordinate system which has the following type ",paraId:2,tocIndex:0},{value:"[number, number, number]",paraId:2,tocIndex:0},{value:".",paraId:2,tocIndex:0},{value:"camera.getPosition(); // [300, 200, 500]\n",paraId:3,tocIndex:0},{value:"Sets the camera's position in the world coordinate system.",paraId:4,tocIndex:1},{value:"The method signature is as follows.",paraId:5,tocIndex:1},{value:"setPosition(x: number | vec2 | vec3, y?: number, z?: number)\n",paraId:6,tocIndex:1},{value:"In G's built-in orthogonal projection camera, the default setting is ",paraId:7,tocIndex:1},{value:"[width / 2, height / 2, 500]",paraId:7,tocIndex:1},{value:", where ",paraId:7,tocIndex:1},{value:"width/height",paraId:7,tocIndex:1},{value:" is the size of the ",paraId:7,tocIndex:1},{value:"Canvas",paraId:8,tocIndex:1},{value:". So if we want to reset the ",paraId:7,tocIndex:1},{value:"x/y",paraId:7,tocIndex:1},{value:" coordinates of the camera, while keeping the ",paraId:7,tocIndex:1},{value:"z",paraId:7,tocIndex:1},{value:" coordinates the same, we can do this.",paraId:7,tocIndex:1},{value:"// Keep the Z-coordinate constant.\ncamera.setPosition(300, 250);\ncamera.setPosition([300, 250]);\n// Or set the Z-coordinate to the default value of 500.\ncamera.setPosition(300, 250, 500);\ncamera.setPosition([300, 250, 500]);\n",paraId:9,tocIndex:1},{value:"Note that in 2D scenes when we set the camera position, we usually need to set the viewpoint position as well, otherwise we will have an unintended effect.",paraId:10,tocIndex:1},{value:"camera.setPosition(100, 100, 500);\ncamera.setFocalPoint(100, 100, 0);\n",paraId:11,tocIndex:1},{value:"Get the position of the viewpoint in the world coordinate system, type ",paraId:12,tocIndex:2},{value:"[number, number, number]",paraId:12,tocIndex:2},{value:".",paraId:12,tocIndex:2},{value:"camera.getFocalPoint(); // [300, 200, 0]\n",paraId:13,tocIndex:2},{value:"Set the position of the viewpoint in the world coordinate system.",paraId:14,tocIndex:3},{value:"The method signature is as follows.",paraId:15,tocIndex:3},{value:"setFocalPoint(x: number | vec2 | vec3, y?: number, z?: number)\n",paraId:16,tocIndex:3},{value:"In G's built-in orthogonal projection camera, the default setting is ",paraId:17,tocIndex:3},{value:"[width / 2, height / 2, 0]",paraId:17,tocIndex:3},{value:", where ",paraId:17,tocIndex:3},{value:"width/height",paraId:17,tocIndex:3},{value:" is the size of the ",paraId:17,tocIndex:3},{value:"Canvas",paraId:18,tocIndex:3},{value:". So if we want to reset the ",paraId:17,tocIndex:3},{value:"x/y",paraId:17,tocIndex:3},{value:" coordinates of the camera viewpoint while keeping the ",paraId:17,tocIndex:3},{value:"z",paraId:17,tocIndex:3},{value:" coordinates the same, we can do this.",paraId:17,tocIndex:3},{value:"// Keep the Z-coordinate constant.\ncamera.setFocalPoint(300, 250);\ncamera.setFocalPoint([300, 250]);\n// Or set the Z-coordinate to the default value of 0.\ncamera.setFocalPoint(300, 250, 0);\n// Or set the Z-coordinate to the default value of 0.\ncamera.setFocalPoint([300, 250, 0]);\n",paraId:19,tocIndex:3},{value:"Get the distance from the camera position to the viewpoint.",paraId:20,tocIndex:4},{value:"For example, in the default camera.",paraId:21,tocIndex:4},{value:"camera.getDistance(); // 500\n",paraId:22,tocIndex:4},{value:"Fix the viewpoint and move the camera position along the ",paraId:23,tocIndex:5},{value:"forward",paraId:23,tocIndex:5},{value:" direction.",paraId:23,tocIndex:5},{value:"For example, move the default camera, fix the viewpoint position, and change the view distance from ",paraId:24,tocIndex:5},{value:"500",paraId:24,tocIndex:5},{value:" to ",paraId:24,tocIndex:5},{value:"400",paraId:24,tocIndex:5},{value:".",paraId:24,tocIndex:5},{value:"camera.setDistance(400);\n",paraId:25,tocIndex:5},{value:"Get the near-plane. Graphics in the near-plane will be rejected.",paraId:26,tocIndex:6},{value:"The default camera setting for G is ",paraId:27,tocIndex:6},{value:"0.1",paraId:27,tocIndex:6},{value:".",paraId:27,tocIndex:6},{value:"camera.getNear(); // 0.1\n",paraId:28,tocIndex:6},{value:"Set up near plane.",paraId:29,tocIndex:7},{value:"The method signature is as follows.",paraId:30,tocIndex:7},{value:"setNear(near: number)\n",paraId:31,tocIndex:7},{value:"Get the far plane. Graphics outside the far plane will be excluded.",paraId:32,tocIndex:8},{value:"The default camera setting for G is ",paraId:33,tocIndex:8},{value:"1000",paraId:33,tocIndex:8},{value:".",paraId:33,tocIndex:8},{value:"camera.getFar(); // 1000\n",paraId:34,tocIndex:8},{value:"Set the far plane.",paraId:35,tocIndex:9},{value:"The method signature is as follows.",paraId:36,tocIndex:9},{value:"setFar(far: number)\n",paraId:37,tocIndex:9},{value:"Gets the scaling. Although visually increasing the camera's scale is the same as calling ",paraId:38,tocIndex:10},{value:"setScale",paraId:39,tocIndex:10},{value:" on the root node, it is clear that the former does not cause any change to the graphics in the scene.",paraId:38,tocIndex:10},{value:"The default scaling is ",paraId:40,tocIndex:10},{value:"1",paraId:40,tocIndex:10},{value:".",paraId:40,tocIndex:10},{value:"camera.getZoom(); // 1\n",paraId:41,tocIndex:10},{value:"zoom",paraId:42,tocIndex:11},{value:" greater than 1 means zoom in, and vice versa means zoom out, ",paraId:42,tocIndex:11},{value:"example",paraId:43,tocIndex:11},{value:".",paraId:42,tocIndex:11},{value:"The method signature is as follows.",paraId:44,tocIndex:11},{value:"setZoom(zoom: number)\n",paraId:45,tocIndex:11},{value:"setZoom",paraId:46,tocIndex:12},{value:" will scale at the center of the camera's position under the world coordinate system. However, sometimes we want to fix the viewpoint, i.e. to scale at the point under ",paraId:47,tocIndex:12},{value:"viewport coordinate system",paraId:48,tocIndex:12},{value:".",paraId:47,tocIndex:12},{value:"In the following ",paraId:49,tocIndex:12},{value:"example",paraId:50,tocIndex:12},{value:", we listen to the ",paraId:49,tocIndex:12},{value:"wheel",paraId:49,tocIndex:12},{value:" event to scale at the position of the event object under the client coordinate system.",paraId:49,tocIndex:12},{value:"// Convert the clientX/Y of the wheel event to the viewport coordinate system\nconst { x, y } = canvas.client2Viewport({ x: e.clientX, y: e.clientY });\ncamera.setZoomByViewportPoint(zoom, [x, y]);\n",paraId:51,tocIndex:12},{value:"The method signature is as follows.",paraId:52,tocIndex:12},{value:"zoom",paraId:53,tocIndex:12},{value:" greater than 1 means zoom in, vice versa means zoom out.",paraId:53,tocIndex:12},{value:"viewportPoint",paraId:53,tocIndex:12},{value:" is the point coordinate under ",paraId:53,tocIndex:12},{value:"viewport coordinate system",paraId:54,tocIndex:12},{value:".",paraId:53,tocIndex:12},{value:"setZoomByViewportPoint(zoom: number, viewportPoint: vec2)\n",paraId:55,tocIndex:12},{value:"Only works in perspective projection, the larger the perspective is the more objects it can hold. ",paraId:56,tocIndex:13},{value:"example",paraId:57,tocIndex:13},{value:"The method signature is as follows.",paraId:58,tocIndex:13},{value:"setFov(fov: number)\n",paraId:59,tocIndex:13},{value:"Only works under perspective projection. Most of the time there is no need to set it manually, it can be updated automatically when the canvas size changes by calling ",paraId:60,tocIndex:14},{value:"canvas.resize()",paraId:60,tocIndex:14},{value:".",paraId:60,tocIndex:14},{value:"The method signature is as follows.",paraId:61,tocIndex:14},{value:"setAspect(aspect: number)\n",paraId:62,tocIndex:14},{value:"Set the minimum view distance. It will not be smaller than this distance when ",paraId:63,tocIndex:15},{value:"dolly",paraId:64,tocIndex:15},{value:" operation is performed.",paraId:63,tocIndex:15},{value:"The default value is ",paraId:65,tocIndex:15},{value:"-Infinity",paraId:65,tocIndex:15},{value:".",paraId:65,tocIndex:15},{value:"Set the maximum view distance. It will not be greater than this distance when ",paraId:66,tocIndex:16},{value:"dolly",paraId:67,tocIndex:16},{value:" operation is performed.",paraId:66,tocIndex:16},{value:"The default value is ",paraId:68,tocIndex:16},{value:"Infinity",paraId:68,tocIndex:16},{value:".",paraId:68,tocIndex:16},{value:"Set the offset of the viewport and immediately recalculate the projection matrix.",paraId:69,tocIndex:17},{value:"The method signature is as follows.",paraId:70,tocIndex:17},{value:"setViewOffset(\n  fullWidth: number,\n  fullHeight: number,\n  x: number,\n  y: number,\n  width: number,\n  height: number,\n)\n",paraId:71,tocIndex:17},{value:"where ",paraId:72,tocIndex:17},{value:"fullWidth/fullHeight",paraId:72,tocIndex:17},{value:" is the original viewport size, ",paraId:72,tocIndex:17},{value:"x/y",paraId:72,tocIndex:17},{value:" is the viewport offset coordinate, and ",paraId:72,tocIndex:17},{value:"width/height",paraId:72,tocIndex:17},{value:" is the offset viewport size.",paraId:72,tocIndex:17},{value:"In this ",paraId:73,tocIndex:17},{value:"example",paraId:74,tocIndex:17},{value:", ",paraId:73,tocIndex:17},{value:"Cube",paraId:75,tocIndex:17},{value:" is originally in the center of the viewport, by setting the ",paraId:73,tocIndex:17},{value:"x/y",paraId:73,tocIndex:17},{value:" offset to the center of the viewport.",paraId:73,tocIndex:17},{value:"When picking up in ",paraId:76,tocIndex:17},{value:"g-plugin-device-renderer",paraId:77,tocIndex:17},{value:", we use this method to set the offset (aligning the camera to the pickup area) and render only the pickup area instead of the whole screen to improve performance.",paraId:76,tocIndex:17},{value:"Clear the previously set viewport offset and immediately recalculate the projection matrix.",paraId:78,tocIndex:18},{value:"In this ",paraId:79,tocIndex:18},{value:"example",paraId:80,tocIndex:18},{value:", the set offset can be removed at any time by clicking the button.",paraId:79,tocIndex:18},{value:"When describing rotation, sometimes Euler angles are more intuitive to understand because they are more closely related to what we describe in everyday life, such as camera motion, latitude and longitude in a horizontal coordinate system (also known as a geocentric coordinate system), and so on. In some GIS-like visualization projects (e.g. Mapbox), pitch/yaw/roll is often used to describe the rotation of itself. An example is an airplane in the picture below.",paraId:81,tocIndex:19},{value:"To set the camera azimuth, you need to recalculate the camera position or viewpoint position in different camera modes.",paraId:82,tocIndex:19},{value:"Sets the angle of rotation around the ",paraId:83,tocIndex:20},{value:"forward",paraId:83,tocIndex:20},{value:" axis in ",paraId:83,tocIndex:20},{value:"deg",paraId:83,tocIndex:20},{value:", with the following method signature.",paraId:83,tocIndex:20},{value:"setRoll(roll: number)\n",paraId:84,tocIndex:20},{value:"Note the different effects of fixed camera position and fixed viewpoint position rotation under different [camera types](/en/api/camera#camera type).",paraId:85,tocIndex:20},{value:"camera.setRoll(30);\n",paraId:86,tocIndex:20},{value:"Sets the ",paraId:87,tocIndex:21},{value:"elevation",paraId:87,tocIndex:21},{value:" angle in ",paraId:87,tocIndex:21},{value:"deg",paraId:87,tocIndex:21},{value:", with the following method signature.",paraId:87,tocIndex:21},{value:"setElevation(angle: number)\n",paraId:88,tocIndex:21},{value:"Note the different effects of fixed camera position and fixed viewpoint position rotation under different [camera types](/en/api/camera#camera type).",paraId:89,tocIndex:21},{value:"camera.setElevation(30);\n",paraId:90,tocIndex:21},{value:"Set the angle around ",paraId:91,tocIndex:22},{value:"azimuth",paraId:91,tocIndex:22},{value:" in ",paraId:91,tocIndex:22},{value:"deg",paraId:91,tocIndex:22},{value:", with the following method signature.",paraId:91,tocIndex:22},{value:"setAzimuth(angle: number)\n",paraId:92,tocIndex:22},{value:"Note the different effects of fixed camera position and fixed viewpoint position rotation under different ",paraId:93,tocIndex:22},{value:"camera types",paraId:94,tocIndex:22},{value:".",paraId:93,tocIndex:22},{value:"camera.setAzimuth(30);\n",paraId:95,tocIndex:22}]},21952:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(49212);const n=[{value:"We all know the ",paraId:0},{value:"window",paraId:0},{value:" object in the browser, the entry point of the DOM tree is ",paraId:0},{value:"window.document",paraId:0},{value:", and the entry point usually contains a root node ",paraId:0},{value:"<html>",paraId:0},{value:" element, which can be obtained from ",paraId:0},{value:"window.document.documentElement",paraId:0},{value:". We add various DOM elements to this root node, such as ",paraId:0},{value:"<head>",paraId:0},{value:", ",paraId:0},{value:"<body>",paraId:0},{value:", etc.",paraId:0},{value:"Canvas canvases can be analogous to ",paraId:1},{value:"window",paraId:1},{value:" objects. Similarly, each canvas is created with a built-in entry ",paraId:1},{value:"Document",paraId:2},{value:", which can be obtained via ",paraId:1},{value:"canvas.document",paraId:1},{value:". This entry contains the root node of ",paraId:1},{value:"Scene Graph",paraId:3},{value:", which can be obtained via ",paraId:1},{value:"canvas.document.documentElement",paraId:1},{value:", and then you can add graphics to this root node via ",paraId:1},{value:"appendChild",paraId:1},{value:" to complete the rendering. and then you can add graphics to this root node with ",paraId:1},{value:"appendChild",paraId:1},{value:" to complete the rendering.",paraId:1},{value:"Returns a built-in ",paraId:4,tocIndex:0},{value:"Document",paraId:5,tocIndex:0},{value:" object that holds the root node of the scene graph. After getting this root node via ",paraId:4,tocIndex:0},{value:"document.documentElement",paraId:4,tocIndex:0},{value:", you can add child nodes using the scene graph capability:",paraId:4,tocIndex:0},{value:"// append a Circle to canvas\ncanvas.document.documentElement.appendChild(circle);\ncanvas.document.documentElement.children; // [circle]\n",paraId:6,tocIndex:0},{value:"In addition to the add/remove node capability, other scene graph and event capabilities are also available on the root node:",paraId:7,tocIndex:0},{value:"canvas.document.documentElement.getBounds();\ncanvas.document.addEventListener('click', () => {});\n",paraId:8,tocIndex:0},{value:"Alias of ",paraId:9,tocIndex:1},{value:"getRoot()",paraId:9,tocIndex:1},{value:", so the following two ways of writing it are equivalent:",paraId:9,tocIndex:1},{value:"const root = canvas.getRoot(); // Group\nconst root = canvas.document.documentElement;\n",paraId:10,tocIndex:1},{value:"Get [rendering context](/en/api/renderer#rendering environment context), which is implemented by the renderer (",paraId:11,tocIndex:2},{value:"g-canvas/svg/webgl",paraId:11,tocIndex:2},{value:"). There are many common methods on this rendering context, such as:",paraId:11,tocIndex:2},{value:"getDomElement()",paraId:12,tocIndex:2},{value:" Get the DOM element of current renderer, for example ",paraId:12,tocIndex:2},{value:"g-canvas/webgl",paraId:12,tocIndex:2},{value:" will return a ",paraId:12,tocIndex:2},{value:"<canvas>",paraId:12,tocIndex:2},{value:" element while ",paraId:12,tocIndex:2},{value:"g-svg",paraId:12,tocIndex:2},{value:" will return a ",paraId:12,tocIndex:2},{value:"<svg>",paraId:12,tocIndex:2},{value:" element.",paraId:12,tocIndex:2},{value:"getDPR()",paraId:12,tocIndex:2},{value:" Get devicePixelRatio of current rendering context.",paraId:12,tocIndex:2},{value:"Get ",paraId:13,tocIndex:3},{value:"camera",paraId:14,tocIndex:3},{value:" and subsequently perform operations on that camera, such as switching projection mode, completing camera actions and animations, etc.",paraId:13,tocIndex:3},{value:"const camera = canvas.getCamera();\n\n// camera actions\ncamera.pan();\ncamera.rotate();\n\n// switch to perspective projection\ncamera\n    .setPosition(300, 100, 500)\n    .setFocalPoint(300, 250, 0)\n    .setPerspective(0.1, 1000, 75, 600 / 500);\n",paraId:15,tocIndex:3}]},79985:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(14434);const n=[{value:'When we talk about "location", it must be relative to some coordinate system, in G we use Client, Screen, Page, Canvas and Viewport coordinate systems, for example, in ',paraId:0},{value:"event system",paraId:1},{value:" you can get the coordinates from the event object in different coordinate systems.",paraId:0},{value:"canvas.addEventListener('click', (e) => {\n    e.clientX;\n    e.screenX;\n    e.pageX;\n    e.canvasX;\n    e.viewportX;\n});\n",paraId:2},{value:"Of these coordinate systems, Client, Screen, and Page are all natively supported by the browser, so we don't make any changes to these coordinate values on the event object. The Canvas canvas is like a \"mini-browser\" implemented in the browser, so its viewport coordinate system is analogous to the browser's Client coordinate system. When the camera moves, our viewing area changes, similar to a page scrolling, but the position of the graphics in the world does not change, so the Canvas coordinate system is analogous to the browser's Page coordinate system.",paraId:3},{value:"These coordinate systems all have the upper left corner as the origin:",paraId:4},{value:"⚠️ If ",paraId:5},{value:"g-plugin-3d",paraId:6},{value:" plugin is used, the Z-axis is pointing off-screen.",paraId:5},{value:"We provide methods to convert between them, and in this ",paraId:7},{value:"example",paraId:8},{value:", move the mouse to see the value of the mouse location in each coordinate system:",paraId:7},{value:"Client <-> Viewport",paraId:9},{value:"Canvas <-> Viewport",paraId:9},{value:"Front-end developers should be most familiar with the Client browser coordinate system, which takes the upper-left corner of the browser as the origin, and G does not modify this coordinate value for native event objects, ",paraId:10,tocIndex:0},{value:"example",paraId:10,tocIndex:0},{value:".",paraId:10,tocIndex:0},{value:"https://developer.mozilla.org/en-US/Web/API/MouseEvent/clientX",paraId:11,tocIndex:0},{value:"If the document is not scrolled, which is equivalent to the Page coordinate, the following figure shows the difference with Screen:",paraId:12,tocIndex:0},{value:"The screen coordinate system is also the common browser coordinate system, with the top left corner of the screen as the origin, and is affected by page scrolling. we won't modify this coordinate value of the native event object.",paraId:13,tocIndex:1},{value:"https://developer.mozilla.org/en-US/Web/API/MouseEvent/screenX",paraId:14,tocIndex:1},{value:"It is worth mentioning that negative numbers may appear in dual screens, for example in the left screen, ",paraId:15,tocIndex:1},{value:"example",paraId:15,tocIndex:1},{value:".",paraId:15,tocIndex:1},{value:"With the top left corner of the document as the origin and considering the document scrolling, G does not modify this coordinate value of the native event object.",paraId:16,tocIndex:2},{value:"https://developer.mozilla.org/en-US/Web/API/MouseEvent/pageX",paraId:17,tocIndex:2},{value:'An analogy can be drawn to the browser\'s Client coordinate system, also known as the world coordinate system, to which the positions we specify when creating a drawing are relative. It takes the top left corner of the DOM element of the canvas as the origin, with the X-axis pointing forward to the right side of the screen and the Y-axis pointing forward to the bottom of the screen. Also known as the "world coordinate system", when it comes to rotation, we set the direction of rotation to be clockwise along the axes.',paraId:18,tocIndex:3},{value:"In the browser's Page coordinate system, the coordinates of the element in the document do not change regardless of page scrolling; what changes is our viewing area.",paraId:19,tocIndex:4},{value:"Similarly, ",paraId:20,tocIndex:4},{value:"camera",paraId:21,tocIndex:4},{value:" determines the angle from which we view the world. If the camera does not move, the Viewport coordinate system and the Canvas coordinate system will coincide exactly, so the coordinates of the upper-left corner of the Viewport are the same as the origin of the Canvas coordinate system, ",paraId:20,tocIndex:4},{value:"[0, 0]",paraId:20,tocIndex:4},{value:", in our visible range. However, if the camera is panned, rotated, or scaled, the viewport will also change accordingly, and the position of ",paraId:20,tocIndex:4},{value:"[0, 0]",paraId:20,tocIndex:4},{value:" in the upper-left corner of the viewport will no longer be ",paraId:20,tocIndex:4},{value:"[0, 0]",paraId:20,tocIndex:4},{value:" in the Canvas coordinate system.",paraId:20,tocIndex:4},{value:"We provide the following transformation methods needed to use Point, which has the following structure and can be introduced from the G core package, ",paraId:22,tocIndex:5},{value:"example",paraId:23,tocIndex:5},{value:":",paraId:22,tocIndex:5},{value:"interface Point {\n    x: number;\n    y: number;\n}\n\nimport type { Point } from '@antv/g';\n",paraId:24,tocIndex:5},{value:'-Viewport type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:25},{value:"We provide a method for converting from the browser's Client coordinate system to the canvas Viewport coordinate system, ",paraId:26,tocIndex:6},{value:"example",paraId:27,tocIndex:6},{value:":",paraId:26,tocIndex:6},{value:"client2Viewport(client: Point): Point",paraId:28,tocIndex:6},{value:"viewport2Client(canvas: Point): Point",paraId:28,tocIndex:6},{value:"In the internal implementation, we use the following calculation logic, for example, from Client to Viewport, we first get the bounding box of the canvas DOM element under the Client coordinate system, using [getBoundingClientRect](",paraId:29,tocIndex:6},{value:"https://developer.mozilla.org/en-US/",paraId:29,tocIndex:6},{value:" Web/API/Element/getBoundingClientRect), and then subtract the coordinates of the upper-left corner of the bounding box from clientX/Y to get the coordinates of the upper-left corner of the DOM element relative to the canvas, i.e., the Viewport coordinates:",paraId:29,tocIndex:6},{value:"// 获取画布 DOM 元素在 Client 坐标系下的包围盒\n// @see https://developer.mozilla.org/en-US/Web/API/Element/getBoundingClientRect\nconst bbox = $canvas.getBoundingClientRect();\n\nviewportX = clientX - bbox.left;\nviewportY = clientY - bbox.top;\n",paraId:30,tocIndex:6},{value:"For example, the ",paraId:31,tocIndex:6},{value:"<canvas>",paraId:31,tocIndex:6},{value:" element in the DOM tree is absolutely positioned at ",paraId:31,tocIndex:6},{value:"[100, 100]",paraId:31,tocIndex:6},{value:" from the top left corner of the browser, and when the mouse moves to the ",paraId:31,tocIndex:6},{value:"[0, 0]",paraId:31,tocIndex:6},{value:" position in the top left corner of ",paraId:31,tocIndex:6},{value:"<canvas>",paraId:31,tocIndex:6},{value:", the Client coordinates are ",paraId:31,tocIndex:6},{value:"[100, 100]",paraId:31,tocIndex:6},{value:".",paraId:31,tocIndex:6},{value:"canvas.viewport2Client({ x: 0, y: 0 }); // Point { x: 100, y: 100 }\ncanvas.client2Viewport({ x: 100, y: 100 }); // Point { x: 0, y: 0 }\n",paraId:32,tocIndex:6},{value:"For compatibility with older versions of the G API, we also provide:",paraId:33,tocIndex:6},{value:"getPointByClient(clientX: number, clientY: number): Point",paraId:34,tocIndex:6},{value:"getClientByPoint(viewportX: number, viewportY: number): Point",paraId:34,tocIndex:6},{value:'-Viewport type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:25},{value:"The ",paraId:35,tocIndex:7},{value:"camera",paraId:36,tocIndex:7},{value:" determines the angle from which we view the world. If the camera does not move, the Viewport coordinate system and the Canvas coordinate system will coincide exactly, so within our visible range, the coordinates of the upper-left corner of the viewport are the same as the Canvas coordinate system origin, both are ",paraId:35,tocIndex:7},{value:"[0, 0]",paraId:35,tocIndex:7},{value:". However, if the camera is panned, rotated, or scaled, the viewport will change accordingly, and the ",paraId:35,tocIndex:7},{value:"[0, 0]",paraId:35,tocIndex:7},{value:" position in the upper-left corner of the viewport will no longer be ",paraId:35,tocIndex:7},{value:"[0, 0]",paraId:35,tocIndex:7},{value:" in the Canvas coordinate system.",paraId:35,tocIndex:7},{value:"In ",paraId:37,tocIndex:7},{value:"example",paraId:38,tocIndex:7},{value:", we moved the camera up a distance (the whole world moves down in the viewer's eyes) and found that the center of the circle remains the same in the Canvas coordinate system, ",paraId:37,tocIndex:7},{value:"[300, 200]",paraId:37,tocIndex:7},{value:", but is shifted in the Viewport coordinate system as follows.",paraId:37,tocIndex:7},{value:"We offer the following conversion methods:",paraId:39,tocIndex:7},{value:"viewport2Canvas(viewport: Point): Point",paraId:40,tocIndex:7},{value:"canvas2Viewport(canvas: Point): Point",paraId:40,tocIndex:7},{value:"In the internal implementation, we use the following computational logic to transform, for example, from Canvas to Viewport, from the world coordinate system to the crop coordinate system, to NDC, and finally to the viewport coordinate system:",paraId:41,tocIndex:7},{value:"// Camera VP Matrix\nconst camera = canvas.getCamera();\nconst projectionMatrix = camera.getPerspective();\nconst viewMatrix = camera.getViewTransform();\nconst vpMatrix = mat4.multiply(mat4.create(), projectionMatrix, viewMatrix);\n\n// Canvas -> Clip\nconst clip = vec3.fromValues(canvasX, canvasY, 0);\nvec3.transformMat4(clip, clip, vpMatrix);\n\n// Clip -> NDC -> Viewport and FlipY\nconst { width, height } = this.canvasConfig; // 画布宽高\nviewportX = ((clip[0] + 1) / 2) * width;\nviewportY = (1 - (clip[1] + 1) / 2) * height;\n",paraId:42,tocIndex:7}]},92116:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(62425);const n=[{value:"Usually we recommend using ",paraId:0},{value:"new Circle()",paraId:0},{value:" to create built-in or custom graphics, but we also provide something like the DOM [CustomElementRegistry](",paraId:0},{value:"https://developer.mozilla.org/en-US/docs/Web/API/",paraId:0},{value:" CustomElementRegistry) API to create a completed registered graph using ",paraId:0},{value:"document.createElement",paraId:1},{value:", so the following writeup is equivalent.",paraId:0},{value:"import { Shape, Circle } from '@antv/g';\n\nconst circle = canvas.document.createElement(Shape.CIRCLE, {\n    style: { r: 100 },\n});\n\n// or\nconst circle = new Circle({ style: { r: 100 } });\n",paraId:2},{value:"canvas.customElements",paraId:3},{value:" provides the following methods.",paraId:3},{value:"The full method signature is:",paraId:4,tocIndex:0},{value:"define(name: string, new (...any[]) => DisplayObject): void;\n",paraId:5,tocIndex:0},{value:"All of G's built-in graphics are registered during canvas initialization, and for custom graphics, if you also want to create them with the ",paraId:6,tocIndex:0},{value:"createElement",paraId:6,tocIndex:0},{value:" method, registration can be done as follows.",paraId:6,tocIndex:0},{value:"import { MyCustomShape } from 'my-custom-shape';\ncanvas.customElements.define(MyCustomShape.tag, MyCustomShape);\n\nconst myCustomShape = canvas.document.createElement(MyCustomShape.tag, {});\n",paraId:7,tocIndex:0},{value:"The full method signature is:",paraId:8,tocIndex:1},{value:"get(name: string): new (...any[]) => DisplayObject\n",paraId:9,tocIndex:1},{value:"Returns the constructor based on the string provided at the time of graphic registration.",paraId:10,tocIndex:1},{value:"import { Shape } from '@antv/g';\n\ncanvas.customElements.get(Shape.CIRCLE); // Circle constructor\n",paraId:11,tocIndex:1}]},61063:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(16260);const n=[{value:"In the ",paraId:0},{value:"event system",paraId:1},{value:", most events bubble up to the canvas. For example, if we click Circle in the following simple scenario, we can see the propagation path of the events in order.",paraId:0},{value:"Circle -> Group(canvas.document.documentElement) -> Document(canvas.document) -> Canvas：\n",paraId:2},{value:"canvas.addEventListener('click', (e) => {\n    e.propagationPath(); // [Circle, Group, Document, Canvas]\n});\n",paraId:3},{value:"Events can be bound on both the Canvas and the root node of the canvas.",paraId:4,tocIndex:0},{value:"canvas.addEventListener('click', () => {});\n\n// or\ncanvas.document.addEventListener('click', () => {});\n",paraId:5,tocIndex:0},{value:"More event-related operations are described in ",paraId:6,tocIndex:0},{value:"event system",paraId:7,tocIndex:0},{value:".",paraId:6,tocIndex:0},{value:"The canvas will trigger corresponding events before and after initialization, rendering, and currently the following canvas-related events can be listened to.",paraId:8,tocIndex:1},{value:"export enum CanvasEvent {\n  READY = 'ready',\n  BEFORE_RENDER = 'beforerender',\n  AFTER_RENDER = 'afterrender',\n  BEFORE_DESTROY = 'beforedestroy',\n  AFTER_DESTROY = 'afterdestroy',\n  RESIZE = 'resize',\n}\n",paraId:9,tocIndex:1},{value:"For example, if we show the live frame rate in all the examples on the website, which is updated after each render, we can do it by listening to the ",paraId:10,tocIndex:1},{value:"afterrender",paraId:10,tocIndex:1},{value:" event.",paraId:10,tocIndex:1},{value:"import { CanvasEvent } from '@antv/g';\n\ncanvas.addEventListener(CanvasEvent.AFTER_RENDER, () => {\n    stats.update();\n});\n// or\ncanvas.addEventListener('afterrender', () => {\n    stats.update();\n});\n",paraId:11,tocIndex:1},{value:"In the browser, we can use ",paraId:12,tocIndex:2},{value:"window.onload",paraId:12,tocIndex:2},{value:" to find out if the initialization of the page, including HTML parsing, style parsing, resource loading, etc., is complete.",paraId:12,tocIndex:2},{value:"// @see https://javascript.info/onload-ondomcontentloaded\nwindow.onload = function () {\n    alert('Page loaded');\n};\n",paraId:13,tocIndex:2},{value:"Also in G these initializations are asynchronous, and we provide a similar ",paraId:14,tocIndex:2},{value:"ready",paraId:14,tocIndex:2},{value:" event. After the initialization is done you can do things like scene graph creation.",paraId:14,tocIndex:2},{value:"canvas.addEventListener(CanvasEvent.READY, () => {\n    canvas.appendChild(circle);\n});\n",paraId:15,tocIndex:2},{value:"In addition to listening to the ",paraId:16,tocIndex:2},{value:"ready",paraId:16,tocIndex:2},{value:" event, you can also choose to ",paraId:16,tocIndex:2},{value:"wait for this Promise",paraId:17,tocIndex:2},{value:".",paraId:16,tocIndex:2},{value:"await canvas.ready;\ncanvas.appendChild(circle);\n",paraId:18,tocIndex:2}]},9034:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(87521);const n=[{value:'Multiple canvases can coexist on the same page, i.e., multiple "parallel worlds" can exist at the same time. However, this is limited by the underlying rendering API, e.g. WebGL only allows up to 8 contexts. ',paraId:0,tocIndex:0},{value:"example",paraId:1,tocIndex:0},{value:"In this ",paraId:2,tocIndex:1},{value:"example",paraId:3,tocIndex:1},{value:", we create our own ",paraId:2,tocIndex:1},{value:"<canvas>",paraId:2,tocIndex:1},{value:" element, which we use to create the canvas.",paraId:2,tocIndex:1},{value:"const $canvas = document.createElement('canvas');\n$canvas.width = 600;\n$canvas.height = 500;\ndocument.getElementById('container').appendChild($canvas);\n\nconst canvas = new Canvas({\n    canvas: $canvas,\n    renderer: new CanvasRenderer(),\n});\n",paraId:4,tocIndex:1}]},63859:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(68043);const n=[{value:"We provide the Canvas as a core object in the ",paraId:0},{value:"@antv/g",paraId:0},{value:', which is a "mini-browser" from a rendering perspective implemented in the browser and hosts three types of objects:',paraId:0},{value:"Scene Graph",paraId:1},{value:". We use it to describe the individual shapes in the scene and their hierarchical relationships.",paraId:2},{value:"Camera",paraId:3},{value:". We use it to define the angle at which the whole scene is viewed. We have a built-in camera for each canvas that uses orthogonal projection by default, which can be modified at any time subsequently.",paraId:2},{value:"Renderer",paraId:4},{value:". We use it to specify which underlying technology the canvas uses to render the scene. Different renderers have different rendering capabilities, for example only ",paraId:2},{value:"g-webgl",paraId:5},{value:" can render 3D graphics. In 2D scenes we try to achieve consistent rendering with different renderers.",paraId:2},{value:"When designing the canvas API, we referenced the DOM API, so they share many similarities:",paraId:6},{value:"The canvas can be analogous to the ",paraId:7},{value:"window",paraId:7},{value:" object in the browser environment. Like window, the canvas inherits from ",paraId:7},{value:"EventTarget",paraId:8},{value:' in the internal implementation. Unlike window, multiple canvases can coexist in the same page, i.e. multiple "parallel worlds" can exist at the same time.',paraId:7},{value:"The entry point of the page in the DOM tree is ",paraId:7},{value:"window.document",paraId:7},{value:" and in the canvas is ",paraId:7},{value:"canvas.document",paraId:7},{value:".",paraId:7},{value:"The root node in the DOM tree is ",paraId:7},{value:"document.documentElement",paraId:7},{value:", which is ",paraId:7},{value:"<html>",paraId:7},{value:". It can also be accessed in the canvas via ",paraId:7},{value:"canvas.document.documentElement",paraId:7},{value:".",paraId:7},{value:"We chose to be as DOM API compatible as possible to reduce the memory learning cost for front-end users on the one hand, and to leverage the existing Web ecosystem on the other hand, e.g. to seamlessly access ",paraId:9},{value:"existing gesture and drag libraries",paraId:10},{value:".",paraId:9},{value:"For unconventional browser environments, we also provide options such as ",paraId:11},{value:"OffscreenCanvas in WebWorker",paraId:12},{value:", ",paraId:11},{value:"server-side rendering",paraId:13},{value:" and other options.",paraId:11},{value:"EventTarget",paraId:14}]},47374:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(9396);const n=[{value:"You may have seen some applications of the rendering engine:",paraId:0,tocIndex:0},{value:"Babylon.js ",paraId:1,tocIndex:0},{value:"https://doc.babylonjs.com/divingDeeper/scene/offscreenCanvas",paraId:1,tocIndex:0},{value:"Three.js ",paraId:1,tocIndex:0},{value:"https://r105.threejsfundamentals.org/threejs/lessons/threejs-offscreencanvas.html",paraId:1,tocIndex:0},{value:"We will use OffscreenCanvas in the following two scenarios, mainly using the Worker to relieve the main thread:",paraId:2,tocIndex:0},{value:"GPGPU 配合 g-webgl 和 g-plugin-gpgpu 使用，例如上层的图分析算法库",paraId:3,tocIndex:0},{value:"g-webgl 在 Worker 中渲染，同步结果到主线程",paraId:3,tocIndex:0},{value:"In this ",paraId:4,tocIndex:0},{value:"example",paraId:5,tocIndex:0},{value:" we demonstrate the second use, creating ",paraId:4,tocIndex:0},{value:"<canvas>",paraId:4,tocIndex:0},{value:" in the main thread, transferring control to the WebWorker via ",paraId:4,tocIndex:0},{value:"transferControlToOffscreen()",paraId:4,tocIndex:0},{value:", and subsequently completing the rendering in the WebWorker and synchronizing the results to the main thread.",paraId:4,tocIndex:0},{value:"// main thread\nconst $canvas = document.createElement('canvas') as HTMLCanvasElement;\nconst dpr = window.devicePixelRatio;\n$canvas.height = dpr * 600;\n$canvas.width = dpr * 500;\n$canvas.style.height = '600px';\n$canvas.style.width = '500px';\ndocument.getElementById('container').appendChild($canvas);\nconst offscreen = $canvas.transferControlToOffscreen();\n\n// 省略 Worker 创建过程\n\n// 在 WebWorker 中使用 OffscreenCanvas\nconst canvas = new Canvas({\n  canvas: offscreenCanvas, // 从主线程\n  devicePixelRatio,\n  renderer,\n});\n",paraId:6,tocIndex:0},{value:"It's worth noting that OffscreenCanvas doesn't have event listening capabilities, our interactions happen on the ",paraId:7,tocIndex:0},{value:"<canvas>",paraId:7,tocIndex:0},{value:" element in the main thread, so when the mouse click event is listened to, how do we know which shape in OffscreenCanvas hit?",paraId:7,tocIndex:0},{value:"We can achieve this by:",paraId:8,tocIndex:0},{value:"Listen for interaction events on ",paraId:9,tocIndex:0},{value:"<canvas>",paraId:9,tocIndex:0},{value:" and pass them to the worker via ",paraId:9,tocIndex:0},{value:"postMessage",paraId:9,tocIndex:0},{value:" when triggered. Note that you can't pass a native event object like [PointerEvent](",paraId:9,tocIndex:0},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/",paraId:9,tocIndex:0},{value:" PointerEvent), it will report the following error when serializing. The correct approach is to extract the key properties of the native event object (e.g. ",paraId:9,tocIndex:0},{value:"clientX/Y",paraId:9,tocIndex:0},{value:") and pass them.",paraId:9,tocIndex:0},{value:"Uncaught (in promise) DOMException: Failed to execute 'postMessage' on 'Worker': PointerEvent object could not be cloned.\n",paraId:10,tocIndex:0},{value:"// 在主线程中监听 `<canvas>` 事件\n$canvas.addEventListener(\n    'pointerdown',\n    (e) => {\n        // 向 WebWorker 传递可序列化的事件对象\n        worker.triggerEvent('pointerdown', clonePointerEvent(e));\n    },\n    true,\n);\n",paraId:11,tocIndex:0},{value:"Trigger the interaction event hook provided by the G rendering service in the worker, e.g. call the ",paraId:12,tocIndex:0},{value:"pointerDown",paraId:12,tocIndex:0},{value:" hook when receiving the ",paraId:12,tocIndex:0},{value:"pointerdown",paraId:12,tocIndex:0},{value:" signal from the main thread.",paraId:12,tocIndex:0},{value:"export function triggerEvent(event, ev) {\n    if (event === 'pointerdown') {\n        canvas.getRenderingService().hooks.pointerDown.call(ev);\n    }\n}\n",paraId:13,tocIndex:0},{value:"cursor",paraId:14,tocIndex:0},{value:" The mouse style obviously cannot be applied in the worker. We can tell the main thread to change the mouse style on ",paraId:15,tocIndex:0},{value:"<canvas>",paraId:15,tocIndex:0},{value:" via ",paraId:15,tocIndex:0},{value:"postMessage",paraId:15,tocIndex:0},{value:" in the Worker when we pick up the image.",paraId:15,tocIndex:0},{value:"Depending on the renderer, we offer the following server-side rendering options:",paraId:16,tocIndex:1},{value:"g-canvas + node-canvas",paraId:17,tocIndex:1},{value:"g-svg + JSDOM",paraId:18,tocIndex:1},{value:"g-webgl + headless-gl",paraId:19,tocIndex:1},{value:"We currently use them in ",paraId:20,tocIndex:1},{value:"integration tests",paraId:20,tocIndex:1},{value:".",paraId:20,tocIndex:1}]},62980:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(94305);const n=[{value:"When creating a canvas, we can pass in the following initialization parameters, which is the simplest way to initialize it.",paraId:0},{value:"container",paraId:1},{value:" The id or DOM element of the canvas container, and the subsequent ",paraId:1},{value:"<canvas>/<svg>",paraId:1},{value:" is automatically created within that DOM element.",paraId:1},{value:"width / height",paraId:1},{value:"renderer",paraId:1},{value:" Currently we provides ",paraId:1},{value:"g-canvas",paraId:2},{value:", ",paraId:1},{value:"g-svg",paraId:3},{value:", ",paraId:1},{value:"g-webgl",paraId:4},{value:" etc.",paraId:1},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\n\nconst renderer = new Renderer();\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:5},{value:"The above initialization approach only requires providing a container ",paraId:6},{value:"container",paraId:6},{value:" that carries ",paraId:6},{value:"<canvas>/<svg>",paraId:6},{value:", but sometimes we have custom requirements as follows:",paraId:6},{value:"Using existed ",paraId:7},{value:"<canvas>",paraId:7},{value:"Using OffscreenCanvas in WebWorker",paraId:8},{value:"Server-side rendering in Node.js",paraId:9},{value:"In this case you can use ",paraId:10},{value:"canvas",paraId:10},{value:" instead of ",paraId:10},{value:"container",paraId:10},{value:", and more initialization parameters are as follows.",paraId:10},{value:"Optional, ",paraId:11,tocIndex:0},{value:"string | HTMLElement",paraId:11,tocIndex:0},{value:". The id or DOM element of the canvas container. Later, when the renderer is initialized, ",paraId:11,tocIndex:0},{value:"<canvas>/<svg>",paraId:11,tocIndex:0},{value:" is automatically created inside that container's DOM element.",paraId:11,tocIndex:0},{value:"Optional, ",paraId:12,tocIndex:1},{value:"HTMLCanvasElement | OffscreenCanvas | NodeCanvas",paraId:12,tocIndex:1},{value:". Using existed ",paraId:12,tocIndex:1},{value:"<canvas>",paraId:12,tocIndex:1},{value:" or OffscreenCanvas.",paraId:12,tocIndex:1},{value:"When this parameter is passed, the ",paraId:13,tocIndex:1},{value:"container",paraId:14,tocIndex:1},{value:" argument is ignored and we assume that ",paraId:13,tocIndex:1},{value:"<canvas>",paraId:13,tocIndex:1},{value:" has been created and added to the document, e.g.",paraId:13,tocIndex:1},{value:"// create a <canvas>\nconst $canvas = document.createElement('canvas');\nconst dpr = window.devicePixelRatio;\n$canvas.height = dpr * 600;\n$canvas.width = dpr * 500;\n$canvas.style.height = '600px';\n$canvas.style.width = '500px';\ndocument.getElementById('container').appendChild($canvas);\n\n// using existed <canvas>\nconst canvas = new Canvas({\n    canvas: $canvas,\n    renderer: canvasRenderer,\n});\n",paraId:15,tocIndex:1},{value:"In addition to the ",paraId:16,tocIndex:1},{value:"HTMLCanvasElement",paraId:16,tocIndex:1},{value:" in the browser environment, you can also use:",paraId:16,tocIndex:1},{value:"OffscreenCanvas",paraId:17,tocIndex:1},{value:" in WebWorker",paraId:17,tocIndex:1},{value:"NodeCanvas",paraId:18,tocIndex:1},{value:" in server-side rendering",paraId:18,tocIndex:1},{value:"Note that once this parameter is used, runtime switching of the renderer is no longer supported.",paraId:19,tocIndex:1},{value:"Set the width and height of canvas.",paraId:20,tocIndex:2},{value:"Required if ",paraId:21,tocIndex:2},{value:"container",paraId:22,tocIndex:2},{value:" passed in. The renderer will create ",paraId:21,tocIndex:2},{value:"<canvas>",paraId:21,tocIndex:2},{value:" with these values.",paraId:21,tocIndex:2},{value:"Optional if ",paraId:21,tocIndex:2},{value:"canvas",paraId:23,tocIndex:2},{value:" passed in. If not provided, we will calculate with ",paraId:21,tocIndex:2},{value:"canvas.width/height",paraId:21,tocIndex:2},{value:" and ",paraId:21,tocIndex:2},{value:"devicePixelRatio",paraId:21,tocIndex:2},{value:".",paraId:21,tocIndex:2},{value:"Required. The following renderers are currently supported:",paraId:24,tocIndex:3},{value:"g-canvas",paraId:25,tocIndex:3},{value:"g-svg",paraId:26,tocIndex:3},{value:"g-webgl",paraId:27,tocIndex:3},{value:"g-webgpu",paraId:28,tocIndex:3},{value:"g-canvaskit",paraId:29,tocIndex:3},{value:"It can be switched at runtime with ",paraId:30,tocIndex:3},{value:"setRenderer()",paraId:31,tocIndex:3},{value:" after initialized.",paraId:30,tocIndex:3},{value:"Optional. The color used to clear the canvas when it is initialized, similar to WebGL's ",paraId:32,tocIndex:4},{value:"clearColor",paraId:32,tocIndex:4},{value:".",paraId:32,tocIndex:4},{value:"Using ",paraId:33,tocIndex:4},{value:"<color>",paraId:34,tocIndex:4},{value:", defaults to ",paraId:33,tocIndex:4},{value:"'transparent'",paraId:33,tocIndex:4},{value:".",paraId:33,tocIndex:4},{value:"In ",paraId:35,tocIndex:4},{value:"this example",paraId:36,tocIndex:4},{value:", we have set a translucent red color for the Canvas, and the bottom ",paraId:35,tocIndex:4},{value:"<div>",paraId:35,tocIndex:4},{value:" has a background gray color set by CSS: ",paraId:35,tocIndex:4},{value:"<div>",paraId:35,tocIndex:4},{value:".",paraId:35,tocIndex:4},{value:"Set the canvas default ",paraId:37,tocIndex:5},{value:"mouse style",paraId:38,tocIndex:5},{value:". If this property is also configured on top of a drawing picked up by an interaction event, it will override the mouse style configured on the canvas, but when the mouse is moved to a blank area, the mouse style configured on the canvas will take effect. The following figure demonstrates this.",paraId:37,tocIndex:5},{value:"const canvas = new Canvas({\n    //...\n    cursor: 'crosshair',\n});\n\nconst circle = new Circle({\n    style: {\n        //...\n        cursor: 'pointer',\n    },\n});\n",paraId:39,tocIndex:5},{value:"In addition to being set at canvas initialization, it can be subsequently modified by ",paraId:40,tocIndex:5},{value:"setCursor()",paraId:40,tocIndex:5},{value:".",paraId:40,tocIndex:5},{value:"// Set at canvas initialization\ncanvas = new Canvas({\n    //...\n    cursor: 'crosshair',\n});\n\n// Or reset later\ncanvas.setCursor('crosshair');\n",paraId:41,tocIndex:5},{value:"Optional. If or not support multiple canvases under one container, default is false.",paraId:42,tocIndex:6},{value:"Example",paraId:43},{value:"6.1.1",paraId:44},{value:"boolean",paraId:45,tocIndex:7},{value:"Optional, default is ",paraId:46,tocIndex:7},{value:"false",paraId:46,tocIndex:7},{value:". Enable high-resolution large image rendering and interactive optimization, through downsampling and slice rendering strategy, large images with hundreds of millions of pixels can also be rendered and interacted smoothly.",paraId:46,tocIndex:7},{value:"Currently only implemented in the native Canvas renderer.",paraId:47},{value:"On some special runtime platforms (e.g. applets), it is not possible to use global variables like [globalThis](",paraId:48,tocIndex:8},{value:"https://developer.mozilla.org/en-US/Web/JavaScript/Reference/Global_Objects/",paraId:48,tocIndex:8},{value:" globalThis), and internally we need to rely on it to create images (",paraId:48,tocIndex:8},{value:"new globalThis.Image()",paraId:48,tocIndex:8},{value:"), determine if a TouchEvent is supported (",paraId:48,tocIndex:8},{value:"'ontouchstart' in globalThis",paraId:48,tocIndex:8},{value:"), and so on. Therefore, users of these particular platforms need to manually pass in the specific creation and determination methods.",paraId:48,tocIndex:8},{value:"Optional. Default will use ",paraId:49,tocIndex:9},{value:"window.document",paraId:49,tocIndex:9},{value:". In ",paraId:49,tocIndex:9},{value:"g-svg based server-side rendering scheme",paraId:50,tocIndex:9},{value:", you need to replace ",paraId:49,tocIndex:9},{value:"window.document",paraId:49,tocIndex:9},{value:" with the corresponding element provided by ",paraId:49,tocIndex:9},{value:"JSDOM",paraId:49,tocIndex:9},{value:" in order to create the corresponding SVG element.",paraId:49,tocIndex:9},{value:"Optional. By default ",paraId:51,tocIndex:10},{value:"window.devicePixelRatio",paraId:51,tocIndex:10},{value:" will be used, if there is no ",paraId:51,tocIndex:10},{value:"window",paraId:51,tocIndex:10},{value:" object in the runtime environment, such as in WebWorker, you can pass it in manually, or use 1 if it is still not passed in.",paraId:51,tocIndex:10},{value:"Optional. By default ",paraId:52,tocIndex:11},{value:"window.requestAnimationFrame",paraId:52,tocIndex:11},{value:" will be used, if there is no ",paraId:52,tocIndex:11},{value:"window",paraId:52,tocIndex:11},{value:" object in the runtime environment, such as an applet environment, you can pass it in manually.",paraId:52,tocIndex:11},{value:"Optional. By default ",paraId:53,tocIndex:12},{value:"window.cancelAnimationFrame",paraId:53,tocIndex:12},{value:" will be used, if there is no ",paraId:53,tocIndex:12},{value:"window",paraId:53,tocIndex:12},{value:" object in the runtime environment, such as an applet environment, you can pass it in manually.",paraId:53,tocIndex:12},{value:"Optional. Returns an ",paraId:54,tocIndex:13},{value:"HTMLImageElement",paraId:54,tocIndex:13},{value:" or similar object, which by default will be created using ",paraId:54,tocIndex:13},{value:"() => new window.Image()",paraId:54,tocIndex:13},{value:". If there is no ",paraId:54,tocIndex:13},{value:"window",paraId:54,tocIndex:13},{value:" object in the runtime environment, such as an applet environment, you can pass it in manually.",paraId:54,tocIndex:13},{value:"For example, in the Alipay applet use ",paraId:55,tocIndex:13},{value:"createImage",paraId:55,tocIndex:13},{value:".",paraId:55,tocIndex:13},{value:"const canvas = new Canvas({\n    createImage: () => canvas.createImage(),\n});\n",paraId:56,tocIndex:13},{value:"Optional. 是否支持在容器上应用 CSS Transform 的情况下确保交互事件坐标转换正确。",paraId:57,tocIndex:14},{value:"Whether or not CSS Transform is supported on the container to ensure that the interaction event coordinates are transformed correctly.",paraId:58,tocIndex:14},{value:"In this ",paraId:59,tocIndex:14},{value:"example",paraId:60,tocIndex:14},{value:", we have enlarged the container by a factor of 1.1, and with this configuration enabled, mouse movement over the circle changes the mouse style correctly.",paraId:59,tocIndex:14},{value:"const $wrapper = document.getElementById('container');\n$wrapper.style.transform = 'scale(1.1)';\n",paraId:61,tocIndex:14},{value:"Optional. Whether PointerEvent is supported or not, the default will use ",paraId:62,tocIndex:15},{value:"! !globalThis.PointerEvent",paraId:62,tocIndex:15},{value:". If ",paraId:62,tocIndex:15},{value:"false",paraId:62,tocIndex:15},{value:" is passed, the event listener plugin will not listen for PointerEvent such as ",paraId:62,tocIndex:15},{value:"pointerdown",paraId:62,tocIndex:15},{value:".",paraId:62,tocIndex:15},{value:"Optional. If ",paraId:63,tocIndex:16},{value:"false",paraId:63,tocIndex:16},{value:" is passed, the event listener plugin will not listen to TouchEvent such as ",paraId:63,tocIndex:16},{value:"touchstart",paraId:63,tocIndex:16},{value:".",paraId:63,tocIndex:16},{value:"Optional. Determines if a native event is a TouchEvent, accepts the native event as parameter, and returns the result.",paraId:64,tocIndex:17},{value:"Optional. Determines if a native event is a MouseEvent, accepts the native event as parameter, and returns the result.",paraId:65,tocIndex:18},{value:"6.0.12",paraId:66,tocIndex:18},{value:"number",paraId:67,tocIndex:19},{value:"Optional, default is 200ms. Numeric type, determines whether two consecutive clicks trigger a double-click event ",paraId:68,tocIndex:19},{value:"dblclick",paraId:68,tocIndex:19},{value:" .",paraId:68,tocIndex:19},{value:"Optional. Returns an ",paraId:69,tocIndex:20},{value:"HTMLCanvasElement | OffscreenCanvas",paraId:69,tocIndex:20},{value:" or similar object. Used to generate an offscreen Canvas2D context, it is currently used in the following scenarios.",paraId:69,tocIndex:20},{value:"The core service calls ",paraId:70,tocIndex:20},{value:"ctx.measureText",paraId:70,tocIndex:20},{value:" to measure the text.",paraId:70,tocIndex:20},{value:"g-plugin-canvas-picker",paraId:71,tocIndex:20},{value:" will draw the path in context and call ",paraId:70,tocIndex:20},{value:"ctx.isPointInPath",paraId:70,tocIndex:20},{value:" Canvas2D API.",paraId:70,tocIndex:20},{value:"g-plugin-device-renderer",paraId:72,tocIndex:20},{value:" will call ",paraId:70,tocIndex:20},{value:"ctx.createLinearGradient",paraId:70,tocIndex:20},{value:" in the context to draw the gradient and then generate the texture.",paraId:70,tocIndex:20},{value:"When not passed in by default, it will try to create an ",paraId:73,tocIndex:20},{value:"OffscreenCanvas",paraId:73,tocIndex:20},{value:" and then use the DOM API to create an ",paraId:73,tocIndex:20},{value:"HTMLCanvasElement",paraId:73,tocIndex:20},{value:" when it fails. However, in non-dom environments like applets, you need to manually pass in.",paraId:73,tocIndex:20},{value:"const canvas = new Canvas({\n    //...\n    offscreenCanvas: {\n        getContext: () => Canvas.createContext(),\n    },\n});\n",paraId:74,tocIndex:20},{value:"When initializing the canvas we pass in the canvas size, renderer and other configurations, which may be modified subsequently, so we provide the following API.",paraId:75,tocIndex:21},{value:"Sometimes we need to resize the canvas after initialization, for example by using ",paraId:76,tocIndex:22},{value:"ResizeObserver",paraId:76,tocIndex:22},{value:" to listen for container size changes.",paraId:76,tocIndex:22},{value:"const resizeObserver = new ResizeObserver((entries) => {\n    for (const entry of entries) {\n        if (entry !== canvas) {\n            continue;\n        }\n        const { width, height } = entry.contentRect;\n        // resize canvas\n        canvas.resize(width, height);\n    }\n});\nresizeObserver.observe($container);\n",paraId:77,tocIndex:22},{value:"In most scenarios we should specify a renderer at canvas initialization and never change it again. However, there are a few scenarios where we need to ",paraId:78,tocIndex:23},{value:"switch renderers at runtime",paraId:79,tocIndex:23},{value:", for example, almost all of the examples on our website do this.",paraId:78,tocIndex:23},{value:"// switch to WebGL renderer if possible\nif (tooManyShapes) {\n    canvas.setRenderer(webglRenderer);\n} else {\n    canvas.setRenderer(svgRenderer);\n}\n",paraId:80,tocIndex:23},{value:"方法签名如下：",paraId:81,tocIndex:23},{value:"setRenderer(renderer: Renderer): Promise<void>;\n",paraId:82,tocIndex:23},{value:"需要注意的是，在切换渲染器时需要重新初始化渲染环境，因此该方法为异步方法。",paraId:83,tocIndex:23},{value:"Set the canvas default ",paraId:84,tocIndex:24},{value:"cursor style",paraId:85,tocIndex:24},{value:".",paraId:84,tocIndex:24},{value:"canvas.setCursor('crosshair');\n",paraId:86,tocIndex:24},{value:"Get the configuration of the initial incoming canvas.",paraId:87,tocIndex:25},{value:"const canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: webglRenderer,\n});\ncanvas.getConfig(); // { container: 'container', width: 600, ... }\n",paraId:88,tocIndex:25}]},79714:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(43442);const n=[{value:"Since canvas does not inherit from ",paraId:0,tocIndex:0},{value:"Node",paraId:1,tocIndex:0},{value:", it does not have node manipulation capability by itself. However, we have added some shortcuts and the following node operations are essentially done on the root node, e.g. the following two writes are equivalent:",paraId:0,tocIndex:0},{value:"canvas.appendChild(circle);\ncanvas.document.documentElement.appendChild(circle);\n",paraId:2,tocIndex:0},{value:"Adds the object to be rendered to the canvas. If the object has children, they are also added together.",paraId:3,tocIndex:1},{value:"const circle = new Circle({ style: { r: 10 } });\n\ncanvas.appendChild(circle);\n// or canvas.document.documentElement.appendChild(circle);\n",paraId:4,tocIndex:1},{value:"Removes the object from the canvas. If the object has children, they are removed as well.",paraId:5,tocIndex:2},{value:"canvas.removeChild(circle);\n// or canvas.document.documentElement.removeChild(circle);\n",paraId:6,tocIndex:2},{value:"To be consistent with the DOM API, just removing the object does not destroy it. If you want to destroy it, you need to call ",paraId:7,tocIndex:2},{value:"destroy()",paraId:7,tocIndex:2},{value:".",paraId:7,tocIndex:2},{value:"Removes all objects in the canvas.",paraId:8,tocIndex:3},{value:"canvas.removeChildren();\n// or canvas.document.documentElement.removeChildren();\n",paraId:9,tocIndex:3},{value:"Removes and destroys all objects in the canvas.",paraId:10,tocIndex:4},{value:"canvas.destroyChildren();\n",paraId:11,tocIndex:4},{value:"The initialization logic is performed upon instantiation, and the following lifecycle methods can be called afterwards.",paraId:12,tocIndex:5},{value:"When initialization is complete, a Promise is returned that is equivalent to listening for the ",paraId:13,tocIndex:6},{value:"CanvasEvent.READY",paraId:14,tocIndex:6},{value:" event.",paraId:13,tocIndex:6},{value:"await canvas.ready;\n\n// or\nimport { CanvasEvent } from '@antv/g';\ncanvas.addEventListener(CanvasEvent.READY, () => {});\n",paraId:15,tocIndex:6},{value:"Rendering the canvas, since the renderer has auto-rendering enabled by default, there is no need to call it manually in most cases. However, some scenes require manual control of rendering timing, in which case ",paraId:16,tocIndex:7},{value:"rendering-on-demand",paraId:17,tocIndex:7},{value:" ",paraId:16,tocIndex:7},{value:"example",paraId:18,tocIndex:7},{value:".",paraId:16,tocIndex:7},{value:"const webglRenderer = new WebGLRenderer({\n    enableAutoRendering: false,\n});\n\ncanvas.render();\n",paraId:19,tocIndex:7},{value:"Destroy the canvas, executing the following destruction logic in turn.",paraId:20,tocIndex:8},{value:"If auto-rendering is enabled, stop the main rendering loop.",paraId:21,tocIndex:8},{value:"Remove the entire scene graph from the canvas, and destroy it if ",paraId:21,tocIndex:8},{value:"destroyScenegraph",paraId:21,tocIndex:8},{value:" is set.",paraId:21,tocIndex:8},{value:"Destroying the rendering context.",paraId:21,tocIndex:8},{value:"// Destroy the canvas only, keep the scene graph\ncanvas.destroy();\n\n// Destroy the scene graph in the canvas together\ncanvas.destroy(true);\n",paraId:22,tocIndex:8}]},64724:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(48112);const n=[{value:"基于样式系统，我们可以提供常用的布局算法，让用户避免相同场景的重复计算，主要参考 CSS Layout API 。",paraId:0},{value:"https://drafts.css-houdini.org/css-layout-api",paraId:1},{value:"https://github.com/w3c/css-houdini-drafts/blob/main/css-layout-api/EXPLAINER.md",paraId:2},{value:"布局算法以 ",paraId:3},{value:"@antv/g-layout-xxx",paraId:3},{value:" 形式命名，用户在运行时：",paraId:3},{value:"选择自己需要的布局算法，通过样式系统提供的 ",paraId:4},{value:"CSS.registerLayout",paraId:4},{value:" API 完成注册",paraId:4},{value:"容器元素通过 ",paraId:4},{value:"display",paraId:4},{value:" 属性使用，容器内元素不再需要使用 x/y/z 属性或者 ",paraId:4},{value:"setPosition",paraId:5},{value:" 等 API 手动定位。定位工作由容器选择的布局算法承担",paraId:4},{value:"使用方式如下：",paraId:6},{value:"import { CSS, Group, Circle } from '@antv/g';\nimport { Layout as BlockFlowLayout } from '@antv/g-layout-blockflow';\nimport { Layout as FlexLayout } from '@antv/g-layout-flex';\nimport { Layout as MasonryLayout } from '@antv/g-layout-masonry';\nimport { Layout as GridLayout } from '@antv/g-layout-grid';\n\n// 注册布局算法\nCSS.registerLayout('block', BlockFlowLayout);\nCSS.registerLayout('flex', FlexLayout);\nCSS.registerLayout('masonry', MasonryLayout);\nCSS.registerLayout('grid', GridLayout);\n\n// 使用 BlockFlow 布局\nconst blockGroup = new Group({\n    style: {\n        display: 'block', // 通过 display 属性使用\n        width: '400px',\n        height: '400px',\n    },\n});\n// 容器内元素无需手动定位，由容器负责\nblockGroup.appendChild(\n    new Circle({\n        style: {\n            r: 100,\n        },\n    }),\n);\ncanvas.appendChild(blockGroup);\n",paraId:7}]},40167:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(47230);const n=[{value:"With ",paraId:0},{value:"CSS Typed OM",paraId:1},{value:" we can easily define property values such as ",paraId:0},{value:"CSS.px(5)",paraId:0},{value:", but properties don't only have values.",paraId:0},{value:"The ",paraId:2},{value:"CSS Properties & Values API",paraId:2},{value:" in the browser allows users to customize CSS properties and configure their types for checks, default values, whether inheritance is supported, and other metadata, which is also part of CSS Houdini.",paraId:2},{value:"For example, the following shows how to customize a color property.",paraId:3},{value:"window.CSS.registerProperty({\n    name: '--my-color',\n    syntax: '<color>',\n    inherits: false,\n    initialValue: '#c0ffee',\n});\n",paraId:4},{value:"We have also implemented this API in G, defining a set of built-in property value types.",paraId:5},{value:"CSS property values contain various types: ",paraId:6,tocIndex:0},{value:"https://drafts.csswg.org/css-values-4/",paraId:6,tocIndex:0},{value:"In G we support the following types.",paraId:7,tocIndex:0},{value:"Keywords, such as ",paraId:8,tocIndex:0},{value:"unset",paraId:8,tocIndex:0},{value:" ",paraId:8,tocIndex:0},{value:"center",paraId:8,tocIndex:0},{value:"Numeric value, such as:\n",paraId:8,tocIndex:0},{value:"<color> e.g. ",paraId:9,tocIndex:0},{value:"red",paraId:9,tocIndex:0},{value:"<paint> e.g. ",paraId:9,tocIndex:0},{value:"transparent",paraId:9,tocIndex:0},{value:" ",paraId:9,tocIndex:0},{value:"linear-gradient",paraId:9,tocIndex:0},{value:"<percentage> e.g. ",paraId:9,tocIndex:0},{value:"%",paraId:9,tocIndex:0},{value:"<number> Pure Digital",paraId:9,tocIndex:0},{value:"<length> Length values with units, e.g. ",paraId:9,tocIndex:0},{value:"px",paraId:9,tocIndex:0},{value:" ",paraId:9,tocIndex:0},{value:"em",paraId:9,tocIndex:0},{value:" ",paraId:9,tocIndex:0},{value:"rem",paraId:9,tocIndex:0},{value:"<angle> Angular values with units, e.g. ",paraId:9,tocIndex:0},{value:"deg",paraId:9,tocIndex:0},{value:" ",paraId:9,tocIndex:0},{value:"rad",paraId:9,tocIndex:0},{value:" ",paraId:9,tocIndex:0},{value:"turn",paraId:9,tocIndex:0},{value:"In some scenarios, these types can be combined, e.g. <length-percentage> is a combination of <length> and <percentage>.",paraId:10,tocIndex:0},{value:"Corresponds to ",paraId:11,tocIndex:1},{value:"CSSKeywordValue",paraId:12,tocIndex:1},{value:" in ",paraId:11,tocIndex:1},{value:"CSS Typed OM",paraId:13,tocIndex:1},{value:".",paraId:11,tocIndex:1},{value:"For example, ",paraId:14,tocIndex:1},{value:"'normal'",paraId:14,tocIndex:1},{value:" will be parsed as",paraId:14,tocIndex:1},{value:"text.style.fontWeight = 'normal';\n\nconst styleMap = text.computedStyleMap();\nstyleMap.get('fontWeight'); // CSSKeywordValue { value: 'normal' }\n",paraId:15,tocIndex:1},{value:"As with CSS, the global keywords are as follows.",paraId:16,tocIndex:1},{value:"It can be used to reset inherited properties.",paraId:17,tocIndex:2},{value:"For example, in the following example, ",paraId:18,tocIndex:2},{value:"<em>",paraId:18,tocIndex:2},{value:" should have inherited the ",paraId:18,tocIndex:2},{value:"color",paraId:18,tocIndex:2},{value:" attribute defined by ",paraId:18,tocIndex:2},{value:"<p>",paraId:18,tocIndex:2},{value:", but it overrides the inherited value by applying the default value (black) via ",paraId:18,tocIndex:2},{value:"initial",paraId:18,tocIndex:2},{value:".",paraId:18,tocIndex:2},{value:"p {\n  color: red;\n}\nem {\n  color: initial;\n}\n\n<p>\n  <span>This text is red.</span>\n  <em>This text is in the initial color (typically black).</em>\n  <span>This is red again.</span>\n</p>\n",paraId:19,tocIndex:2},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/initial",paraId:20,tocIndex:2},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/inherit",paraId:21,tocIndex:3},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/unset",paraId:22,tocIndex:4},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:"Corresponds to ",paraId:24,tocIndex:5},{value:"CSSUnitValue",paraId:25,tocIndex:5},{value:" in ",paraId:24,tocIndex:5},{value:"CSS Typed OM",paraId:26,tocIndex:5},{value:".",paraId:24,tocIndex:5},{value:"Property values that currently use this type include.",paraId:27,tocIndex:5},{value:"opacity",paraId:28,tocIndex:5},{value:"fillOpacity",paraId:29,tocIndex:5},{value:"strokeOpacity",paraId:30,tocIndex:5},{value:"circle.style.opacity = '0.5';\n\nconst styleMap = circle.computedStyleMap();\nstyleMap.get('opacity'); // CSSUnitValue { unit:'', value: 0.5 }\n",paraId:31,tocIndex:5},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:"The length type is used to define distances, which in turn include absolute and relative types.",paraId:32,tocIndex:6},{value:"https://drafts.csswg.org/css-values-4/#length-value",paraId:33,tocIndex:6},{value:"Pixels are obviously an absolute unit, and if a length value uses ",paraId:34,tocIndex:7},{value:"number",paraId:34,tocIndex:7},{value:" the default unit is ",paraId:34,tocIndex:7},{value:"px",paraId:34,tocIndex:7},{value:". It is then resolved to ",paraId:34,tocIndex:7},{value:"CSS.px()",paraId:34,tocIndex:7},{value:".",paraId:34,tocIndex:7},{value:"circle.style.r = 10;\n// or\ncircle.style.r = '10px';\n\nconst styleMap = circle.computedStyleMap();\nstyleMap.get('r'); // CSSUnitValue { unit: 'px', value: 10 }\n",paraId:35,tocIndex:7},{value:"Represents the font-size of the root element. When used within the root element font-size, it represents its initial value (a common browser default is 16px, but user-defined preferences may modify this).",paraId:36,tocIndex:8},{value:"Represents the calculated font-size of the element. If used on the font-size property itself, it represents the inherited font-size of the element.",paraId:37,tocIndex:9},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:"https://drafts.csswg.org/css-values-4/#percentage-value",paraId:38,tocIndex:10},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:"https://drafts.csswg.org/css-values-4/#angle-value",paraId:39,tocIndex:11},{value:"Represents an angle in degrees. One full circle is 360deg. Examples: 0deg, 90deg, 14.23deg.",paraId:40,tocIndex:12},{value:"Represents an angle in gradians. One full circle is 400grad. Examples: 0grad, 100grad, 38.8grad.",paraId:41,tocIndex:13},{value:"Represents an angle in radians. One full circle is 2π radians which approximates to 6.2832rad. 1rad is 180/π degrees. Examples: 0rad, 1.0708rad, 6.2832rad.",paraId:42,tocIndex:14},{value:"Represents an angle in a number of turns. One full circle is 1turn. Examples: 0turn, 0.25turn, 1.2turn.",paraId:43,tocIndex:15},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:"Referring to the CSS specification definition of the type ",paraId:44,tocIndex:16},{value:"<color>",paraId:44,tocIndex:16},{value:", we support the following color value types, which exist as ",paraId:44,tocIndex:16},{value:"string",paraId:44,tocIndex:16},{value:" types in JS.",paraId:44,tocIndex:16},{value:"It is a type included in ",paraId:45,tocIndex:16},{value:"<paint>",paraId:46,tocIndex:16},{value:".",paraId:45,tocIndex:16},{value:"examples",paraId:47,tocIndex:16},{value:".",paraId:48,tocIndex:16},{value:"Properties that would currently use this type are.",paraId:49,tocIndex:16},{value:"shadowColor",paraId:50,tocIndex:16},{value:"CSS defines a series of basic color keywords that are ",paraId:51,tocIndex:17},{value:"case sensitive",paraId:51,tocIndex:17},{value:". The image below left shows the basic color keywords, and the image below right shows some of the extended keywords.",paraId:51,tocIndex:17},{value:"In the internal implementation, we will pass the keyword string to ",paraId:52,tocIndex:17},{value:"d3-color",paraId:52,tocIndex:17},{value:" to parse it and get ",paraId:52,tocIndex:17},{value:"CSSRGB",paraId:53,tocIndex:17},{value:".",paraId:52,tocIndex:17},{value:"Example usage is as follows.",paraId:54,tocIndex:17},{value:"circle.style.fill = 'red';\ncircle.style.fill = 'darkcyan';\n",paraId:55,tocIndex:17},{value:"Defined in the ",paraId:56,tocIndex:19},{value:"sRGB",paraId:56,tocIndex:19},{value:" color space and supports hexadecimal writing.",paraId:56,tocIndex:19},{value:"Usage examples are as follows.",paraId:57,tocIndex:19},{value:"circle.style.fill = '#f00';\ncircle.style.fill = '#ff0000';\ncircle.style.fill = 'rgb(255,0,0)';\ncircle.style.fill = 'rgb(100%, 0%, 0%)';\n",paraId:58,tocIndex:19},{value:"Adds a transparency channel to ",paraId:59,tocIndex:20},{value:"rgb",paraId:59,tocIndex:20},{value:". According to ",paraId:59,tocIndex:20},{value:"specification",paraId:59,tocIndex:20},{value:", ",paraId:59,tocIndex:20},{value:"alpha",paraId:59,tocIndex:20},{value:" takes values in the range ",paraId:59,tocIndex:20},{value:"[0, 1]",paraId:59,tocIndex:20},{value:".",paraId:59,tocIndex:20},{value:"Usage examples are as follows.",paraId:60,tocIndex:20},{value:"circle.style.fill = 'rgb(255,0,0)';\ncircle.style.fill = 'rgba(255,0,0,1)';\ncircle.style.fill = 'rgba(100%,0%,0%,1)';\n",paraId:61,tocIndex:20},{value:"Equivalent to ",paraId:62,tocIndex:21},{value:"rgba(0,0,0,0)",paraId:62,tocIndex:21},{value:" i.e. completely transparent black.",paraId:62,tocIndex:21},{value:"Note that it has a different meaning than ",paraId:63,tocIndex:21},{value:"none",paraId:63,tocIndex:21},{value:" supported by ",paraId:63,tocIndex:21},{value:"<paint>",paraId:64,tocIndex:21},{value:".",paraId:63,tocIndex:21},{value:"https://www.w3.org/TR/css-color-3/#currentcolor",paraId:65,tocIndex:24},{value:"Equivalent to black in the Canvas / WebGL rendering environment, and the same name property effect in SVG.",paraId:66,tocIndex:24},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:23},{value:"Referring to ",paraId:67,tocIndex:27},{value:"<paint>",paraId:67,tocIndex:27},{value:" in SVG, it is a concatenation of the following types.",paraId:67,tocIndex:27},{value:"<paint> = none | <color> | <gradient> | <pattern>\n",paraId:68,tocIndex:27},{value:"Example",paraId:69,tocIndex:27},{value:"。",paraId:70,tocIndex:27},{value:"The following properties are currently in use.",paraId:71,tocIndex:27},{value:"fill",paraId:72,tocIndex:27},{value:"stroke",paraId:73,tocIndex:27},{value:"Not using any color is not equal to ",paraId:74,tocIndex:28},{value:"<color>",paraId:75,tocIndex:28},{value:" of [transparent](/en/api/css/css-properties-values-api #transparent) keyword. In the case of the ",paraId:74,tocIndex:28},{value:"fill",paraId:74,tocIndex:28},{value:" property, for example, both are visually identical, but setting it to ",paraId:74,tocIndex:28},{value:"'transparent'",paraId:74,tocIndex:28},{value:" will still pick it up, while setting it to ",paraId:74,tocIndex:28},{value:"'none'",paraId:74,tocIndex:28},{value:" will not.",paraId:74,tocIndex:28},{value:"For example, when a drawing is initialized without the ",paraId:76,tocIndex:28},{value:"fill",paraId:76,tocIndex:28},{value:" attribute set, it is equivalent to manually changing it to ",paraId:76,tocIndex:28},{value:"none",paraId:76,tocIndex:28},{value:" after creation.",paraId:76,tocIndex:28},{value:"const circle = new Circle({\n    r: 150,\n});\n\ncircle.style.fill = 'none';\n",paraId:77,tocIndex:28},{value:"All CSS property metadata in Blink is defined in a JSON list, which describes how the style system should parse and calculate style values.",paraId:78,tocIndex:29},{value:"The attribute metadata contains the following key information.",paraId:79,tocIndex:29},{value:"The name of the property. For example, fill width r",paraId:80,tocIndex:29},{value:'Value parser. Different attribute values naturally require different parsers, for example fill stroke can share a color parser. Note that we only need to implement parsing for "values", not implementations like ',paraId:80,tocIndex:29},{value:"https://github.com/csstree/csstree",paraId:80,tocIndex:29},{value:".",paraId:80,tocIndex:29},{value:"Whether interpolation is supported. If not, smooth transitions in the animation system are not possible. ",paraId:80,tocIndex:29},{value:"https://drafts.csswg.org/css-values-4/#combining-values",paraId:80,tocIndex:29},{value:"Whether or not inheritance is supported. For example font-size needs to be supported. There are a number of similar tricks in D3.",paraId:80,tocIndex:29},{value:"Whether it is independent or not. For example visibility is not, and ancestor nodes need to be taken into account to get the final calculated value.",paraId:80,tocIndex:29},{value:"Default value. For example, the default value for fill is black (SVG specification)",paraId:80,tocIndex:29},{value:"Keyword list. For example, the width property supports the auto keyword.",paraId:80,tocIndex:29},{value:"Alias list. For example, the alias for line-width is stroke-width.",paraId:80,tocIndex:29},{value:'The defaults have a different definition of "whether the property supports inheritance".',paraId:81,tocIndex:30},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/initial_value",paraId:82,tocIndex:30},{value:"For inherited properties, the initial value is used on the root element only, as long as no specified value is supplied.",paraId:83,tocIndex:30},{value:"For non-inherited properties, the initial value is used on all elements, as long as no specified value is supplied.",paraId:83,tocIndex:30},{value:"Therefore, for the root node of G, all ",paraId:84,tocIndex:30},{value:"inherited",paraId:84,tocIndex:30},{value:" attributes need to be set to their default values at creation time, e.g. ",paraId:84,tocIndex:30},{value:"visibility",paraId:84,tocIndex:30},{value:" is defined in the attribute metadata as follows, and it supports inheritance.",paraId:84,tocIndex:30},{value:"{\n  name: 'visibility',\n  keywords: ['visible', 'hidden'],\n  inherited: true,\n  interpolable: true,\n  defaultValue: 'visible',\n  handler: CSSPropertyVisibility,\n}\n",paraId:85,tocIndex:30},{value:"Since inheritance is supported, the child element will be ",paraId:86,tocIndex:30},{value:"visible",paraId:86,tocIndex:30},{value:" by default, even if ",paraId:86,tocIndex:30},{value:"visibility",paraId:86,tocIndex:30},{value:" has not been set.",paraId:86,tocIndex:30},{value:"The parsing of property values goes through the following stages.",paraId:87,tocIndex:31},{value:"The original value (usually a string) is converted to a CSSStyleUnit, called computed value",paraId:88,tocIndex:31},{value:"The computed value is calculated to get the used value",paraId:88,tocIndex:31},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/computed_value",paraId:89,tocIndex:31},{value:"In this step it is necessary to.",paraId:90,tocIndex:31},{value:"Handle special keywords (usually generic), e.g. ",paraId:91,tocIndex:31},{value:"initial",paraId:92,tocIndex:31},{value:" [inherit](/en/api/css/css-properties-values- api#inherit)",paraId:91,tocIndex:31},{value:"Do some value calculations, except for those that require the layout phase to be involved",paraId:91,tocIndex:31},{value:"The computed value map can be obtained via the ",paraId:93,tocIndex:31},{value:"computedStyleMap",paraId:94,tocIndex:31},{value:" method, which is a ",paraId:93,tocIndex:31},{value:"Map",paraId:93,tocIndex:31},{value:" type.",paraId:93,tocIndex:31},{value:"/**\n * computed values\n */\nconst styleMap = circle.computedStyleMap();\n\nexpect((styleMap.get('r') as CSSUnitValue).equals(CSS.px(100))).to.be.true;\nconst fill = styleMap.get('fill') as CSSRGB;\nexpect(fill.r).toBe(255);\nexpect(fill.g).toBe(0);\nexpect(fill.b).toBe(0);\nexpect(fill.alpha).toBe(1);\n",paraId:95,tocIndex:31},{value:"However, the computed value cannot be used directly for rendering, e.g., percentages, relative lengths need to be further calculated.",paraId:96,tocIndex:31},{value:"https://developer.mozilla.org/en-US/docs/Web/CSS/used_value",paraId:97,tocIndex:32},{value:"The computed value is further processed to get the value that will eventually be fed into the rendering pipeline.",paraId:98,tocIndex:32},{value:"For example ",paraId:99,tocIndex:32},{value:"CSS.percent(50)",paraId:99,tocIndex:32},{value:" needs to be computed to get ",paraId:99,tocIndex:32},{value:"CSS.px(?)",paraId:99,tocIndex:32},{value:".",paraId:99,tocIndex:32},{value:"Define the new property in CSS as follows.",paraId:100,tocIndex:33},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSS/RegisterProperty",paraId:101,tocIndex:33},{value:"CSS.registerProperty({\n    name: '--my-color',\n    syntax: '<color>',\n    inherits: false,\n    initialValue: '#c0ffee',\n});\n",paraId:102,tocIndex:33},{value:"This property can then be used in CSS. One of the more critical ones is ",paraId:103,tocIndex:33},{value:"syntax",paraId:103,tocIndex:33},{value:", the limitation being that you can only use the browser's built-in implementation and can't really do custom parsing in the true sense.",paraId:103,tocIndex:33},{value:"In this ",paraId:104,tocIndex:33},{value:"example",paraId:105,tocIndex:33},{value:", we register several different types of custom properties, allowing them to support interpolation.",paraId:104,tocIndex:33},{value:"import { CSS, PropertySyntax } from '@antv/g';\n\n// Register custom properties\nCSS.registerProperty({\n    name: 'myNumber',\n    syntax: PropertySyntax.NUMBER, // Using the built-in \"number\" parser\n    initialValue: '0',\n    interpolable: true, // Support interpolation during animation\n});\n\n// Apply animations to custom properties\nconst animation = myCustomElement.animate(\n    [\n        {\n            myNumber: 0,\n        },\n        {\n            myNumber: 1,\n        },\n    ],\n    { duration: 2000, fill: 'both' },\n);\n",paraId:106,tocIndex:33},{value:"The name of the attribute in string form. It needs to be globally unique and cannot conflict with built-in properties, and can be prefixed with a namespace.",paraId:107,tocIndex:34},{value:"Whether to support inheritance.",paraId:108,tocIndex:35},{value:"Default value.",paraId:109,tocIndex:36},{value:"If or not interpolation is supported. Only supported to apply ",paraId:110,tocIndex:37},{value:"animation",paraId:111,tocIndex:37},{value:".",paraId:110,tocIndex:37},{value:"For example, in the following custom element, we define the custom attribute ",paraId:112,tocIndex:37},{value:"angle",paraId:112,tocIndex:37},{value:", which uses the ",paraId:112,tocIndex:37},{value:"<angle>",paraId:112,tocIndex:37},{value:" parser and supports interpolation.",paraId:112,tocIndex:37},{value:"CSS.registerProperty({\n    name: 'angle',\n    syntax: PropertySyntax.ANGLE,\n    initialValue: '0',\n    interpolable: true,\n});\n",paraId:113,tocIndex:37},{value:"We currently support the following parsers.",paraId:114,tocIndex:38},{value:"/**\n * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type\n */\nexport enum PropertySyntax {\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#coordinate\n   */\n  COORDINATE = '<coordinate>',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#color\n   */\n  COLOR = '<color>',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#paint\n   */\n  PAINT = '<paint>',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#number\n   */\n  NUMBER = '<number>',\n  /**\n   * @see https://developer.mozilla.org/zh-CN/docs/Web/CSS/angle\n   */\n  ANGLE = '<angle>',\n  /**\n   * <number> with range 0..1\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#opacity_value\n   */\n  OPACITY_VALUE = '<opacity-value>',\n  /**\n   * <number> with range 0..Infinity\n   */\n  SHADOW_BLUR = '<shadow-blur>',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#length\n   */\n  LENGTH = '<length>',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#percentage\n   */\n  PERCENTAGE = '<percentage>',\n  LENGTH_PERCENTAGE = '<length> | <percentage>',\n\n  LENGTH_PERCENTAGE_12 = '[<length> | <percentage>]{1,2}',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/CSS/margin#formal_syntax\n   */\n  LENGTH_PERCENTAGE_14 = '[<length> | <percentage>]{1,4}',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/SVG/Content_type#list-of-ts\n   */\n  LIST_OF_POINTS = '<list-of-points>',\n  PATH = '<path>',\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/CSS/filter#formal_syntax\n   */\n  FILTER = '<filter>',\n  Z_INDEX = '<z-index>',\n  OFFSET_PATH = '<offset-path>',\n  OFFSET_DISTANCE = '<offset-distance>',\n  CLIP_PATH = '<clip-path>',\n  TRANSFORM = '<transform>',\n  TRANSFORM_ORIGIN = '<transform-origin>',\n  TEXT = '<text>',\n  TEXT_TRANSFORM = '<text-transform>',\n}\n",paraId:115,tocIndex:38}]},94627:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(97337);const n=[{value:"In the browser, CSS parsing used to be a black box for front-end developers for a long time. We could only interact with the style system via unstructured strings like ",paraId:0},{value:"el.style.width = '50%'",paraId:0},{value:".",paraId:0},{value:"The ",paraId:1},{value:"CSS Typed OM API",paraId:1},{value:" allows parsed property values to be manipulated using JS, and it is also [CSS Houdini](",paraId:1},{value:"https://drafts",paraId:1},{value:". css-houdini.org/). In the case of ",paraId:1},{value:"width: '50%'",paraId:1},{value:" above, the attribute value in string form is parsed to ",paraId:1},{value:"CSS.percent(50)",paraId:1},{value:" for the next step in the calculation.",paraId:1},{value:"We provide a series of quick creation methods on ",paraId:2,tocIndex:0},{value:"CSS",paraId:2,tocIndex:0},{value:".",paraId:2,tocIndex:0},{value:"import { CSS } from '@antv/g';\n\nCSS.number(5);\nCSS.px(5);\nCSS.em(1.2);\nCSS.percent(50);\n",paraId:3,tocIndex:0},{value:"Create a ",paraId:4,tocIndex:1},{value:"CSSUnitValue",paraId:5,tocIndex:1},{value:" in ",paraId:4,tocIndex:1},{value:"UnitType.kNumber",paraId:4,tocIndex:1},{value:", written in the same way as the following two.",paraId:4,tocIndex:1},{value:"import { CSS, CSSUnitValue } from '@antv/g';\n\nCSS.number(5);\nnew CSSUnitValue(5); // The default unit is UnitType.kNumber\n",paraId:6,tocIndex:1},{value:"We use it to store the result of parsing a property value of type ",paraId:7,tocIndex:1},{value:"<number>",paraId:8,tocIndex:1},{value:", for example ",paraId:7,tocIndex:1},{value:"opacity: 0.5",paraId:7,tocIndex:1},{value:" will be parsed to ",paraId:7,tocIndex:1},{value:"CSS.number(0.5)",paraId:7,tocIndex:1},{value:" and stored in ",paraId:7,tocIndex:1},{value:"computedStyle.opacity",paraId:7,tocIndex:1},{value:".",paraId:7,tocIndex:1},{value:"Create a ",paraId:9,tocIndex:2},{value:"CSSUnitValue",paraId:10,tocIndex:2},{value:" in ",paraId:9,tocIndex:2},{value:"UnitType.kPixels",paraId:9,tocIndex:2},{value:", written in the same way as the following two.",paraId:9,tocIndex:2},{value:"import { CSS, CSSUnitValue } from '@antv/g';\n\nCSS.px(5);\nnew CSSUnitValue(5, 'px');\n",paraId:11,tocIndex:2},{value:"We will use it to store the result of parsing a property value of type ",paraId:12,tocIndex:2},{value:"<length>",paraId:13,tocIndex:2},{value:", for example ",paraId:12,tocIndex:2},{value:"r: 50",paraId:12,tocIndex:2},{value:" will be parsed to ",paraId:12,tocIndex:2},{value:"CSS.px(50)",paraId:12,tocIndex:2},{value:" and saved in ",paraId:12,tocIndex:2},{value:"computedStyle.r",paraId:12,tocIndex:2},{value:".",paraId:12,tocIndex:2},{value:"Create a ",paraId:14,tocIndex:3},{value:"CSSUnitValue",paraId:15,tocIndex:3},{value:" in ",paraId:14,tocIndex:3},{value:"UnitType.kEms",paraId:14,tocIndex:3},{value:", written in the same way as the following two.",paraId:14,tocIndex:3},{value:"import { CSS, CSSUnitValue } from '@antv/g';\n\nCSS.em(5);\nnew CSSUnitValue(5, 'em');\n",paraId:16,tocIndex:3},{value:"Create a ",paraId:17,tocIndex:4},{value:"CSSUnitValue",paraId:18,tocIndex:4},{value:" in ",paraId:17,tocIndex:4},{value:"UnitType.kRems",paraId:17,tocIndex:4},{value:", written in the same way as the following two.",paraId:17,tocIndex:4},{value:"import { CSS, CSSUnitValue } from '@antv/g';\n\nCSS.rem(5);\nnew CSSUnitValue(5, 'rem');\n",paraId:19,tocIndex:4},{value:"It is the base class for the following types.",paraId:20,tocIndex:5},{value:"Inherits from CSSStyleValue and provides a series of mathematical operations.",paraId:21,tocIndex:6},{value:"For example, we can represent the value of a property like ",paraId:22,tocIndex:6},{value:"10px + 10%",paraId:22,tocIndex:6},{value:" like this.",paraId:22,tocIndex:6},{value:"const length = new CSSUnitValue(10, 'px');\nconst percent = new CSSUnitValue(10, '%');\nconst result = percent.add(length);\n\n// 字符串表示\nexpect(result.toString()).toBe('calc(10% + 10px)');\nexpect(result.toSum('px', 'percent').toString()).toBe('calc(10px + 10%)');\nexpect(result.toSum('percent', 'px').toString()).toBe('calc(10% + 10px)');\n",paraId:23,tocIndex:6},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue",paraId:24,tocIndex:6},{value:"Reflects what type the property value represents (CSSNumericType), e.g. ",paraId:25,tocIndex:7},{value:"<length>",paraId:25,tocIndex:7},{value:", ",paraId:25,tocIndex:7},{value:"<angle>",paraId:25,tocIndex:7},{value:", etc.",paraId:25,tocIndex:7},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/type",paraId:26,tocIndex:7},{value:"// <number>\nconst number = new CSSUnitValue(10);\nexpect(number.type()).to.eqls({\n    length: 0,\n    angle: 0,\n    time: 0,\n    frequency: 0,\n    resolution: 0,\n    flex: 0,\n    percent: 0,\n    percentHint: 'length',\n});\n\n// <length>\nconst length = new CSSUnitValue(10, 'px');\nexpect(length.type()).to.eqls({\n    length: 1,\n    angle: 0,\n    time: 0,\n    frequency: 0,\n    resolution: 0,\n    flex: 0,\n    percent: 0,\n    percentHint: 'length',\n});\n",paraId:27,tocIndex:7},{value:"Provides conversion between different units. The method signature is as follows.",paraId:28,tocIndex:8},{value:"to(unit: UnitType | string): CSSUnitValue;\n",paraId:29,tocIndex:8},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/to",paraId:30,tocIndex:8},{value:"For example, to convert between different angular units.",paraId:31,tocIndex:8},{value:"const degValue = new CSSUnitValue(360, 'deg');\n\nexpect(degValue.to('deg').value).to.eqls(360);\nexpect(degValue.to('rad').value).to.eqls(deg2rad(360));\nexpect(degValue.to('turn').value).to.eqls(deg2turn(360));\n",paraId:32,tocIndex:8},{value:"If the conversion between the current unit and the target unit is not possible (e.g. converting 'px' to 'deg'), null will be returned.",paraId:33,tocIndex:8},{value:"Calculations between different units are completed whenever possible. The method signature is as follows.",paraId:34,tocIndex:9},{value:"toSum(...unit_strings: string[]): CSSMathSum {}\n",paraId:35,tocIndex:9},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/toSum",paraId:36,tocIndex:9},{value:"For example, we want to simplify the result of the expression by using 'px' and '%'.",paraId:37,tocIndex:9},{value:"let v = CSS.px('20').add(CSS.percent('4')).add(CSS.px('20'));\nv.toString(); // => \"calc(20px + 4% + 20px)\"\nv.toSum('px', 'percent').toString(); // => \"calc(40px + 4%)\"\n",paraId:38,tocIndex:9},{value:"It is important to note that the order of the units passed in affects the value of the final expression: the",paraId:39,tocIndex:9},{value:"const length = new CSSUnitValue(10, 'px');\nconst percent = new CSSUnitValue(10, '%');\nconst result = percent.add(length);\n\nexpect(result.toString()).toBe('calc(10% + 10px)');\nexpect(result.toSum('px', 'percent').toString()).toBe('calc(10px + 10%)');\nexpect(result.toSum('percent', 'px').toString()).toBe('calc(10% + 10px)');\n",paraId:40,tocIndex:9},{value:"Both type and value are required to be identical, e.g. both type is ",paraId:41,tocIndex:10},{value:"<length>",paraId:41,tocIndex:10},{value:" and both unit is 'px'.",paraId:41,tocIndex:10},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/equals",paraId:42,tocIndex:10},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/add",paraId:43,tocIndex:11},{value:"let mathSum = CSS.px('23').add(CSS.percent('4'));\n// Prints \"calc(23px + 4%)\"\nconsole.log(mathSum.toString());\n",paraId:44,tocIndex:11},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/sub",paraId:45,tocIndex:12},{value:"let mathSum = CSS.px('23').sub(CSS.percent('4'));\n// Prints \"calc(23px - 4%)\"\nconsole.log(mathSum.toString());\n",paraId:46,tocIndex:12},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/mul",paraId:47,tocIndex:13},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSNumericValue/div",paraId:48,tocIndex:14},{value:"Numeric value + unit. Inherited from CSSNumericValue.",paraId:49,tocIndex:19},{value:"We currently support enumerated values in the following units.",paraId:50,tocIndex:19},{value:"export enum UnitType {\n  kUnknown,\n  // <number>\n  kNumber,\n  // <percentage>\n  kPercentage,\n  // <length>\n  kEms,\n  kRems,\n  kPixels,\n  // <angle>\n  kDegrees,\n  kRadians,\n  kGradians,\n  kTurns,\n}\n",paraId:51,tocIndex:19},{value:"In addition to using enumeration values when creating, you can also use strings, so the following three ways of writing are consistent.",paraId:52,tocIndex:19},{value:"import { CSS, CSSUnitValue, UnitType } from '@antv/g';\n\nCSS.px(5);\nnew CSSUnitValue(5, UnitType.kPixels);\nnew CSSUnitValue(5, 'px');\n",paraId:53,tocIndex:19},{value:"The mapping relationship between enumeration values and strings is as follows.",paraId:54,tocIndex:19},{value:"UnitType.kNumber = 'number';\nUnitType.kPercentage = '%' | 'percent';\nUnitType.kEms = 'em';\nUnitType.kRems = 'rem';\nUnitType.kPixels = 'px';\nUnitType.kDegrees = 'deg';\nUnitType.kRadians = 'rad';\nUnitType.kGradians = 'grad';\nUnitType.kTurns = 'turn';\n",paraId:55,tocIndex:19},{value:"Return to the unit.",paraId:56,tocIndex:20},{value:"Return to the value.",paraId:57,tocIndex:21},{value:"Stands for keywords, such as ",paraId:58,tocIndex:22},{value:"unset",paraId:58,tocIndex:22},{value:" ",paraId:58,tocIndex:22},{value:"initial",paraId:58,tocIndex:22},{value:" ",paraId:58,tocIndex:22},{value:"inherit",paraId:58,tocIndex:22},{value:" etc.",paraId:58,tocIndex:22},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSSKeywordValue",paraId:59,tocIndex:22},{value:"const display = new CSSKeywordValue('initial');\ndisplay.value; // 'initial';\n",paraId:60,tocIndex:23},{value:"Inherited from CSSColorValue.",paraId:61,tocIndex:25},{value:"const value = new CSSRGB(0, 0, 0);\n\nexpect(value.toString()).to.eqls('rgba(0,0,0,1)');\n",paraId:62,tocIndex:25}]},1530:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(51353);const n=[{value:"In CSS, gradients are created by functions such as ",paraId:0},{value:"linear-gradient",paraId:0},{value:".",paraId:0},{value:"background: linear-gradient(#e66465, #9198e5);\n",paraId:1},{value:"We have followed that syntax so that it can be used in properties that support gradients.",paraId:2},{value:"rect.style.fill = 'linear-gradient(#e66465, #9198e5)';\n",paraId:3},{value:"In this ",paraId:4},{value:"example",paraId:5},{value:" we show the currently supported gradient effects, including linear and radial gradients, multiple gradients overlaid, etc.",paraId:4},{value:"Linear gradients are used to create an image that represents a linear gradient of two or more colors. ",paraId:6,tocIndex:0},{value:"This tutorial",paraId:6,tocIndex:0},{value:" can help you understand the meaning and calculation logic of the linear gradient direction.",paraId:6,tocIndex:0},{value:"The usage is exactly like CSS ",paraId:7,tocIndex:0},{value:"linear-gradient",paraId:7,tocIndex:0},{value:", but with the following differences.",paraId:7,tocIndex:0},{value:"The gradient direction defaults to bottom-to-top in CSS, while we use left-to-right to be consistent with Canvas / SVG.",paraId:8,tocIndex:0},{value:"So a linear gradient with a left-to-right orientation and a rotation angle of 0 would look like this, ",paraId:9,tocIndex:0},{value:"example",paraId:10,tocIndex:0},{value:".",paraId:9,tocIndex:0},{value:"rect.style.fill = 'linear-gradient(0deg, blue, green 40%, red)';\n",paraId:11,tocIndex:0},{value:"Finally, consistent with CSS, multiple gradients can be stacked.",paraId:12,tocIndex:0},{value:"rect.style.fill = `linear-gradient(217deg, rgba(255,0,0,.8), rgba(255,0,0,0) 70.71%),\n            linear-gradient(127deg, rgba(0,255,0,.8), rgba(0,255,0,0) 70.71%),\n            linear-gradient(336deg, rgba(0,0,255,.8), rgba(0,0,255,0) 70.71%)`;\n",paraId:13,tocIndex:0},{value:"A radial gradient consists of a gradual transition between two or more colors emanating from the origin.",paraId:14,tocIndex:1},{value:"The usage is exactly like CSS ",paraId:15,tocIndex:1},{value:"radial-gradient",paraId:15,tocIndex:1},{value:".",paraId:15,tocIndex:1},{value:"So a gradient centered at the center of the shape, with a radial gradient transitioning from red to blue to green as follows, ",paraId:16,tocIndex:1},{value:"example",paraId:17,tocIndex:1},{value:".",paraId:16,tocIndex:1},{value:"rect.style.fill = 'radial-gradient(circle at center, red, blue, green 100%)';\n",paraId:18,tocIndex:1},{value:"Caution.",paraId:19,tocIndex:1},{value:"Shapes are only supported for ",paraId:20,tocIndex:1},{value:"circle",paraId:20,tocIndex:1},{value:" but not for ",paraId:20,tocIndex:1},{value:"ellipse",paraId:20,tocIndex:1},{value:"Support for specifying ",paraId:20,tocIndex:1},{value:"circle",paraId:20,tocIndex:1},{value:" radius\n",paraId:20,tocIndex:1},{value:"'closest-side'",paraId:21,tocIndex:1},{value:" The gradient's ending shape meets the side of the box closest to its center.",paraId:21,tocIndex:1},{value:"'farthest-corner'",paraId:21,tocIndex:1},{value:" The default value, the gradient's ending shape is sized so that it exactly meets the farthest corner of the box from its center.",paraId:21,tocIndex:1},{value:"'closest-corner'",paraId:21,tocIndex:1},{value:" The gradient's ending shape is sized so that it exactly meets the closest corner of the box from its center.",paraId:21,tocIndex:1},{value:"'farthest-side'",paraId:21,tocIndex:1},{value:" Similar to closest-side, except the ending shape is sized to meet the side of the box farthest from its center (or vertical and horizontal sides).",paraId:21,tocIndex:1},{value:"<length>",paraId:21,tocIndex:1},{value:" e.g. ",paraId:21,tocIndex:1},{value:"'radial-gradient(circle 80px at center, red 100%, blue 100%)'",paraId:21,tocIndex:1},{value:"The following figures show the effect of ",paraId:22,tocIndex:1},{value:"'closest-side'",paraId:22,tocIndex:1},{value:", ",paraId:22,tocIndex:1},{value:"'farthest-side'",paraId:22,tocIndex:1},{value:" and ",paraId:22,tocIndex:1},{value:"80px",paraId:22,tocIndex:1},{value:" respectively.",paraId:22,tocIndex:1},{value:"Support specifying the position of the center of the circle and positioning it relative to the upper left corner of the enclosing box, e.g. ",paraId:23,tocIndex:1},{value:"radial-gradient(circle at 50px 50px, red, blue, green 100%)",paraId:23,tocIndex:1},{value:".\n",paraId:23,tocIndex:1},{value:"'top'",paraId:24,tocIndex:1},{value:" Top edge midpoint",paraId:24,tocIndex:1},{value:"'left'",paraId:24,tocIndex:1},{value:" Left edge midpoint",paraId:24,tocIndex:1},{value:"'bottom'",paraId:24,tocIndex:1},{value:" Bottom edge midpoint",paraId:24,tocIndex:1},{value:"'right'",paraId:24,tocIndex:1},{value:" Right edge midpoint",paraId:24,tocIndex:1},{value:"'center'",paraId:24,tocIndex:1},{value:" Horizontal and vertical centering",paraId:24,tocIndex:1},{value:"'top left'",paraId:24,tocIndex:1},{value:" Left-top corner",paraId:24,tocIndex:1},{value:"'left top'",paraId:24,tocIndex:1},{value:" Same as ",paraId:24,tocIndex:1},{value:"'top left'",paraId:24,tocIndex:1},{value:"'top right'",paraId:24,tocIndex:1},{value:" Right-top corner",paraId:24,tocIndex:1},{value:"'bottom left'",paraId:24,tocIndex:1},{value:" Left-bottom corner",paraId:24,tocIndex:1},{value:"'bottom right'",paraId:24,tocIndex:1},{value:" Right-bottom corner",paraId:24,tocIndex:1},{value:"<length> <length>",paraId:24,tocIndex:1},{value:" e.g. ",paraId:24,tocIndex:1},{value:"'25% 25%'",paraId:24,tocIndex:1},{value:" and ",paraId:24,tocIndex:1},{value:"'50px 50px'",paraId:24,tocIndex:1},{value:"The following figures show the effect of ",paraId:25,tocIndex:1},{value:"'50px 50px'",paraId:25,tocIndex:1},{value:", ",paraId:25,tocIndex:1},{value:"'top right'",paraId:25,tocIndex:1},{value:" and ",paraId:25,tocIndex:1},{value:"'left'",paraId:25,tocIndex:1},{value:" respectively.",paraId:25,tocIndex:1},{value:"Like linear gradients, it also supports multiple overlays.",paraId:26,tocIndex:1}]},49319:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(24103);const n=[{value:"In CSS, when no value is set for an attribute, the inheritable attribute will take the calculated value from the parent element.",paraId:0},{value:"https://developer.mozilla.org/zh-CN/docs/Web/CSS/inheritance",paraId:1},{value:"For example, the ",paraId:2},{value:"color",paraId:2},{value:" property of CSS is inheritable, so for an ",paraId:2},{value:"<em>",paraId:2},{value:" element that does not have this property set, it will use the value of the parent element, ",paraId:2},{value:"green",paraId:2},{value:".",paraId:2},{value:"p { color: green; }\n\n<p>This paragraph has <em>emphasized text</em> in it.</p>\n",paraId:3},{value:"We have implemented a style system in G that also supports inheritance. For example, we create a ",paraId:4},{value:"Text",paraId:5},{value:" without specifying ",paraId:4},{value:"fontSize",paraId:4},{value:" or ",paraId:4},{value:"fontFamily",paraId:4},{value:" properties, but it can still be rendered because it inherits the default style from the root node when added to the canvas: ",paraId:4},{value:"fontSize: '16px'; fontFamily: 'sans-serif'",paraId:4},{value:".",paraId:4},{value:"const text = new Text({\n    style: {\n        x: 100,\n        y: 100,\n        text: 'hello',\n    },\n});\n\ncanvas.appendChild(text);\n",paraId:6},{value:"In this ",paraId:7},{value:"example",paraId:8},{value:", modifying the font size of the root node also affects the child elements, and with units like ",paraId:7},{value:"rem",paraId:7},{value:' we can easily achieve an "elastic layout:"',paraId:7},{value:"canvas.document.documentElement.style.fontSize = `32px`;\n",paraId:9},{value:"As with browsers, the default value (",paraId:10,tocIndex:0},{value:"initial value",paraId:10,tocIndex:0},{value:") applies inheritable attributes at the root node.",paraId:10,tocIndex:0},{value:"For example, the browser default ",paraId:11,tocIndex:0},{value:"fontSize",paraId:11,tocIndex:0},{value:" is ",paraId:11,tocIndex:0},{value:"16px",paraId:11,tocIndex:0},{value:". We have styled ",paraId:11,tocIndex:0},{value:"root node",paraId:12,tocIndex:0},{value:" in G as follows.",paraId:11,tocIndex:0},{value:"expect(documentElement.style.fill).to.equal('');\nexpect(documentElement.style.fillOpacity).to.equal('1');\nexpect(documentElement.style.fontFamily).to.equal('sans-serif');\nexpect(documentElement.style.fontSize).to.equal('16px');\nexpect(documentElement.style.fontStyle).to.equal('normal');\nexpect(documentElement.style.fontVariant).to.equal('normal');\nexpect(documentElement.style.fontWeight).to.equal('normal');\nexpect(documentElement.style.height).to.equal('');\nexpect(documentElement.style.lineCap).to.equal('butt');\nexpect(documentElement.style.lineDashOffset).to.equal('0');\nexpect(documentElement.style.lineJoin).to.equal('miter');\nexpect(documentElement.style.lineWidth).to.equal('1');\nexpect(documentElement.style.opacity).to.equal('');\nexpect(documentElement.style.stroke).to.equal('');\nexpect(documentElement.style.strokeOpacity).to.equal('1');\nexpect(documentElement.style.textTransform).to.equal('none');\nexpect(documentElement.style.textAlign).to.equal('start');\nexpect(documentElement.style.textBaseline).to.equal('alphabetic');\nexpect(documentElement.style.transformOrigin).to.equal('');\nexpect(documentElement.style.visibility).to.equal('visible');\nexpect(documentElement.style.pointerEvents).to.equal('auto');\nexpect(documentElement.style.width).to.equal('');\nexpect(documentElement.style.x).to.equal(0);\nexpect(documentElement.style.y).to.equal(0);\nexpect(documentElement.style.z).to.equal(0);\nexpect(documentElement.style.zIndex).to.equal(0);\n",paraId:13,tocIndex:0},{value:"We currently support the following inheritable properties.",paraId:14,tocIndex:1},{value:"method name",paraId:15,tocIndex:1},{value:"initial value",paraId:15,tocIndex:1},{value:"element",paraId:15,tocIndex:1},{value:"inheritable",paraId:15,tocIndex:1},{value:"animatable",paraId:15,tocIndex:1},{value:"computed value",paraId:15,tocIndex:1},{value:"fillOpacity",paraId:15,tocIndex:1},{value:"'1'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"<number>",paraId:15,tocIndex:1},{value:"strokeOpacity",paraId:15,tocIndex:1},{value:"'1'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"<number>",paraId:15,tocIndex:1},{value:"lineWidth",paraId:15,tocIndex:1},{value:"'1'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"<length> <percentage>",paraId:15,tocIndex:1},{value:"lineJoin",paraId:15,tocIndex:1},{value:"'miter'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"lineCap",paraId:15,tocIndex:1},{value:"'butt'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"lineDash",paraId:15,tocIndex:1},{value:"无",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"<array>",paraId:15,tocIndex:1},{value:"lineDashOffset",paraId:15,tocIndex:1},{value:"'0'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"<length> <percentage>",paraId:15,tocIndex:1},{value:"visibility",paraId:15,tocIndex:1},{value:"'visible'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"pointerEvents",paraId:15,tocIndex:1},{value:"'auto'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"fontSize",paraId:15,tocIndex:1},{value:"'16px'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"<length> <percentage>",paraId:15,tocIndex:1},{value:"fontFamily",paraId:15,tocIndex:1},{value:"'sans-serif'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"fontStyle",paraId:15,tocIndex:1},{value:"'normal'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"fontWeight",paraId:15,tocIndex:1},{value:"'normal'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"fontVariant",paraId:15,tocIndex:1},{value:"'normal'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"textBaseline",paraId:15,tocIndex:1},{value:"'alphabetic'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1},{value:"textAlign",paraId:15,tocIndex:1},{value:"'start'",paraId:15,tocIndex:1},{value:"all",paraId:15,tocIndex:1},{value:"yes",paraId:15,tocIndex:1},{value:"no",paraId:15,tocIndex:1},{value:"<keywords>",paraId:15,tocIndex:1}]},82809:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(20152);const n=[{value:"We use a large number of style attributes in CSS, some of which affect the appearance of an element, and some of which affect the layout of an element.",paraId:0},{value:"div {\n    display: 'flex'; // 使用 Flex 布局\n    color: 'red'; // 字体颜色\n    opacity: 0.5;\n}\n",paraId:1},{value:"A similar ",paraId:2},{value:"attribute",paraId:2},{value:" exists in SVG, for example, to draw a red translucent circle with a radius of 5.",paraId:2},{value:'<circle r="5" fill="red" opacity="0.5"></circle>\n',paraId:3},{value:"The two overlap in some of their properties and we combine them so that the above effect can be achieved in G as follows:",paraId:4},{value:"const circle = new Circle({\n    // come from CSS\n    style: {\n        r: 5, // come from SVG\n        fill: 'red', // come from SVG\n        opacity: 0.5, // both from SVG & CSS\n    },\n});\n",paraId:5},{value:"In modern browsers, ",paraId:6},{value:"CSS",paraId:6},{value:' provides a number of APIs to help front-end developers better interact with the "black box" that is the style system.',paraId:6},{value:"CSS Typed OM",paraId:7},{value:" converts user-input strings into JS representations and provides tools such as math operations",paraId:7},{value:"CSS Properties & Values API](",paraId:7},{value:"https://developer.mozilla.org/en-US/docs/Web/API/CSS_Properties_and_Values_API",paraId:7},{value:") supports custom style properties",paraId:7},{value:"The ",paraId:7},{value:"CSS Layout API",paraId:7},{value:" supports custom layouts and implements layout algorithms that are not yet supported in browsers.",paraId:7},{value:"We have designed a simple style system (no support for style rules yet) by referring to the implementation of Blink (currently WebKit does not support CSS Typed OM, etc.) to implement the above CSS API. The CSS Properties & Values API registers a set of built-in properties during initialization, which can also be used in custom graphics to register Custom properties. Parsing of properties is done using CSS Typed OM, for example ",paraId:8},{value:"r: 5",paraId:8},{value:" will be parsed as ",paraId:8},{value:"CSS.px(5)",paraId:8},{value:". If the user sets the layout property ",paraId:8},{value:"display",paraId:8},{value:", we will use the CSS Layout API to do the layout calculations during the layout phase.",paraId:8},{value:"With this style system, we hope to make layout simpler, so that users can avoid complicated manual calculations, use ",paraId:9},{value:"setPosition()",paraId:9},{value:" to set the element position, and do the task easily with the layout property. Imagine all the fancy ways of centering elements before browsers supported ",paraId:9},{value:"display: flex",paraId:9},{value:".",paraId:9},{value:"container.appendChild(child1);\ncontainer.appendChild(child2);\n\n// Set the container to use the Flex layout to directly position the child elements\ncontainer.style.display = 'flex';\n\n// or Manually perform a series of complex layout calculations\nconst [x1, y1, x2, y2] = heavyLifting(container, child1, child2);\nchild1.setPosition(x1, y1);\nchild2.setPosition(x2, y2);\n",paraId:10},{value:"In the browser, CSS parsing used to be a black box for front-end developers for a long time.",paraId:11,tocIndex:0},{value:"We could only interact with the style system through unstructured strings like ",paraId:12,tocIndex:0},{value:"el.style.width = '50%'",paraId:12,tocIndex:0},{value:".",paraId:12,tocIndex:0},{value:"Different style properties support different types, for example the radius of a circle ",paraId:13,tocIndex:0},{value:"r",paraId:13,tocIndex:0},{value:" supports length ",paraId:13,tocIndex:0},{value:"<length>",paraId:13,tocIndex:0},{value:" and percentage ",paraId:13,tocIndex:0},{value:"<percentage>",paraId:13,tocIndex:0},{value:", which we can represent as strings.",paraId:13,tocIndex:0},{value:"circle.style.r = '5px';\ncircle.style.r = '50%';\n",paraId:14,tocIndex:0},{value:"We will parse such strings as ",paraId:15,tocIndex:0},{value:"CSSStyleValue",paraId:16,tocIndex:0},{value:", for example ",paraId:15,tocIndex:0},{value:"CSS.px(5)",paraId:15,tocIndex:0},{value:" and ",paraId:15,tocIndex:0},{value:"CSS.percent(50)",paraId:15,tocIndex:0},{value:", for more information see [CSS Typed OM](/ docs/api/css/css-typed-om).",paraId:15,tocIndex:0},{value:"Obviously, the metadata of an attribute (whether it can be inherited, whether it supports animations, default values, etc.) affects how we parse the value of the attribute.",paraId:17,tocIndex:1}]},41577:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(70104);const n=[{value:"Just like tileable tiles, floors, sometimes we want to fill a shape with the same pattern repeated.",paraId:0},{value:"In this ",paraId:1},{value:"example",paraId:2},{value:" we show the currently supported template padding effects, the sources can include image URLs, ",paraId:1},{value:"HTMLImageElement",paraId:1},{value:" ",paraId:1},{value:"HTMLCanvasElement",paraId:1},{value:" ",paraId:1},{value:"HTMLVideoElement",paraId:1},{value:" ",paraId:1},{value:"Rect",paraId:3},{value:" etc., and also specify the padding repeat direction.",paraId:1},{value:"In style properties that support Pattern (such as ",paraId:4},{value:"fill",paraId:4},{value:"), an object description can be used, including source, fill mode and transformation:",paraId:4},{value:"rect.style.fill = {\n    image: 'http://example.png',\n    repetition: 'repeat',\n    transform: 'rotate(30deg)',\n};\n",paraId:5},{value:"The supported parameters are as follows:",paraId:6},{value:"interface Pattern {\n    image: string | CanvasImageSource | Rect;\n    repetition?: 'repeat' | 'repeat-x' | 'repeat-y' | 'no-repeat';\n    transform?: string;\n}\n",paraId:7},{value:"required. The following sources are supported:",paraId:8,tocIndex:0},{value:"Image URL, eg. ",paraId:9,tocIndex:0},{value:"'http://example.png'",paraId:9,tocIndex:0},{value:"HTMLImageElement",paraId:9,tocIndex:0},{value:"HTMLCanvasElement",paraId:9,tocIndex:0},{value:"HTMLVideoElement",paraId:9,tocIndex:0},{value:"Rect",paraId:10,tocIndex:0},{value:"This is a more common usage, using the image URL as the pattern source:",paraId:11,tocIndex:1},{value:"// <img> URL\nrect.style.fill = {\n    image: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*jgjxQ57sACsAAAAAAAAAAAAAARQnAQ',\n    repetition: 'repeat',\n};\n",paraId:12,tocIndex:1},{value:"Instead of using an image URL, you can also pass in an ",paraId:13,tocIndex:2},{value:"Image",paraId:13,tocIndex:2},{value:" object as the source:",paraId:13,tocIndex:2},{value:"// HTMLImageElement(<img>)\nconst image = new window.Image();\nimage.onload = () => {\n    const rect2 = new Rect({\n        style: {\n            x: 300,\n            y: 50,\n            width: 200,\n            height: 100,\n            fill: {\n                image,\n                repetition: 'repeat',\n            },\n        },\n    });\n};\nimage.crossOrigin = 'Anonymous';\nimage.src =\n    'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*jgjxQ57sACsAAAAAAAAAAAAAARQnAQ';\n",paraId:14,tocIndex:2},{value:"<video>",paraId:15,tocIndex:3},{value:" can also be passed in as the source.",paraId:15,tocIndex:3},{value:"// HTMLVideoElement(<video>)\nconst video = document.createElement('video');\nvideo.src =\n    'https://gw.alipayobjects.com/v/rms_6ae20b/afts/video/A*VD0TTbZB9WMAAAAAAAAAAAAAARQnAQ/720P';\nvideo.crossOrigin = 'Anonymous';\nvideo.autoplay = true;\nvideo.controls = false;\nvideo.muted = true;\nvideo.height = 100;\nvideo.width = 200;\n\nvideo.onloadeddata = function () {\n    const rect5 = new Rect({\n        style: {\n            x: 50,\n            y: 350,\n            width: 200,\n            height: 100,\n            fill: {\n                image: video,\n                repetition: 'no-repeat',\n            },\n        },\n    });\n    canvas.appendChild(rect5);\n};\n",paraId:16,tocIndex:3},{value:"In addition to using pictures and videos as sources, programmatic generation can also be used. In this case, ",paraId:17,tocIndex:4},{value:"<canvas>",paraId:17,tocIndex:4},{value:" and native [Canvas API](",paraId:17,tocIndex:4},{value:"https://developer.mozilla.org/en-US/docs/Web",paraId:17,tocIndex:4},{value:" /API/Canvas_API).",paraId:17,tocIndex:4},{value:"In this ",paraId:18,tocIndex:4},{value:"example",paraId:19,tocIndex:4},{value:", we use HTMLCanvasElement to draw a 20 * 20 template first, and then use it to fill:",paraId:18,tocIndex:4},{value:"// @see https://observablehq.com/@awoodruff/canvas-cartography-nacis-2019\nconst patternCanvas = document.createElement('canvas');\npatternCanvas.width = 20;\npatternCanvas.height = 20;\nconst ctx = patternCanvas.getContext('2d');\nctx.strokeStyle = '#333';\nctx.lineWidth = 1;\nctx.beginPath();\nfor (let i = 0.5; i < 20; i += 5) {\n    ctx.moveTo(0, i);\n    ctx.lineTo(20, i);\n}\nctx.stroke();\n\nconst rect3 = new Rect({\n    style: {\n        x: 50,\n        y: 200,\n        width: 200,\n        height: 100,\n        fill: {\n            image: patternCanvas,\n            repetition: 'repeat',\n        },\n    },\n});\n",paraId:20,tocIndex:4},{value:"The above programmatically generated Pattern using the native ",paraId:21,tocIndex:5},{value:"Canvas API",paraId:21,tocIndex:5},{value:" has the following limitations:",paraId:21,tocIndex:5},{value:"If you want to use the Pattern generated by the Canvas API in the SVG renderer, you can only export the image by referencing the Canvas, which will lead to the loss of the excellent characteristics of the vector map, such as blurring after zooming in",paraId:22,tocIndex:5},{value:"High learning cost, especially difficult to define complex patterns",paraId:22,tocIndex:5},{value:"Therefore, we hope to use G's graphics API to define Patterns, consistent with defining scenarios. On the one hand, the unified description ability improves usability, so that users do not need to touch the underlying rendering API; on the other hand, it also allows us to use different Pattern implementations in different renderers, such as using native ",paraId:23,tocIndex:5},{value:"<pattern>",paraId:23,tocIndex:5},{value:" in SVG to improve clarity The following figure shows the comparison between Canvas and SVG after zooming in.",paraId:23,tocIndex:5},{value:"In the ",paraId:24,tocIndex:5},{value:"example",paraId:25,tocIndex:5},{value:" below, we create a ",paraId:24,tocIndex:5},{value:"16 * 16",paraId:24,tocIndex:5},{value:" pattern with a red dot on a white background. It can be seen that the usage of the conventional definition scene is no different:",paraId:24,tocIndex:5},{value:"const background = new Rect({\n    style: {\n        width: 16,\n        height: 16,\n        fill: 'red',\n    },\n});\nconst dot = new Circle({\n    style: {\n        cx: 8,\n        cy: 8,\n        r: 6,\n        fill: 'white',\n    },\n});\nbackground.appendChild(dot);\n",paraId:26,tocIndex:5},{value:"Then apply the Pattern tile to the graphics, and at the same time rotate a certain angle through ",paraId:27,tocIndex:5},{value:"transform",paraId:28,tocIndex:5},{value:":",paraId:27,tocIndex:5},{value:"const rect = new Rect({\n    style: {\n        fill: {\n            image: background,\n            repetition: 'repeat',\n            transform: 'rotate(30deg)',\n        },\n    },\n});\n",paraId:29,tocIndex:5},{value:"The effect is as follows:",paraId:30,tocIndex:5},{value:"Finally, the ",paraId:31,tocIndex:5},{value:"g-pattern",paraId:32,tocIndex:5},{value:" mentioned below is also defined in this way.",paraId:31,tocIndex:5},{value:"Optional. The following patterns are supported and can be viewed in this ",paraId:33,tocIndex:6},{value:"example",paraId:34,tocIndex:6},{value:":",paraId:33,tocIndex:6},{value:"'repeat'",paraId:35,tocIndex:6},{value:" default, tiles horizontally and vertically",paraId:35,tocIndex:6},{value:"'repeat-x'",paraId:35,tocIndex:6},{value:" tiles horizontally",paraId:35,tocIndex:6},{value:"'repeat-y'",paraId:35,tocIndex:6},{value:" tiles vertically",paraId:35,tocIndex:6},{value:"'no-repeat'",paraId:35,tocIndex:6},{value:" do not tile",paraId:35,tocIndex:6},{value:"Optional. Sometimes we want to transform the mode, such as rotating a certain angle, at this time we can use ",paraId:36,tocIndex:7},{value:"transform",paraId:36,tocIndex:7},{value:" attribute, the value is exactly the same as CSS Transform.",paraId:36,tocIndex:7},{value:"In the ",paraId:37,tocIndex:7},{value:"example",paraId:38,tocIndex:7},{value:" below, we want the pattern to rotate:",paraId:37,tocIndex:7},{value:"rect.style.fill = {\n    image: canvas,\n    repetition: 'repeat',\n    transform: `rotate(30deg)`,\n};\n",paraId:39,tocIndex:7},{value:"It should be noted that the value of ",paraId:40,tocIndex:7},{value:"patternTransform",paraId:40,tocIndex:7},{value:" in SVG is slightly different from that of CSS Transform, and there is no value in vector graphics. unit, only supports ",paraId:40,tocIndex:7},{value:"transform_functions",paraId:40,tocIndex:7},{value:", so for example ",paraId:40,tocIndex:7},{value:"rotate(20deg)",paraId:40,tocIndex:7},{value:" needs to remove the unit and rewrite it as",paraId:40,tocIndex:7},{value:"rotate(20)",paraId:40,tocIndex:7},{value:", ",paraId:40,tocIndex:7},{value:"transform(20px, 30px)",paraId:40,tocIndex:7},{value:" are the same. But we have unified it internally, so the value of CSS Transform can be fully used.",paraId:40,tocIndex:7},{value:"Refer to ",paraId:41,tocIndex:8},{value:"nivo patterns",paraId:41,tocIndex:8},{value:", we provide some built-in patterns, and you can adjust the appearance through more friendly parameters. Currently we support the following three patterns:",paraId:41,tocIndex:8},{value:"dots",paraId:42,tocIndex:8},{value:" Pattern with dots.",paraId:42,tocIndex:8},{value:"lines",paraId:42,tocIndex:8},{value:" Pattern with lines.",paraId:42,tocIndex:8},{value:"squares",paraId:42,tocIndex:8},{value:" Pattern with squares.",paraId:42,tocIndex:8},{value:"The method signatures of these three patterns are as follows, the first parameter is ",paraId:43,tocIndex:8},{value:"Canvas",paraId:44,tocIndex:8},{value:", and the second parameter is the style configuration of the pattern:",paraId:43,tocIndex:8},{value:"dots(cfg?: DotPatternCfg): HTMLCanvasElement;\nlines(cfg?: LinePatternCfg): HTMLCanvasElement;\nsquares(cfg?: SquarePatternCfg): HTMLCanvasElement;\n",paraId:45,tocIndex:8},{value:"In the following ",paraId:46,tocIndex:8},{value:"example",paraId:47,tocIndex:8},{value:", we choose ",paraId:46,tocIndex:8},{value:"dots",paraId:46,tocIndex:8},{value:" and use ",paraId:46,tocIndex:8},{value:"transform",paraId:48,tocIndex:8},{value:" to rotate and scale it:",paraId:46,tocIndex:8},{value:"import { dots } from '@antv/g-pattern';\n\nrect.style.fill = {\n    image: dots(canvas, {\n        size: 6,\n        padding: 2,\n        fill: '#ff0000',\n        isStagger: true,\n    }),\n    repetition: 'repeat',\n    transform: `rotate(30deg) scale(1.2)`,\n};\n",paraId:49,tocIndex:8},{value:"Common configuration for all types of pattern:",paraId:50,tocIndex:8},{value:"Attribute",paraId:51,tocIndex:8},{value:"Type",paraId:51,tocIndex:8},{value:"Description",paraId:51,tocIndex:8},{value:"backgroundColor",paraId:51,tocIndex:8},{value:"string",paraId:51,tocIndex:8},{value:"Background color of the pattern, default to ",paraId:51,tocIndex:8},{value:"'transparent'",paraId:51,tocIndex:8},{value:"backgroundOpacity",paraId:51,tocIndex:8},{value:"string",paraId:51,tocIndex:8},{value:"Background opacity of the pattern, default to ",paraId:51,tocIndex:8},{value:"1",paraId:51,tocIndex:8},{value:"fill",paraId:51,tocIndex:8},{value:"string",paraId:51,tocIndex:8},{value:"Fill color of the symbol in pattern, ",paraId:51,tocIndex:8},{value:"dots",paraId:51,tocIndex:8},{value:" and ",paraId:51,tocIndex:8},{value:"squares",paraId:51,tocIndex:8},{value:" default to ",paraId:51,tocIndex:8},{value:"'#fff'",paraId:51,tocIndex:8},{value:"，",paraId:51,tocIndex:8},{value:"fillOpacity",paraId:51,tocIndex:8},{value:"number",paraId:51,tocIndex:8},{value:"Transparency of the symbol in pattern, default to ",paraId:51,tocIndex:8},{value:"1",paraId:51,tocIndex:8},{value:"stroke",paraId:51,tocIndex:8},{value:"string",paraId:51,tocIndex:8},{value:"Stroke color of the symbol in pattern, ",paraId:51,tocIndex:8},{value:"dots",paraId:51,tocIndex:8},{value:" and ",paraId:51,tocIndex:8},{value:"squares",paraId:51,tocIndex:8},{value:" default to ",paraId:51,tocIndex:8},{value:"'transparent'",paraId:51,tocIndex:8},{value:", ",paraId:51,tocIndex:8},{value:"lines",paraId:51,tocIndex:8},{value:" default to ",paraId:51,tocIndex:8},{value:"'#fff'",paraId:51,tocIndex:8},{value:"strokeOpacity",paraId:51,tocIndex:8},{value:"number",paraId:51,tocIndex:8},{value:"Stroke opacity of the symbol in pattern, default to ",paraId:51,tocIndex:8},{value:"1",paraId:51,tocIndex:8},{value:"lineWidth",paraId:51,tocIndex:8},{value:"number",paraId:51,tocIndex:8},{value:"The thickness of the symbol's stroke, ",paraId:51,tocIndex:8},{value:"dots",paraId:51,tocIndex:8},{value:" and ",paraId:51,tocIndex:8},{value:"squares",paraId:51,tocIndex:8},{value:" default to ",paraId:51,tocIndex:8},{value:"0",paraId:51,tocIndex:8},{value:", ",paraId:51,tocIndex:8},{value:"lines",paraId:51,tocIndex:8},{value:" default to ",paraId:51,tocIndex:8},{value:"2",paraId:51,tocIndex:8},{value:"opacity",paraId:51,tocIndex:8},{value:"number",paraId:51,tocIndex:8},{value:"Overall transparency of the pattern, default to ",paraId:51,tocIndex:8},{value:"1",paraId:51,tocIndex:8},{value:"Additional configuration for ",paraId:52,tocIndex:9},{value:"dots",paraId:52,tocIndex:9},{value:", ",paraId:52,tocIndex:9},{value:"example",paraId:53,tocIndex:9},{value:"：",paraId:52,tocIndex:9},{value:"Attribute",paraId:54,tocIndex:9},{value:"Type",paraId:54,tocIndex:9},{value:"Description",paraId:54,tocIndex:9},{value:"size",paraId:54,tocIndex:9},{value:"number",paraId:54,tocIndex:9},{value:"The size of the dot, default to ",paraId:54,tocIndex:9},{value:"6",paraId:54,tocIndex:9},{value:"padding",paraId:54,tocIndex:9},{value:"number",paraId:54,tocIndex:9},{value:"The distance between dots, default to ",paraId:54,tocIndex:9},{value:"2",paraId:54,tocIndex:9},{value:"isStagger",paraId:54,tocIndex:9},{value:"boolean",paraId:54,tocIndex:9},{value:"Staggered dots. default to ",paraId:54,tocIndex:9},{value:"true",paraId:54,tocIndex:9},{value:"Additional configuration for ",paraId:55,tocIndex:9},{value:"lines",paraId:55,tocIndex:9},{value:", ",paraId:55,tocIndex:9},{value:"example",paraId:56,tocIndex:9},{value:"：",paraId:55,tocIndex:9},{value:"Attribute",paraId:57,tocIndex:10},{value:"Type",paraId:57,tocIndex:10},{value:"Description",paraId:57,tocIndex:10},{value:"spacing",paraId:57,tocIndex:10},{value:"number",paraId:57,tocIndex:10},{value:"The distance between the two lines, default to ",paraId:57,tocIndex:10},{value:"5",paraId:57,tocIndex:10},{value:"Additional configuration for ",paraId:58,tocIndex:10},{value:"squares",paraId:58,tocIndex:10},{value:", ",paraId:58,tocIndex:10},{value:"example",paraId:59,tocIndex:10},{value:":",paraId:58,tocIndex:10},{value:"Attribute",paraId:60,tocIndex:11},{value:"Type",paraId:60,tocIndex:11},{value:"Description",paraId:60,tocIndex:11},{value:"size",paraId:60,tocIndex:11},{value:"number",paraId:60,tocIndex:11},{value:"The size of the square, default to ",paraId:60,tocIndex:11},{value:"6",paraId:60,tocIndex:11},{value:"padding",paraId:60,tocIndex:11},{value:"number",paraId:60,tocIndex:11},{value:"The distance between squares, default to ",paraId:60,tocIndex:11},{value:"1",paraId:60,tocIndex:11},{value:"isStagger",paraId:60,tocIndex:11},{value:"boolean",paraId:60,tocIndex:11},{value:"Staggered squares. default to ",paraId:60,tocIndex:11},{value:"true",paraId:60,tocIndex:11}]},41072:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(7298);const n=[{value:"Web Components",paraId:0},{value:" 允许扩展浏览器内置的 HTML 元素并完成复用。在使用声明式写法的同时，这也是一种与视图层（React Vue Svelte 等）无关的方案。当然如果有需要，视图层也很容易基于它继续封装。",paraId:0},{value:"在该 ",paraId:1},{value:"示例",paraId:2},{value:" 中，我们使用 HTML 语法定义",paraId:1},{value:"场景图",paraId:3},{value:"，避免了大量诸如 ",paraId:1},{value:"appendChild",paraId:4},{value:" 这样的命令式调用。而对于各个图形则非常类似 SVG 的用法，属性值都以字符串形式存在。",paraId:1},{value:'<g-canvas renderer="canvas" width="400" height="400">\n    <g-rect\n        fill="#2f54eb"\n        radius="0 24px 24px"\n        x="12px"\n        y="24px"\n        width="200px"\n        height="50px"\n    >\n        <g-circle fill="#adc6ff" r="16px" cx="25px" cy="25px"></g-circle>\n        <g-text fill="#fff" x="50px" y="20px">我是一段文字</g-text>\n    </g-rect>\n</g-canvas>\n',paraId:5},{value:"当然在事件绑定这样必须要使用命令式 API 的情况下，可以通过。",paraId:6},{value:"同样有以下两种使用方式。",paraId:7,tocIndex:0},{value:"使用 CDN：",paraId:8,tocIndex:0},{value:'<script src="https://unpkg.com/@antv/g"><\/script>\n<script src="https://unpkg.com/@antv/g-canvas"><\/script>\n<script src="https://unpkg.com/@antv/g-web-components"><\/script>\n',paraId:9,tocIndex:0},{value:"使用 NPM module:",paraId:10,tocIndex:0},{value:"import '@antv/g';\nimport '@antv/g-canvas';\nimport '@antv/g-web-components';\n",paraId:11,tocIndex:0},{value:"安装完成之后会使用 ",paraId:12,tocIndex:0},{value:"CustomElementRegistry.define()",paraId:12,tocIndex:0},{value:" 自动完成相关组件的注册。",paraId:12,tocIndex:0},{value:"目前支持以下自定义元素。大部分都可以参考对应图形的命令式 API。",paraId:13,tocIndex:1},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:14},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:14},{value:"可参考 ",paraId:15,tocIndex:3},{value:"Circle",paraId:16,tocIndex:3},{value:"。",paraId:15,tocIndex:3},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:14},{value:"可参考 ",paraId:17,tocIndex:4},{value:"Ellipse",paraId:18,tocIndex:4},{value:"。",paraId:17,tocIndex:4},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:14},{value:"可参考 ",paraId:19,tocIndex:5},{value:"Rect",paraId:20,tocIndex:5},{value:"。",paraId:19,tocIndex:5},{value:"需要注意 ",paraId:21,tocIndex:5},{value:"radius",paraId:22,tocIndex:5},{value:" 需要使用数组字符串形式：",paraId:21,tocIndex:5},{value:'<g-rect\n    radius="0 24px 24px"\n    x="12px"\n    y="24px"\n    width="200px"\n    height="50px"\n></g-rect>\n',paraId:23,tocIndex:5},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:14},{value:"可参考 ",paraId:24,tocIndex:6},{value:"Line",paraId:25,tocIndex:6},{value:"。",paraId:24,tocIndex:6},{value:' type="button" class="ant-btn ant-btn-text ant-btn-icon-only button comment-link">',paraId:14},{value:"可参考 ",paraId:26,tocIndex:7},{value:"Path",paraId:27,tocIndex:7},{value:"。",paraId:26,tocIndex:7},{value:"需要注意路径定义一定要使用字符串形式。",paraId:28,tocIndex:7},{value:'<g-path\n    transform="translate(0, 100px)"\n    stroke="#2f54eb"\n    path="M 0,40 C 5.5555555555555545,40,22.222222222222218,44.44444444444445,33.33333333333333,40 C 44.444444444444436, ..."\n></g-path>\n',paraId:29,tocIndex:7}]},17934:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(63480);const n=[{value:"我们提供了一款 Chrome 浏览器插件，用于开发时审查画布中的元素。",paraId:0},{value:"https://github.com/antvis/g/tree/next/packages/g-devtool",paraId:1}]},64324:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(77668);const n=[{value:"G 内置了一些渲染相关的统计信息，可以通过 ",paraId:0},{value:"canvas.getStats",paraId:0},{value:" 获取，例如在每一帧中获取：",paraId:0},{value:"import { CanvasEvent } from '@antv/g';\n\ncanvas.addEventListener(CanvasEvent.AFTER_RENDER, () => {\n    canvas.getStats(); // { total: 0, rendered: 0 }\n});\n",paraId:1},{value:"目前包含的统计信息如下：",paraId:2},{value:"total 当前帧中需要渲染的图形总数",paraId:3},{value:"rendered 当前帧中实际渲染的图形数目",paraId:3},{value:"其中 total 不一定等于当前场景中包含的图形数量，例如相比上一帧，当前帧所有图形都没有发生变化，此时不应该发生重绘，total 为 0。",paraId:4},{value:"在某些情况下 rendered 会比 total 少，例如图形被剔除（处于视口 / 视锥范围之外）。",paraId:5}]},22458:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(3803);const n=[{value:"在使用 G 开发时，有很多通用的第三方工具可以辅助我们开发调试。",paraId:0},{value:"stats.js",paraId:1,tocIndex:0},{value:" 常用于展示 FPS。配合 G 使用时可以监听 ",paraId:1,tocIndex:0},{value:"CanvasEvent 画布事件",paraId:2,tocIndex:0},{value:"，在每一帧结束时更新：",paraId:1,tocIndex:0},{value:"import { CanvasEvent } from '@antv/g';\n\n// 创建 stats\nconst stats = new Stats();\nstats.showPanel(0);\nconst $stats = stats.dom;\n$stats.style.position = 'absolute';\n$stats.style.left = '0px';\n$stats.style.top = '0px';\nconst $wrapper = document.getElementById('container');\n$wrapper.appendChild($stats);\n\n// 在每一帧结束时刷新帧数\ncanvas.addEventListener(CanvasEvent.AFTER_RENDER, () => {\n    stats.update();\n});\n",paraId:3,tocIndex:0},{value:"如果使用 ",paraId:4,tocIndex:1},{value:"g-webgl",paraId:4,tocIndex:1},{value:" 作为",paraId:4,tocIndex:1},{value:"渲染器",paraId:5,tocIndex:1},{value:"，可以安装 Chrome 浏览器插件 ",paraId:4,tocIndex:1},{value:"Spector.js",paraId:4,tocIndex:1},{value:"，捕获当前帧执行的所有 WebGL API：",paraId:4,tocIndex:1}]},50701:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(57549);const n=[{value:"In the event listener's callback function, we can get the event object and access the properties and methods on it. These properties and methods are consistent with the DOM Event API, so you can directly refer to their documentation.",paraId:0},{value:"We will try to normalize the native events to ",paraId:1},{value:"PointerEvent",paraId:1},{value:" event object and then handle them uniformly, which can be accessed on ",paraId:1},{value:"nativeEvent",paraId:2},{value:" to access native events.",paraId:1},{value:"Common properties on the event object include event type, graphics of the current triggered event, location, etc., where location is related to [coordinate system](/en/api/canvas#coordinate system).",paraId:3,tocIndex:0},{value:"Event type：",paraId:4,tocIndex:1},{value:"pointerup",paraId:5,tocIndex:1},{value:"pointerdown",paraId:5,tocIndex:1},{value:"pointerupoutside",paraId:5,tocIndex:1},{value:"pointermove",paraId:5,tocIndex:1},{value:"pointercancel",paraId:5,tocIndex:1},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Event/type",paraId:6,tocIndex:1},{value:"Native event object. When we call ",paraId:7,tocIndex:2},{value:"preventDefault",paraId:8,tocIndex:2},{value:" method, it will call the method of the same name on the native event object.",paraId:7,tocIndex:2},{value:"Point to ",paraId:9,tocIndex:3},{value:"Canvas",paraId:10,tocIndex:3},{value:".",paraId:9,tocIndex:3},{value:"https://developer.mozilla.org/en-US/docs/Web/API/UIEvent/view",paraId:11,tocIndex:3},{value:"If or not the event is triggered with an ",paraId:12,tocIndex:4},{value:"alt",paraId:12,tocIndex:4},{value:" press.",paraId:12,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/altKey",paraId:13,tocIndex:4},{value:"If or not the event is triggered with a ",paraId:14,tocIndex:5},{value:"meta",paraId:14,tocIndex:5},{value:" press.",paraId:14,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/metaKey",paraId:15,tocIndex:5},{value:"If or not the event is triggered with a ",paraId:16,tocIndex:6},{value:"ctrl",paraId:16,tocIndex:6},{value:" press.",paraId:16,tocIndex:6},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/ctrlKey",paraId:17,tocIndex:6},{value:"If or not the event is triggered with a ",paraId:18,tocIndex:7},{value:"shift",paraId:18,tocIndex:7},{value:" press.",paraId:18,tocIndex:7},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/shiftKey",paraId:19,tocIndex:7},{value:"Timestamp when the event was created.",paraId:20,tocIndex:8},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/timeStamp",paraId:21,tocIndex:8},{value:"The current event phase. There are three enumeration values as follows.",paraId:22,tocIndex:9},{value:"CAPTURING_PHASE = 1;\nAT_TARGET = 2;\nBUBBLING_PHASE = 3;\n",paraId:23,tocIndex:9},{value:"For example, with the ",paraId:24,tocIndex:9},{value:"capture",paraId:24,tocIndex:9},{value:" configuration item, events are processed only during the capture phase.",paraId:24,tocIndex:9},{value:"circle.addEventListener(\n    'click',\n    (e: FederatedEvent) => {\n        console.log(e.eventPhase); // e.CAPTURING_PHASE\n    },\n    { capture: true },\n);\n",paraId:25,tocIndex:9},{value:"The data object carried by the event object. For example, when a click is triggered, the number of clicks is carried.",paraId:26,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/CustomEvent/detail",paraId:27,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/target",paraId:28,tocIndex:11},{value:"The ",paraId:29,tocIndex:11},{value:"EventTarget",paraId:30,tocIndex:11},{value:" of the current triggering event.",paraId:29,tocIndex:11},{value:"Useful when implementing event delegation, for example in a scenario like this, similar to ",paraId:31,tocIndex:11},{value:"ul/li",paraId:31,tocIndex:11},{value:" in the DOM.",paraId:31,tocIndex:11},{value:"Group(ul) - Rect(li) - Rect(li);\n",paraId:32,tocIndex:11},{value:"We can listen for events on ",paraId:33,tocIndex:11},{value:"ul",paraId:33,tocIndex:11},{value:" that will trigger when each ",paraId:33,tocIndex:11},{value:"li",paraId:33,tocIndex:11},{value:" is clicked on.",paraId:33,tocIndex:11},{value:"const ul = new Group();\nconst li1 = new Rect();\nconst li2 = new Rect();\nul.appendChild(li1);\nul.appendChild(li2);\n\nul.addEventListener(\n    'click',\n    (e) => {\n        e.target; // li1 或者 li2\n        e.currentTarget; // ul\n    },\n    false,\n);\n",paraId:34,tocIndex:11},{value:"Example",paraId:35},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/currentTarget",paraId:36,tocIndex:12},{value:"Always points to the event-bound element.",paraId:37,tocIndex:12},{value:"ul.addEventListener(\n    'click',\n    (e) => {\n        e.currentTarget; // ul\n    },\n    false,\n);\n",paraId:38,tocIndex:12},{value:"Under ",paraId:39,tocIndex:13},{value:"Canvas coordinate system/world coordinate system",paraId:40,tocIndex:13},{value:", the upper left corner of the canvas DOM element is the origin, the X-axis is pointing to the right side of the screen and the Y-axis is pointing to the bottom of the screen. Can be interconverted with ",paraId:39,tocIndex:13},{value:"viewportX/Y",paraId:41,tocIndex:13},{value:", ",paraId:39,tocIndex:13},{value:"see",paraId:42,tocIndex:13},{value:".",paraId:39,tocIndex:13},{value:"canvas.canvas2Viewport({ x: e.canvasX, y: e.canvasY }); // Point { x: 100, y: 100 }\ncanvas.viewport2Canvas({ x: e.viewportX, y: e.viewportY }); // Point { x: 0, y: 0 }\n",paraId:43,tocIndex:13},{value:"The alias is x/y, so the following writing is equivalent.",paraId:44,tocIndex:13},{value:"e.canvasX;\ne.x;\n\ne.canvasY;\ne.y;\n",paraId:45,tocIndex:13},{value:"Under ",paraId:46,tocIndex:14},{value:"Viewport coordinate system",paraId:47,tocIndex:14},{value:", consider the camera transformation.",paraId:46,tocIndex:14},{value:"Can be interconverted with ",paraId:48,tocIndex:14},{value:"canvasX/Y",paraId:49,tocIndex:14},{value:", ",paraId:48,tocIndex:14},{value:"see",paraId:50,tocIndex:14},{value:".",paraId:48,tocIndex:14},{value:"canvas.canvas2Viewport({ x: e.canvasX, y: e.canvasY }); // Point { x: 100, y: 100 }\ncanvas.viewport2Canvas({ x: e.viewportX, y: e.viewportY }); // Point { x: 0, y: 0 }\n",paraId:51,tocIndex:14},{value:"Can be interconverted with ",paraId:52,tocIndex:14},{value:"clientX/Y",paraId:53,tocIndex:14},{value:", ",paraId:52,tocIndex:14},{value:"see",paraId:54,tocIndex:14},{value:".",paraId:52,tocIndex:14},{value:"canvas.viewport2Client({ x: 0, y: 0 }); // Point { x: 100, y: 100 }\ncanvas.client2Viewport({ x: 100, y: 100 }); // Point { x: 0, y: 0 }\n",paraId:55,tocIndex:14},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/clientX",paraId:56,tocIndex:15},{value:"Under ",paraId:57,tocIndex:15},{value:"browser coordinate system",paraId:58,tocIndex:15},{value:", the upper left corner is ",paraId:57,tocIndex:15},{value:"(0, 0)",paraId:57,tocIndex:15},{value:". G does not modify this property on the native event, so they are identical.",paraId:57,tocIndex:15},{value:"e.clientX;\ne.nativeEvent.clientX;\n",paraId:59,tocIndex:15},{value:"Can be interconverted with ",paraId:60,tocIndex:15},{value:"viewportX/Y",paraId:61,tocIndex:15},{value:", ",paraId:60,tocIndex:15},{value:"see",paraId:62,tocIndex:15},{value:".",paraId:60,tocIndex:15},{value:"canvas.viewport2Client({ x: 0, y: 0 }); // Point { x: 100, y: 100 }\ncanvas.client2Viewport({ x: 100, y: 100 }); // Point { x: 0, y: 0 }\n",paraId:63,tocIndex:15},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/screenX",paraId:64,tocIndex:16},{value:"Under ",paraId:65,tocIndex:16},{value:"screen coordinate system",paraId:66,tocIndex:16},{value:", page scrolling is not considered. g does not modify this property on native events, so they are identical.",paraId:65,tocIndex:16},{value:"e.screenX;\ne.nativeEvent.screenX;\n",paraId:67,tocIndex:16},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/pageX",paraId:68,tocIndex:17},{value:"Under ",paraId:69,tocIndex:17},{value:"page coordinate system",paraId:70,tocIndex:17},{value:", consider page scrolling. g does not modify this property on native events, so they are identical.",paraId:69,tocIndex:17},{value:"e.pageX;\ne.nativeEvent.pageX;\n",paraId:71,tocIndex:17},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/MouseEvent/movementX",paraId:72,tocIndex:18},{value:"The value of the mouse movement in the horizontal direction between the current event and the previous ",paraId:73,tocIndex:18},{value:"mousemove",paraId:73,tocIndex:18},{value:" event. In other words, this value is calculated like this: ",paraId:73,tocIndex:18},{value:"currentEvent.movementX = currentEvent.screenX - previousEvent.screenX",paraId:73,tocIndex:18},{value:"Returns the device type of the event with the following return value.",paraId:74,tocIndex:20},{value:"'pointer'",paraId:75,tocIndex:20},{value:" ",paraId:75,tocIndex:20},{value:"PointerEvent",paraId:75,tocIndex:20},{value:"'mouse'",paraId:75,tocIndex:20},{value:" ",paraId:75,tocIndex:20},{value:"MouseEvent",paraId:75,tocIndex:20},{value:"'touch'",paraId:75,tocIndex:20},{value:" ",paraId:75,tocIndex:20},{value:"TouchEvent",paraId:75,tocIndex:20},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerType",paraId:76,tocIndex:20},{value:"Returns a value that uniquely identifies the point in contact with the touch plane. This value remains consistent across all events raised by this finger (or stylus, etc.) until it leaves the touch plane.",paraId:77,tocIndex:21},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerId",paraId:78,tocIndex:21},{value:"If or not it is primary pointer, it means the current event is generated by the primary pointer in multi-touch scenario.",paraId:79,tocIndex:22},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/isPrimary",paraId:80,tocIndex:22},{value:"Identifies which button was clicked for the mouse event. 0 is the left button, 2 is the right button.",paraId:81,tocIndex:23},{value:"https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/button",paraId:82,tocIndex:23},{value:"https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/buttons",paraId:83,tocIndex:24},{value:"The width of the contact area. Returns ",paraId:84,tocIndex:25},{value:"1",paraId:84,tocIndex:25},{value:" if the native event is MouseEvent.",paraId:84,tocIndex:25},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/width",paraId:85,tocIndex:25},{value:"The height of the contact area. Returns ",paraId:86,tocIndex:26},{value:"1",paraId:86,tocIndex:26},{value:" if the native event is MouseEvent.",paraId:86,tocIndex:26},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/height",paraId:87,tocIndex:26},{value:"The angle of the contact with the screen in the Y-Z plane. Returns a fixed value of ",paraId:88,tocIndex:27},{value:"0",paraId:88,tocIndex:27},{value:" if the native event is MouseEvent.",paraId:88,tocIndex:27},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltX",paraId:89,tocIndex:27},{value:"The angle of the contact with the screen in the X-Z plane. Returns a fixed value of ",paraId:90,tocIndex:28},{value:"0",paraId:90,tocIndex:28},{value:" if the native event is MouseEvent.",paraId:90,tocIndex:28},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltY",paraId:91,tocIndex:28},{value:"Returns the amount of pressure corresponding to the finger squeezing the touch plane, from ",paraId:92,tocIndex:29},{value:"0.0",paraId:92,tocIndex:29},{value:" (no pressure) to ",paraId:92,tocIndex:29},{value:"1.0",paraId:92,tocIndex:29},{value:" (maximum pressure) as a floating point number. Returns a fixed value of ",paraId:92,tocIndex:29},{value:"0.5",paraId:92,tocIndex:29},{value:" if the native event is MouseEvent.",paraId:92,tocIndex:29},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pressure",paraId:93,tocIndex:29},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tangentialPressure",paraId:94,tocIndex:30},{value:"The clockwise rotation angle. Returns a fixed value of ",paraId:95,tocIndex:31},{value:"0",paraId:95,tocIndex:31},{value:" if the native event is MouseEvent.",paraId:95,tocIndex:31},{value:"https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/twist",paraId:96,tocIndex:31},{value:"In the mouse wheel event, you can get the scroll amount.",paraId:97,tocIndex:32},{value:"WheelEvent",paraId:98,tocIndex:33},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/WheelEvent",paraId:99,tocIndex:33},{value:"The amount of lateral/longitudinal/Z-axis roll of the roller.",paraId:100,tocIndex:33},{value:"Certain methods on the event object can control the behavior of the event as it propagates, such as preventing bubbling, etc.",paraId:101,tocIndex:34},{value:"Prevents other event listeners listening to the same event from being called, and prevents bubbling.",paraId:102,tocIndex:35},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/stopImmediatePropagation",paraId:103,tocIndex:35},{value:"For example, if multiple click listeners are bound to the graph.",paraId:104,tocIndex:35},{value:"// group -> circle\n\ncircle.on(\n    'click',\n    () => {\n        // Normal execution\n    },\n    false,\n);\n\ncircle.on(\n    'click',\n    (e) => {\n        // Normal execution\n        e.stopImmediatePropagation();\n    },\n    false,\n);\n\ncircle.on(\n    'click',\n    () => {\n        // Listeners registered afterwards will not be executed\n    },\n    false,\n);\n\ngroup.on(\n    'click',\n    () => {\n        // Since upward bubbling is prevented, the same will not be executed\n    },\n    false,\n);\n",paraId:105,tocIndex:35},{value:"Stops further propagation of the current event in the capture and bubble phases.",paraId:106,tocIndex:36},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/stopPropagation",paraId:107,tocIndex:36},{value:"The difference with ",paraId:108,tocIndex:36},{value:"stopImmediatePropagation",paraId:108,tocIndex:36},{value:" is that it does not prevent other event listeners listening to the same event from being called.",paraId:108,tocIndex:36},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/preventDefault",paraId:109,tocIndex:37},{value:"Block the default browser behavior. Calling this method for Passive events is not valid and will throw a warning.",paraId:110,tocIndex:37},{value:"A solution for wheel events can be found at ",paraId:111,tocIndex:37},{value:"Disable default page scrolling behavior in Chrome",paraId:112,tocIndex:37},{value:".",paraId:111,tocIndex:37},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Event/composedPath",paraId:113,tocIndex:38},{value:"Returns the event path, which is an array containing ",paraId:114,tocIndex:38},{value:"EventTarget",paraId:115,tocIndex:38},{value:", similar to ",paraId:114,tocIndex:38},{value:"propagationPath",paraId:114,tocIndex:38},{value:" in the old G version. In this array, ",paraId:114,tocIndex:38},{value:"event.target",paraId:114,tocIndex:38},{value:" is the first element of the array, ",paraId:114,tocIndex:38},{value:"scene graph root",paraId:116,tocIndex:38},{value:", ",paraId:114,tocIndex:38},{value:"Document",paraId:117,tocIndex:38},{value:" and ",paraId:114,tocIndex:38},{value:"Canvas",paraId:118,tocIndex:38},{value:" are the three elements at the end of the array.",paraId:114,tocIndex:38},{value:"Still using a DOM-like ",paraId:119,tocIndex:38},{value:"ul/li",paraId:119,tocIndex:38},{value:" scenario as an example.",paraId:119,tocIndex:38},{value:"Group(ul) - Rect(li) - Rect(li);\n",paraId:120,tocIndex:38},{value:"Listen for events on ",paraId:121,tocIndex:38},{value:"ul",paraId:121,tocIndex:38},{value:" that are triggered when each ",paraId:121,tocIndex:38},{value:"li",paraId:121,tocIndex:38},{value:" is clicked, with the event propagation path being ",paraId:121,tocIndex:38},{value:"[li1, ul, Group, Document, Canvas]",paraId:121,tocIndex:38},{value:".",paraId:121,tocIndex:38},{value:"const ul = new Group();\nconst li1 = new Rect();\nconst li2 = new Rect();\nul.appendChild(li1);\nul.appendChild(li2);\n\nul.addEventListener(\n    'click',\n    (e) => {\n        const path = e.composedPath(); // [li1, ul, Group, Document, Canvas];\n    },\n    false,\n);\n",paraId:122,tocIndex:38},{value:"Example",paraId:123},{value:"Currently event objects are reused in the event system to avoid the creation of a large number of event objects. Reused objects are only used to carry different data, such as coordinate information, native event objects, etc., so the life cycle is limited to the event handler, which can lead to unintended consequences once an attempt is made to cache the entire event object and use it outside the event handler. It is therefore recommended to cache the data carried on the event object rather than the object itself.",paraId:124,tocIndex:39},{value:"While keeping the above performance considerations in mind, we also provide a clone method that creates a new event object when the user really wants to cache it, e.g.",paraId:125,tocIndex:39},{value:"circle.addEventListener('click', (e) => {\n    const newEvent = e.clone();\n});\n",paraId:126,tocIndex:39},{value:"The cloned event object will retain all the properties on the original event object.",paraId:127,tocIndex:39},{value:"Currently, we only support interactive events, namely ",paraId:128,tocIndex:39},{value:"PointerEvent",paraId:129,tocIndex:39},{value:" and ",paraId:128,tocIndex:39},{value:"WheelEvent",paraId:130,tocIndex:39},{value:". Other events such as AnimationEvent and CustomEvent are not supported at the moment.",paraId:128,tocIndex:39}]},24415:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(6387);const n=[{value:"Refer to ",paraId:0,tocIndex:0},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener#the_value_of_this_within_the_handler",paraId:0,tocIndex:0},{value:"Inside the event listener ",paraId:1,tocIndex:0},{value:"this",paraId:1,tocIndex:0},{value:" should point to the same as ",paraId:1,tocIndex:0},{value:"e.currentTarget",paraId:1,tocIndex:0},{value:". However, if the arrow function is used, the context will be lost:",paraId:1,tocIndex:0},{value:"circle.addEventListener('mouseenter', function (e) {\n    console.log(this); // circle\n    console.log(e.currentTarget === this); // true\n});\n\ncircle.addEventListener('mouseleave', () => {\n    console.log(this); // undefined\n});\n",paraId:2,tocIndex:0},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Element/mouseenter_event",paraId:3,tocIndex:1},{value:"mouseenter does not bubble, while mouseover does. Similarly mouseleave does not bubble, while mouseout does.",paraId:4,tocIndex:1},{value:"The event system only responds to events within the Canvas canvas. For example, when mousemove is listened to, moving outside of the canvas to other areas of the page does not trigger the event handler. The ",paraId:5,tocIndex:2},{value:"target",paraId:6,tocIndex:2},{value:" property of the event object returns ",paraId:5,tocIndex:2},{value:"Document",paraId:7,tocIndex:2},{value:" when picking up a blank area of the canvas (without hitting any visible graphics).",paraId:5,tocIndex:2},{value:"canvas.addEventListener('mousemove', (e) => {\n    if (e.target.nodeName === 'document') {\n        // move on empty area\n    }\n});\n",paraId:8,tocIndex:2},{value:"Some built-in events have an order of firing, for example, the click event will be fired after the pointerdown and pointerup events. In this process, it is possible that the target of the pointerdown and pointerup events may not match. For example, if you press the mouse on one graph, move to another graph and then lift the mouse, we will trigger the click event on an ancestor node that is common to both targets (e.g. the root of the scene graph ",paraId:9,tocIndex:3},{value:"document.documentElement",paraId:10,tocIndex:3},{value:").",paraId:9,tocIndex:3},{value:"This can be tried in ",paraId:11,tocIndex:3},{value:"this example",paraId:12,tocIndex:3},{value:".",paraId:11,tocIndex:3},{value:"Sometimes we need to disable the default scrolling behavior of a page, for example when implementing a zoom class. Disabling the default behavior can be done with ",paraId:13,tocIndex:4},{value:"preventDefault",paraId:14,tocIndex:4},{value:", but the following code will not work in Chrome and the page will still scroll.",paraId:13,tocIndex:4},{value:"canvas.addEventListener('wheel', (e) => {\n  e.preventDefault();\n});\n",paraId:15,tocIndex:4},{value:"The reason for this problem is that G added the ",paraId:16,tocIndex:4},{value:"passive: true",paraId:16,tocIndex:4},{value:" configuration item when listening to the wheel event of the canvas event.",paraId:16,tocIndex:4},{value:"// $el is the DOM element, <canvas> in g-canvas/webgl while <svg> in g-svg\n$el.addEventListener('wheel', onPointerWheel, {\n    passive: true,\n    capture: true,\n});\n",paraId:17,tocIndex:4},{value:"For more information about Passive event handlers, please refer to this article from ",paraId:18,tocIndex:4},{value:"https://zhuanlan.zhihu.com/p/24555031",paraId:18,tocIndex:4},{value:". The short answer is that this option improves the browser's scrolling smoothness by telling the browser in advance that \"I won't block your default scrolling behavior\".",paraId:18,tocIndex:4},{value:"Now back to our question, if the user does need to disable the default scrolling behavior, a non-Passive event handler can be manually added to the DOM node of the canvas, ",paraId:19,tocIndex:4},{value:"g-plugin-control",paraId:19,tocIndex:4},{value:" plugin does this. How to get the DOM node of the canvas can be done using ",paraId:19,tocIndex:4},{value:"getDomElement",paraId:20,tocIndex:4},{value:".",paraId:19,tocIndex:4},{value:"canvas\n    .getContextService()\n    .getDomElement() // g-canvas/webgl 为 <canvas>，g-svg 为 <svg>\n    .addEventListener(\n        'wheel',\n        (e) => {\n            e.preventDefault();\n        },\n        { passive: false },\n    );\n",paraId:21,tocIndex:4},{value:"Most of the other native events, especially keyboard and clipboard events that need to be bound to window/document, have no special usage in G. You can directly refer to the related events documentation.",paraId:22,tocIndex:5},{value:"Sometimes we want to disable the browser's default right-click menu, so we can disable the default behavior in the ",paraId:23,tocIndex:6},{value:"contextmenu",paraId:23,tocIndex:6},{value:" event handler with the ",paraId:23,tocIndex:6},{value:"preventDefault()",paraId:23,tocIndex:6},{value:" method to disable the default behavior. To get the DOM node of the canvas you can use ",paraId:23,tocIndex:6},{value:"getDomElement",paraId:24,tocIndex:6},{value:".",paraId:23,tocIndex:6},{value:"canvas\n    .getContextService()\n    .getDomElement() // g-canvas/webgl 为 <canvas>，g-svg 为 <svg>\n    .addEventListener('contextmenu', (e) => {\n        e.preventDefault();\n    });\n",paraId:25,tocIndex:6},{value:"Note that since the default behavior of the rightup / down events is not to pop up the system menu, the following writeup is not valid.",paraId:26,tocIndex:6},{value:"// wrong\ncanvas.addEventListener('rightup', (e) => {\n    e.preventDefault();\n});\n",paraId:27,tocIndex:6},{value:"Use ",paraId:28,tocIndex:7},{value:"KeyboardEvent",paraId:28,tocIndex:7},{value:" directly.",paraId:28,tocIndex:7},{value:"window.addEventListener('keydown', () => {}, false);\n",paraId:29,tocIndex:7},{value:"However, we have not yet implemented A11y-related features, such as using tabs to toggle selection between shapes within the canvas.",paraId:30,tocIndex:7},{value:"Use ",paraId:31,tocIndex:8},{value:"ClipboardEvent",paraId:31,tocIndex:8},{value:" directly.",paraId:31,tocIndex:8},{value:"We don't have a built-in ",paraId:32,tocIndex:9},{value:"focus event",paraId:32,tocIndex:9},{value:" like focus/blur, so the following code is not valid.",paraId:32,tocIndex:9},{value:"circle.addEventListener('focus', () => {});\ncircle.addEventListener('blur', () => {});\n",paraId:33,tocIndex:9},{value:"Focus-related functions can be implemented through events such as click/mouseenter/mouseleave. ",paraId:34,tocIndex:9},{value:"example",paraId:35,tocIndex:9},{value:"Due to the need to be as compatible as possible with PC and mobile events, we do not listen to the native ",paraId:36,tocIndex:10},{value:"dblclick",paraId:36,tocIndex:10},{value:" event, but to the ",paraId:36,tocIndex:10},{value:"pointerdown",paraId:37,tocIndex:10},{value:" property by listening to pointerdown and pointerup, the number of clicks within a certain time interval (200ms) is recorded in the ",paraId:36,tocIndex:10},{value:"detail",paraId:38,tocIndex:10},{value:" attribute, so that it is possible to distinguish between a click and a double click.",paraId:36,tocIndex:10},{value:"canvas.addEventListener('click', (e) => {\n    if (e.detail === 2) {\n        // dbclick\n    } else if (e.detail === 1) {\n        // click\n    }\n});\n",paraId:39,tocIndex:10},{value:"The following way of writing delegates in event names is supported in older versions, in the format ",paraId:40,tocIndex:11},{value:"[delegated-graphic name]:[event-name]",paraId:40,tocIndex:11},{value:", ",paraId:40,tocIndex:11},{value:"example",paraId:41,tocIndex:11},{value:".",paraId:40,tocIndex:11},{value:"// Listen for click events bubbling up on all graphs with the name node\ngraph.on('node:click', () => {});\n\n// or\ngraph.addEventListener('click', (e) => {\n    if (e.target.name === 'node') {\n    }\n});\n",paraId:42,tocIndex:11},{value:"As mentioned before, event binding is not done in the core event system, it should be left to the corresponding rendering environment plugins. For example, ",paraId:43,tocIndex:13},{value:"g-plugin-dom-interaction",paraId:44,tocIndex:13},{value:" which uses DOM API to bind/unbind, other environments such as applets should write their own plugins.",paraId:43,tocIndex:13},{value:"In this class of plugins, we need to complete the binding in ",paraId:45,tocIndex:13},{value:"init",paraId:45,tocIndex:13},{value:" and the unbinding in ",paraId:45,tocIndex:13},{value:"destroy",paraId:45,tocIndex:13},{value:". When implementing the binding, multiple (if any) native events in that rendering environment need to be mapped to G's standard event handlers.",paraId:45,tocIndex:13},{value:"// g-plugin-dom-interaction\n\nconst onPointerDown = (ev: InteractivePointerEvent) => {\n    renderingService.hooks.pointerDown.call(ev);\n};\n\nrenderingService.hooks.init.tap(DOMInteractionPlugin.tag, () => {\n    // using native DOM API\n    $el.addEventListener(\n        'pointerdown', // native event\n        onPointerDown,\n        true,\n    );\n\n    // If mobile support is required\n    if (supportsTouchEvents) {\n        $el.addEventListener('touchstart', onPointerDown, true);\n    }\n    // ...\n});\n\nrenderingService.hooks.destroy.tap(DOMInteractionPlugin.tag, () => {});\n",paraId:46,tocIndex:13},{value:"Different rendering environments use different pickup plugins for determining the EventTarget of native events.",paraId:47,tocIndex:14},{value:"g-plugin-canvas-picker",paraId:48,tocIndex:14},{value:" Use mainly mathematical operations.",paraId:49,tocIndex:14},{value:"g-plugin-svg-picker",paraId:50,tocIndex:14},{value:" Use SVG API.",paraId:49,tocIndex:14},{value:"g-plugin-device-renderer",paraId:51,tocIndex:14},{value:" Use GPU-based methods.",paraId:49,tocIndex:14},{value:"In ",paraId:52,tocIndex:15},{value:"g-plugin-a11y",paraId:53,tocIndex:15},{value:", we listen to keyboard events for navigation.",paraId:52,tocIndex:15}]},99858:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(82702);const n=[{value:'When we want to implement certain "advanced events" in addition to the base events, such as common gestures and drag and drop, we can do so by combining these base events. Thanks to the scene graph\'s compatibility with the DOM API, we can also use the existing ecosystem directly and let these libraries think they are still manipulating the DOM.',paraId:0},{value:"Taking a gesture library like ",paraId:1,tocIndex:0},{value:"Hammer.js",paraId:1,tocIndex:0},{value:" as an example, we can pass ",paraId:1,tocIndex:0},{value:"DisplayObject",paraId:1,tocIndex:0},{value:" in directly since it is fully DOM API compatible. In addition, we need to tell Hammer.js that our input event is a PointerEvent via ",paraId:1,tocIndex:0},{value:"inputClass",paraId:1,tocIndex:0},{value:", so we don't need to take into account interaction events such as TouchEvent and other interactive events, ",paraId:1,tocIndex:0},{value:"example",paraId:2,tocIndex:0},{value:".",paraId:1,tocIndex:0},{value:"import Hammer from 'hammerjs';\n\nconst hammer = new Hammer(circle, {\n    inputClass: Hammer.PointerEventInput, // use PointerEvent\n});\nhammer.on('press', (e) => {\n    console.log(\"You're pressing me!\");\n    console.log(e.target); // circle\n});\n",paraId:3,tocIndex:0},{value:"The Pinch gesture is implemented in this ",paraId:4,tocIndex:1},{value:"example",paraId:5,tocIndex:1},{value:", see ",paraId:4,tocIndex:1},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Pointer_events/Pinch",paraId:4,tocIndex:1},{value:"_zoom_gestures",paraId:4,tocIndex:1},{value:"The core idea is to manage the touch points on the screen by listening to PointerEvents based on the ",paraId:6,tocIndex:1},{value:"pointerId",paraId:7,tocIndex:1},{value:" on the event object without caring about Mouse/TouchEvent.",paraId:6,tocIndex:1},{value:"Interact.js",paraId:8,tocIndex:2},{value:" is an interaction library that includes Drag&Drop, Resize, gestures, and more.",paraId:8,tocIndex:2},{value:"As an example of drag and drop.",paraId:9,tocIndex:2},{value:"import interact from 'interactjs';\n\ninteract(\n    circle, //draggable object\n    {\n        context: canvas.document, // Pass the canvas document in\n    },\n).draggable({\n    startAxis: 'xy', // Allows dragging in both horizontal and vertical directions\n    lockAxis: 'start', // Lock the dragging direction to the initial setting\n    onmove: function (event) {\n        const { dx, dy } = event; // interact.js mounts dx/dy on the event object\n        circle.translateLocal(dx, dy); // Move the object\n    },\n});\n",paraId:10,tocIndex:2},{value:"Example",paraId:11},{value:"If you find interact.js too heavy, you can choose to use the simple drag-and-drop plugin we provide: ",paraId:12,tocIndex:3},{value:"g-plugin-dragndrop",paraId:13,tocIndex:3},{value:".",paraId:12,tocIndex:3},{value:"This plugin is completely based on [PointerEvents](/en/api/event#interaction events) to implement drag and drop functionality. In this ",paraId:14,tocIndex:3},{value:"example",paraId:15,tocIndex:3},{value:", we listen to the drag event of the soccer ball to move it to the right position and the dragover event of the goal to change the transparency when the soccer ball crosses the goal area.",paraId:14,tocIndex:3},{value:"In addition to using the above off-the-shelf libraries, we can also implement simple drag-and-drop effects by combining PointerEvents listeners, which is what ",paraId:16,tocIndex:4},{value:"g-plugin-dragndrop",paraId:17,tocIndex:4},{value:" does internally, as referenced in ",paraId:16,tocIndex:4},{value:"Drag'n'Drop with mouse events",paraId:16,tocIndex:4},{value:".",paraId:16,tocIndex:4},{value:"ball.addEventListener('pointerdown', function (event) {\n    let shiftX = event.clientX - ball.getBoundingClientRect().left;\n    let shiftY = event.clientY - ball.getBoundingClientRect().top;\n\n    moveAt(event.canvasX, event.canvasY);\n\n    function moveAt(canvasX, canvasY) {\n        ball.style.x = canvasX - shiftX + 'px';\n        ball.style.y = canvasY - shiftY + 'px';\n    }\n\n    async function onMouseMove(event) {\n        moveAt(event.canvasX, event.canvasY);\n    }\n\n    canvas.document.addEventListener('pointermove', onMouseMove);\n\n    ball.addEventListener(\n        'pointerup',\n        function () {\n            canvas.document.removeEventListener('pointermove', onMouseMove);\n        },\n        { once: true },\n    );\n});\n",paraId:18,tocIndex:4},{value:"Example",paraId:19}]},90002:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(49457);const n=[{value:"The event system can provide rich interactions and we follow two principles in its design.",paraId:0},{value:"Keeping it as consistent as possible with the DOM API, besides reducing learning costs, is most important to be able to access existing ecologies (e.g. gesture libraries).",paraId:1},{value:"Only standard events are provided. Advanced events such as drag and drop, gestures, etc. are defined by extension.",paraId:1},{value:"Developers familiar with ",paraId:2},{value:"DOM Event Stream",paraId:2},{value:" will be familiar with the following concepts.",paraId:2},{value:"Event objects have a reference to the EventTarget, which is naturally a DOM element in the DOM and ",paraId:3},{value:"EventTarget",paraId:4},{value:" in G.",paraId:3},{value:"The event stream contains capture and bubble phases, and you can intervene in them through certain methods on the event object.",paraId:3},{value:"One or more listeners can be added to an event, and they are triggered sequentially in the order in which they are registered.",paraId:3},{value:"The following diagram shows the three phases of event propagation, the listener is triggered from top to bottom in the capture phase, and bubbles up after reaching the target node. In the listener, you can get the current phase by ",paraId:5},{value:"eventPhase",paraId:6},{value:". The following image is from ",paraId:5},{value:"https://javascript.info/bubbling-and-capturing#capturing",paraId:5},{value:"We currently support the following ",paraId:7},{value:"base events",paraId:8},{value:", which are compatible with DOM event streams as much as possible, so we have included reference links to the corresponding DOM Event APIs in many of the API introductions below.",paraId:7},{value:"For example, we want to add a simple mouse-in/out interaction to this circle, ",paraId:9},{value:"example",paraId:10},{value:".",paraId:9},{value:"circle.addEventListener('mouseenter', () => {\n    circle.attr('fill', '#2FC25B');\n});\ncircle.addEventListener('mouseleave', () => {\n    circle.attr('fill', '#1890FF');\n});\n",paraId:11},{value:"We currently support listening to two types of events: interaction events and scene graph events. The former is the same as most of the mouse and touch screen events provided in the DOM Event API, while the latter is based on the scene graph triggered when nodes are added, deleted, or property transformed.",paraId:12,tocIndex:0},{value:"Browser support for interaction events has gone through the following stages, as detailed in.",paraId:13,tocIndex:1},{value:"https://javascript.info/pointer-events#the-brief-history",paraId:14,tocIndex:1},{value:"The earliest supported is ",paraId:15,tocIndex:1},{value:"MouseEvent",paraId:15,tocIndex:1},{value:".",paraId:15,tocIndex:1},{value:"With the popularity of mobile devices, ",paraId:15,tocIndex:1},{value:"TouchEvent",paraId:15,tocIndex:1},{value:" appeared and also triggered [MouseEvent](",paraId:15,tocIndex:1},{value:"https://developer.mozilla",paraId:15,tocIndex:1},{value:". org/zh-cn/docs/Web/API/MouseEvent)",paraId:15,tocIndex:1},{value:"Then later new devices appeared, such as the pen, so that the various event structures were different and painful to use (e.g. hammer.js for ",paraId:15,tocIndex:1},{value:"compatibility of processing",paraId:15,tocIndex:1},{value:")",paraId:15,tocIndex:1},{value:"A new standard has been proposed, ",paraId:15,tocIndex:1},{value:"PointerEvent",paraId:15,tocIndex:1},{value:" that wants to cover all the above input devices",paraId:15,tocIndex:1},{value:"The image below is from ",paraId:16,tocIndex:1},{value:"https://w3c.github.io/pointerevents/",paraId:16,tocIndex:1},{value:"So now the Level 2 PointerEvent is supported by all major browsers: ",paraId:17,tocIndex:1},{value:"https://www.w3.org/TR/pointerevents2/",paraId:17,tocIndex:1},{value:"The new runtime environments also all use a uniform definition like PointerEvent and no longer have Touch / Mouse / PenEvent, e.g.",paraId:18,tocIndex:1},{value:"Flutter：",paraId:19,tocIndex:1},{value:"https://api.flutter.dev/flutter/gestures/PointerEvent-class.html",paraId:19,tocIndex:1},{value:"Kraken：",paraId:19,tocIndex:1},{value:"https://zhuanlan.zhihu.com/p/371640453",paraId:19,tocIndex:1},{value:"We therefore recommend using PointerEvent directly. multi-finger touch gestures are also fully implementable, e.g.",paraId:20,tocIndex:1},{value:"Pinch: ",paraId:21,tocIndex:1},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Pointer_events/Pinch_zoom_gestures",paraId:21,tocIndex:1},{value:"The following interaction events are currently supported for listening.",paraId:22,tocIndex:1},{value:"PointerEvents:",paraId:23,tocIndex:1},{value:"pointerdown",paraId:24,tocIndex:1},{value:"pointerup",paraId:24,tocIndex:1},{value:"pointerupoutside",paraId:24,tocIndex:1},{value:"pointertap",paraId:24,tocIndex:1},{value:"pointerover",paraId:24,tocIndex:1},{value:"pointerenter",paraId:24,tocIndex:1},{value:"pointerleave",paraId:24,tocIndex:1},{value:"pointerout",paraId:24,tocIndex:1},{value:"MouseEvents:",paraId:25,tocIndex:1},{value:"mousedown",paraId:26,tocIndex:1},{value:" Left mouse button pressed",paraId:26,tocIndex:1},{value:"rightdown",paraId:26,tocIndex:1},{value:" Right mouse button pressed",paraId:26,tocIndex:1},{value:"mouseup",paraId:26,tocIndex:1},{value:" Left mouse button lift",paraId:26,tocIndex:1},{value:"rightup",paraId:26,tocIndex:1},{value:" Right mouse button lift",paraId:26,tocIndex:1},{value:"mouseupoutside",paraId:26,tocIndex:1},{value:" Different graphics when the left mouse button is lifted and when it is pressed",paraId:26,tocIndex:1},{value:"rightupoutside",paraId:26,tocIndex:1},{value:" Different graphics when the right mouse button is raised and pressed",paraId:26,tocIndex:1},{value:"click",paraId:26,tocIndex:1},{value:" Click & double click ",paraId:26,tocIndex:1},{value:"how to distinguish?",paraId:27,tocIndex:1},{value:"mousemove",paraId:26,tocIndex:1},{value:" The mouse continuously moves over the graph",paraId:26,tocIndex:1},{value:"mouseover",paraId:26,tocIndex:1},{value:" Mouse over the graph will bubble",paraId:26,tocIndex:1},{value:"mouseout",paraId:26,tocIndex:1},{value:" The mouse is removed from the graph and will bubble up",paraId:26,tocIndex:1},{value:"mouseenter",paraId:26,tocIndex:1},{value:" The mouse is moved in from the graph and will not bubble",paraId:26,tocIndex:1},{value:"mouseleave",paraId:26,tocIndex:1},{value:" The mouse is removed from this graphic without bubbling",paraId:26,tocIndex:1},{value:"wheel",paraId:26,tocIndex:1},{value:"TouchEvents:",paraId:28,tocIndex:1},{value:"touchstart",paraId:29,tocIndex:1},{value:"touchend",paraId:29,tocIndex:1},{value:"touchendoutside",paraId:29,tocIndex:1},{value:"touchmove",paraId:29,tocIndex:1},{value:"touchcancel",paraId:29,tocIndex:1},{value:"In addition to interaction events, we can also listen for some scene graph-related events, such as listening for the first load of each node on the canvas (",paraId:30,tocIndex:2},{value:"g-svg",paraId:30,tocIndex:2},{value:" will create the DOM associated with the current graph at this point), ",paraId:30,tocIndex:2},{value:"example",paraId:31,tocIndex:2},{value:"import { ElementEvent } from '@antv/g';\n\ncanvas.addEventListener(ElementEvent.MOUNTED, (e) => {\n    e.target;\n});\n",paraId:32,tocIndex:2},{value:"We currently support the following scenegraph related events.",paraId:33,tocIndex:2},{value:"CHILD_INSERTED",paraId:34,tocIndex:2},{value:" Triggered when a child node is added as a parent.",paraId:34,tocIndex:2},{value:"INSERTED",paraId:34,tocIndex:2},{value:" Triggered when added as a child node.",paraId:34,tocIndex:2},{value:"CHILD_REMOVED",paraId:34,tocIndex:2},{value:" Triggered when a parent node is removed as a child node.",paraId:34,tocIndex:2},{value:"REMOVED",paraId:34,tocIndex:2},{value:" Triggered when removed as a child node.",paraId:34,tocIndex:2},{value:"MOUNTED",paraId:34,tocIndex:2},{value:" Triggered when first entering the canvas.",paraId:34,tocIndex:2},{value:"UNMOUNTED",paraId:34,tocIndex:2},{value:" Triggered when removed from the canvas.",paraId:34,tocIndex:2},{value:"ATTR_MODIFIED",paraId:34,tocIndex:2},{value:" Triggered when modifying properties.",paraId:34,tocIndex:2},{value:"DESTROY",paraId:34,tocIndex:2},{value:" Triggered on destruction.",paraId:34,tocIndex:2},{value:"In the following example, the canvas listens for INSERTED REMOVED MOUNTED and UNMOUNTED events. The following events are triggered sequentially when the scene graph is added and removed.",paraId:35,tocIndex:2},{value:"canvas.addEventListener(ElementEvent.INSERTED, (e) => {\n    console.log(ElementEvent.INSERTED, e.target);\n});\n// Omitting other event listeners\n\nparent.appendChild(child); // Building father-son relationships\ncanvas.appendChild(parent); // Add to the scenegraph\ncanvas.removeChild(parent, false); // Remove from the scene graph, but do not destroy\n\n// MOUNTED parent\n// MOUNTED child\n// INSERTED parent\n// REMOVED parent\n// UNMOUNTED child\n// UNMOUNTED parent\n",paraId:36,tocIndex:2},{value:"Adding event listeners to graphics is fully referenced in the DOM Event API: ",paraId:37,tocIndex:4},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/EventTarget/addEventListener",paraId:37,tocIndex:4},{value:"Method signature.",paraId:38,tocIndex:4},{value:"target.addEventListener(type, listener, options);\ntarget.addEventListener(type, listener, useCapture);\n",paraId:39,tocIndex:4},{value:"Parameters:",paraId:40,tocIndex:4},{value:"type 事件名称，",paraId:41,tocIndex:4},{value:"内置标准事件",paraId:42,tocIndex:4},{value:" 或",paraId:41,tocIndex:4},{value:"自定义事件名",paraId:43,tocIndex:4},{value:"listener 事件监听器，支持以下两种写法：\n",paraId:41,tocIndex:4},{value:"处理函数 ",paraId:44,tocIndex:4},{value:"Function",paraId:44,tocIndex:4},{value:"EventListener",paraId:44,tocIndex:4},{value:" 对象，形如 ",paraId:44,tocIndex:4},{value:"{ handleEvent: Function }",paraId:44,tocIndex:4},{value:"options ",paraId:41,tocIndex:4},{value:"可选",paraId:41,tocIndex:4},{value:"capture ",paraId:45,tocIndex:4},{value:"boolean",paraId:45,tocIndex:4},{value:"，表示 listener 会在该类型的事件捕获阶段传播到该 EventTarget 时触发。",paraId:45,tocIndex:4},{value:"once ",paraId:45,tocIndex:4},{value:"boolean",paraId:45,tocIndex:4},{value:"，表示 listener 在添加之后最多只调用一次。如果是 ",paraId:45,tocIndex:4},{value:"true",paraId:45,tocIndex:4},{value:"， listener 会在其被调用之后自动移除。",paraId:45,tocIndex:4},{value:"useCapture ",paraId:41,tocIndex:4},{value:"可选",paraId:41,tocIndex:4},{value:" ",paraId:41,tocIndex:4},{value:"boolean",paraId:41,tocIndex:4},{value:" 默认为 ",paraId:41,tocIndex:4},{value:"false",paraId:41,tocIndex:4},{value:"。如果是 ",paraId:41,tocIndex:4},{value:"true",paraId:41,tocIndex:4},{value:"，向上冒泡的事件不会触发 listener。",paraId:41,tocIndex:4},{value:"button.addEventListener('click', () => {});\nbutton.addEventListener('click', {\n  handleEvent(e): {}\n});\n",paraId:46,tocIndex:4},{value:"Register listeners that are executed only during the capture phase.",paraId:47,tocIndex:4},{value:"circle.addEventListener('click', () => {}, { capture: true });\ncircle.addEventListener('click', () => {}, true);\n",paraId:48,tocIndex:4},{value:"Register listeners that are executed only once.",paraId:49,tocIndex:4},{value:"circle.addEventListener('click', () => {}, { once: true });\n",paraId:50,tocIndex:4},{value:"For compatibility with the old G API, the use of ",paraId:51,tocIndex:4},{value:"on",paraId:51,tocIndex:4},{value:" is also supported, so the following writeup is equivalent.",paraId:51,tocIndex:4},{value:"circle.addEventListener('mouseenter', () => {});\ncircle.on('mouseenter', () => {});\n",paraId:52,tocIndex:4},{value:"You can refer to ",paraId:53,tocIndex:4},{value:"this section",paraId:54,tocIndex:4},{value:" for more information about the pointing of this in the listener.",paraId:53,tocIndex:4},{value:"Removing the event listener.",paraId:55,tocIndex:5},{value:"circle.removeEventListener('click', handler);\n",paraId:56,tocIndex:5},{value:"The use of ",paraId:57,tocIndex:5},{value:"off",paraId:57,tocIndex:5},{value:" is also supported for compatibility with older versions of the G API, so the following writeup is equivalent.",paraId:57,tocIndex:5},{value:"circle.removeEventListener('mouseenter', () => {});\ncircle.off('mouseenter', () => {});\n",paraId:58,tocIndex:5},{value:"Removes all event listeners.",paraId:59,tocIndex:6},{value:"The use of ",paraId:60,tocIndex:6},{value:"off",paraId:60,tocIndex:6},{value:" is also supported for compatibility with older versions of the G API, so the following writeup is equivalent.",paraId:60,tocIndex:6},{value:"circle.removeAllEventListeners();\ncircle.off();\n",paraId:61,tocIndex:6},{value:"Manually triggered events, like interactively triggered events, go through the full event propagation process.",paraId:62,tocIndex:7},{value:"https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/dispatchEvent",paraId:63,tocIndex:7},{value:"⚠️ Before manually firing an event on a drawing, you must ensure that the element has been added to the canvas.",paraId:64,tocIndex:7},{value:"In addition to the built-in standard events, sometimes we also need to trigger some custom events, refer to ",paraId:65,tocIndex:8},{value:"Web CustomEvent",paraId:65,tocIndex:8},{value:", we also support the following writeup, ",paraId:65,tocIndex:8},{value:"examples",paraId:66,tocIndex:8},{value:".",paraId:65,tocIndex:8},{value:"import { CustomEvent } from '@antv/g';\n\nconst event = new CustomEvent('build', { detail: { prop1: 'xx' } });\ncircle.addEventListener('build', (e) => {\n    e.target; // circle\n    e.detail; // { prop1: 'xx' }\n});\n\ncircle.dispatchEvent(event);\n",paraId:67,tocIndex:8},{value:"The parameters of the CustomEvent constructor are as follows.",paraId:68,tocIndex:8},{value:"eventName",paraId:69,tocIndex:8},{value:" required, type is ",paraId:69,tocIndex:8},{value:"string",paraId:69,tocIndex:8},{value:"eventObject",paraId:69,tocIndex:8},{value:" optional, contains the following attributes.\n",paraId:69,tocIndex:8},{value:"detail",paraId:70,tocIndex:8},{value:" contains custom data which type is ",paraId:70,tocIndex:8},{value:"any",paraId:70,tocIndex:8},{value:"For compatibility with older G APIs, the use of ",paraId:71,tocIndex:8},{value:"emit",paraId:71,tocIndex:8},{value:" is also supported.",paraId:71,tocIndex:8},{value:"circle.on('build', (e) => {\n    e.target; // circle\n    e.detail; // { prop1: 'xx' }\n});\ncircle.emit('build', { prop1: 'xx' });\n",paraId:72,tocIndex:8}]},17146:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(34429);const n=[{value:"Create the canvas and use the renderer in the same way as in the previous tutorial on rendering, but make sure it runs in a WebGPU-enabled browser environment. Also, since there is no rendering involved, we choose a canvas size of 1 for the length and width.",paraId:0,tocIndex:0},{value:"import { Canvas, CanvasEvent } from '@antv/g';\nimport { DeviceRenderer, Renderer } from '@antv/g-webgpu';\nimport { Plugin, Kernel } from '@antv/g-plugin-gpgpu';\n\nconst { BufferUsage } = DeviceRenderer;\n\nconst renderer = new Renderer();\nrenderer.registerPlugin(new Plugin());\n\nconst $wrapper = document.getElementById('container');\nconst canvas = new Canvas({\n    container: $wrapper,\n    width: 1,\n    height: 1,\n    renderer,\n});\n",paraId:1,tocIndex:0},{value:"When creating a compute task, we need to get the GPU device (Device) and use it to create the underlying objects such as Buffer. We can get the Device through the renderer either in the [READY](/en/api/canvas#canvas-specific events) event handler of the canvas or after waiting for the ",paraId:2,tocIndex:1},{value:"canvas.ready",paraId:2,tocIndex:1},{value:" Promise to complete, [full Device API](/en/plugins/device -renderer#device).",paraId:2,tocIndex:1},{value:"import { CanvasEvent } from '@antv/g';\n\n// Waiting for the canvas to be ready\ncanvas.addEventListener(CanvasEvent.READY, () => {\n    // Get Device by Renderer\n    const plugin = renderer.getPlugin('device-renderer');\n    const device = plugin.getDevice();\n\n    // Use Device to create GPU-related objects, see the following section\n});\n\n// Or\nawait canvas.ready;\nconst plugin = renderer.getPlugin('device-renderer');\nconst device = plugin.getDevice();\n",paraId:3,tocIndex:1},{value:"Therefore, the ",paraId:4,tocIndex:2},{value:"g-plugin-gpgpu",paraId:5,tocIndex:2},{value:" plugin provides the Kernel to describe the computational task, which, in addition to passing in the device obtained in the previous section, needs to be described by the computeShader using the string.",paraId:4,tocIndex:2},{value:"import { Kernel } from '@antv/g-plugin-gpgpu';\n\nconst kernel = new Kernel(device, {\n    computeShader: `...`,\n});\n",paraId:6,tocIndex:2},{value:"Once the Kernel is defined, we need to pass it the input and get the output when we are done. The allocation of memory is performed on the Host side, creating a Buffer from the Device, where ",paraId:7,tocIndex:3},{value:"usage",paraId:7,tocIndex:3},{value:" needs to correspond to the memory usage defined in the Compute Shader, and writing the initial memory data.",paraId:7,tocIndex:3},{value:"const firstMatrixBuffer = device.createBuffer({\n    usage: BufferUsage.STORAGE,\n    viewOrSize: firstMatrix, // new Float32Array([2 /* rows */, 4 /* columns */, 1, 2, 3, 4, 5, 6, 7, 8])\n});\n",paraId:8,tocIndex:3},{value:"After creating the Buffer, it needs to be bound to the specified location in the Kernel (corresponding to the binding in the Compute Shader).",paraId:9,tocIndex:3},{value:"kernel.setBinding(0, firstMatrixBuffer);\n",paraId:10,tocIndex:3},{value:"The following is a list of common configurations for usage and Buffer in Compute Shader.",paraId:11,tocIndex:3},{value:"var<storage, read>",paraId:12,tocIndex:3},{value:" -> ",paraId:12,tocIndex:3},{value:"BufferUsage.STORAGE",paraId:12,tocIndex:3},{value:"var<storage, read_write>",paraId:12,tocIndex:3},{value:" -> ",paraId:12,tocIndex:3},{value:"BufferUsage.STORAGE | BufferUsage.COPY_SRC",paraId:12,tocIndex:3},{value:"var<uniform>",paraId:12,tocIndex:3},{value:" -> ",paraId:12,tocIndex:3},{value:"BufferUsage.UNIFORM | BufferUsage.COPY_DST | BufferUsage.COPY_SRC",paraId:12,tocIndex:3},{value:"Using ",paraId:13,tocIndex:4},{value:"dispatch",paraId:13,tocIndex:4},{value:" you can allocate the thread grid size and execute the computation pipeline. In the matrix multiplication example, if the size of the thread group is ",paraId:13,tocIndex:4},{value:"1 * 1",paraId:13,tocIndex:4},{value:", the grid size is ",paraId:13,tocIndex:4},{value:"M * N",paraId:13,tocIndex:4},{value:".",paraId:13,tocIndex:4},{value:"const x = Math.ceil(firstMatrix[0] / WORKGROUP_SIZE_X);\nconst y = Math.ceil(secondMatrix[1] / WORKGROUP_SIZE_Y);\nkernel.dispatch(x, y);\n",paraId:14,tocIndex:4},{value:"After the computation is complete, we need to read the data in the result matrix, which is an asynchronous GPU-to-CPU read operation.",paraId:15,tocIndex:4},{value:"const readback = device.createReadback();\nconst result = await readback.readBuffer(resultBuffer); // Float32Array([...])\n",paraId:16,tocIndex:4}]},63220:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(59279);const n=[{value:"The principle of the classic GPGPU implementation using the Graphics Rendering API can be simply summarized as: scientific computation by texturing. For compatibility reasons, we also use this approach in WebGL.",paraId:0},{value:"「GPGPU 编程技术 - 从 GLSL、CUDA 到 OpenCL」",paraId:1},{value:"Normally the final output target of the graphics rendering API is the screen, which displays the rendered result. But in a GPGPU scenario we just want to read the final computation on the CPU side. Therefore the off-screen rendering feature provided by the rendering API is used - rendering to a texture, where the key technique is to use a Framebuffer Object (FBO) as the rendering object.",paraId:2,tocIndex:0},{value:"However, this approach has the obvious limitation that the texture cache is either read-only or write-only for all threads, making it impossible for one thread to read a texture and another to write it. This is essentially due to the hardware design of the GPU. If you want to implement multiple threads reading/writing the same texture at the same time, you need to design complex synchronization mechanisms to avoid read/write conflicts, which inevitably affects the efficiency of parallel thread execution.",paraId:3,tocIndex:0},{value:"Therefore, in a classical GPGPU implementation, we usually prepare two textures, one to hold the input data and one to hold the output data. This is why we are allowed to use only one ",paraId:4,tocIndex:0},{value:"@out",paraId:4,tocIndex:0},{value:" declaration for output variables.",paraId:4,tocIndex:0},{value:"Our data is stored in video memory, using the RGBA texture format, which contains 4 channels per pixel, so using ",paraId:5,tocIndex:0},{value:"vec4[]",paraId:5,tocIndex:0},{value:" in GWebGPU is the most memory-efficient data format. If ",paraId:5,tocIndex:0},{value:"float[]",paraId:5,tocIndex:0},{value:" is used, the three channels of GBA in each pixel are wasted. Of course the decision of the data type is up to the developer and can be decided based on the ease of access in the actual program.",paraId:5,tocIndex:0},{value:"Our computational logic is written in the Fragment Shader, where each pixel is assigned to a thread for shading during the rasterization phase of the rendering pipeline, achieving a parallel effect.",paraId:6,tocIndex:1},{value:"When mapped to the concept of computation in the CPU, textures can be considered as arrays, and the programs executed by the fragment shader are looping statements.",paraId:7,tocIndex:1},{value:"A 3D model consists of many triangular surfaces, each of which can theoretically continue to be subdivided infinitely, but coloring each triangular surface is very performance intensive. A faster approach is mapping, where a 2D bitmap (texture) is applied to the surface of the model, a process known as texture mapping. Instead of defining texture coordinates for each vertex of the model, we only need to define the coordinates of the four corners and leave the rest to the rendering pipeline for interpolation.",paraId:8,tocIndex:2},{value:"Many algorithms need to be run several times in succession, for example, the layout algorithm used in G6 needs to be iterated several times to reach a steady state. The computation result output in the previous iteration needs to be used as input for the next iteration. In practice, we allocate two texture caches and swap the input and output textures after each iteration.",paraId:9,tocIndex:3},{value:"「GPGPU 编程技术 - 从 GLSL、CUDA 到 OpenCL」",paraId:10,tocIndex:4},{value:"🔗",paraId:10,tocIndex:4},{value:"http://www.vizitsolutions.com/portfolio/webgl/gpgpu/",paraId:10,tocIndex:4}]},98099:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(76334);const n=[{value:"GPUs and CPUs are good at performing different types of computational tasks due to different hardware architectures. In particular, in single instruction stream multiple data stream (SIMD) scenarios, GPUs are much faster than CPUs.",paraId:0,tocIndex:0},{value:"The following image is from: ",paraId:1,tocIndex:0},{value:"https://www.techpowerup.com/199624/nvidia-to-launch-geforce-337-50-beta-later-today",paraId:1,tocIndex:0},{value:". Clearly demonstrates the huge advantages of GPUs in both floating point operations per second and data throughput metrics.",paraId:1,tocIndex:0},{value:"The powerful computing power of the GPU is not limited to rendering, ",paraId:2,tocIndex:0},{value:"G",paraId:2,tocIndex:0},{value:"eneral-",paraId:2,tocIndex:0},{value:"p",paraId:2,tocIndex:0},{value:"urpose computing on ",paraId:2,tocIndex:0},{value:"g",paraId:2,tocIndex:0},{value:"raphics ",paraId:2,tocIndex:0},{value:"p",paraId:2,tocIndex:0},{value:"rocessing ",paraId:2,tocIndex:0},{value:"u",paraId:2,tocIndex:0},{value:"nits, that is the introduction of the GPU general-purpose computing concept pushes this capability to a broader computing scenario.",paraId:2,tocIndex:0},{value:"Early Classic Series Books GPU Gems ",paraId:3,tocIndex:0},{value:"Gem2 🔗",paraId:3,tocIndex:0},{value:" ",paraId:3,tocIndex:0},{value:"Gem3 🔗",paraId:3,tocIndex:0},{value:" includes a large number of practices in general-purpose computing, including video decoding, real-time encryption and decryption, image compression, random number generation, simulation, and so on.",paraId:3,tocIndex:0},{value:"Modern GPUs are more likely to design hardware for specific types of computational tasks. For example, NVIDIA's Turing architecture includes the Tensor Core, which specializes in tensor calculations, and the RT Core, which is dedicated to ray-tracing calculations.",paraId:4,tocIndex:0},{value:"To lower the barrier to GPU-oriented programming for developers, NVIDIA has proposed the CUDA（",paraId:5,tocIndex:0},{value:"C",paraId:5,tocIndex:0},{value:"ompute ",paraId:5,tocIndex:0},{value:"U",paraId:5,tocIndex:0},{value:"nified ",paraId:5,tocIndex:0},{value:"D",paraId:5,tocIndex:0},{value:"evice ",paraId:5,tocIndex:0},{value:"A",paraId:5,tocIndex:0},{value:" rchitecture）. Developers can write their own code for computational tasks in C, Java, Python, and other languages.",paraId:5,tocIndex:0},{value:"And as front-end developers, we are facing more and more data-intensive computing tasks suitable for parallelism, can we use GPGPU technology on the web side?",paraId:6,tocIndex:0},{value:"In fact, there are already many excellent GPGPU practices on the Web side, such as:",paraId:7,tocIndex:1},{value:"tensorflow.js",paraId:8,tocIndex:1},{value:"GPU.js",paraId:8,tocIndex:1},{value:"Stardust.js",paraId:8,tocIndex:1},{value:"From an implementation point of view, the above solutions all use the WebGL graphics API to emulate Compute Shaders that are not supported, specifically through programmable Vertex/Fragment Shaders in the regular rendering pipeline, if you are interested in our implementation, you can read [Principles of Classic GPGPU Implementation](/ api/implements). The following diagram from ",paraId:9,tocIndex:2},{value:"http://www.vizitsolutions.com/portfolio/webgl/gpgpu/",paraId:9,tocIndex:2},{value:" briefly shows the basic implementation.",paraId:9,tocIndex:2},{value:"This is of course for compatibility reasons, as the thread groups, shared memory, synchronization and other mechanisms that should be present in the Compute Shader cannot be emulated by the Vertex/Fragment Shader. In addition, the compute pipeline is also much more compact compared to the regular rendering pipeline. In the figure below, the programmable rendering and compute pipelines for Vulkan are shown on the left and right, respectively, from: ",paraId:10,tocIndex:2},{value:"https://vulkan.lunarg.com/doc/view/1.0.26.0/windows/vkspec.chunked/ch09.html",paraId:10,tocIndex:2},{value:":",paraId:10,tocIndex:2},{value:"Of course WebGL 2 also considered native support for Compute Shader, which is after all a core feature in OpenGL ES 3.1. Even the ",paraId:11,tocIndex:2},{value:"WebGL 2.0 Compute draft",paraId:11,tocIndex:2},{value:" and [DEMO](",paraId:11,tocIndex:2},{value:"https://github.com/9ballsyndrome/",paraId:11,tocIndex:2},{value:" WebGL_Compute_shader) have also been proposed for a long time. However, due to Apple's lack of support, WebGL 2.0 Compute currently only runs under Windows Chrome/Edge. Similarly, the WebGL 2.0 Transform Feedback has compatibility issues as an alternative.",paraId:11,tocIndex:2},{value:"The image below is from: ",paraId:12,tocIndex:2},{value:"https://slideplayer.com/slide/16710114/",paraId:12,tocIndex:2},{value:", shows the correspondence between WebGL and OpenGL.",paraId:12,tocIndex:2},{value:"WebGPU, the successor to WebGL, is currently ",paraId:13,tocIndex:3},{value:"supported",paraId:13,tocIndex:3},{value:" by major browser vendors and can be experienced in the following browsers (experimental feature webgpu flag needs to be enabled).",paraId:13,tocIndex:3},{value:"Chrome Canary",paraId:14,tocIndex:3},{value:"Edge Canary",paraId:14,tocIndex:3},{value:"Safari Technology Preview",paraId:14,tocIndex:3},{value:"Chrome 94 is now supported by Origin trial: ",paraId:15,tocIndex:3},{value:"https://web.dev/gpu/",paraId:15,tocIndex:3},{value:"The image below is from: ",paraId:16,tocIndex:3},{value:"https://www.chromestatus.com/feature/6213121689518080",paraId:16,tocIndex:3},{value:". As a modern graphics API, one of the features of WebGPU is support for Compute Shader, which is rightfully our first choice for the future.",paraId:16,tocIndex:3},{value:"In addition to computation, the browser implementation of the WebGPU API encapsulates modern graphics APIs like Vulkan, DX12, and Metal instead of OpenGL, further reducing driver overhead and providing better support for multi-threading. For users, the problems that existed in the WebGL API in the past will also be solved. The shader language for WebGPU has been determined to be ",paraId:17,tocIndex:3},{value:"WGSL",paraId:17,tocIndex:3},{value:".",paraId:17,tocIndex:3},{value:"Although WebGPU is still in the development stage, there are many good practices, such as:",paraId:18,tocIndex:3},{value:"tensorflow.js is trying ",paraId:19,tocIndex:3},{value:"WebGPU-based backend implementation",paraId:19,tocIndex:3},{value:"。",paraId:19,tocIndex:3},{value:"Babylon.js is trying to implement ",paraId:19,tocIndex:3},{value:"a WebGPU-based rendering engine",paraId:19,tocIndex:3},{value:"。",paraId:19,tocIndex:3},{value:"When we focus from the field of general-purpose computing to visualization scenarios, we find that many parallelizable computational tasks exist that are suitable for GPU execution, such as:",paraId:20,tocIndex:4},{value:"The ",paraId:21,tocIndex:4},{value:"Fruchterman layout algorithm",paraId:21,tocIndex:4},{value:" in G6 is a typical example, where the position of each node in each iteration needs to be calculated based on the positions of other nodes, and it needs to go through many iterations to reach a steady state. The computation of each node position in each iteration is based on the positions of other nodes, and it takes many iterations to reach a stable state, so it is computationally intensive.",paraId:21,tocIndex:4},{value:"Instanced-based Vis. Stardust.js is exactly for this scenario, such as the sanddance effect.",paraId:21,tocIndex:4},{value:"Data transformation. In charting scenarios where large amounts of data require high interaction, many parallelizable algorithms such as reduce & scan can be executed in the GPU. P4 & P5（IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 26, NO. 3, MARCH 2020）",paraId:21,tocIndex:4}]},55253:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(32585);const n=[{value:"Referring to the CUDA programming model, understanding it helps us to write high-performance parallel code.",paraId:0},{value:"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model",paraId:1},{value:"In CUDA the Kernel is parallelized on the GPU side (Device), while the CPU side (Host) is responsible for serial tasks such as writing and reading data, specifying the size of the thread group, and calling the Kernel.",paraId:2,tocIndex:0},{value:"The two need to be executed in conjunction, for example, by allocating memory in the Host and copying it to the Device.",paraId:3,tocIndex:0},{value:"//allocate memory\ncudaMalloc((void**) &d_in_V, V.size() *sizeof(int));\n\n//copy to device memory\ncudaMemcpy(d_in_V, V.data(), V.size() *sizeof(int), cudaMemcpyHostToDevice);\n",paraId:4,tocIndex:0},{value:"In the following CUDA program (matrix addition), for example, the kernel function is parallelized between each thread of the GPU, and each thread receives part of the data according to its number to perform the operation and writes the result back to the global array. Each thread in the addition is responsible for the computation of elements in the same position between two matrices.",paraId:5,tocIndex:0},{value:"// Kernel\n__global__ void MatAdd(\n  float A[N][N], // Input array 1\n  float B[N][N], // Input array 2\n  float C[N][N]) // Result array\n{\n    int i = blockIdx.x * blockDim.x + threadIdx.x; // These are built-in variables related to thread groups and are only available in Kernel functions\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i < N && j < N)\n        C[i][j] = A[i][j] + B[i][j]; // Perform addition and write back\n}\n\nint main()\n{\n    // ... Omit the buffer creation process\n    // Kernel invocation\n    dim3 threadsPerBlock(16, 16); // Specify the thread group size\n    dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);\n    MatAdd<<<numBlocks, threadsPerBlock>>>(A, B, C); // Calling Kernel Functions\n}\n",paraId:6,tocIndex:0},{value:'"single source" is undoubtedly one of the highlights of CUDA, i.e. Host and Device code are written in C++, which definitely reduces the learning cost for users. This is definitely not possible with Compute Shader, which uses the rendering API. Device code must be written in the Shader language, which makes synchronization difficult due to RPC-like calls, and the Shader language has a lot of limitations (no recursion, restricted parameter types).',paraId:7,tocIndex:1},{value:"The following figure from this ",paraId:8,tocIndex:1},{value:"PPT",paraId:8,tocIndex:1},{value:" compares differences between CUDA and Compute Shader.",paraId:8,tocIndex:1},{value:"CUDA C++ allows developers to write kernel functions in C++ and compile them into GPU-executable code using nvcc. If we want to do the same thing on the web side, the JS language doesn't scale well, in other words Device and Host code are hard to write together.",paraId:9,tocIndex:1},{value:"A simple approach is to write the Device code in a string, taking advantage of the computational pipeline provided by the WebGPU API. The next question is which language should the Device code in the string be in?",paraId:10,tocIndex:1},{value:"WGSL. Using WebGPU's Shader language is the most straightforward, but there are some learning costs for front-end developers (but it's actually fine, you only need to learn Compute Shader), plus you lose syntax highlighting when writing code in strings.",paraId:11,tocIndex:1},{value:"TS. This is the idea behind the GWebGPU project, which provides syntax highlighting with the editor plugin.",paraId:11,tocIndex:1},{value:"Although the usage of CUDA and Compute Shader is quite different, it is not difficult to port a CUDA implementation to Compute Shader for the same algorithm, as long as Compute Shader is feature-rich enough.",paraId:12,tocIndex:1},{value:"GPU threads are not quite the same as what we normally understand as threads, these threads execute the same instructions, but just use different data (SIMD). In the kernel function each thread finds the data it is responsible for by its ID.",paraId:13,tocIndex:2},{value:"The image below is from: ",paraId:14,tocIndex:3},{value:"http://on-demand.gputechconf.com/gtc/2010/presentations/S12312-DirectCompute-Pre-Conference-Tutorial.pdf",paraId:14,tocIndex:3},{value:". It only shows the hierarchical relationship between grids and thread groups, and is not limited to DirectCompute.",paraId:14,tocIndex:3},{value:"Assign a 3-dimensional thread grid via ",paraId:15,tocIndex:3},{value:"dispatch(x, y, z)",paraId:15,tocIndex:3},{value:"The grid contains many thread groups (Work Groups, Thread Groups, Thread Blocks, local workgroups are called differently), each of which contains many threads, and the thread groups are also 3-dimensional, generally specified in the Shader by ",paraId:15,tocIndex:3},{value:"numthreads(x, y, z)",paraId:15,tocIndex:3},{value:"Our Shader program will eventually run on each thread. For each thread, you can get the 3-dimensional coordinates of your own thread group, or you can get the 3-dimensional coordinates of the thread group in the whole thread grid, and map it to different data",paraId:15,tocIndex:3},{value:"The number of Blocks and the number of threads in each Block are allocated in CUDA in the following way.",paraId:16,tocIndex:3},{value:"dim3 threadsPerBlock(16, 16); // Specify the thread group size\ndim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);\nMatAdd<<<numBlocks, threadsPerBlock>>>(A, B, C); // Calling Kernel Functions\n",paraId:17,tocIndex:3},{value:"Instead, the following syntax is used in the Compute Shader. ",paraId:18,tocIndex:3},{value:"https://www.w3.org/TR/WGSL/#entry-point-attributes",paraId:18,tocIndex:3},{value:"@compute @workgroup_size(8,4,1)\n",paraId:19,tocIndex:3},{value:"The correspondence between grids, thread groups and threads is also reflected in the hardware implementation of the GPU.",paraId:20,tocIndex:4},{value:"There are many SMs (Streaming Multiprocessor) on the GPU and each SM contains many cores, the following diagram shows the correspondence of CUDA implementations.",paraId:21,tocIndex:4},{value:"The image below is from: ",paraId:22,tocIndex:4},{value:"http://www.adms-conf.org/2019-presentations/ADMS19_nvidia_keynote.pdf",paraId:22,tocIndex:4},{value:"Now that we understand the hierarchy of grids, thread groups and threads, each thread needs to know its own coordinates in the thread group it is in, and the coordinates of the thread group in the entire thread grid when it executes the Shader program. The following figure is from [",paraId:23,tocIndex:5},{value:"https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/sm5-attributes-numthreads?redirectedfrom=MSDN](",paraId:23,tocIndex:5},{value:"https://docs",paraId:23,tocIndex:5},{value:". microsoft.com/en-us/windows/win32/direct3dhlsl/sm5-attributes-numthreads?redirectedfrom=MSDN), shows the logic for calculating these coordinates.",paraId:23,tocIndex:5},{value:"parameter",paraId:24,tocIndex:5},{value:"data type",paraId:24,tocIndex:5},{value:"remarks",paraId:24,tocIndex:5},{value:"numWorkGroups",paraId:24,tocIndex:5},{value:"ivec3",paraId:24,tocIndex:5},{value:"Number of threaded workgroups for dispatch",paraId:24,tocIndex:5},{value:"workGroupSize",paraId:24,tocIndex:5},{value:"ivec3",paraId:24,tocIndex:5},{value:"The number of threads per thread group declared by ",paraId:24,tocIndex:5},{value:"numthreads",paraId:24,tocIndex:5},{value:" within the Shader",paraId:24,tocIndex:5},{value:"workGroupID",paraId:24,tocIndex:5},{value:"ivec3",paraId:24,tocIndex:5},{value:"The index of the current thread workgroup. The range of values is from ",paraId:24,tocIndex:5},{value:"(0, 0, 0)",paraId:24,tocIndex:5},{value:" to ",paraId:24,tocIndex:5},{value:"(numWorkGroups.x - 1, numWorkGroups.y - 1, numWorkGroups.z - 1)",paraId:24,tocIndex:5},{value:"localInvocationID",paraId:24,tocIndex:5},{value:"ivec3",paraId:24,tocIndex:5},{value:"The index of the current thread in its own thread group. The range of values is from ",paraId:24,tocIndex:5},{value:"(0, 0, 0)",paraId:24,tocIndex:5},{value:" to ",paraId:24,tocIndex:5},{value:"(workGroupSize.x - 1, * workGroupSize.y - 1, workGroupSize.z - 1)",paraId:24,tocIndex:5},{value:"globalInvocationID",paraId:24,tocIndex:5},{value:"ivec3",paraId:24,tocIndex:5},{value:"The index of the current thread in the global thread group. It is calculated as ",paraId:24,tocIndex:5},{value:"workGroupID * workGroupSize + localInvocationID",paraId:24,tocIndex:5},{value:"localInvocationIndex",paraId:24,tocIndex:5},{value:"int",paraId:24,tocIndex:5},{value:"The one-dimensional index of the current thread in its own thread group, calculated as ",paraId:24,tocIndex:5},{value:"localInvocationID.z * workGroupSize.x * workGroupSize.y + localInvocationID.y * workGroupSize.x + localInvocationID.x",paraId:24,tocIndex:5},{value:"In some computing tasks, each thread not only needs to process the part of data it is responsible for, but may also need to read and modify the data processed by other threads, which requires shared memory and synchronization.",paraId:25,tocIndex:6},{value:"https://zhuanlan.zhihu.com/p/128996252",paraId:26,tocIndex:6},{value:"When a variable is declared as shared, it will be saved to a specific location and thus visible to all compute shaders in the same local workgroup. If a compute shader requests a write to a shared variable, then information about the changes to this data will eventually be notified to all shaders in the same local workgroup. Access to shared variables is usually much better than access to image or shader storage caches (e.g. main memory). Because shaders treat shared memory as a local quantity and can make copies in the device, accessing shared variables may be faster than using the buffer approach. Therefore, if a shader needs to make a large number of accesses to the same memory, give preference to copying the memory to a shared variable and then manipulating it.",paraId:27,tocIndex:6},{value:"Since shared memory is involved, it is definitely necessary to set up synchronization points.",paraId:28,tocIndex:6},{value:"The execution barrier, which can be triggered by the barrier() function. If a request from a compute shader encounters the barrier, it stops running and waits for all requests from the same local workgroup to also reach the barrier before executing the code that follows.",paraId:29,tocIndex:6},{value:"For example, in our implementation of Reduce summation ",paraId:30,tocIndex:6},{value:"example",paraId:31,tocIndex:6},{value:", the following is used.",paraId:30,tocIndex:6},{value:"shared memory",paraId:32,tocIndex:6},{value:"workgroupBarrier",paraId:32,tocIndex:6},{value:"var<workgroup> shared : array<f32, 128>;\n\nworkgroupBarrier();\n",paraId:33,tocIndex:6}]},1717:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(40135);const n=[{value:"We refer to ",paraId:0},{value:"cuGraph",paraId:0},{value:" and other CUDA implementations to implement common graph analysis algorithms based on the WebGPU capabilities behind ",paraId:0},{value:"g-plugin-gpgpu",paraId:1},{value:" to achieve large-scale node edge data volume.",paraId:0},{value:"This is a significant improvement over the ",paraId:2},{value:"CPU serial version",paraId:2},{value:" currently offered by G6.",paraId:2},{value:"Algorithm name",paraId:3},{value:"Node / Edge",paraId:3},{value:"CPU time consumption",paraId:3},{value:"GPU time consumption",paraId:3},{value:"Speed up",paraId:3},{value:"SSSP",paraId:3},{value:"1k Nodes & 5k Edges",paraId:3},{value:"27687.10 ms",paraId:3},{value:"261.60 ms",paraId:3},{value:"~100x",paraId:3},{value:"PageRank",paraId:3},{value:"1k Nodes & 500k Edges",paraId:3},{value:"13641.50 ms",paraId:3},{value:"130.20 ms",paraId:3},{value:"~100x",paraId:3},{value:"Before using it, you need to confirm the operating environment and data as two preconditions.",paraId:4,tocIndex:0},{value:"WebGPU is currently (2022-3-21) supported in Chrome 94 official version and above, but since we are using the latest WGSL syntax, it is recommended to update your browser to the latest version.",paraId:5,tocIndex:1},{value:"For production use at this time, Origin Trial will need to be enabled to support WebGPU features (no longer required for Chrome 100+).",paraId:6,tocIndex:1},{value:"Get Token",paraId:7,tocIndex:1},{value:"Add the ",paraId:7,tocIndex:1},{value:"<meta>",paraId:7,tocIndex:1},{value:" tag to the page with the Token obtained in the previous step, e.g. via the DOM API.",paraId:7,tocIndex:1},{value:"const tokenElement = document.createElement('meta');\ntokenElement.httpEquiv = 'origin-trial';\ntokenElement.content = 'AkIL...5fQ==';\ndocument.head.appendChild(tokenElement);\n",paraId:8,tocIndex:1},{value:"We use G6's ",paraId:9,tocIndex:2},{value:"graph data format",paraId:9,tocIndex:2},{value:", which is also the first fixed of all the following algorithms parameters.",paraId:9,tocIndex:2},{value:"const data = {\n    // 点集\n    nodes: [\n        {\n            id: 'node1', // String，该节点存在则必须，节点的唯一标识\n            x: 100, // Number，可选，节点位置的 x 值\n            y: 200, // Number，可选，节点位置的 y 值\n        },\n        {\n            id: 'node2', // String，该节点存在则必须，节点的唯一标识\n            x: 300, // Number，可选，节点位置的 x 值\n            y: 200, // Number，可选，节点位置的 y 值\n        },\n    ],\n    // 边集\n    edges: [\n        {\n            source: 'node1', // String，必须，起始点 id\n            target: 'node2', // String，必须，目标点 id\n        },\n    ],\n};\n",paraId:10,tocIndex:2},{value:"If the data format does not meet the above requirements, the algorithm will not execute properly.",paraId:11,tocIndex:2},{value:"We offer the following two ways to use it.",paraId:12,tocIndex:3},{value:"Canvas",paraId:13,tocIndex:3},{value:" without G. You only want to use it to execute the algorithm, no rendering is involved. This is also the easiest way to use it.",paraId:14,tocIndex:3},{value:"There is already a ",paraId:14,tocIndex:3},{value:"Canvas",paraId:15,tocIndex:3},{value:" for G, e.g. it is being used for rendering, and only the algorithm needs to be called at this point.",paraId:14,tocIndex:3},{value:"A WebGPUGraph is created and a series of initialization work such as canvas creation and plugin registration is done internally. Once completed, the algorithm is called directly.",paraId:16,tocIndex:4},{value:"import { WebGPUGraph } from '@antv/webgpu-graph';\nconst graph = new WebGPUGraph();\n\n(async () => {\n    const result = await graph.pageRank(data);\n})();\n",paraId:17,tocIndex:4},{value:"If you are already using G's Canvas for rendering, you can reuse it and do the following.",paraId:18,tocIndex:5},{value:"Register ",paraId:19,tocIndex:5},{value:"g-plugin-gpgpu",paraId:20,tocIndex:5},{value:"Waiting for the canvas to initialize",paraId:19,tocIndex:5},{value:"Get GPU ",paraId:19,tocIndex:5},{value:"Device",paraId:21,tocIndex:5},{value:"The algorithm is called, and the first parameter of the algorithm is the Device obtained in the previous step",paraId:19,tocIndex:5},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-webgl';\nimport { Plugin } from '@antv/g-plugin-gpgpu';\nimport { pageRank } from '@antv/webgpu-graph';\n\nconst webglRenderer = new Renderer();\nwebglRenderer.registerPlugin(new Plugin());\n\nconst canvas = new Canvas({\n    container: 'my-canvas-id',\n    width: 1,\n    height: 1,\n    renderer: webglRenderer,\n});\n\n(async () => {\n    // Wait for the canvas initialization to complete\n    await canvas.ready;\n\n    // Get Device by Renderer\n    const plugin = renderer.getPlugin('device-renderer');\n    const device = plugin.getDevice();\n\n    // Call the algorithm, pass in Device and graph data\n    const result = await pageRank(device, data);\n})();\n",paraId:22,tocIndex:5},{value:"All the following algorithms are called asynchronously.",paraId:23,tocIndex:5},{value:"The list of parameters is as follows.",paraId:24,tocIndex:7},{value:"name",paraId:25,tocIndex:7},{value:"type",paraId:25,tocIndex:7},{value:"isRequired",paraId:25,tocIndex:7},{value:"description",paraId:25,tocIndex:7},{value:"graphData",paraId:25,tocIndex:7},{value:"GraphData",paraId:25,tocIndex:7},{value:"true",paraId:25,tocIndex:7},{value:"epsilon",paraId:25,tocIndex:7},{value:"number",paraId:25,tocIndex:7},{value:"false",paraId:25,tocIndex:7},{value:"The precision value to determine if the PageRank score is stable, default value is ",paraId:25,tocIndex:7},{value:"1e-05",paraId:25,tocIndex:7},{value:".",paraId:25,tocIndex:7},{value:"alpha",paraId:25,tocIndex:7},{value:"number",paraId:25,tocIndex:7},{value:"false",paraId:25,tocIndex:7},{value:"The dumping factor is the probability that a user will continue to access the node pointed to by a node at any given moment, with a default value of ",paraId:25,tocIndex:7},{value:"0.85",paraId:25,tocIndex:7},{value:".",paraId:25,tocIndex:7},{value:"maxIteration",paraId:25,tocIndex:7},{value:"number",paraId:25,tocIndex:7},{value:"false",paraId:25,tocIndex:7},{value:"Number of iterations, default value is ",paraId:25,tocIndex:7},{value:"1000",paraId:25,tocIndex:7},{value:"The return value is an array of results containing the ",paraId:26,tocIndex:7},{value:"id",paraId:26,tocIndex:7},{value:" and ",paraId:26,tocIndex:7},{value:"score",paraId:26,tocIndex:7},{value:" attributes, in the form ",paraId:26,tocIndex:7},{value:"[{ id: 'A', score: 0.38 }, { id: 'B', score: 0.32 }...]",paraId:26,tocIndex:7},{value:".",paraId:26,tocIndex:7},{value:"The array elements have been sorted by ",paraId:27,tocIndex:7},{value:"score",paraId:27,tocIndex:7},{value:" from highest to lowest, so the first element represents the node with the highest importance.",paraId:27,tocIndex:7},{value:"Refer to the following CUDA version implementation.",paraId:28,tocIndex:7},{value:"https://github.com/princeofpython/PageRank-with-CUDA/blob/main/parallel.cu",paraId:29,tocIndex:7},{value:"https://docs.rapids.ai/api/cugraph/stable/api_docs/api/cugraph.dask.link_analysis.pagerank.pagerank.html",paraId:29,tocIndex:7},{value:"It is used in the following way, ",paraId:30,tocIndex:7},{value:"example",paraId:31,tocIndex:7},{value:"：",paraId:30,tocIndex:7},{value:"const result = await graph.pageRank(data);\n// [{id: 'B', score: 0.3902697265148163}, {}...]\n",paraId:32,tocIndex:7},{value:"There is a very significant improvement in larger point-side scenarios.",paraId:33,tocIndex:7},{value:"Algorithm name",paraId:34,tocIndex:7},{value:"Node / Edge",paraId:34,tocIndex:7},{value:"CPU time consumption",paraId:34,tocIndex:7},{value:"GPU time consumption",paraId:34,tocIndex:7},{value:"Speed up",paraId:34,tocIndex:7},{value:"PageRank",paraId:34,tocIndex:7},{value:"1k Nodes & 500k Edges",paraId:34,tocIndex:7},{value:"13641.50 ms",paraId:34,tocIndex:7},{value:"130.20 ms",paraId:34,tocIndex:7},{value:"~100x",paraId:34,tocIndex:7},{value:"Single source shortest path, i.e., the shortest path from one node to all other nodes.",paraId:35,tocIndex:9},{value:"The list of parameters is as follows.",paraId:36,tocIndex:9},{value:"name",paraId:37,tocIndex:9},{value:"type",paraId:37,tocIndex:9},{value:"isRequired",paraId:37,tocIndex:9},{value:"description",paraId:37,tocIndex:9},{value:"graphData",paraId:37,tocIndex:9},{value:"GraphData",paraId:37,tocIndex:9},{value:"true",paraId:37,tocIndex:9},{value:"图数据",paraId:37,tocIndex:9},{value:"source",paraId:37,tocIndex:9},{value:"number",paraId:37,tocIndex:9},{value:"false",paraId:37,tocIndex:9},{value:"判断 PageRank 得分是否稳定的精度值，默认值为 ",paraId:37,tocIndex:9},{value:"1e-05",paraId:37,tocIndex:9},{value:"Refer to the following CUDA version implementations.",paraId:38,tocIndex:9},{value:"https://www.lewuathe.com/illustration-of-distributed-bellman-ford-algorithm.html",paraId:39,tocIndex:9},{value:"https://github.com/sengorajkumar/gpu_graph_algorithms",paraId:39,tocIndex:9},{value:"https://docs.rapids.ai/api/cugraph/stable/api_docs/api/cugraph.traversal.sssp.sssp.html",paraId:39,tocIndex:9},{value:"Accelerating large graph algorithms on the GPU using CUDA",paraId:40,tocIndex:10},{value:"Scalable GPU Graph Traversal",paraId:41,tocIndex:11},{value:"https://github.com/rafalk342/bfs-cuda",paraId:41,tocIndex:11},{value:"https://github.com/kaletap/bfs-cuda-gpu",paraId:41,tocIndex:11},{value:"https://github.com/divyanshu-talwar/Parallel-DFS",paraId:42,tocIndex:12},{value:"A CUDA Implementation of the K-Means Clustering Algorithm",paraId:43,tocIndex:14},{value:'"Yinyang" K-means and K-nn using NVIDIA CUDA',paraId:43,tocIndex:14},{value:"Demystifying Louvain’s Algorithm and Its implementation in GPU",paraId:44,tocIndex:16},{value:"https://docs.rapids.ai/api/cugraph/stable/api_docs/api/cugraph.louvain.html",paraId:44,tocIndex:16},{value:"https://github.com/rapidsai/cugraph/tree/branch-22.08/cpp/src/community",paraId:44,tocIndex:16},{value:"K-Core Decomposition with CUDA",paraId:45,tocIndex:17},{value:"Parallel Graph Component Labelling with GPUs and CUDA",paraId:46,tocIndex:18},{value:"GPU-Accelerated Graph Label Propagation for Real-Time Fraud Detection",paraId:46,tocIndex:18},{value:"https://github.com/jiachengpan/cudaMST",paraId:47,tocIndex:19},{value:"https://github.com/Dibyadarshan/GPU-Based-Fast-Minimum-Spanning-Tree",paraId:47,tocIndex:19},{value:"https://github.com/adamantmc/CudaCosineSimilarity",paraId:48,tocIndex:21},{value:"https://github.com/divyanshu-talwar/Parallel-DFS",paraId:49,tocIndex:24},{value:"https://github.com/hamham240/cudaGraph/blob/main/src/algos/cudaCD.cu",paraId:50,tocIndex:25}]},89676:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(21763);const n=[{value:"Use ",paraId:0},{value:"CanvasRenderingContext2D",paraId:0},{value:" to draw 2D graphics. A ",paraId:0},{value:"<canvas>",paraId:0},{value:" element will be created in the container.",paraId:0},{value:"As with ",paraId:1,tocIndex:0},{value:"@antv/g",paraId:1,tocIndex:0},{value:", there are two ways to use it.",paraId:1,tocIndex:0},{value:"After installing ",paraId:2,tocIndex:1},{value:"@antv/g-canvas",paraId:2,tocIndex:1},{value:" you can get the renderer from it.",paraId:2,tocIndex:1},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\n\nconst canvasRenderer = new Renderer();\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: canvasRenderer,\n});\n",paraId:3,tocIndex:1},{value:'<script\n  src="https://unpkg.com/@antv/g-canvas/dist/index.umd.min.js"\n  type="application/javascript">\n',paraId:4,tocIndex:2},{value:"The renderer can be obtained from the ",paraId:5,tocIndex:2},{value:"G.Canvas2D",paraId:5,tocIndex:2},{value:" namespace under.",paraId:5,tocIndex:2},{value:"const canvasRenderer = new window.G.Canvas2D.Renderer();\n",paraId:6,tocIndex:2},{value:"When creating a renderer, you can pass in some initialization configuration items, such as.",paraId:7,tocIndex:3},{value:"import { Renderer } from '@antv/g-canvas';\nconst renderer = new Renderer({\n    enableDirtyRectangleRendering: true,\n});\n",paraId:8,tocIndex:3},{value:'Indicates if "dirty rectangle" rendering is enabled. Enabled will improve the rendering performance in Canvas2D environment significantly. Enabled by default.',paraId:9,tocIndex:4},{value:'A common interaction is to highlight a shape with the mouse. In this case, only a small part of the scene has changed, so erasing the entire canvas and redrawing it is unnecessary. In analogy to the React diff algorithm that finds the smallest part of the scene that has really changed, "dirty rectangle" rendering reuses the previous frame\'s rendering as much as possible, drawing only the part that has changed, which is especially suitable for the Canvas2D API.',paraId:10,tocIndex:4},{value:"The following diagram illustrates this idea.",paraId:11,tocIndex:4},{value:'When the mouse hovers over the circle, we know the corresponding "dirty rectangle", which is the enclosing box of the circle.',paraId:12,tocIndex:4},{value:"Find other shapes in the scene that intersect with this enclosing box area, here another rectangle is found.",paraId:12,tocIndex:4},{value:"Use ",paraId:12,tocIndex:4},{value:"clearRect",paraId:12,tocIndex:4},{value:' to clear this "dirty rectangle ", instead of clearing the entire canvas',paraId:12,tocIndex:4},{value:"Draws a rectangle and a circle in order of z-index",paraId:12,tocIndex:4},{value:"In the above intersection and region query, we can reuse the optimizations in the culling scheme, such as the acceleration structure. In the implementation we use ",paraId:13,tocIndex:4},{value:"RBush",paraId:13,tocIndex:4},{value:".",paraId:13,tocIndex:4},{value:'Obviously, when the number of dynamically changing objects is too large, this optimization becomes meaningless, as the "dirty rectangle" is almost equal to the whole canvas after some calculations, so it is better to just empty and redraw all objects. So 2D game rendering engines like Pixi.js, for example, are ',paraId:14,tocIndex:4},{value:"not considered built-in",paraId:14,tocIndex:4},{value:".",paraId:14,tocIndex:4},{value:"But it makes sense in relatively static scenarios like visualization, where for example only parts of the chart are updated after triggering a pickup, and the rest remains unchanged.",paraId:15,tocIndex:4},{value:"Used for debug, disabled by default, when enabled the canvas will trigger ",paraId:16,tocIndex:5},{value:"CanvasEvent.DIRTY_RECTANGLE",paraId:16,tocIndex:5},{value:" event and carry dirty rectangle information which can be used for subsequent visualization.",paraId:16,tocIndex:5},{value:"In this ",paraId:17,tocIndex:5},{value:"example",paraId:18,tocIndex:5},{value:", the current dirty rectangle that needs to be cleared is displayed as the mouse passes over the individual circles, and the current frame will only redraw the area.",paraId:17,tocIndex:5},{value:"Note that the coordinates of the dirty rectangle are under the ",paraId:19,tocIndex:5},{value:"Canvas coordinate system",paraId:20,tocIndex:5},{value:", so if you want to draw the floating layer using HTML, you need to use the ",paraId:19,tocIndex:5},{value:"coordinate system conversion method",paraId:21,tocIndex:5},{value:".",paraId:19,tocIndex:5},{value:"// display dirty rectangle\nconst $dirtyRectangle = document.createElement('div');\n$dirtyRectangle.style.cssText = `\nposition: absolute;\npointer-events: none;\nbackground: rgba(255, 0, 0, 0.5);\n`;\n$wrapper.appendChild($dirtyRectangle);\n\ncanvas.addEventListener(CanvasEvent.DIRTY_RECTANGLE, (e) => {\n    const { dirtyRect } = e.detail;\n    const { x, y, width, height } = dirtyRect;\n\n    const dpr = window.devicePixelRatio;\n\n    // convert from canvas coords to viewport\n    $dirtyRectangle.style.left = `${x / dpr}px`;\n    $dirtyRectangle.style.top = `${y / dpr}px`;\n    $dirtyRectangle.style.width = `${width / dpr}px`;\n    $dirtyRectangle.style.height = `${height / dpr}px`;\n});\n",paraId:22,tocIndex:5},{value:"The renderer has the following plug-ins built in.",paraId:23,tocIndex:6},{value:"g-plugin-canvas-renderer",paraId:24,tocIndex:6},{value:" Rendering with ",paraId:25,tocIndex:6},{value:"CanvasRenderingContext2D",paraId:25,tocIndex:6},{value:".",paraId:25,tocIndex:6},{value:"g-plugin-canvas-picker",paraId:26,tocIndex:6},{value:" Picking up graphics based on mathematical methods and ",paraId:25,tocIndex:6},{value:"CanvasRenderingContext2D",paraId:25,tocIndex:6},{value:".",paraId:25,tocIndex:6},{value:"g-plugin-dom-interaction",paraId:27,tocIndex:6},{value:" DOM API-based event binding.",paraId:25,tocIndex:6},{value:"In addition to the built-in plug-ins, the following optional plug-ins are available.",paraId:28,tocIndex:7},{value:"Use the Canvas version of ",paraId:29,tocIndex:8},{value:"rough.js",paraId:29,tocIndex:8},{value:" for hand-drawn style rendering.",paraId:29,tocIndex:8},{value:"We provide ",paraId:30,tocIndex:8},{value:"g-plugin-rough-canvas-renderer",paraId:31,tocIndex:8},{value:" plugin, which will replace ",paraId:30,tocIndex:8},{value:"g-plugin-canvas-renderer",paraId:32,tocIndex:8},{value:" for partial 2D graphics rendering capability after registration.",paraId:30,tocIndex:8},{value:"Example",paraId:33,tocIndex:8},{value:".",paraId:34,tocIndex:8},{value:"This renderer relies on ",paraId:35,tocIndex:9},{value:"CanvasRenderingContext2D",paraId:35,tocIndex:9},{value:" rendering capabilities and is not limited to the browser side, so you can also use ",paraId:35,tocIndex:9},{value:"node-canvas",paraId:35,tocIndex:9},{value:" for server-side rendering.",paraId:35,tocIndex:9},{value:"In our ",paraId:36,tocIndex:9},{value:"integration test",paraId:36,tocIndex:9},{value:", it will be paired with ",paraId:36,tocIndex:9},{value:"node-canvas",paraId:36,tocIndex:9},{value:" on the Node side Automattic/node-canvas) to render the result image and compare it with the baseline image. Other server-side rendering scenarios can also follow the following steps.",paraId:36,tocIndex:9},{value:"Use ",paraId:37,tocIndex:9},{value:"unregisterPlugin",paraId:38,tocIndex:9},{value:" to uninstall the DOM API-related plugins built into ",paraId:37,tocIndex:9},{value:"g-canvas",paraId:39,tocIndex:9},{value:". For example ",paraId:37,tocIndex:9},{value:"g-plugin-dom-interaction",paraId:40,tocIndex:9},{value:" which is responsible for event binding",paraId:37,tocIndex:9},{value:"Use ",paraId:37,tocIndex:9},{value:"node-canvas",paraId:37,tocIndex:9},{value:" to create a class ",paraId:37,tocIndex:9},{value:"Canvas",paraId:37,tocIndex:9},{value:" object to be passed into the canvas via the ",paraId:37,tocIndex:9},{value:"canvas",paraId:41,tocIndex:9},{value:" property",paraId:37,tocIndex:9},{value:"Normal use of ",paraId:37,tocIndex:9},{value:"g-canvas",paraId:42,tocIndex:9},{value:" renderer to create scenes via G's API",paraId:37,tocIndex:9},{value:"Use the methods provided by ",paraId:37,tocIndex:9},{value:"node-canvas",paraId:37,tocIndex:9},{value:" (e.g. [createPNGStream](",paraId:37,tocIndex:9},{value:"https://github.com/Automattic/node-canvas",paraId:37,tocIndex:9},{value:"# canvascreatepngstream)) to output the resulting image",paraId:37,tocIndex:9},{value:"https://github.com/antvis/g/blob/next/integration/",paraId:43,tocIndex:9},{value:"node",paraId:43,tocIndex:9},{value:"tests__/canvas/circle.spec.js",paraId:43,tocIndex:9},{value:"const { createCanvas } = require('canvas');\nconst { Circle, Canvas } = require('@antv/g');\nconst { Renderer } = require('@antv/g-canvas');\n\n// create a node-canvas\nconst nodeCanvas = createCanvas(200, 200);\n\n// create a renderer, unregister plugin relative to DOM\nconst renderer = new Renderer();\nconst domInteractionPlugin = renderer.getPlugin('dom-interaction');\nrenderer.unregisterPlugin(domInteractionPlugin);\n\nconst canvas = new Canvas({\n    width: 200,\n    height: 200,\n    canvas: nodeCanvas, // use node-canvas\n    renderer,\n});\n\nconst circle = new Circle({\n    style: {\n        r: 10,\n        fill: 'red',\n    },\n});\ncanvas.appendChild(circle);\n\n// output image\nconst out = fs.createWriteStream(__dirname + RESULT_IMAGE);\nconst stream = nodeCanvas.createPNGStream();\nstream.pipe(out);\nout.on('finish', () => {});\n",paraId:44,tocIndex:9},{value:"If you want to use ",paraId:45,tocIndex:10},{value:"CanvasRenderingContext2D",paraId:45,tocIndex:10},{value:" to continue drawing after G has drawn, you can get the context at ",paraId:45,tocIndex:10},{value:"CanvasEvent. AFTER_RENDER",paraId:45,tocIndex:10},{value:" to get the context when G has finished drawing, but since it is set to be transformable in the context, it needs to be cleared before drawing, and then you can draw in the Canvas native coordinate system:",paraId:45,tocIndex:10},{value:"// 在 G 绘制完接着画\ncanvas.addEventListener(CanvasEvent.AFTER_RENDER, () => {\n    // 获取原生 Canvas2DContext\n    const context = canvas.getContextService().getContext();\n\n    // 重置 transform\n    context.resetTransform();\n\n    // 绘制\n    context.fillStyle = 'red';\n    context.fillRect(200, 200, 100, 100);\n});\n",paraId:46,tocIndex:10},{value:"DEMO in CodeSandbox",paraId:47,tocIndex:10}]},49906:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(11098);const n=[{value:"Use ",paraId:0},{value:"Skia",paraId:0},{value:" to draw 2D graphics. Load ",paraId:0},{value:"Canvaskit",paraId:0},{value:" in WASM format asynchronously at runtime, and wrap [WebGL2RenderingContext](",paraId:0},{value:"https://developer",paraId:0},{value:" .mozilla.org/en-US/Web/API/WebGL2RenderingContext) into ",paraId:0},{value:"SkSurface",paraId:0},{value:", which in turn is drawn by the ",paraId:0},{value:"<canvas>",paraId:0},{value:" element on the page.",paraId:0},{value:"Skia offers more features than the Canvas2D API, such as text paragraph layout, ",paraId:1},{value:"Lottie animation",paraId:1},{value:", particle effects, and more. In addition to Chrome and Android, some cross-platform solutions such as ",paraId:1},{value:"Flutter",paraId:1},{value:", ",paraId:1},{value:"Weex",paraId:1},{value:" weex) also use it as the underlying rendering engine.",paraId:1},{value:"DEMO in CodeSandbox",paraId:2},{value:"As with ",paraId:3,tocIndex:0},{value:"@antv/g",paraId:3,tocIndex:0},{value:", there are two ways to use it.",paraId:3,tocIndex:0},{value:"After installing ",paraId:4,tocIndex:1},{value:"@antv/g-canvaskit",paraId:4,tocIndex:1},{value:" you can get the renderer from.",paraId:4,tocIndex:1},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-canvaskit';\n\nconst canvaskitRenderer = new Renderer();\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: canvaskitRenderer,\n});\n",paraId:5,tocIndex:1},{value:'<script\n  src="https://unpkg.com/@antv/g-canvaskit/dist/index.umd.min.js"\n  type="application/javascript">\n',paraId:6,tocIndex:2},{value:"The renderer is available from the ",paraId:7,tocIndex:2},{value:"G.Canvaskit",paraId:7,tocIndex:2},{value:" namespace under.",paraId:7,tocIndex:2},{value:"const canvasRenderer = new window.G.Canvaskit.Renderer();\n",paraId:8,tocIndex:2},{value:"The path to the WASM folder for CanvasKit. The default value is ",paraId:9,tocIndex:4},{value:"'https://unpkg.com/canvaskit-wasm@0.34.1/bin/full/'",paraId:9,tocIndex:4},{value:", which means that it is downloaded from a CDN.",paraId:9,tocIndex:4},{value:"In practice, we can copy the WASM to the server resource directory (e.g. with a build tool like webpack) instead of loading it from the CDN. In our case, the file is copied to the root directory (''/''), and the folder path can be specified via the ",paraId:10,tocIndex:4},{value:"wasmDir",paraId:10,tocIndex:4},{value:" configuration item.",paraId:10,tocIndex:4},{value:"const canvaskitRenderer = new CanvaskitRenderer({\n    wasmDir: '/',\n});\n",paraId:11,tocIndex:4},{value:"It is worth noting that CanvasKit provides several versions of the WASM file.",paraId:12,tocIndex:4},{value:"Lite version, about 7.1MB",paraId:13,tocIndex:4},{value:"'https://unpkg.com/canvaskit-wasm@0.34.1/bin/'",paraId:13,tocIndex:4},{value:"Full-featured, about 7.9MB, includes full ",paraId:13,tocIndex:4},{value:"enhancements",paraId:14,tocIndex:4},{value:", this version is recommended ",paraId:13,tocIndex:4},{value:"'https://unpkg.com/canvaskit-wasm@0.34.1/bin/full'",paraId:13,tocIndex:4},{value:"Development version, approx. 9.1MB ",paraId:13,tocIndex:4},{value:"'https://unpkg.com/canvaskit-wasm@0.34.1/bin/profiling'",paraId:13,tocIndex:4},{value:"CanvasKit provides multi-line layout, decoration, omission, etc. in text and especially paragraphs compared to the familiar Canvas 2D API. The only problem is that the font file needs to be loaded at runtime.",paraId:15,tocIndex:5},{value:"For CJK (Chinese, Japanese, and Korean) fonts, if you use fonts that do not support them, the following effect will occur when rendering, as shown below from ",paraId:16,tocIndex:5},{value:"an ISSUE in Flutter",paraId:16,tocIndex:5},{value:" 76248).",paraId:16,tocIndex:5},{value:"Therefore, Android uses ",paraId:17,tocIndex:5},{value:"NotoSansCJK",paraId:17,tocIndex:5},{value:" font by default.",paraId:17,tocIndex:5},{value:'<family lang="zh-Hans">\n    <font weight="400" style="normal" index="2">NotoSansCJK-Regular.ttc</font>\n</family>\n<family lang="zh-Hant zh-Bopo">\n    <font weight="400" style="normal" index="3">NotoSansCJK-Regular.ttc</font>\n</family>\n<family lang=" ja  ja-Latn">\n    <font weight="400" style="normal" index="0">NotoSansCJK-Regular.ttc</font>\n</family>\n<family lang="ko ko-Latn  ">\n    <font weight="400" style="normal" index="1">NotoSansCJK-Regular.ttc</font>\n</family>\n',paraId:18,tocIndex:5},{value:"However, ",paraId:19,tocIndex:5},{value:"the complete NotoSansCJK",paraId:19,tocIndex:5},{value:" is so large that in our actual development, if we only need Simplified Chinese, we can load only a subset of it (about 36MB):.",paraId:19,tocIndex:5},{value:"const canvaskitRenderer = new CanvaskitRenderer({\n    wasmDir: '/',\n    fonts: [\n        {\n            name: 'sans-serif',\n            url: '/NotoSansCJKsc-VF.ttf',\n        },\n    ],\n});\n",paraId:20,tocIndex:5},{value:"The renderer has the following plug-ins built in.",paraId:21,tocIndex:6},{value:"g-plugin-canvaskit-renderer",paraId:22,tocIndex:6},{value:" Rendering with CanvasKit.",paraId:23,tocIndex:6},{value:"g-plugin-canvas-picker",paraId:24,tocIndex:6},{value:" Picking up graphics based on mathematical methods and ",paraId:23,tocIndex:6},{value:"CanvasRenderingContext2D",paraId:23,tocIndex:6},{value:"g-plugin-dom-interaction",paraId:25,tocIndex:6},{value:" DOM API-based event binding",paraId:23,tocIndex:6},{value:"CanvasKit (full version) provides the following enhancements compared to the familiar Canvas 2D API.",paraId:26,tocIndex:7},{value:"Skottie",paraId:27,tocIndex:7},{value:" Lottie Player",paraId:27,tocIndex:7},{value:"Particle effect",paraId:27,tocIndex:7},{value:"Paragraph",paraId:27,tocIndex:7},{value:"The ",paraId:28,tocIndex:8},{value:"Lottie",paraId:28,tocIndex:8},{value:" animation is created with the ",paraId:28,tocIndex:8},{value:"Bodymovin",paraId:28,tocIndex:8},{value:" plugin for After Effects and exported to JSON format. JSON format. CanvasKit provides ",paraId:28,tocIndex:8},{value:"Skottie",paraId:28,tocIndex:8},{value:", a Lottie animation player.",paraId:28,tocIndex:8},{value:"In this ",paraId:29,tocIndex:8},{value:"example",paraId:30,tocIndex:8},{value:" we show how to play a Lego animation.",paraId:29,tocIndex:8},{value:"First create the renderer and get the ",paraId:31,tocIndex:8},{value:"g-plugin-canvaskit-renderer",paraId:32,tocIndex:8},{value:" plugin via ",paraId:31,tocIndex:8},{value:"getPlugin",paraId:33,tocIndex:8},{value:".",paraId:31,tocIndex:8},{value:"import { Renderer } from '@antv/g-canvaskit';\n\nconst canvaskitRenderer = new Renderer({\n    wasmDir: '/',\n});\nconst plugin = canvaskitRenderer.getPlugin('canvaskit-renderer');\n",paraId:34,tocIndex:8},{value:"Then wait for the canvas initialization to complete, load the Lottie animation description file, and call ",paraId:35,tocIndex:8},{value:"playAnimation",paraId:36,tocIndex:8},{value:" to start playing immediately when it's done.",paraId:35,tocIndex:8},{value:"(async () => {\n    const cdn = 'https://storage.googleapis.com/skia-cdn/misc/';\n\n    const [_, jsonstr] = await Promise.all([\n        // wait for initialization of Canvas\n        canvas.ready,\n        // load Lottie description file\n        fetch(cdn + 'lego_loader.json').then((response) => response.text()),\n    ]);\n\n    const animation = plugin.playAnimation(\n        'sk_legos',\n        jsonstr,\n        [-50, 0, 350, 300],\n    );\n})();\n",paraId:37,tocIndex:8},{value:"If you want to remove the animation, you can call.",paraId:38,tocIndex:8},{value:"animation.delete();\n",paraId:39,tocIndex:8},{value:'For example, particle effects such as fireworks, flames, etc. require generating and animating a large number of "particles", which are usually programmed in the GPU through the shader, e.g. interpolation calculations to change the position of each particle should be done in the GPU instead of the CPU.',paraId:40,tocIndex:9},{value:"CanvasKit provides a Skia-based programming language ",paraId:41,tocIndex:9},{value:"SkSL(Skia's shading language)",paraId:41,tocIndex:9},{value:" implementation, which is syntactically very close to GLSL and is used in the shader to control particle generation and animation. and animation in the shader, which is a certain threshold for developers who have not been exposed to shader programming.",paraId:41,tocIndex:9},{value:"In this ",paraId:42,tocIndex:9},{value:"example",paraId:43,tocIndex:9},{value:", we have implemented some particle effects.",paraId:42,tocIndex:9},{value:"First create the renderer and get the ",paraId:44,tocIndex:9},{value:"g-plugin-canvaskit-renderer",paraId:45,tocIndex:9},{value:" plugin via ",paraId:44,tocIndex:9},{value:"getPlugin",paraId:46,tocIndex:9},{value:".",paraId:44,tocIndex:9},{value:"import { Renderer } from '@antv/g-canvaskit';\n\nconst canvaskitRenderer = new Renderer({\n    wasmDir: '/',\n});\nconst plugin = canvaskitRenderer.getPlugin('canvaskit-renderer');\n",paraId:47,tocIndex:9},{value:"Then call the plugin's ",paraId:48,tocIndex:9},{value:"createParticles",paraId:49,tocIndex:9},{value:" to create the particle effect, transform the canvas to adjust the position of the particles in the callback function at each frame, and finally start the particle generation with ",paraId:48,tocIndex:9},{value:"start",paraId:50,tocIndex:9},{value:".",paraId:48,tocIndex:9},{value:"const textParticles = plugin.createParticles(JSON.stringify(text), (canvas) => {\n    canvas.translate(250, 250);\n});\ntextParticles.start(Date.now() / 1000.0, true);\n",paraId:51,tocIndex:9},{value:"Finally, let's look at the key particle effect definitions.",paraId:52,tocIndex:9},{value:"MaxCount",paraId:53,tocIndex:9},{value:" Number of particles",paraId:53,tocIndex:9},{value:"Drawable",paraId:53,tocIndex:9},{value:" The type of particle, usually ",paraId:53,tocIndex:9},{value:"'SkCircleDrawable'",paraId:53,tocIndex:9},{value:", can be modified in size",paraId:53,tocIndex:9},{value:"Code",paraId:53,tocIndex:9},{value:" SkSL code to control the life cycle of the particles, such as how the position and color should change in each frame",paraId:53,tocIndex:9},{value:"Bindings",paraId:53,tocIndex:9},{value:"const text = {\n    MaxCount: 2000,\n    Drawable: {\n        Type: 'SkCircleDrawable',\n        Radius: 1,\n    },\n    Code: [\n        'void effectSpawn(inout Effect effect) {',\n        '  effect.rate = 1000;',\n        '}',\n        '',\n        'void spawn(inout Particle p) {',\n        '  p.lifetime = mix(1, 3, rand(p.seed));',\n        '  float a = radians(mix(250, 290, rand(p.seed)));',\n        '  float s = mix(10, 30, rand(p.seed));',\n        '  p.vel.x = cos(a) * s;',\n        '  p.vel.y = sin(a) * s;',\n        '  p.pos += text(rand(p.seed)).xy;',\n        '}',\n        '',\n        'void update(inout Particle p) {',\n        '  float4 startColor = float4(1, 0.196, 0.078, 1);',\n        '  float4 endColor   = float4(1, 0.784, 0.078, 1);',\n        '  p.color = mix(startColor, endColor, p.age);',\n        '}',\n        '',\n    ],\n    Bindings: [\n        {\n            Type: 'SkTextBinding',\n            Name: 'text',\n            Text: 'AntV',\n            FontSize: 96,\n        },\n    ],\n};\n",paraId:54,tocIndex:9},{value:"Compared to ",paraId:55,tocIndex:10},{value:"fillText",paraId:55,tocIndex:10},{value:" in the Canvas2D API, CanvasKit provides the ability to draw along a specified path text along a specified path.",paraId:55,tocIndex:10},{value:"In this ",paraId:56,tocIndex:10},{value:"example",paraId:57,tocIndex:10},{value:", we can draw text along ",paraId:56,tocIndex:10},{value:"Path",paraId:58,tocIndex:10},{value:".",paraId:56,tocIndex:10},{value:"We can use the ",paraId:59,tocIndex:10},{value:"alongPath",paraId:60,tocIndex:10},{value:" attribute to.",paraId:59,tocIndex:10},{value:"const alongPath = new Path({\n    style: {\n        d: 'M 0,40 C 5.5555555555555545...',\n    },\n});\n\nconst text = new Text({\n    style: {\n        fontFamily: 'sans-serif',\n        fontSize: 22,\n        fill: '#1890FF',\n        text: 'abcdefghijklmn这是测试文字',\n        alongPath,\n    },\n});\n",paraId:61,tocIndex:10},{value:"Emoji cannot be supported by normal fonts.",paraId:62,tocIndex:11},{value:"const emoji = new Text({\n    style: {\n        fontFamily: 'sans-serif',\n        fontSize: 30,\n        fill: 'black',\n        text: 'Emoji 🍕🍔🍟🥝🍱🕶🎩👩‍👩‍👦👩‍👩‍👧‍👧👩‍👩‍👦👩‍👩‍👧‍👧👩‍👩‍👦👩‍👩‍👧‍👧👩‍👩‍👦👩‍👩‍👧‍👧👩‍👩‍👦👩‍👩‍👧‍👧👩‍👩‍👦👩‍👩‍👧‍👧👩‍👩‍👦👩‍👩‍👧‍👧',\n    },\n});\n",paraId:63,tocIndex:11},{value:"For example, ",paraId:64,tocIndex:11},{value:"NotoSansCJKsc-VF",paraId:64,tocIndex:11},{value:" will show the following effect.",paraId:64,tocIndex:11},{value:"In this ",paraId:65,tocIndex:11},{value:"example",paraId:66,tocIndex:11},{value:", we load fonts that support Emoji such as ",paraId:65,tocIndex:11},{value:"NotoColorEmoji",paraId:65,tocIndex:11},{value:", which is also used in Android and Chrome use.",paraId:65,tocIndex:11},{value:"const canvaskitRenderer = new CanvaskitRenderer({\n    wasmDir: '/',\n    fonts: [\n        {\n            name: 'Roboto',\n            url: '/NotoSansCJKsc-VF.ttf',\n        },\n        {\n            name: 'Noto Color Emoji',\n            url: '/NotoColorEmoji.ttf',\n        },\n    ],\n});\n",paraId:67,tocIndex:11},{value:"At this point it can be displayed normally, specifying two fonts in ",paraId:68,tocIndex:11},{value:"fontFamily",paraId:68,tocIndex:11},{value:".",paraId:68,tocIndex:11},{value:"const emoji = new Text({\n    style: {\n        fontFamily: 'Roboto, Noto Color Emoji',\n    },\n});\n",paraId:69,tocIndex:11},{value:"CanvasKit provides enhanced ",paraId:70,tocIndex:12},{value:"paragraph drawing capabilities",paraId:70,tocIndex:12},{value:".",paraId:70,tocIndex:12},{value:"The ",paraId:71,tocIndex:13},{value:"text-decoration",paraId:71,tocIndex:13},{value:" property can be used in CSS to set the appearance of the text's modifier lines.",paraId:71,tocIndex:13},{value:"In this ",paraId:72,tocIndex:13},{value:"example",paraId:73,tocIndex:13},{value:", we use underscores.",paraId:72,tocIndex:13},{value:"const decoratedText = new Text({\n    style: {\n        fontFamily: 'sans-serif',\n        fontSize: 22,\n        fill: '#1890FF',\n        text: 'abcdefghijklmnopqrstuvwxyz这是测试文本',\n        wordWrap: true,\n        wordWrapWidth: 100,\n        decorationLine: 'underline',\n        decorationColor: 'red',\n        decorationStyle: 'wavy',\n        decorationThickness: 1.5,\n    },\n});\n",paraId:74,tocIndex:13},{value:"The following attributes are supported.",paraId:75,tocIndex:13},{value:"decorationLine ",paraId:76,tocIndex:13},{value:"text-decoration-line",paraId:76,tocIndex:13},{value:" support: ",paraId:76,tocIndex:13},{value:"'none'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'underline'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'overline'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'line-through'",paraId:76,tocIndex:13},{value:"decorationColor ",paraId:76,tocIndex:13},{value:"text-decoration-color",paraId:76,tocIndex:13},{value:"decorationThickness ",paraId:76,tocIndex:13},{value:"text-decoration-thickness",paraId:76,tocIndex:13},{value:"decorationStyle ",paraId:76,tocIndex:13},{value:"text-decoration-style",paraId:76,tocIndex:13},{value:" support: ",paraId:76,tocIndex:13},{value:"'solid'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'double'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'dotted'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'dashed'",paraId:76,tocIndex:13},{value:" ",paraId:76,tocIndex:13},{value:"'wavy'",paraId:76,tocIndex:13},{value:"In this ",paraId:77,tocIndex:14},{value:"example",paraId:78,tocIndex:14},{value:", using ",paraId:77,tocIndex:14},{value:"maxLines",paraId:77,tocIndex:14},{value:" and ",paraId:77,tocIndex:14},{value:"ellipsis",paraId:77,tocIndex:14},{value:" allows you to truncate and add ellipses after exceeding.",paraId:77,tocIndex:14},{value:"const text = new Text({\n    style: {\n        fontFamily: 'Roboto',\n        fontSize: 22,\n        fill: '#1890FF',\n        text: 'abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz',\n        wordWrap: true,\n        wordWrapWidth: 100,\n        maxLines: 3,\n        ellipsis: '...',\n    },\n});\n",paraId:79,tocIndex:14},{value:"Note that using certain fonts (e.g. Noto) can have the following strange effect.",paraId:80,tocIndex:14},{value:'The reason is that Skia will add a blank character after the ellipsis, and the missing character in some font files will show "tofu", the solution is as follows.',paraId:81,tocIndex:14},{value:"https://github.com/flutter/flutter/issues/76473",paraId:82,tocIndex:14},{value:"https://github.com/flutter/flutter/issues/90135#issuecomment-984916656",paraId:82,tocIndex:14},{value:"Using ",paraId:83,tocIndex:15},{value:"direction",paraId:83,tocIndex:15},{value:" you can specify the text direction from left to right or right to left, supporting ",paraId:83,tocIndex:15},{value:"'ltr'",paraId:83,tocIndex:15},{value:" and ",paraId:83,tocIndex:15},{value:"'rtl'",paraId:83,tocIndex:15},{value:", the default is ",paraId:83,tocIndex:15},{value:"'ltr'",paraId:83,tocIndex:15},{value:". The following figure shows the effect of ",paraId:83,tocIndex:15},{value:"'rtl'",paraId:83,tocIndex:15},{value:".",paraId:83,tocIndex:15},{value:"The foreground and background colors of text can be specified using ",paraId:84,tocIndex:16},{value:"foregroundColor",paraId:84,tocIndex:16},{value:" and ",paraId:84,tocIndex:16},{value:"backgroundColor",paraId:84,tocIndex:16},{value:".",paraId:84,tocIndex:16},{value:"Multiple shadows can be added to text in CSS using the ",paraId:85,tocIndex:17},{value:"text-shadow",paraId:85,tocIndex:17},{value:" property.",paraId:85,tocIndex:17},{value:"We support specifying a set of shadows via the ",paraId:86,tocIndex:17},{value:"shadows",paraId:86,tocIndex:17},{value:" property, where each shadow supports the following configuration.",paraId:86,tocIndex:17},{value:"color",paraId:87,tocIndex:17},{value:"blurRadius",paraId:87,tocIndex:17},{value:" The default is 0. The larger the value, the larger the blur radius and the lighter the shadows.",paraId:87,tocIndex:17},{value:"offset",paraId:87,tocIndex:17},{value:" Specify the offset of the shadow relative to the text.",paraId:87,tocIndex:17},{value:"In this ",paraId:88,tocIndex:17},{value:"example",paraId:89,tocIndex:17},{value:", we specify two shadows.",paraId:88,tocIndex:17},{value:"const shadowedText = new Text({\n    style: {\n        shadows: [\n            {\n                color: 'black',\n                blurRadius: 15,\n            },\n            {\n                color: 'red',\n                blurRadius: 5,\n                offset: [10, 10],\n            },\n        ],\n    },\n});\n",paraId:90,tocIndex:17},{value:'Strut (meaning "pillar") sets the minimum line height relative to the baseline. Similar to the ',paraId:91,tocIndex:18},{value:"line-height",paraId:91,tocIndex:18},{value:" property in CSS.",paraId:91,tocIndex:18},{value:"StrutStyle can be configured in SkParagraph, and a document with the same name is available in Flutter: ",paraId:92,tocIndex:18},{value:"https://api.flutter.dev/flutter/painting/StrutStyle-class.html",paraId:92,tocIndex:18},{value:"We will pass on the following attributes.",paraId:93,tocIndex:18},{value:"strutEnabled",paraId:94,tocIndex:18},{value:"fontFamilies which can be consistent with TextStyle",paraId:94,tocIndex:18},{value:"fontSize",paraId:94,tocIndex:18},{value:"heightMultiplier",paraId:94,tocIndex:18},{value:"leading",paraId:94,tocIndex:18},{value:"halfLeading",paraId:94,tocIndex:18},{value:"forceStrutHeight",paraId:94,tocIndex:18},{value:"In this ",paraId:95,tocIndex:18},{value:"example",paraId:96,tocIndex:18},{value:" we use this to control line height and line spacing.",paraId:95,tocIndex:18},{value:"decoratedText.style.strutStyle = {\n    strutEnabled: false,\n    fontFamilies: ['sans-serif'],\n    fontSize: 22,\n    heightMultiplier: 1,\n    leading: 0,\n    halfLeading: false,\n    forceStrutHeight: false,\n};\n",paraId:97,tocIndex:18},{value:"The ",paraId:98,tocIndex:19},{value:"font-feature-settings",paraId:98,tocIndex:19},{value:" property in CSS can be consulted to control the advanced printing features in OpenType fonts.",paraId:98,tocIndex:19},{value:"We provide control of the ",paraId:99,tocIndex:19},{value:"fontFeatures",paraId:99,tocIndex:19},{value:" property, which accepts an array of features. In this ",paraId:99,tocIndex:19},{value:"example",paraId:100,tocIndex:19},{value:", we use the Roboto font and turn on the small-cap feature (note the initial D).",paraId:99,tocIndex:19},{value:"const fontFeaturesText = new Text({\n    style: {\n        fontFamily: 'Roboto',\n        fontSize: 22,\n        fill: '#1890FF',\n        text: 'Difficult waffles 0O 3.14',\n        fontFeatures: [\n            {\n                name: 'smcp',\n                value: 1,\n            },\n            {\n                name: 'zero',\n                value: 1,\n            },\n        ],\n    },\n});\n",paraId:101,tocIndex:19},{value:"Skia itself does not include Harfbuzz.",paraId:102,tocIndex:20},{value:"https://skia.org/user/tips/",paraId:103,tocIndex:20},{value:"But CanvasKit packages it in by default.",paraId:104,tocIndex:20},{value:"https://skia.googlesource.com/skia/+/main/modules/canvaskit/CHANGELOG.md#0_4_0_2019_02_25",paraId:105,tocIndex:20},{value:"https://skia.googlesource.com/skia.git/+/4bd08c52c07d1f2ae313a54b45e5937b80fe2fa1",paraId:106,tocIndex:20},{value:"Text shaping with ShapedText object and SkCanvas.drawText. At compile time, one can choose between using Harfbuzz/ICU (default) or a primitive one (“primitive_shaper”) which just does line breaking. Using Harfbuzz/ICU substantially increases code size (4.3 MB to 6.4 MB).",paraId:107,tocIndex:20},{value:"CanvasKit draws via ",paraId:108,tocIndex:21},{value:"WebGL2RenderingContext",paraId:108,tocIndex:21},{value:" and does a full redraw at each frame.",paraId:108,tocIndex:21}]},54072:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(11720);const n=[{value:"In ",paraId:0},{value:"Renderer Introduction",paraId:1},{value:", we learned that a renderer consists of a rendering context and a set of plugins that can dynamically extend the capabilities of the renderer at runtime.",paraId:0},{value:"When the existing renderer does not satisfy the current rendering context, customization can be accomplished by following these steps.",paraId:2},{value:"Inherit from ",paraId:3},{value:"AbstractRenderer",paraId:3},{value:" to implement a ",paraId:3},{value:"Renderer",paraId:3},{value:", which can be registered by selecting an existing plug-in",paraId:3},{value:"Implement a custom context registration plugin",paraId:3},{value:"Customize the rendering environment context service",paraId:3},{value:"Here we will take ",paraId:4},{value:"g-canvas",paraId:5},{value:" as an example to show how to complete the above steps.",paraId:4},{value:"After inheriting ",paraId:6,tocIndex:0},{value:"AbstractRenderer",paraId:6,tocIndex:0},{value:", you can select a set of existing plugins in the constructor and register them using ",paraId:6,tocIndex:0},{value:"registerPlugin()",paraId:7,tocIndex:0},{value:", for example using the Canvas2D API g-plugin-canvas-path-generator](/en/plugins/canvas-path-generator) for path definition, ",paraId:6,tocIndex:0},{value:"g-plugin-canvas-picker",paraId:8,tocIndex:0},{value:" for pickup using Canvas2D API, [g-plugin-canvas-picker](/ plugins/canvas-picker).",paraId:6,tocIndex:0},{value:"https://github.com/antvis/G/blob/next/packages/g-svg/src/index.ts",paraId:9,tocIndex:0},{value:"import type { RendererConfig } from '@antv/g';\nimport { AbstractRenderer } from '@antv/g';\nimport * as CanvasPathGenerator from '@antv/g-plugin-canvas-path-generator';\nimport * as CanvasPicker from '@antv/g-plugin-canvas-picker';\nimport * as CanvasRenderer from '@antv/g-plugin-canvas-renderer';\nimport * as DomInteraction from '@antv/g-plugin-dom-interaction';\nimport * as HTMLRenderer from '@antv/g-plugin-html-renderer';\nimport * as ImageLoader from '@antv/g-plugin-image-loader';\nimport { ContextRegisterPlugin } from './ContextRegisterPlugin';\n\nexport class Renderer extends AbstractRenderer {\n  constructor(config?: Partial<RendererConfig>) {\n    super(config);\n\n    // register Canvas2DContext\n    this.registerPlugin(new ContextRegisterPlugin());\n\n    // register other built-in plugins\n    this.registerPlugin(new ImageLoader.Plugin());\n    this.registerPlugin(new CanvasPathGenerator.Plugin());\n    this.registerPlugin(new CanvasRenderer.Plugin());\n    this.registerPlugin(new DomInteraction.Plugin());\n    this.registerPlugin(new CanvasPicker.Plugin());\n    this.registerPlugin(new HTMLRenderer.Plugin());\n  }\n}\n",paraId:10,tocIndex:0},{value:"In addition to these ready-made built-in plugins, we need to develop an additional one.",paraId:11,tocIndex:0},{value:"You can refer to ",paraId:12,tocIndex:1},{value:"plugin basic structure",paraId:13,tocIndex:1},{value:" on how to implement a plugin that does only one thing, and that is to register the rendering context service.",paraId:12,tocIndex:1},{value:"import { AbstractRendererPlugin, Module } from '@antv/g';\nimport { Canvas2DContextService } from './Canvas2DContextService';\n\nconst containerModule = Module((register) => {\n  /**\n   * implements ContextService\n   */\n  register(Canvas2DContextService);\n});\n\nexport class ContextRegisterPlugin extends AbstractRendererPlugin {\n  name = 'canvas-context-register';\n  init(): void {\n    this.container.load(containerModule, true);\n  }\n  destroy(): void {\n    this.container.unload(containerModule);\n  }\n}\n",paraId:14,tocIndex:1},{value:"The rendering context service masks the details of the underlying rendering API upwards so that Canvas2D, SVG, or WebGL are not perceived when using the service.",paraId:15,tocIndex:1},{value:"A rendering context service needs to be registered with the ",paraId:16,tocIndex:2},{value:"ContextService",paraId:16,tocIndex:2},{value:" token and implement the ",paraId:16,tocIndex:2},{value:"ContextService",paraId:16,tocIndex:2},{value:" interface.",paraId:16,tocIndex:2},{value:"import { ContextService, inject, singleton } from '@antv/g';\n\n@singleton({ token: ContextService })\nexport class Canvas2DContextService\n  implements ContextService<CanvasRenderingContext2D> {}\n",paraId:17,tocIndex:2},{value:"The ",paraId:18,tocIndex:2},{value:"ContextService",paraId:18,tocIndex:2},{value:" interface is defined as follows.",paraId:18,tocIndex:2},{value:"export interface ContextService<Context> {\n  init: () => Promise<void>;\n  destroy: () => void;\n  getContext: () => Context | null;\n  getDomElement: () => CanvasLike | null;\n  getDPR: () => number;\n  getBoundingClientRect: () => DOMRect | undefined;\n  resize: (width: number, height: number) => void;\n  applyCursorStyle: (cursor: string) => void;\n  toDataURL: (options: Partial<DataURLOptions>) => Promise<string>;\n}\n",paraId:19,tocIndex:2},{value:"Below we detail the meaning of each method.",paraId:20,tocIndex:2},{value:"Different underlying rendering APIs have different initialization methods, for example, while Canvas2D / WebGL / WebGPU can all get the context from the ",paraId:21,tocIndex:3},{value:"<canvas>",paraId:21,tocIndex:3},{value:" element via the DOM API, WebGPU is asynchronous, so we designed the method to be asynchronous.",paraId:21,tocIndex:3},{value:"@inject(CanvasConfig)\nprivate canvasConfig: CanvasConfig;\n\nasync init() {\n  const { container, canvas, devicePixelRatio } = this.canvasConfig;\n  this.context = this.$canvas.getContext('2d');\n}\n",paraId:22,tocIndex:3},{value:"In this method, we can get the parameters passed by the user when creating ",paraId:23,tocIndex:3},{value:"Canvas",paraId:24,tocIndex:3},{value:" by injection, such as ",paraId:23,tocIndex:3},{value:"devicePixelRatio",paraId:25,tocIndex:3},{value:".",paraId:23,tocIndex:3},{value:"Regarding the timing of the call, it will be called not only when initializing the canvas for the first time, but also when switching the renderer at subsequent runtimes.",paraId:26,tocIndex:3},{value:"In this method, we can do some context destruction.",paraId:27,tocIndex:4},{value:"Regarding the timing of the call, in addition to being called when the canvas is initialized for the first time, it will also be called when switching renderers at subsequent runtimes, where the old renderer context will be destroyed first.",paraId:28,tocIndex:4},{value:"During runtime, sometimes the initialized ",paraId:29,tocIndex:5},{value:"canvas size",paraId:30,tocIndex:5},{value:" will change, and then ",paraId:29,tocIndex:5},{value:"canvas.resize()",paraId:29,tocIndex:5},{value:" will eventually call this method.",paraId:29,tocIndex:5},{value:"Returns a custom rendering context, with different renderers returning different objects, e.g.",paraId:31,tocIndex:6},{value:"g-canvas",paraId:32,tocIndex:6},{value:" will return ",paraId:33,tocIndex:6},{value:"CanvasRenderingContext2D",paraId:33,tocIndex:6},{value:"g-svg",paraId:34,tocIndex:6},{value:" will return ",paraId:33,tocIndex:6},{value:"SVGElement",paraId:33,tocIndex:6},{value:"g-webgl",paraId:35,tocIndex:6},{value:" will return a complex object ",paraId:33,tocIndex:6},{value:"WebGLRenderingContext",paraId:33,tocIndex:6},{value:"interface WebGLRenderingContext {\n  engine: RenderingEngine;\n  camera: Camera;\n  view: IView;\n}\n",paraId:36,tocIndex:6},{value:"Returns the DOM element to which the context belongs. For example, ",paraId:37,tocIndex:7},{value:"g-canvas/webgl",paraId:37,tocIndex:7},{value:" will return ",paraId:37,tocIndex:7},{value:"<canvas>",paraId:37,tocIndex:7},{value:", while ",paraId:37,tocIndex:7},{value:"g-svg",paraId:37,tocIndex:7},{value:" will return ",paraId:37,tocIndex:7},{value:"<svg>",paraId:37,tocIndex:7},{value:".",paraId:37,tocIndex:7},{value:"Returns devicePixelRatio.",paraId:38,tocIndex:8},{value:"It is available in most rendering environments via the DOM API method of the same name.",paraId:39,tocIndex:9},{value:"Set the mouse style. This can be set in most rendering environments via the DOM API.",paraId:40,tocIndex:10},{value:"When implementing requirements like ",paraId:41,tocIndex:11},{value:"export-image",paraId:42,tocIndex:11},{value:", you need to rely on the capabilities of the rendering context.",paraId:41,tocIndex:11},{value:"Different rendering contexts naturally have different difficulties to implement, for example, native ",paraId:43,tocIndex:11},{value:"toDataURL",paraId:43,tocIndex:11},{value:" can be used in ",paraId:43,tocIndex:11},{value:"g-canvas",paraId:44,tocIndex:11},{value:" HTMLCanvasElement/toDataURL) method.",paraId:43,tocIndex:11},{value:"https://github.com/antvis/G/blob/next/packages/g-svg/src/Canvas2DContextService.ts#L107-L110",paraId:45,tocIndex:11},{value:"async toDataURL(options: Partial<DataURLOptions> = {}) {\n  const { type, encoderOptions } = options;\n  return (this.context.canvas as HTMLCanvasElement).toDataURL(type, encoderOptions);\n}\n",paraId:46,tocIndex:11},{value:"However, ",paraId:47,tocIndex:11},{value:"g-svg",paraId:48,tocIndex:11},{value:" is much more complicated to implement and requires the ",paraId:47,tocIndex:11},{value:"XMLSerializer",paraId:47,tocIndex:11},{value:" serialization capabilities.",paraId:47,tocIndex:11},{value:"https://github.com/antvis/G/blob/next/packages/g-svg/src/SVGContextService.ts#L74-L90",paraId:49,tocIndex:11},{value:"async toDataURL(options: Partial<DataURLOptions> = {}) {\n  const cloneNode = this.$namespace.cloneNode(true);\n  const svgDocType = document.implementation.createDocumentType(\n    'svg',\n    '-//W3C//DTD SVG 1.1//EN',\n    'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd',\n  );\n  const svgDoc = document.implementation.createDocument(\n    'http://www.w3.org/2000/svg',\n    'svg',\n    svgDocType,\n  );\n  svgDoc.replaceChild(cloneNode, svgDoc.documentElement);\n  return `data:image/svg+xml;charset=utf8,${encodeURIComponent(\n    new XMLSerializer().serializeToString(svgDoc),\n  )}`;\n}\n",paraId:50,tocIndex:11},{value:"The situation is more complicated in ",paraId:51,tocIndex:11},{value:"g-webgl",paraId:52,tocIndex:11},{value:", which even requires the use of asynchronous methods.",paraId:51,tocIndex:11},{value:"https://github.com/antvis/G/blob/next/packages/g-plugin-device-renderer/src/RenderGraphPlugin.ts#L428-L438",paraId:53,tocIndex:11}]},50796:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(67884);const n=[{value:"Renderers use the underlying rendering API to draw various types of graphics. We currently provide the following renderers, which are:",paraId:0},{value:"g-canvas",paraId:1},{value:" based on Canvas2D API",paraId:2},{value:"g-canvaskit",paraId:3},{value:" based on Canvaskit / Skia",paraId:2},{value:"g-svg",paraId:4},{value:" based on SVG",paraId:2},{value:"g-webgl",paraId:5},{value:" based on WebGL 2/1",paraId:2},{value:"g-webgpu",paraId:6},{value:" based on WebGPU",paraId:2},{value:"The renderer consists of a rendering context and a set of ",paraId:7},{value:"plugins",paraId:8},{value:" that allow the capabilities of the renderer to be dynamically extended at runtime.",paraId:7},{value:"Using the ",paraId:9},{value:"g-canvas",paraId:9},{value:" renderer as an example, the basic usage is as follows.",paraId:9},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\n\nconst canvasRenderer = new Renderer();\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: canvasRenderer,\n});\n",paraId:10},{value:"When creating a renderer, a series of initialization configurations can be passed in to affect the actual rendering behavior.",paraId:11,tocIndex:0},{value:'Whether to enable auto-rendering or not, the default is on. "Auto-rendering" means that you do not need to manually invoke the rendering method of the canvas, but simply add the graphics to the canvas, which is also consistent with the browser behavior.',paraId:12,tocIndex:1},{value:"It can be turned off for some scenes where the rendering timing needs to be controlled manually.",paraId:13,tocIndex:1},{value:"const webglRenderer = new WebGLRenderer({\n    enableAutoRendering: false,\n});\n",paraId:14,tocIndex:1},{value:"Whether to turn on dirty check, default is on. When enabled, only changes in the graphics will trigger canvas redraw.",paraId:15,tocIndex:2},{value:"Whether to turn on view cone culling, off by default. When on, only drawings within the viewport range will be drawn.",paraId:16,tocIndex:3},{value:"The ",paraId:17,tocIndex:4},{value:"setConfig",paraId:17,tocIndex:4},{value:" allows you to modify the initial configuration, for example to enable automatic rendering again.",paraId:17,tocIndex:4},{value:"renderer.setConfig({ enableAutoRendering: true });\n",paraId:18,tocIndex:4},{value:"We provide a number of ways to operate the plug-in.",paraId:19,tocIndex:5},{value:"Renders can dynamically add plugins at runtime to extend their capabilities, e.g. ",paraId:20,tocIndex:6},{value:"g-webgl",paraId:20,tocIndex:6},{value:" can render 3D scenes via ",paraId:20,tocIndex:6},{value:"g-pluin-3d",paraId:21,tocIndex:6},{value:".",paraId:20,tocIndex:6},{value:"import { Plugin } from '@antv/g-plugin-3d';\n\nwebglRenderer.registerPlugin(new Plugin());\n",paraId:22,tocIndex:6},{value:"Removal of plug-ins.",paraId:23,tocIndex:7},{value:"renderer.unregisterPlugin(plugin);\n",paraId:24,tocIndex:7},{value:"Get plugins by name. Each plugin has its own name, and we agree that the name of ",paraId:25,tocIndex:8},{value:"g-plugin-name",paraId:25,tocIndex:8},{value:" is ",paraId:25,tocIndex:8},{value:"name",paraId:25,tocIndex:8},{value:".",paraId:25,tocIndex:8},{value:"import { Plugin } from '@antv/g-plugin-testonly';\n\nconst plugin = new Plugin();\nplugin.name; // 'testonly'\n",paraId:26,tocIndex:8},{value:"So in the renderer it is possible to obtain by plugin name.",paraId:27,tocIndex:8},{value:"renderer.register(plugin);\n\nrenderer.getPlugin('testonly'); // plugin\n",paraId:28,tocIndex:8},{value:"Returns the list of plug-ins for the current renderer.",paraId:29,tocIndex:9},{value:"renderer.getPlugins(); // [Plugin1, Plugin2]\n",paraId:30,tocIndex:9}]},95827:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(69058);const n=[{value:"Use ",paraId:0},{value:"SVG",paraId:0},{value:" to draw 2D graphics. A ",paraId:0},{value:"<svg>",paraId:0},{value:" element is created in the container.",paraId:0},{value:"SVG has the unique advantage of relying directly on the browser's ability to render text. It is also possible to embed HTML fragments via ",paraId:1},{value:"<foreignObject>",paraId:1},{value:".",paraId:1},{value:"As with ",paraId:2,tocIndex:0},{value:"@antv/g",paraId:2,tocIndex:0},{value:", there are two ways to use it.",paraId:2,tocIndex:0},{value:"After installing ",paraId:3,tocIndex:1},{value:"@antv/g-svg",paraId:3,tocIndex:1},{value:" you can get the renderer from.",paraId:3,tocIndex:1},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-svg';\n\nconst svgRenderer = new Renderer();\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: svgRenderer,\n});\n",paraId:4,tocIndex:1},{value:'<script\n  src="https://unpkg.com/@antv/g-svg/dist/index.umd.min.js"\n  type="application/javascript">\n',paraId:5,tocIndex:2},{value:"The renderer is available from the ",paraId:6,tocIndex:2},{value:"G.SVG",paraId:6,tocIndex:2},{value:" namespace under.",paraId:6,tocIndex:2},{value:"const svgRenderer = new window.G.SVG.Renderer();\n",paraId:7,tocIndex:2},{value:"When creating a renderer, you can pass in some initialization configuration items, such as.",paraId:8,tocIndex:3},{value:"import { Renderer } from '@antv/g-svg';\nconst renderer = new Renderer({\n    outputSVGElementId: false,\n});\n",paraId:9,tocIndex:3},{value:"The renderer adds the ",paraId:10,tocIndex:4},{value:"id",paraId:10,tocIndex:4},{value:" attribute when generating the SVGElement, which is used to pick up the decision to counter-check the element when interacting. However, in scenarios like server-side rendering, where there is no interaction and no need for generation, this can be turned off with this configuration item.",paraId:10,tocIndex:4},{value:'\x3c!-- Enable by default --\x3e\n<g id="g_svg_g_450" fill="none"></g>\n\n\x3c!-- Disable --\x3e\n<g fill="none"></g>\n',paraId:11,tocIndex:4},{value:"The renderer has the following plug-ins built in.",paraId:12,tocIndex:5},{value:"g-plugin-svg-renderer",paraId:13,tocIndex:5},{value:" Draw shapes using SVG elements, such as ",paraId:14,tocIndex:5},{value:"<circle>",paraId:14,tocIndex:5},{value:", ",paraId:14,tocIndex:5},{value:"<rect>",paraId:14,tocIndex:5},{value:", etc.",paraId:14,tocIndex:5},{value:"g-plugin-svg-picker",paraId:15,tocIndex:5},{value:" Pick up graphics based on ",paraId:14,tocIndex:5},{value:"elementFromPoint",paraId:14,tocIndex:5},{value:" DOM API",paraId:14,tocIndex:5},{value:"g-plugin-dom-interaction",paraId:16,tocIndex:5},{value:" DOM API-based event binding",paraId:14,tocIndex:5},{value:"In addition to the built-in plug-ins, the following optional plug-ins are available.",paraId:17,tocIndex:6},{value:"Use the SVG version of ",paraId:18,tocIndex:7},{value:"rough.js",paraId:18,tocIndex:7},{value:" for hand-drawn style rendering.",paraId:18,tocIndex:7},{value:"We provide ",paraId:19,tocIndex:7},{value:"g-plugin-rough-svg-renderer",paraId:20,tocIndex:7},{value:" plugin, which will replace [g-plugin-svg-renderer](/en/plugins/svg- renderer) for some 2D graphics.",paraId:19,tocIndex:7},{value:"The effect of ",paraId:21,tocIndex:7},{value:"example",paraId:22,tocIndex:7},{value:" is as follows.",paraId:21,tocIndex:7},{value:"The renderer relies on the rendering capabilities of the SVG DOM API and is not limited to the browser side, so server-side rendering is also possible using ",paraId:23,tocIndex:8},{value:"JSDOM",paraId:23,tocIndex:8},{value:".",paraId:23,tocIndex:8},{value:"In our ",paraId:24,tocIndex:8},{value:"integration test",paraId:24,tocIndex:8},{value:", we will work with ",paraId:24,tocIndex:8},{value:"JSDOM",paraId:24,tocIndex:8},{value:" on the Node side jsdom) with ",paraId:24,tocIndex:8},{value:"node-canvas",paraId:24,tocIndex:8},{value:" to render the result image and compare it with the benchmark image. Other server-side rendering scenes can also follow the following steps.",paraId:24,tocIndex:8},{value:"Use ",paraId:25,tocIndex:8},{value:"unregisterPlugin",paraId:26,tocIndex:8},{value:" to unregister the DOM API-related plugins built into ",paraId:25,tocIndex:8},{value:"g-svg",paraId:27,tocIndex:8},{value:", such as the event binding ",paraId:25,tocIndex:8},{value:"g-plugin-dom-interaction",paraId:28,tocIndex:8},{value:".",paraId:25,tocIndex:8},{value:"Create a canvas container using JSDOM.",paraId:25,tocIndex:8},{value:"Use the container from the previous step to create the canvas, and pass in the ",paraId:25,tocIndex:8},{value:"document",paraId:25,tocIndex:8},{value:" created by JSDOM instead of ",paraId:25,tocIndex:8},{value:"window.document",paraId:25,tocIndex:8},{value:" in the browser environment, and the same for ",paraId:25,tocIndex:8},{value:"raf",paraId:25,tocIndex:8},{value:".",paraId:25,tocIndex:8},{value:"Normal use of ",paraId:25,tocIndex:8},{value:"g-svg",paraId:29,tocIndex:8},{value:" renderer to create scenes via G's API.",paraId:25,tocIndex:8},{value:"Use ",paraId:25,tocIndex:8},{value:"xmlserializer",paraId:25,tocIndex:8},{value:" to serialize JSDOM to a string and save it as an SVG image.",paraId:25,tocIndex:8},{value:"https://github.com/antvis/g/blob/next/integration/__node__tests__/svg/circle.spec.js",paraId:30,tocIndex:8},{value:"const fs = require('fs');\nconst { JSDOM } = require('jsdom');\nconst xmlserializer = require('xmlserializer');\nconst { Circle, Canvas } = require('@antv/g');\nconst { Renderer } = require('@antv/g-svg');\n\n// create a renderer, unregister plugin relative to DOM\nconst renderer = new Renderer();\nconst domInteractionPlugin = renderer.getPlugin('dom-interaction');\nrenderer.unregisterPlugin(domInteractionPlugin);\n\n// create JSDOM\nconst dom = new JSDOM(`\n<div id=\"container\">\n</div>\n`);\n\nconst SIZE = 200;\nconst canvas = new Canvas({\n    container: 'container',\n    width: SIZE,\n    height: SIZE,\n    renderer,\n    document: dom.window.document, // use document created by JSDOM\n    requestAnimationFrame: dom.window.requestAnimationFrame,\n    cancelAnimationFrame: dom.window.cancelAnimationFrame,\n});\n\n// use G API constructing scene graph\nconst circle1 = new Circle({\n    style: {\n        cx: 10,\n        cy: 10,\n        r: 10,\n        fill: 'red',\n    },\n});\ncanvas.appendChild(circle1);\n\n// serialize JSDOM to SVG string\nxmlserializer.serializeToString(\n    dom.window.document.getElementById('container').children[0],\n);\n",paraId:31,tocIndex:8}]},83302:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(10023);const n=[{value:"Use ",paraId:0},{value:"WebGLRenderingContext",paraId:0},{value:" or [WebGL2RenderingContext](https: //developer.mozilla.org/en-US/Web/API/WebGL2RenderingContext) for rendering. Compared with ",paraId:0},{value:"Canvas renderer",paraId:1},{value:" and ",paraId:0},{value:"SVG renderer",paraId:2},{value:", it has more powerful rendering capabilities and has obvious advantages in large volume graphics and 3D scenes.",paraId:0},{value:"As with ",paraId:3,tocIndex:0},{value:"@antv/g",paraId:3,tocIndex:0},{value:", there are two ways to use it.",paraId:3,tocIndex:0},{value:"After installing ",paraId:4,tocIndex:1},{value:"@antv/g-webgl",paraId:4,tocIndex:1},{value:" you can get the renderer from.",paraId:4,tocIndex:1},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-webgl';\n\nconst webglRenderer = new Renderer();\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: webglRenderer,\n});\n",paraId:5,tocIndex:1},{value:'<script\n  src="https://unpkg.com/@antv/g-webgl/dist/index.umd.min.js"\n  type="application/javascript">\n',paraId:6,tocIndex:2},{value:"The renderer is available from the ",paraId:7,tocIndex:2},{value:"G.WebGL",paraId:7,tocIndex:2},{value:" namespace under.",paraId:7,tocIndex:2},{value:"const webglRenderer = new window.G.WebGL.Renderer();\n",paraId:8,tocIndex:2},{value:"Selects the rendering environment. The default value is ",paraId:9,tocIndex:4},{value:"['webgl2', 'webgl1']",paraId:9,tocIndex:4},{value:" and is automatically downgraded automatically by that priority.",paraId:9,tocIndex:4},{value:"For example, in some special environments, only the WebGL1 environment is selected to run in.",paraId:10,tocIndex:4},{value:"const webglRenderer = new WebGLRenderer({\n    targets: ['webgl1'],\n});\n",paraId:11,tocIndex:4},{value:"The ",paraId:12,tocIndex:5},{value:"webglcontextlost",paraId:12,tocIndex:5},{value:" event of the WebGL API is fired if the user agent detects that the drawing buffer associated with a WebGLRenderingContext object has been lost.",paraId:12,tocIndex:5},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/HTMLCanvasElement/webglcontextlost_event",paraId:13,tocIndex:5},{value:"const webglRenderer = new WebGLRenderer({\n    onContextLost: (e: Event) => {},\n});\n",paraId:14,tocIndex:5},{value:"The ",paraId:15,tocIndex:6},{value:"webglcontextrestored",paraId:15,tocIndex:6},{value:" event of the WebGL API is fired if the user agent restores the drawing buffer for a WebGLRenderingContext object.",paraId:15,tocIndex:6},{value:"https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event",paraId:16,tocIndex:6},{value:"const webglRenderer = new WebGLRenderer({\n    onContextRestored: (e: Event) => {},\n});\n",paraId:17,tocIndex:6},{value:"The ",paraId:18,tocIndex:7},{value:"webglcontextcreationerror",paraId:18,tocIndex:7},{value:" event of the WebGL API is fired if the user agent is unable to create a WebGLRenderingContext context.",paraId:18,tocIndex:7},{value:"https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event",paraId:19,tocIndex:7},{value:"const webglRenderer = new WebGLRenderer({\n    onContextCreationError: (e: Event) => {},\n});\n",paraId:20,tocIndex:7},{value:"The renderer has the following plug-ins built in.",paraId:21,tocIndex:8},{value:"g-plugin-device-renderer",paraId:22,tocIndex:8},{value:" GPUDevice based rendering capabilities",paraId:23,tocIndex:8},{value:"g-plugin-webgl-device",paraId:24,tocIndex:8},{value:" Implementing GPUDevice Capabilities based on ",paraId:23,tocIndex:8},{value:"WebGLRenderingContext",paraId:23,tocIndex:8},{value:" and ",paraId:23,tocIndex:8},{value:"WebGL2RenderingContext",paraId:23,tocIndex:8},{value:"g-plugin-dom-interaction",paraId:25,tocIndex:8},{value:" DOM API-based event binding",paraId:23,tocIndex:8},{value:"In addition to the built-in plug-ins, the following plug-ins are also available.",paraId:26,tocIndex:9},{value:"g-plugin-3d",paraId:27,tocIndex:10},{value:" Provides 3D rendering capabilities, including common objects such as ",paraId:28,tocIndex:10},{value:"Mesh",paraId:29,tocIndex:10},{value:" ",paraId:28,tocIndex:10},{value:"Material",paraId:30,tocIndex:10},{value:" ",paraId:28,tocIndex:10},{value:"Geometry",paraId:31,tocIndex:10},{value:".",paraId:28,tocIndex:10},{value:"g-plugin-control",paraId:32,tocIndex:11},{value:" provides camera interaction for 3D scenes, internally using Hammer.js to respond to mouse-over, scroll-wheel events. Depending on the ",paraId:33,tocIndex:11},{value:"camera type",paraId:34,tocIndex:11},{value:", different interaction effects are provided.",paraId:33,tocIndex:11}]},29389:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(83891);const n=[{value:"Based on ",paraId:0},{value:"WebGPU",paraId:0},{value:" to provide rendering and computation capabilities.",paraId:0},{value:"In particular, the ability to use the GPU for parallel computation is not available with WebGL, and we provide ",paraId:1},{value:"g-plugin-gpgpu",paraId:2},{value:" to help simplify this process.",paraId:1},{value:"The following pre-requisites need to be met.",paraId:3,tocIndex:0},{value:"When using it, you need to determine whether the current environment supports WebGPU, the following feature detection code from ",paraId:4,tocIndex:1},{value:"https://web.dev/gpu/#feature-detection",paraId:4,tocIndex:1},{value:".",paraId:4,tocIndex:1},{value:"if ('gpu' in navigator) {\n    // WebGPU is supported! 🎉\n}\n",paraId:5,tocIndex:1},{value:"This is currently available in the latest version of Chrome (101) via Open Trial.",paraId:6,tocIndex:1},{value:"At runtime we use ",paraId:7,tocIndex:2},{value:"wgpu naga",paraId:7,tocIndex:2},{value:" for shader translation (GLSL 300 -> WGSL), so the runtime environment needs to support WASM.",paraId:7,tocIndex:2},{value:"As with ",paraId:8,tocIndex:3},{value:"@antv/g",paraId:8,tocIndex:3},{value:", there are two ways to use it.",paraId:8,tocIndex:3},{value:"After installing ",paraId:9,tocIndex:4},{value:"@antv/g-webgpu",paraId:9,tocIndex:4},{value:" you can get the renderer from.",paraId:9,tocIndex:4},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-webgpu';\n\nconst webgpuRenderer = new Renderer({\n    shaderCompilerPath: '/glsl_wgsl_compiler_bg.wasm',\n});\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: webgpuRenderer,\n});\n",paraId:10,tocIndex:4},{value:'<script\n  src="https://unpkg.com/@antv/g-webgpu/dist/index.umd.min.js"\n  type="application/javascript">\n',paraId:11,tocIndex:5},{value:"The renderer is available from the ",paraId:12,tocIndex:5},{value:"G.WebGPU",paraId:12,tocIndex:5},{value:" namespace under.",paraId:12,tocIndex:5},{value:"const webgpuRenderer = new window.G.WebGPU.Renderer({\n    shaderCompilerPath: '/glsl_wgsl_compiler_bg.wasm',\n});\n",paraId:13,tocIndex:5},{value:"Since our shader is written in GLSL 300, it needs to be translated to WGSL in order to run in WebGPU. For this step we use naga, which is compiled into WASM to run in the browser, so it needs to be loaded at runtime:",paraId:14,tocIndex:7},{value:"const webgpuRenderer = new WebGPURenderer({\n    shaderCompilerPath: '/glsl_wgsl_compiler_bg.wasm',\n});\n",paraId:15,tocIndex:7},{value:"Like WebGL, WebGPU applications may experience context loss during runtime, and this callback function will be triggered.",paraId:16,tocIndex:8},{value:"https://github.com/gpuweb/gpuweb/blob/main/design/ErrorHandling.md#fatal-errors-requestadapter-requestdevice-and-devicelost",paraId:17,tocIndex:8},{value:"const webgpuRenderer = new WebGPURenderer({\n    shaderCompilerPath: '/glsl_wgsl_compiler_bg.wasm',\n    onContextLost: () => {},\n});\n",paraId:18,tocIndex:8},{value:"The renderer has the following plug-ins built in.",paraId:19,tocIndex:9},{value:"g-plugin-device-renderer",paraId:20,tocIndex:9},{value:" GPUDevice based rendering capabilities",paraId:21,tocIndex:9},{value:"g-plugin-webgpu-device",paraId:22,tocIndex:9},{value:" Implementing GPUDevice Capabilities based on WebGPU",paraId:21,tocIndex:9},{value:"g-plugin-dom-interaction",paraId:23,tocIndex:9},{value:" DOM API-based event binding",paraId:21,tocIndex:9},{value:"In addition to the built-in plug-ins, the following plug-ins are also available",paraId:24,tocIndex:10},{value:"g-plugin-gpgpu",paraId:25,tocIndex:11},{value:" provides GPGPU capabilities. Thanks to the WebGPU's support for Compute Shader, we can implement many parallelizable algorithms.",paraId:26,tocIndex:11},{value:"g-plugin-3d",paraId:27,tocIndex:12},{value:" Provides 3D rendering capabilities, including common objects such as ",paraId:28,tocIndex:12},{value:"Mesh",paraId:29,tocIndex:12},{value:" ",paraId:28,tocIndex:12},{value:"Material",paraId:30,tocIndex:12},{value:" ",paraId:28,tocIndex:12},{value:"Geometry",paraId:31,tocIndex:12},{value:".",paraId:28,tocIndex:12},{value:"g-plugin-control",paraId:32,tocIndex:13},{value:" provides camera interaction for 3D scenes, internally using Hammer.js to respond to mouse-over, scroll-wheel events. Depending on the ",paraId:33,tocIndex:13},{value:"camera type",paraId:34,tocIndex:13},{value:", different interaction effects are provided.",paraId:33,tocIndex:13}]},84798:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(98246);const n=[{value:"我们提供了一些",paraId:0},{value:"基础图形",paraId:1},{value:"，例如 ",paraId:0},{value:"Circle",paraId:2},{value:"、",paraId:0},{value:"Path",paraId:3},{value:" 等等。通过",paraId:0},{value:"场景图",paraId:4},{value:"能力也能构建它们之间的层次关系。但当场景层次嵌套较深又需要复用时，我们便需要一种自定义组件机制，能把这些基础图形封装成高级图形。",paraId:0},{value:"类似的问题在 Web Components 中是通过 ",paraId:5},{value:"Custom Element",paraId:5},{value:" 实现的。在",paraId:5},{value:"官方示例",paraId:5},{value:"中我们能看到一个自定义图形的注册过程按照如下步骤进行：",paraId:5},{value:"在构造函数中创建内部 DOM 结构",paraId:6},{value:"在 ",paraId:6},{value:"connectedCallback()",paraId:6},{value:" 即元素首次插入文档后，设置样式",paraId:6},{value:"在 ",paraId:6},{value:"attributeChangedCallback()",paraId:6},{value:" 中处理属性更新，重新设置样式",paraId:6},{value:"使用 ",paraId:6},{value:"customElements.define()",paraId:6},{value:" 完成自定义图形的注册",paraId:6},{value:"我们沿用了这样的设计。",paraId:7},{value:"在本文中我们将介绍自定义图形的用法，实现一个简单的箭头，其中包含以下步骤：",paraId:8},{value:"设计自定义属性",paraId:9},{value:"定义场景图",paraId:9},{value:"使用自定义图形",paraId:9},{value:"处理属性更新",paraId:9},{value:"过程中会涉及",paraId:10},{value:"场景图",paraId:11},{value:"、",paraId:10},{value:"动画系统",paraId:12},{value:"、",paraId:10},{value:"事件系统",paraId:13},{value:"等。在开始前我们推荐先阅读以上各个系统的文档。",paraId:10},{value:"完整 DEMO",paraId:14},{value:"源码",paraId:15},{value:"一个箭头由躯干部分 + 一或两个端点组成。如下图所示，躯干部分可以是 Line / Polyline / Path，而端点可以是任意基础/高级图形，我们提供的默认端点是 Path。可见箭头就是一个由若干基础图形组合而成的“高级图形”。",paraId:16,tocIndex:0},{value:"首先所有自定义图形都需要继承 CustomElement 基类：",paraId:17,tocIndex:1},{value:"import { CustomElement } from '@antv/g';\n\nexport class Arrow extends CustomElement<ArrowStyleProps> {}\n",paraId:18,tocIndex:1},{value:"然后可以定义自定义图形的属性，这里我们给箭头提供了以下自定义属性：",paraId:19,tocIndex:1},{value:"body 躯干部分只能接受 ",paraId:20,tocIndex:1},{value:"Line",paraId:21,tocIndex:1},{value:" ",paraId:20,tocIndex:1},{value:"Path",paraId:22,tocIndex:1},{value:" ",paraId:20,tocIndex:1},{value:"Polyline",paraId:23,tocIndex:1},{value:"start/endHead 端点部分可以是任何基础图形，传入布尔值时开启/关闭默认内置端点",paraId:20,tocIndex:1},{value:"stroke/lineWidth/opacity 等常规绘图属性",paraId:20,tocIndex:1},{value:"type ArrowHead = boolean | DisplayObject;\ntype ArrowBody = Line | Path | Polyline;\n\nexport interface ArrowStyleProps extends BaseStyleProps {\n    body?: ArrowBody; // 躯干\n    startHead?: ArrowHead; // 起始端点\n    endHead?: ArrowHead; // 结束端点\n    stroke?: string; // 颜色\n    lineWidth?: number; // 线宽\n    opacity?: number; // 透明度\n    strokeOpacity?: number;\n}\n",paraId:24,tocIndex:1},{value:"有了自定义属性，下一步需要通过场景图组合基础图形。",paraId:25,tocIndex:1},{value:"我们需要在构造函数中完成场景图的定义。这里会使用到基础图形的节点操作能力，例如使用 ",paraId:26,tocIndex:2},{value:"appendChild",paraId:27,tocIndex:2},{value:" 添加箭头的躯干和端点部分。",paraId:26,tocIndex:2},{value:"static tag = 'arrow';\n\nconstructor(config: DisplayObjectConfig<ArrowStyleProps>) {\n  // 调用基类构造函数\n  super({\n    ...config,\n    type: Arrow.tag, // 定义自定义图形类型\n  });\n\n  // 获取用户传入的自定义属性\n  // @see /zh/api/builtin-objects/element#attributes\n  const { body, startHead, endHead, ...rest } = this.attributes;\n\n  // 躯干部分必须指定\n  if (!body) {\n    throw new Error(\"Arrow's body is required\");\n  }\n\n  // 添加躯干\n  this.body = body;\n  this.appendChild(this.body);\n\n  // 添加起始/结束端点\n  if (startHead) {\n    this.appendArrowHead(this.getArrowHeadType(startHead), true);\n  }\n  if (endHead) {\n    this.appendArrowHead(this.getArrowHeadType(endHead), false);\n  }\n\n  // 给躯干、端点应用样式\n  this.applyArrowStyle(rest, [this.body, this.startHead, this.endHead]);\n}\n",paraId:28,tocIndex:2},{value:"我们支持内置端点和用户传入的端点，即使是由用户传入，它也只用于描述端点的形状，为了确保箭头和躯干部分朝向一致，我们还需要对端点进行变换。另外，我们使用了 ",paraId:29,tocIndex:3},{value:"zIndex",paraId:30,tocIndex:3},{value:"，由于默认 zIndex 为 0，因此设置成 1 就可以保证端点的展示次序在躯干部分之上。",paraId:29,tocIndex:3},{value:"private appendArrowHead(type: ArrowHeadType, isStart: boolean) {\n  let head: DisplayObject;\n  if (type === 'default') {\n    // 创建一个默认端点\n    head = this.createDefaultArrowHead();\n  } else {\n    // 使用用户传入的端点\n    head = isStart ? this.attributes.startHead : this.attributes.endHead;\n  }\n\n  // 对端点进行变换\n  this.transformArrowHead(head, isStart);\n\n  // 让端点展示在躯干上\n  head.setAttribute('zIndex', 1);\n  // 或者 head.style.zIndex = 1;\n\n  if (isStart) {\n    this.startHead = head;\n  } else {\n    this.endHead = head;\n  }\n\n  // 场景图中添加端点\n  this.appendChild(head);\n}\n",paraId:31,tocIndex:3},{value:"对于内置默认端点，我们使用一个形如 ",paraId:32,tocIndex:3},{value:"<",paraId:32,tocIndex:3},{value:" 的 ",paraId:32,tocIndex:3},{value:"Path",paraId:33,tocIndex:3},{value:"，这里将 anchor 设置为 ",paraId:32,tocIndex:3},{value:"[0.5, 0.5]",paraId:32,tocIndex:3},{value:" 即 Path 的中心点，便于后续对端点进行变换：",paraId:32,tocIndex:3},{value:"private createDefaultArrowHead() {\n  // 沿用箭头的自定义属性\n  const { stroke, lineWidth } = this.attributes;\n  const { sin, cos, PI } = Math;\n  return new Path({\n    style: {\n      path: `M${10 * cos(PI / 6)},${10 * sin(PI / 6)} L0,0 L${10 * cos(PI / 6)},-${10 * sin(PI / 6)\n        }`,\n      stroke,\n      lineWidth,\n      anchor: [0.5, 0.5], // 锚点默认为 [0, 0]\n    },\n  });\n}\n",paraId:34,tocIndex:3},{value:"下一步需要对端点进行变换，确保它出现在正确的位置（躯干的两端）以及拥有正确的朝向。",paraId:35,tocIndex:3},{value:"对于端点的变换可以分成两步，设置位置（躯干的起始还是结束）以及朝向。",paraId:36,tocIndex:4},{value:"根据不同的躯干图形，可以通过不同的方法得到两个端点坐标。需要注意的是，设置端点位置时，一定要使用",paraId:37,tocIndex:4},{value:"局部坐标系下的操作方法",paraId:38,tocIndex:4},{value:"，即 setLocalPosition 或者 translateLocal，原因是我们希望端点在整个箭头而非世界坐标系下定位，这样当整个箭头移动时，其内部的各个组成部分（躯干、端点）会跟着移动，但彼此的相对位置不会改变。",paraId:37,tocIndex:4},{value:"同样的，在设置端点随躯干的旋转角度时，也需要在端点本身的旋转角度基础上，增加躯干切线的角度，因此需要使用 get/setLocalEulerAngles。",paraId:39,tocIndex:4},{value:"private transformArrowHead(head: DisplayObject, isStart: boolean) {\n  let rad = 0;\n  let x1 = 0;\n  let x2 = 0;\n  let y1 = 0;\n  let y2 = 0;\n\n  // 躯干类型\n  const bodyType = this.body && this.body.nodeName;\n  if (bodyType === Shape.LINE) {\n    // 省略计算切线\n  } else if (bodyType === Shape.POLYLINE) {\n    // 省略计算切线\n  } else if (bodyType === Shape.PATH) {\n    // 省略计算切线\n  }\n\n  // 计算弧度\n  const x = x1 - x2;\n  const y = y1 - y2;\n  rad = Math.atan2(y, x);\n\n  // 设置局部坐标系下的位置\n  head.setLocalPosition(x2, y2);\n  // 设置局部坐标系下的旋转角度，弧度转换成角度\n  head.setLocalEulerAngles((rad * 180) / Math.PI + head.getLocalEulerAngles());\n}\n",paraId:40,tocIndex:4},{value:"下面我们来看不同类型的躯干如何计算切线，这部分纯粹是简单的数学运算，和本文的主题关系不大。",paraId:41,tocIndex:4},{value:"对于 Line 和 Polyline 只需要找到两个端点坐标相减即可，对于 Path 我们提供了",paraId:42,tocIndex:5},{value:"计算切线的 API",paraId:43,tocIndex:5},{value:"：",paraId:42,tocIndex:5},{value:"private getTangent(path: Path, isStart: boolean): number[][] {\n  return isStart ? path.getStartTangent() : path.getEndTangent();\n}\n",paraId:44,tocIndex:5},{value:"至此一个简单的箭头就组装完成了。",paraId:45,tocIndex:5},{value:"自定义图形可以使用大部分基础图形的能力，例如节点操作、变换、动画、响应事件等。",paraId:46,tocIndex:6},{value:"使用箭头这样的高级图形和其他基础图形一样，例如我们可以创建一个躯干为 Line 的箭头。随后对它使用变换方法，例如平移。同样也可以使用场景图的节点查询能力，例如 getElementById：",paraId:47,tocIndex:7},{value:"const lineArrow = new Arrow({\n    id: 'lineArrow',\n    style: {\n        body: new Line({\n            style: {\n                x1: 200,\n                y1: 100,\n                x2: 0,\n                y2: 0,\n            },\n        }),\n        startHead: true,\n        stroke: '#1890FF',\n        lineWidth: 10,\n        cursor: 'pointer',\n    },\n});\n\n// 平移\nlineArrow.translate(200, 100);\n\n// 按 id 查询\ncanvas.document.getElementById('lineArrow'); // Arrow lineArrow\n",paraId:48,tocIndex:7},{value:"同样也可以对它",paraId:49,tocIndex:8},{value:"应用动画",paraId:50,tocIndex:8},{value:"，例如对 transform stroke 和 opacity 这三个属性：",paraId:49,tocIndex:8},{value:"lineArrow.animate(\n    [\n        { transform: 'scale(1)', stroke: '#F04864', opacity: 1 },\n        { transform: 'scale(2)', stroke: '#1890FF', opacity: 0.8 },\n    ],\n    {\n        duration: 1500,\n        iterations: Infinity,\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n    },\n);\n",paraId:51,tocIndex:8},{value:"完整 DEMO",paraId:52},{value:"自定义图形也可以",paraId:53,tocIndex:9},{value:"响应事件",paraId:54,tocIndex:9},{value:"，例如当鼠标移入移出时更改颜色：",paraId:53,tocIndex:9},{value:"lineArrow.addEventListener('mouseenter', () => {\n    lineArrow.style.stroke = '#2FC25B';\n});\nlineArrow.addEventListener('mouseleave', () => {\n    lineArrow.style.stroke = '#1890FF';\n});\n",paraId:55,tocIndex:9},{value:"自定义属性有可能发生更新，例如在创建后改变箭头端点的样式，因此需要监听属性值的变化。参考 Web Components 标准，我们提供了以下生命周期方法供子类实现，这里我们着重关注 attributeChangedCallback。",paraId:56,tocIndex:10},{value:"export interface CustomElement<CustomElementStyleProps> {\n  /**\n   * 加入画布时触发\n   */\n  connectedCallback?(): void;\n\n  /**\n   * 从画布移除时触发\n   */\n  disconnectedCallback?(): void;\n\n  /**\n   * 属性发生修改时触发\n   */\n  attributeChangedCallback?<Key extends keyof CustomElementStyleProps>(\n    name: Key,\n    oldValue: CustomElementStyleProps[Key],\n    newValue: CustomElementStyleProps[Key],\n  ): void;\n}\n",paraId:57,tocIndex:10},{value:"在我们的 ",paraId:58,tocIndex:10},{value:"DEMO",paraId:59,tocIndex:10},{value:" 中，可以随时切换端点和躯干图形。例如切换起始端点为一个图片：",paraId:58,tocIndex:10},{value:"const image = new Image({\n    style: {\n        width: 50,\n        height: 50,\n        anchor: [0.5, 0.5],\n        src: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*N4ZMS7gHsUIAAAAAAAAAAABkARQnAQ',\n    },\n});\nimage.rotateLocal(90);\n// 修改起始端点\nlineArrow.style.startHead = image;\n",paraId:60,tocIndex:10},{value:"此时我们可以监听 startHead 属性的更新，当该属性发生修改时，首先需要移除已存在的起始端点，然后再重新添加：",paraId:61,tocIndex:10},{value:"attributeChangedCallback<Key extends keyof ArrowStyleProps>(\n  name: Key,\n  oldValue: ArrowStyleProps[Key],\n  newValue: ArrowStyleProps[Key],\n) {\n  if (name === 'startHead' || name === 'endHead') {\n    const isStart = name === 'startHead';\n    // 移除已有的端点\n    this.destroyArrowHead(isStart);\n\n    if (newValue) {\n      const { body, startHead, endHead, ...rest } = this.attributes;\n      // 重新添加端点\n      this.appendArrowHead(this.getArrowHeadType(newValue), isStart);\n      this.applyArrowStyle(rest, [isStart ? this.startHead : this.endHead]);\n    }\n  }\n}\n",paraId:62,tocIndex:10},{value:"其中移除端点使用到了 removeChild，这同样是场景图提供的节点操作方法：",paraId:63,tocIndex:10},{value:"private destroyArrowHead(isStart: boolean) {\n  if (isStart && this.startHead) {\n    this.removeChild(this.startHead);\n    this.startHead = undefined;\n  }\n  if (!isStart && this.endHead) {\n    this.removeChild(this.endHead);\n    this.endHead = undefined;\n  }\n}\n",paraId:64,tocIndex:10},{value:"一旦挂载到画布后，自定义组件就视作一个整体，内部的图形不能再通过场景图查询能力（例如 getElementById）获得。因此可以暴露方法给使用者，例如获取箭头的躯干、端点部分。",paraId:65,tocIndex:11},{value:"getBody() {\n  return this.body;\n}\n\ngetStartHead() {\n  return this.startHead;\n}\n\ngetEndHead() {\n  return this.endHead;\n}\n",paraId:66,tocIndex:11}]},52831:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(87587);const n=[{value:"在之前的",paraId:0},{value:"入门教程",paraId:1},{value:"中，我们已经掌握了如何为图形添加事件监听器。在本教程中我们将深入了解监听器被触发时，事件对象上一些有用的属性和方法，同时理解事件传播路径，最终实现一个简单的事件委托效果。",paraId:0},{value:"最终示例：",paraId:2},{value:"官网示例",paraId:3},{value:"CodeSandbox 示例",paraId:4},{value:"这次我们的场景十分简单，类似 DOM 中的 ul/li：",paraId:5,tocIndex:0},{value:"Group(ul)\n    - Rect(li)\n    - Rect(li)\n",paraId:6,tocIndex:0},{value:"我们希望给 ul 下每个 li 增加点击事件监听，最直接的做法当然是：",paraId:7,tocIndex:0},{value:"li1.addEventListener('click', () => {});\nli2.addEventListener('click', () => {});\n",paraId:8,tocIndex:0},{value:"这没有任何问题，但每次给 ul 添加新的 li 时，都需要添加这样的一个监听器，有没有“一劳永逸”的方法呢？",paraId:9,tocIndex:0},{value:"在引入事件委托之前，我们先来看看事件传播机制。由于我们完全兼容 DOM Event API，不妨借用 MDN 上的教程来说明。在下图中，当我们点击 ",paraId:10,tocIndex:0},{value:"<video>",paraId:10,tocIndex:0},{value:" 元素时，会依次触发捕获（capturing）和冒泡（bubbling）两个阶段，前者从根节点一路进行到目标节点，触发路径上每个节点的 onclick 事件监听器（如有），后者则相反。",paraId:10,tocIndex:0},{value:"https://developer.mozilla.org/zh-CN/docs/Learn/JavaScript/Building_blocks/Events",paraId:11,tocIndex:0},{value:"在我们的示例场景中，点击每一个 li 时同样也会经历上述传播阶段，因此只需要在父节点 ul 上监听即可，事件自然会冒泡上来，这就是事件委托：",paraId:12,tocIndex:0},{value:"ul.addEventListener('click', (ev) => {\n    ev.target; // li1 li2...\n});\n",paraId:13,tocIndex:0},{value:"事件对象上有很多有用的属性，我们先来看看上一节中提到的事件传播路径，通过",paraId:14,tocIndex:1},{value:"composedPath()",paraId:15,tocIndex:1},{value:"方法可以获取它。当我们点击 li1 时，此时路径会返回如下结果：",paraId:14,tocIndex:1},{value:"ev.composedPath(); // [Rect(li1), Group(ul), Group(root), Document, Canvas];\n",paraId:16,tocIndex:1},{value:"该结果是一个数组，依次展示了从事件触发的目标节点到根节点的路径，我们从后往前看：",paraId:17,tocIndex:1},{value:"Canvas",paraId:18,tocIndex:1},{value:" 即画布对象，可以对应 ",paraId:19,tocIndex:1},{value:"window",paraId:19,tocIndex:1},{value:"Document",paraId:20,tocIndex:1},{value:" 文档，可以对应 ",paraId:19,tocIndex:1},{value:"window.document",paraId:19,tocIndex:1},{value:"Group(root)",paraId:21,tocIndex:1},{value:" 文档根节点，可以对应 ",paraId:19,tocIndex:1},{value:"window.document.documentElement",paraId:19,tocIndex:1},{value:"除了事件传播路径，事件对象上其他的常用属性有：",paraId:22,tocIndex:1},{value:"target",paraId:23,tocIndex:1},{value:" 返回当前触发事件的图形",paraId:24,tocIndex:1},{value:"currentTarget",paraId:25,tocIndex:1},{value:" 总是指向事件绑定的图形",paraId:24,tocIndex:1},{value:"各个坐标系下的",paraId:24,tocIndex:1},{value:"事件坐标",paraId:26,tocIndex:1},{value:"还有一些常见的需求可以在绑定事件时做到，例如绑定一个“一次性”的监听器：",paraId:27,tocIndex:2},{value:"circle.addEventListener('click', () => {}, { once: true });\n",paraId:28,tocIndex:2},{value:"再比如注册一个仅在事件捕获阶段执行的监听器：",paraId:29,tocIndex:2},{value:"circle.addEventListener('click', () => {}, { capture: true });\n// 或者\ncircle.addEventListener('click', () => {}, true);\n",paraId:30,tocIndex:2},{value:"更多用法可以参考 ",paraId:31,tocIndex:2},{value:"addEventListener()",paraId:32,tocIndex:2},{value:" 的文档。",paraId:31,tocIndex:2}]},4718:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(21973);const n=[{value:"Some chart libraries offer the ability to save content to an image, the image below is from ",paraId:0},{value:"Highcharts",paraId:0},{value:"：",paraId:0},{value:"For this purpose, we provide ",paraId:1},{value:"g-image-exporter",paraId:1},{value:", which supports functions such as selecting canvas area, exporting dataURL in specified format or saving it as image, ",paraId:1},{value:"example",paraId:2},{value:". Some of the functions depend on DOM API, for non-browser environment, please refer to [special platform adaptation of canvas](/en/api/canvas#special platform adaptation). For example, the download function needs to be implemented by ",paraId:1},{value:"document.createElement('a')",paraId:1},{value:", non-browser environment needs to pass ",paraId:1},{value:"document",paraId:1},{value:" object by itself.",paraId:1},{value:"When creating, you can specify the following configuration items, where ",paraId:3,tocIndex:0},{value:"canvas",paraId:3,tocIndex:0},{value:" is required, to pass the canvas into.",paraId:3,tocIndex:0},{value:"import { ImageExporter } from '@antv/g-image-exporter';\n\nconst exporter = new ImageExporter({\n    canvas, // pass canvas in\n    defaultFilename: 'my-default-filename',\n});\n",paraId:4,tocIndex:0},{value:"When calling ",paraId:5,tocIndex:1},{value:"downloadImage",paraId:6,tocIndex:1},{value:" to save and download an image, the value of this configuration item will be used as the default file name if no file name is specified.",paraId:5,tocIndex:1},{value:"This method is used to draw the canvas content of the specified area to an additional HTMLCanvasElement, which can then be further processed as needed, such as adding background colors, watermarks, etc.",paraId:7,tocIndex:3},{value:"The full method signature is as follows, and the method is ",paraId:8,tocIndex:3},{value:"asynchronous",paraId:8,tocIndex:3},{value:".",paraId:8,tocIndex:3},{value:"toCanvas(options: Partial<CanvasOptions> = {}): Promise<HTMLCanvasElement>;\n\ninterface CanvasOptions {\n  clippingRegion: Rectangle;\n  beforeDrawImage: (context: CanvasRenderingContext2D) => void;\n  afterDrawImage: (context: CanvasRenderingContext2D) => void;\n}\n",paraId:9,tocIndex:3},{value:"The meaning of each configuration item is as follows.",paraId:10,tocIndex:3},{value:"clippingRegion",paraId:11,tocIndex:3},{value:" The clipping region of the canvas, represented by a rectangle",paraId:11,tocIndex:3},{value:"beforeDrawImage",paraId:11,tocIndex:3},{value:" Called before drawing the content of the canvas, suitable for drawing the background color",paraId:11,tocIndex:3},{value:"afterDrawImage",paraId:11,tocIndex:3},{value:" is called after drawing the content of the canvas, suitable for drawing watermarks",paraId:11,tocIndex:3},{value:"ignoreElements",paraId:11,tocIndex:3},{value:" How to determine whether an HTMLElement in the container is ignored when exporting HTML content",paraId:11,tocIndex:3},{value:"In this ",paraId:12,tocIndex:3},{value:"example",paraId:13,tocIndex:3},{value:", we add a background color and watermark that can be drawn by passing in [CanvasRenderingContext2D](",paraId:12,tocIndex:3},{value:"https://developer.mozilla.org/en-US/",paraId:12,tocIndex:3},{value:" docs/Web/API/CanvasRenderingContext2D) can call the Canvas2D API to draw.",paraId:12,tocIndex:3},{value:"import { Rectangle } from '@antv/g';\n\nconst canvas = await exporter.toCanvas({\n    // Ignore DOM elements added inside containers such as stats.js lil-gui\n    ignoreElements: (element) => {\n        return [gui.domElement, stats.dom].indexOf(element) > -1;\n    },\n    // Specify the export canvas area\n    clippingRegion: new Rectangle(\n        clippingRegionX,\n        clippingRegionY,\n        clippingRegionWidth,\n        clippingRegionHeight,\n    ),\n    beforeDrawImage: (context) => {\n        // Drawing background color\n        context.fillStyle = backgroundColor;\n        context.fillRect(0, 0, clippingRegionWidth, clippingRegionHeight);\n    },\n    afterDrawImage: (context) => {\n        // Draw watermark\n        context.font = '24px Times New Roman';\n        context.fillStyle = '#FFC82C';\n        context.fillText('AntV', 20, 20);\n    },\n});\n",paraId:14,tocIndex:3},{value:"Note that the crop area uses ",paraId:15,tocIndex:3},{value:"Rectangle",paraId:15,tocIndex:3},{value:" instead of ",paraId:15,tocIndex:3},{value:"Rect",paraId:16,tocIndex:3},{value:" graphics. Its constructor contains four parameters ",paraId:15,tocIndex:3},{value:"x/y/width/height",paraId:15,tocIndex:3},{value:". It is relative to ",paraId:15,tocIndex:3},{value:"viewport coordinate system",paraId:17,tocIndex:3},{value:" under ",paraId:15,tocIndex:3},{value:"viewport",paraId:18,tocIndex:3},{value:", i.e. for a 400 x 400 canvas, the maximum width and height of the crop is 400.",paraId:15,tocIndex:3},{value:"When exporting ",paraId:19,tocIndex:3},{value:"HTML",paraId:20,tocIndex:3},{value:", all HTMLElement in the container will be exported by default, but sometimes some elements are not the ones we want to export, so we can use ",paraId:19,tocIndex:3},{value:"ignoreElements: (element: Element): boolean;",paraId:19,tocIndex:3},{value:" method to filter. For example, in this ",paraId:19,tocIndex:3},{value:"example",paraId:21,tocIndex:3},{value:" there are DOM elements added by stats.js and lil-gui in the container that we don't want to export, so we can.",paraId:19,tocIndex:3},{value:"ignoreElements: (element) => {\n    return [gui.domElement, stats.dom].indexOf(element) > -1;\n},\n",paraId:22,tocIndex:3},{value:"Sometimes we want to export vector images. Unlike ",paraId:23,tocIndex:4},{value:"toCanvas",paraId:24,tocIndex:4},{value:" which is supported for all renderers, only ",paraId:23,tocIndex:4},{value:"g-svg",paraId:25,tocIndex:4},{value:" renderer supports generating SVG type dataURL, if other renderer is selected, ",paraId:23,tocIndex:4},{value:"Promise<undefined>",paraId:23,tocIndex:4},{value:" will be returned.",paraId:23,tocIndex:4},{value:"The method signature is as follows.",paraId:26,tocIndex:4},{value:"toSVGDataURL(): Promise<string>;\n",paraId:27,tocIndex:4},{value:"Implemented internally using ",paraId:28,tocIndex:4},{value:"XMLSerializer",paraId:28,tocIndex:4},{value:" to serialize SVGElement into an XML string.",paraId:28,tocIndex:4},{value:"To trigger browser download behavior, you can pass ",paraId:29,tocIndex:5},{value:"exported dataURL",paraId:30,tocIndex:5},{value:" and specify the name of the saved file.",paraId:29,tocIndex:5},{value:"The full method signature is as follows.",paraId:31,tocIndex:5},{value:"downloadImage(options: DownloadImageOptions): void;\n\ninterface DownloadImageOptions {\n  dataURL: string;\n  name?: string;\n}\n",paraId:32,tocIndex:5},{value:"In this ",paraId:33,tocIndex:5},{value:"example",paraId:34,tocIndex:5},{value:", click the button to start downloading the image immediately, and if the ",paraId:33,tocIndex:5},{value:"image/png",paraId:33,tocIndex:5},{value:" format is selected, it will eventually be saved as a ",paraId:33,tocIndex:5},{value:"my-file.png",paraId:33,tocIndex:5},{value:" file.",paraId:33,tocIndex:5},{value:"const canvas = await exporter.toCanvas();\nconst dataURL = canvas.toDataURL();\n\n// Trigger downloading\nexporter.downloadImage({\n    dataURL,\n    name: 'my-file',\n});\n",paraId:35,tocIndex:5},{value:"The download behavior is achieved by creating an HTMLAnchorElement using ",paraId:36,tocIndex:5},{value:"document",paraId:36,tocIndex:5},{value:" and triggering its default click behavior.",paraId:36,tocIndex:5},{value:"With ",paraId:37,tocIndex:6},{value:"toCanvas",paraId:38,tocIndex:6},{value:" we get the HTMLCanvasElement containing the canvas content, using its native method [toDataURL](",paraId:37,tocIndex:6},{value:"https://developer.mozilla",paraId:37,tocIndex:6},{value:". org/en-cn/docs/Web/API/HTMLCanvasElement/toDataURL) to get the dataURL.",paraId:37,tocIndex:6},{value:"const canvas = await exporter.toCanvas();\nconst dataURL = canvas.toDataURL(); // data:...\n",paraId:39,tocIndex:6},{value:"The ",paraId:40,tocIndex:6},{value:"toDataURL",paraId:40,tocIndex:6},{value:" method allows you to specify the image format, which defaults to ",paraId:40,tocIndex:6},{value:"image/png",paraId:40,tocIndex:6},{value:", and the image quality, as described in [parameters] (",paraId:40,tocIndex:6},{value:"https://developer.mozilla.org/en-CN/docs/Web/API/HTMLCanvasElement/toDataURL#%E5%8F%82%E6%95%B0",paraId:40,tocIndex:6},{value:").",paraId:40,tocIndex:6},{value:"HTMLCanvasElement also provides the ",paraId:41,tocIndex:7},{value:"getImageData",paraId:41,tocIndex:7},{value:" method for getting pixel data of the specified area.",paraId:41,tocIndex:7},{value:"const canvas = await exporter.toCanvas();\nconst imageData = canvas.getContext('2d').getImageData(50, 50, 100, 100); // ImageData { width: 100, height: 100, data: Uint8ClampedArray[40000] }\n",paraId:42,tocIndex:7},{value:"If we also want to generate PDF based on the image in the front-end, you can refer to. ",paraId:43,tocIndex:8},{value:"https://github.com/parallax/jsPDF",paraId:43,tocIndex:8},{value:"The physical size of the exported image already includes resolution, i.e. for a canvas with a specified width and height of 400 x 400, if the ",paraId:44,tocIndex:10},{value:"devicePixelRatio",paraId:44,tocIndex:10},{value:" of the current environment is 2 devicePixelRatio) is 2, an 800 x 800 image will be generated.",paraId:44,tocIndex:10},{value:"Yes, if the canvas contains ",paraId:45,tocIndex:11},{value:"HTML",paraId:46,tocIndex:11},{value:", the different renderers currently implement the following.",paraId:45,tocIndex:11},{value:"Export SVG, which naturally contains ",paraId:47,tocIndex:11},{value:"foreignObject",paraId:47,tocIndex:11},{value:"export other image formats, which are implemented internally using ",paraId:47,tocIndex:11},{value:"html2canvas",paraId:47,tocIndex:11},{value:"In this ",paraId:48,tocIndex:11},{value:"example",paraId:49,tocIndex:11},{value:", the Tooltip in the top left corner is an HTML.",paraId:48,tocIndex:11},{value:"HTMLCanvasElement's native method ",paraId:50,tocIndex:12},{value:"toDataURL",paraId:50,tocIndex:12},{value:" is indeed a synchronization method.",paraId:50,tocIndex:12},{value:"However, since WebGL / Canvaskit uses a double buffering mechanism, with a drawing buffer and a display buffer, the advantage is that it is more efficient to swap directly than to copy the contents of the drawing buffer to the display buffer every frame. Therefore, we turn off ",paraId:51,tocIndex:12},{value:"preserveDrawingBuffer",paraId:51,tocIndex:12},{value:" when creating the WebGL context. the-effort), but need to make sure that the rendering is not cleared when calling toDataURL (calling ",paraId:51,tocIndex:12},{value:"gl.clear()",paraId:51,tocIndex:12},{value:"), which will cause the behavior to become asynchronous and wait for the next rendering tick to fetch the content.",paraId:51,tocIndex:12},{value:"Also when exporting ",paraId:52,tocIndex:12},{value:"HTML",paraId:53,tocIndex:12},{value:" content, using the export method provided by ",paraId:52,tocIndex:12},{value:"html2canvas",paraId:52,tocIndex:12},{value:" is also an asynchronous operation.",paraId:52,tocIndex:12},{value:"The export methods we provide are only for the canvas viewport range, even cropping is relative to ",paraId:54,tocIndex:13},{value:"viewport coordinate system",paraId:55,tocIndex:13},{value:". So if you want to export graphics outside the viewport, you can use ",paraId:54,tocIndex:13},{value:"camera API",paraId:56,tocIndex:13},{value:" to change the viewport range without changing the scene structure, for example by ",paraId:54,tocIndex:13},{value:"setZoom",paraId:54,tocIndex:13},{value:" to zoom in and out to allow more graphics to fit inside the viewport.",paraId:54,tocIndex:13},{value:"The HTMLCanvasElement's native method ",paraId:57,tocIndex:14},{value:"toDataURL",paraId:57,tocIndex:14},{value:" may not be supported on some ancient browsers, in which case you can use polyfill: ",paraId:57,tocIndex:14},{value:"https://stackoverflow.com/a/47148969",paraId:57,tocIndex:14},{value:"In this ",paraId:58,tocIndex:15},{value:"example",paraId:59,tocIndex:15},{value:", the exported SVG contains the following ",paraId:58,tocIndex:15},{value:"<style>",paraId:58,tocIndex:15},{value:" content, using CSS Animations to save some animation effects:",paraId:58,tocIndex:15},{value:"#g-svg-xx {\n  animation: u0 linear 2250ms infinite;\n}\n@keyframes u0{1.32%{transform:scale(0,1)}\n",paraId:60,tocIndex:15},{value:"But it should be noted that not all properties that support animation can be converted into CSS Animations representation, such as the path property used in [Deformation animation](/en/api/animation/waapi#Deformation animation). In addition, in ",paraId:61,tocIndex:15},{value:"EffectTiming",paraId:62,tocIndex:15},{value:", some configuration items are not supported by CSS Animations, so they cannot be reflected in the exported file:",paraId:61,tocIndex:15},{value:"easing function",paraId:63,tocIndex:15},{value:"endDelay",paraId:64,tocIndex:15},{value:"iterationStart",paraId:65,tocIndex:15},{value:"Finally, when using this feature, you need to ensure that all animation effects are paused before exporting. Only in this way can we ensure that the graphics are in the initial state at the moment of export, otherwise the state at the intermediate moment will be saved in SVG:",paraId:66,tocIndex:15},{value:"animation.pause();\nconst svgDataURL = await exporter.toSVGDataURL();\n",paraId:67,tocIndex:15}]},61217:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(93519);const n=[{value:'As browsers iterate over new features, they get bigger and bigger. Although we want to achieve a "small browser", in size sensitive scenarios, users still want to use a minimal feature set. This requires that we split the existing features in a reasonable way, trying to achieve a minimal core + incremental enhancements model.',paraId:0},{value:"The following figure shows the composition of the bundle ",paraId:1},{value:"@antv/g",paraId:1},{value:".",paraId:1},{value:"The full version ",paraId:2},{value:"@antv/g",paraId:2},{value:" consists of the following parts.",paraId:2},{value:"@antv/g-lite",paraId:3},{value:" Includes ",paraId:3},{value:"canvas",paraId:4},{value:", ",paraId:3},{value:"basic graphics",paraId:5},{value:", ",paraId:3},{value:"event system",paraId:6},{value:", ",paraId:3},{value:"plugins system",paraId:7},{value:" and other core functions",paraId:3},{value:"@antv/g-camera-api",paraId:3},{value:" Provides full camera motion and animation capabilities",paraId:3},{value:"@antv/g-web-animations-api",paraId:3},{value:" Provides an animation system compatible with the ",paraId:3},{value:"Web Animations API",paraId:3},{value:"@antv/g-css-typed-om-api",paraId:3},{value:" Provides CSS Typed OM API",paraId:3},{value:"@antv/g-css-layout-api",paraId:3},{value:" Provides CSS Layout API]",paraId:3},{value:"@antv/g-dom-mutation-observer-api",paraId:3},{value:" Provides DOM Mutation Observer API",paraId:3},{value:"The Lite version is identical to the full version in the use of core functions, such as creating canvases, basic graphics, using the renderer, etc.",paraId:8,tocIndex:0},{value:"import { Canvas, Circle } from '@antv/g-lite';\nimport { Renderer } from '@antv/g-canvas';\n",paraId:9,tocIndex:0},{value:"Calling the element's animation method at this point will have no effect。",paraId:10,tocIndex:0},{value:"circle.animate([], {});\n",paraId:11,tocIndex:0},{value:"Manual introduction of ",paraId:12,tocIndex:0},{value:"@antv/g-web-animations-api",paraId:12,tocIndex:0},{value:" is required for this to take effect.",paraId:12,tocIndex:0},{value:"import { Canvas, Circle } from '@antv/g-lite';\nimport '@antv/g-web-animations-api';\n",paraId:13,tocIndex:0},{value:"Other progressive features can be introduced on-demand using a similar approach.",paraId:14,tocIndex:0},{value:"The following is a detailed description of the functions of each part after splitting.",paraId:15,tocIndex:1},{value:"Contains core functions such as ",paraId:16,tocIndex:2},{value:"canvas",paraId:17,tocIndex:2},{value:", ",paraId:16,tocIndex:2},{value:"basic graphics",paraId:18,tocIndex:2},{value:", ",paraId:16,tocIndex:2},{value:"event system",paraId:19,tocIndex:2},{value:", ",paraId:16,tocIndex:2},{value:"plugins system",paraId:20,tocIndex:2},{value:".",paraId:16,tocIndex:2},{value:"There is no change in the way the above functions are used, ",paraId:21,tocIndex:2},{value:"example",paraId:22,tocIndex:2},{value:".",paraId:21,tocIndex:2},{value:"import { Canvas, Circle } from '@antv/g-lite';\nimport { Renderer } from '@antv/g-canvas';\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: new Renderer(),\n});\n\nconst circle = new Circle({\n    style: { r: 100 },\n});\n",paraId:23,tocIndex:2},{value:"@antv/g-lite",paraId:24,tocIndex:3},{value:" contains a simple camera implementation, but it does not work with ",paraId:24,tocIndex:3},{value:"camera action",paraId:25,tocIndex:3},{value:" and ",paraId:24,tocIndex:3},{value:"camera animation",paraId:26,tocIndex:3},{value:".",paraId:24,tocIndex:3},{value:"camera.pan(); // throw new Error('Method not implemented.');\ncamera.createLandmark(); // throw new Error('Method not implemented.');\n",paraId:27,tocIndex:3},{value:"Provides ",paraId:28,tocIndex:4},{value:"animation capabilities",paraId:29,tocIndex:4},{value:" for base graphics compatible with the ",paraId:28,tocIndex:4},{value:"Web Animations API",paraId:28,tocIndex:4},{value:". The ",paraId:28,tocIndex:4},{value:"object.animate()",paraId:28,tocIndex:4},{value:" method can still be called without this capability, but without any effect.",paraId:28,tocIndex:4},{value:"The ",paraId:30,tocIndex:5},{value:"CSS Typed OM API",paraId:30,tocIndex:5},{value:" allows parsed property values to be manipulated using JS, which is also the basis of CSS Houdini. In the case of ",paraId:30,tocIndex:5},{value:"width: '50%'",paraId:30,tocIndex:5},{value:", the property value in string form is parsed to ",paraId:30,tocIndex:5},{value:"CSS.percent(50)",paraId:30,tocIndex:5},{value:", facilitating the next calculation.",paraId:30,tocIndex:5},{value:"We provide ",paraId:31,tocIndex:5},{value:"similar capabilities",paraId:32,tocIndex:5},{value:".",paraId:31,tocIndex:5},{value:"Reference ",paraId:33,tocIndex:6},{value:"CSS Layout API",paraId:33,tocIndex:6},{value:" provides ",paraId:33,tocIndex:6},{value:"layout capabilities",paraId:34,tocIndex:6},{value:".",paraId:33,tocIndex:6},{value:"In the DOM API, we can use ",paraId:35,tocIndex:7},{value:"MutationObserver",paraId:35,tocIndex:7},{value:" when we want to sense modifications in the DOM tree nodes, such as new nodes added, attribute values changed.",paraId:35,tocIndex:7},{value:"In G we also implement this ",paraId:36,tocIndex:7},{value:"API",paraId:37,tocIndex:7},{value:" to listen to changes in the scene graph.",paraId:36,tocIndex:7},{value:"Methods compatible with older versions are provided on the base graphics, most of which have DOM API-compatible implementations in newer versions. The use of these methods is therefore not recommended and may be removed at any time subsequently.",paraId:38,tocIndex:8},{value:"getCount",paraId:39,tocIndex:8},{value:" Get the number of child nodes, the new version uses ",paraId:39,tocIndex:8},{value:"childElementCount",paraId:40,tocIndex:8},{value:"getParent",paraId:39,tocIndex:8},{value:" Get the parent, the new version uses ",paraId:39,tocIndex:8},{value:"parentElement",paraId:41,tocIndex:8},{value:"getChildren",paraId:39,tocIndex:8},{value:" Get the list of child nodes, the new version uses ",paraId:39,tocIndex:8},{value:"children",paraId:42,tocIndex:8},{value:"getFirst",paraId:39,tocIndex:8},{value:" Get the first child node, the new version uses ",paraId:39,tocIndex:8},{value:"firstElementChild",paraId:43,tocIndex:8},{value:"getLast",paraId:39,tocIndex:8},{value:" Get the last child node, the new version uses ",paraId:39,tocIndex:8},{value:"lastElementChild",paraId:44,tocIndex:8},{value:"getChildByIndex",paraId:39,tocIndex:8},{value:" the new version uses ",paraId:39,tocIndex:8},{value:"this.children[index]",paraId:39,tocIndex:8},{value:"add",paraId:39,tocIndex:8},{value:" the new version uses ",paraId:39,tocIndex:8},{value:"appendChild",paraId:45,tocIndex:8},{value:"setClip",paraId:39,tocIndex:8},{value:" the new version uses ",paraId:39,tocIndex:8},{value:"clipPath",paraId:46,tocIndex:8},{value:"getClip",paraId:39,tocIndex:8},{value:" ld.",paraId:39,tocIndex:8},{value:"set",paraId:39,tocIndex:8},{value:" Storing key-value pairs on initialized configurations",paraId:39,tocIndex:8},{value:"get",paraId:39,tocIndex:8},{value:" Read values on initialized configuration",paraId:39,tocIndex:8},{value:"show",paraId:39,tocIndex:8},{value:" the new version uses ",paraId:39,tocIndex:8},{value:"visibility",paraId:47,tocIndex:8},{value:"hide",paraId:39,tocIndex:8},{value:" ld.",paraId:39,tocIndex:8},{value:"moveTo",paraId:39,tocIndex:8},{value:" the new version uses ",paraId:39,tocIndex:8},{value:"setPosition",paraId:48,tocIndex:8},{value:"move",paraId:39,tocIndex:8},{value:" ld.",paraId:39,tocIndex:8},{value:"setZIndex",paraId:39,tocIndex:8},{value:" the new version uses ",paraId:39,tocIndex:8},{value:"zIndex",paraId:49,tocIndex:8}]},54474:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(71452);const n=[{value:"任何一个渲染引擎都会在性能优化上下足功夫，任何优化手段都需要结合场景与具体 API 应用。在我们的可视化场景（2D 图表、大规模图场景）中，高效绘制大量简单图形是一个核心诉求。下面我们结合 Canvas2D / SVG / WebGL 和 WebGPU 这些渲染 API 介绍目前在 G 中使用的优化手段。",paraId:0},{value:"首先我们需要引入一个核心概念 draw call，以下介绍的优化方法大多围绕它展开。",paraId:1},{value:"为啥 draw call 多了就会影响性能呢？在 CPU 和 GPU 进行异步协作的过程中，会向 ",paraId:2,tocIndex:0},{value:"command buffer",paraId:2,tocIndex:0},{value:" 中提交需要 GPU 执行的命令，例如设置状态、绘制或者拷贝资源。CPU 准备这些命令的速度与 GPU 执行的速度存在不小差异，这就造成了性能瓶颈。",paraId:2,tocIndex:0},{value:"下图来自 ",paraId:3,tocIndex:0},{value:"https://toncijukic.medium.com/draw-calls-in-a-nutshell-597330a85381，分别展示了每一帧中",paraId:3,tocIndex:0},{value:" CPU 和 GPU 的时间线，可以看出 GPU 总是在执行上一帧 CPU 提交的命令，与此同时 CPU 在准备下一帧的命令。当这些绘制命令数量不多时，两者协作没问题，但如果数量很多，GPU 在做完这一帧的渲染任务后就不得不等待，也就无法在 16ms 内完成了，这造成了卡顿的体感。",paraId:3,tocIndex:0},{value:"因此我们需要想办法减少 CPU 提交的绘制命令数量，即能少画就少画，能不画就不画。下面我们会介绍不同渲染 API 下常用的优化手段，它们各有适合的场景。",paraId:4,tocIndex:1},{value:"图场景中一种常见的交互是通过鼠标滚轮进行放大查看，此时场景中仅有一部分可见，大部分都在视口范围之外。如果我们能将视口之外的图形“剔除”掉，就能减少绘制命令的数量。",paraId:5,tocIndex:2},{value:"决定场景中一个图形是否需要绘制的标准是什么呢？在下图中，灰色区域代表画布视口，如果对象“处于”视口内，我们就画（绿色图形），反之则剔除（红色图形）。",paraId:6,tocIndex:2},{value:"在判断一个图形是否在视口内时，我们通常会使用一种称作“包围盒”的结构。图形可以千变万化，但总可以找到一个包裹住它的最小基础几何结构，这个结构可以是“包围盒”，也可以是“包围球”，总之是为何后续与视口求交方便。在 G 中我们选择轴对齐包围盒。推广到 3D 场景中，视口也变成了视锥，下图来自 ",paraId:7,tocIndex:2},{value:"Unreal - Visibility and Occlusion Culling",paraId:7,tocIndex:2},{value:"：",paraId:7,tocIndex:2},{value:"在每一帧都在 CPU 端进行这样的求交运算开销不小，特别当场景中图形数量较多时。另外在 3D 场景中视锥与包围盒（立方体）各个面的求交开销更大，因此我们也采用了一系列优化方法：",paraId:8,tocIndex:2},{value:"在 3D 场景进行视锥剔除时，我们尽量使用了如下",paraId:9,tocIndex:2},{value:"加速检测方法",paraId:9,tocIndex:2},{value:"：",paraId:9,tocIndex:2},{value:"基础相交测试 the basic intersection test",paraId:10,tocIndex:2},{value:"平面一致性测试 the plane-coherency test",paraId:10,tocIndex:2},{value:"八分测试 the octant test",paraId:10,tocIndex:2},{value:"标记 masking",paraId:10,tocIndex:2},{value:"平移旋转一致性测试 TR coherency test",paraId:10,tocIndex:2},{value:"更多可以参考：",paraId:11,tocIndex:2},{value:"Optimized View Frustum Culling Algorithms for Bounding Boxes",paraId:12,tocIndex:2},{value:"Efficient View Frustum Culling",paraId:12,tocIndex:2},{value:"视锥体剔除 AABB 和 OBB 包围盒的优化方法",paraId:12,tocIndex:2},{value:"在 2D 场景中我们使用了空间索引（R-tree）进行区域查询的加速。首次为场景对象构建索引需要消耗一定时间，后续当图形发生变换时，也需要随时更新。",paraId:13,tocIndex:2},{value:"最后，由于剔除发生在 CPU 侧，与具体渲染 API 无关，因此这是一种相对通用的优化手段。",paraId:14,tocIndex:2},{value:"在 WebGL / WebGPU 这样的渲染 API 中，还提供了其他剔除手段：",paraId:15,tocIndex:3},{value:"背面剔除，",paraId:16,tocIndex:3},{value:"gl.cullFace",paraId:16,tocIndex:3},{value:"遮挡剔除，",paraId:16,tocIndex:3},{value:"gl.createQuery",paraId:16,tocIndex:3},{value:"。至少需要 WebGL2，G 中暂未使用",paraId:16,tocIndex:3},{value:"另一种常见的交互是通过鼠标高亮某个图形。此时场景中仅有一小部分发生了改变，擦除画布中的全部图形再重绘就显得没有必要了。类比 React diff 算法能够找出真正变化的最小部分，“脏矩形”渲染能尽可能复用上一帧的渲染结果，仅绘制变更部分，特别适合 Canvas2D API。",paraId:17,tocIndex:4},{value:"下图展示了这个思路：",paraId:18,tocIndex:4},{value:"当鼠标悬停在圆上时，我们知道了对应的“脏矩形”，也就是这个圆的包围盒",paraId:19,tocIndex:4},{value:"找到场景中与这个包围盒区域相交的其他图形，这里找到了另一个矩形",paraId:19,tocIndex:4},{value:"使用 ",paraId:19,tocIndex:4},{value:"clearRect",paraId:19,tocIndex:4},{value:" 清除这个“脏矩形”，代替清空整个画布",paraId:19,tocIndex:4},{value:"按照 z-index 依次绘制一个矩形和圆形",paraId:19,tocIndex:4},{value:"在以上求交与区域查询的过程中，我们可以复用剔除方案中的优化手段，例如加速结构。",paraId:20,tocIndex:4},{value:"显然当动态变化的对象数目太多时，该优化手段就失去了意义，试想经过一番计算合并后的“脏矩形”几乎等于整个画布，那还不如直接清空重绘所有对象。因此例如 Pixi.js 这样的 2D 游戏渲染引擎就",paraId:21,tocIndex:4},{value:"不考虑内置",paraId:21,tocIndex:4},{value:"。",paraId:21,tocIndex:4},{value:"但在可视化这类相对静态的场景下就显得有意义了，例如在触发拾取后只更新图表的局部，其余部分保持不变。",paraId:22,tocIndex:4},{value:"我们将该渲染器特性做成了开关，可以随时",paraId:23,tocIndex:4},{value:"根据具体情况关闭",paraId:24,tocIndex:4},{value:"。",paraId:23,tocIndex:4},{value:"以上两种方法当然有不适合的场景，例如希望总览一个大规模图场景的全貌时，无法应用剔除（所有节点/边都在视口内）。拖拽移动整个场景时，“脏矩形”渲染效果也不佳（整个场景都变“脏”了）。",paraId:25,tocIndex:5},{value:"除了使用一些上层的 LOD 手段，例如缩放等级较高时，隐藏掉边和文本（因为也看不清），以此减少绘制命令数量之外，",paraId:26,tocIndex:5},{value:"draw call batching",paraId:26,tocIndex:5},{value:" 是非常合适的。",paraId:26,tocIndex:5},{value:"不同于 Canvas2D / Skia 提供的抽象层次较高的绘制 API，WebGL / WebGPU 提供了更低层次的 API，可以让我们将一批“同类”图形合并成一次绘制命令。在渲染引擎中，常用于渲染类似森林中大量树木这种场景。图场景同样十分契合，场景中包含大量同类但简单的图形（节点、边）。",paraId:27,tocIndex:5},{value:"结合我们的",paraId:28,tocIndex:5},{value:"这个教程",paraId:29,tocIndex:5},{value:"，配合 Chrome Spector.js 插件能看出，一次 draw call 完成了 8k 个节点的绘制，这是性能提升的关键：",paraId:28,tocIndex:5},{value:"通常创建出的 instance 仅具有原图形的部分能力。例如 Babylon.js 只允许每个 instance 在部分变换属性上",paraId:30,tocIndex:5},{value:"有差异",paraId:30,tocIndex:5},{value:"。在 G 中并不需要用户显式声明 instance，按照常规图形创建即可，内部会进行自动合并。",paraId:30,tocIndex:5},{value:"值得一提的是我们使用 SDF 绘制部分 2D 图形例如 Circle、Ellipse、Rect。一方面能减少顶点数目（通常三角化一个圆需要 30+ 三角形，SDF 固定 2 个），另一方面也增加了不同图形合并的可能性。",paraId:31,tocIndex:5},{value:"⚠️ 仅 ",paraId:32,tocIndex:6},{value:"g-webgl",paraId:32,tocIndex:6},{value:" 下生效。",paraId:32,tocIndex:6},{value:"当主线程需要处理较重的交互时，我们可以将 Canvas 的渲染工作交给 Worker 完成，主线程仅负责同步结果。目前很多渲染引擎已经支持，例如 ",paraId:33,tocIndex:6},{value:"Babylon.js",paraId:33,tocIndex:6},{value:"。",paraId:33,tocIndex:6},{value:"为了支持该特性，引擎本身并不需要做很多改造，只要能够保证 ",paraId:34,tocIndex:6},{value:"g-webgl",paraId:34,tocIndex:6},{value:" 能在 Worker 中运行即可。",paraId:34,tocIndex:6},{value:"由于运行在 Worker 环境，用户需要手动处理一些 DOM 相关的事件。",paraId:35,tocIndex:7},{value:"https://unrealartoptimization.github.io/book/pipelines/",paraId:36,tocIndex:8}]},39563:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(44328);const n=[{value:"react render for @antv/g",paraId:0,tocIndex:0},{value:"npm i @antv/react-g\n",paraId:1,tocIndex:1},{value:"react-g provide host-component:",paraId:2,tocIndex:2},{value:"Container: ",paraId:3,tocIndex:2},{value:"Canvas",paraId:3,tocIndex:2},{value:" and ",paraId:3,tocIndex:2},{value:"Group",paraId:3,tocIndex:2},{value:".",paraId:3,tocIndex:2},{value:"Shape: ",paraId:3,tocIndex:2},{value:"Text",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Circle",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Ellipse",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Image",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Line",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Marker",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Path",paraId:3,tocIndex:2},{value:", ",paraId:3,tocIndex:2},{value:"Polygon",paraId:3,tocIndex:2},{value:" and ",paraId:3,tocIndex:2},{value:"Polyline",paraId:3,tocIndex:2},{value:".",paraId:3,tocIndex:2},{value:"import React, { useState } from 'react';\nimport { Canvas, Circle } from '@antv/react-g';\nimport { Renderer as CanvasRenderer } from '@antv/g-canvas';\n\nconst renderer = new CanvasRenderer();\n\nconst App = () => {\n    const [size, setSize] = useState(50);\n    return (\n        <Canvas width={600} height={400} renderer={renderer}>\n            <Circle\n                x={100}\n                y={200}\n                r={size}\n                fill=\"#1890FF\"\n                stroke=\"#F04864\"\n                lineWidth={4}\n                onClick={() => {\n                    setSize(100);\n                }}\n            />\n        </Canvas>\n    );\n};\n\nexport default App;\n",paraId:4,tocIndex:3},{value:"Like react-dom, you can use ",paraId:5,tocIndex:4},{value:"ref",paraId:5,tocIndex:4},{value:" to access the shape instance.",paraId:5,tocIndex:4},{value:"import React, { useState, useRef } from 'react';\nimport { Canvas, Circle } from '@antv/react-g';\nimport { Renderer as CanvasRenderer } from '@antv/g-canvas';\n\nconst renderer = new CanvasRenderer();\n\nconst App = () => {\n    const circleRef = useRef();\n    const [size, setSize] = useState(50);\n    return (\n        <Canvas width={600} height={400} renderer={renderer}>\n            <Circle\n                ref={circleRef}\n                x={100}\n                y={200}\n                r={size}\n                fill=\"#1890FF\"\n                stroke=\"#F04864\"\n                lineWidth={4}\n                onClick={() => {\n                    setSize(100);\n                }}\n            />\n        </Canvas>\n    );\n};\n\nexport default App;\n",paraId:6,tocIndex:4},{value:"render",paraId:7},{value:"将 react-g 组件渲染到任意的 g 实例（Canvas/Group/Shape）中",paraId:8,tocIndex:5},{value:"意味着可以将 react-g 组件渲染到 g2,g6 等其他库中",paraId:8,tocIndex:5},{value:"import React, { useState } from 'react';\nimport { Canvas as GCanvas } from '@antv/g';\nimport { Circle, render } from '@antv/react-g';\nimport { Renderer as CanvasRenderer } from '@antv/g-canvas';\n\nconst renderer = new CanvasRenderer();\n\nconst CircleComponent = () => {\n    const [size, setSize] = useState(50);\n    return (\n        <Circle\n            x={100}\n            y={200}\n            r={size}\n            fill=\"#1890FF\"\n            stroke=\"#F04864\"\n            lineWidth={4}\n            onMouseenter={() => {\n                setSize(100);\n            }}\n            onMouseleave={() => {\n                setSize(50);\n            }}\n        />\n    );\n};\n\nconst canvas = new GCanvas({\n    container: 'container', // DOM 节点id\n    width: 600,\n    height: 500,\n    renderer,\n});\n\n// canvas can also be group/shape\nrender(<CircleComponent />, canvas);\n",paraId:9,tocIndex:5}]},84440:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(50090);const n=[{value:"In this tutorial series, we will step-by-step implement a simple visualization scene that shows nodes and edges and gives them basic interaction capabilities such as dragging and picking.",paraId:0},{value:"In this section, we will learn how to describe a scene using a ",paraId:1},{value:"scene graph",paraId:2},{value:".",paraId:1},{value:"Our scene is very simple, it contains two nodes implemented with ",paraId:3},{value:"Circle",paraId:4},{value:", an edge connecting them implemented with ",paraId:3},{value:"Line",paraId:5},{value:", where the text on each node is implemented with ",paraId:3},{value:"Text",paraId:6},{value:".",paraId:3},{value:"DEMO in CodeSandbox",paraId:7},{value:"First we import the base graph ",paraId:8,tocIndex:0},{value:"Circle",paraId:9,tocIndex:0},{value:" from ",paraId:8,tocIndex:0},{value:"@antv/g",paraId:8,tocIndex:0},{value:", which our node uses to implement:",paraId:8,tocIndex:0},{value:"import { Circle } from '@antv/g';\n",paraId:10,tocIndex:0},{value:"Then we need to define a set of properties for the graph：",paraId:11,tocIndex:0},{value:"const node1 = new Circle({\n    style: {\n        r: 100,\n        fill: '#1890FF',\n        stroke: '#F04864',\n        lineWidth: 4,\n    },\n});\n",paraId:12,tocIndex:0},{value:"We can create a second node in the same way.",paraId:13,tocIndex:0},{value:"We want to display descriptive text on the node, again we bring in the base graph ",paraId:14,tocIndex:1},{value:"Text",paraId:15,tocIndex:1},{value:" from ",paraId:14,tocIndex:1},{value:"@antv/g",paraId:14,tocIndex:1},{value:":",paraId:14,tocIndex:1},{value:"import { Text } from '@antv/g';\n\nconst text1 = new Text({\n    style: {\n        text: 'Node1',\n        fontFamily: 'Avenir',\n        fontSize: 22,\n        fill: '#fff',\n        textAlign: 'center',\n        textBaseline: 'middle',\n    },\n});\n",paraId:16,tocIndex:1},{value:"The text should be a child of the node, and in the scene graph, this parent-child relationship is constructed via ",paraId:17,tocIndex:1},{value:"appendChild",paraId:17,tocIndex:1},{value:"：",paraId:17,tocIndex:1},{value:"node1.appendChild(text1);\n",paraId:18,tocIndex:1},{value:"We only need to set the position of the node, and all its children (text) will follow:",paraId:19,tocIndex:1},{value:"node1.setPosition(200, 200);\n",paraId:20,tocIndex:1},{value:"We can import ",paraId:21,tocIndex:2},{value:"Line",paraId:22,tocIndex:2},{value:" from ",paraId:21,tocIndex:2},{value:"@antv/g",paraId:21,tocIndex:2},{value:" to connect the two endpoints:",paraId:21,tocIndex:2},{value:"import { Line } from '@antv/g';\n\nconst edge = new Line({\n    style: {\n        x1: 200,\n        y1: 200,\n        x2: 400,\n        y2: 200,\n        stroke: '#1890FF',\n        lineWidth: 2,\n    },\n});\n",paraId:23,tocIndex:2},{value:"At this point our scene is defined and in the next section we will render the scene using the renderer.",paraId:24,tocIndex:2}]},22210:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(57706);const n=[{value:"In this tutorial series, we will step-by-step implement a simple visualization scene that shows nodes and edges and gives them basic interaction capabilities such as dragging and picking.",paraId:0},{value:"In the previous section we defined a simple scene, in this section we will learn how to use ",paraId:1},{value:"renderer",paraId:2},{value:" to complete the rendering.",paraId:1},{value:"Example of this section",paraId:3},{value:"DEMO in CodeSandbox",paraId:4},{value:"First we need to introduce one or more renderers, and if we introduce more than one, we can also switch them ",paraId:5,tocIndex:0},{value:"at runtime",paraId:6,tocIndex:0},{value:". In this example we have selected only one Canvas2D renderer:",paraId:5,tocIndex:0},{value:"import { Renderer } from '@antv/g-canvas';\n\nconst renderer = new Renderer();\n",paraId:7,tocIndex:0},{value:"Then we need to create the canvas, using the renderer introduced above:.",paraId:8,tocIndex:1},{value:"const canvas = new Canvas({\n    container: 'container', // id of the DOM container\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:9,tocIndex:1},{value:"With the canvas, we can add two nodes and an edge from the scene graph to the canvas, but of course we have to wait until the canvas is ready. We have two ways to know when the canvas is ready, either by listening to the ",paraId:10,tocIndex:2},{value:"ready event",paraId:11,tocIndex:2},{value:" or ",paraId:10,tocIndex:2},{value:"waiting for the ready Promise to return",paraId:12,tocIndex:2},{value:".",paraId:10,tocIndex:2},{value:"canvas.addEventListener(CanvasEvent.READY, () => {\n    canvas.appendChild(node1);\n    canvas.appendChild(node2);\n    canvas.appendChild(edge);\n});\n\n// or\nawait canvas.ready;\ncanvas.appendChild(node1);\ncanvas.appendChild(node2);\ncanvas.appendChild(edge);\n",paraId:13,tocIndex:2},{value:"At this point you can see the rendering effect, but there is something strange, the edge appears on top of the node, even blocking the text:",paraId:14,tocIndex:2},{value:'This problem is caused by the order in which we added the shapes to the canvas. We added the "edge" to the canvas last, and according to the painter\'s algorithm, it was drawn last, so it appears at the top.',paraId:15,tocIndex:2},{value:"The simplest solution is to modify the order, drawing the edges first and then the nodes.",paraId:16,tocIndex:2},{value:"canvas.appendChild(edge);\ncanvas.appendChild(node1);\ncanvas.appendChild(node2);\n",paraId:17,tocIndex:2},{value:"At this point the effect is normal.",paraId:18,tocIndex:2},{value:"Alternatively, we can manually adjust the ",paraId:19,tocIndex:2},{value:"zIndex",paraId:19,tocIndex:2},{value:".",paraId:19,tocIndex:2},{value:"Similar to ",paraId:20,tocIndex:3},{value:"zIndex",paraId:20,tocIndex:3},{value:" in CSS, we can manually set the drawing order of the two nodes so that they are higher than the edge (default is 0)：",paraId:20,tocIndex:3},{value:"node1.style.zIndex = 1;\nnode2.style.zIndex = 1;\n",paraId:21,tocIndex:3},{value:"The basic graphics are drawn, so let's add some interaction.",paraId:22,tocIndex:3}]},36406:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(3882);const n=[{value:"In this tutorial series, we will step-by-step implement a simple visualization scene that shows nodes and edges and gives them basic interaction capabilities such as dragging and picking.",paraId:0},{value:"In this section, we will learn how to make graphics respond to events, ",paraId:1},{value:"example of this section",paraId:2},{value:". The following APIs will be involved：",paraId:1},{value:"Using ",paraId:3},{value:"addEventListener",paraId:4},{value:"Using ",paraId:3},{value:"style",paraId:5},{value:"Using ",paraId:3},{value:"translateLocal",paraId:6},{value:"DEMO in CodeSandbox",paraId:7},{value:"We want node 1 to respond to an activation event: turn the node red when the mouse is moved in, change the mouse style, and restore it when it is moved out.",paraId:8,tocIndex:0},{value:"As with the DOM API, we add event listeners to the graphics via ",paraId:9,tocIndex:0},{value:"addEventListener",paraId:10,tocIndex:0},{value:" to listen for mouseenter and mouseleave events.",paraId:9,tocIndex:0},{value:"node1.addEventListener('mouseenter', () => {\n    node1.style.fill = 'red';\n});\nnode1.addEventListener('mouseleave', () => {\n    node1.style.fill = '#1890FF';\n});\n",paraId:11,tocIndex:0},{value:"Then we can add the ",paraId:12,tocIndex:0},{value:"cursor",paraId:12,tocIndex:0},{value:' property to the node to set the [mouse hover style](/en/api/basic/display-object#mouse style), here we use the "finger" shape ',paraId:12,tocIndex:0},{value:"pointer",paraId:12,tocIndex:0},{value:".",paraId:12,tocIndex:0},{value:"const node1 = new Circle({\n    style: {\n        //...\n        cursor: 'pointer',\n    },\n});\n",paraId:13,tocIndex:0},{value:"Our ",paraId:14,tocIndex:0},{value:"event system",paraId:15,tocIndex:0},{value:" is fully compatible with the DOM Event API, which means that it is possible to bind/unbind event listeners, trigger custom events, delegate events, and more using the familiar API on the front-end. Besides the fact that these method names are better remembered, we will see another big advantage of it in the next section.",paraId:14,tocIndex:0},{value:"Dragging is a common interaction and we want to implement dragging for node 1 while changing the endpoint position of the edge.",paraId:16,tocIndex:1},{value:"We can certainly drag and drop by combining listening to the base events (pointerup, pointermove, pointerdown). But here we go with a simpler approach. Since our ",paraId:17,tocIndex:2},{value:"event system",paraId:18,tocIndex:2},{value:" is fully compatible with the DOM Event API, we can directly use a web-side off-the-shelf drag-and-drop library such as ",paraId:17,tocIndex:2},{value:"interact.js",paraId:17,tocIndex:2},{value:' to do most of the of the "dirty work". Instead, we only need to do two things:',paraId:17,tocIndex:2},{value:"Pass interact.js a fake context ",paraId:19,tocIndex:2},{value:"canvas.document",paraId:19,tocIndex:2},{value:" and node 1 to make it think it's operating on the real DOM",paraId:19,tocIndex:2},{value:"Changing the position of nodes and edge endpoints in the ",paraId:19,tocIndex:2},{value:"onmove",paraId:19,tocIndex:2},{value:" callback function of interact.js",paraId:19,tocIndex:2},{value:"import interact from 'interactjs';\n\n// Use interact.js\ninteract(node1, {\n    context: canvas.document, // Pass our fake DOM-like context\n}).draggable({\n    onmove: function (event) {\n        // Get the offset from interact.js\n        const { dx, dy } = event;\n        // Change the position of node 1\n        node1.translateLocal(dx, dy);\n        // Get the position of node 1\n        const [nx, ny] = node1.getLocalPosition();\n        // Changing the endpoint position of an edge\n        edge.style.x1 = nx;\n        edge.style.y1 = ny;\n    },\n});\n",paraId:20,tocIndex:2},{value:"You may have noticed that the mouse style automatically changes to a ",paraId:21,tocIndex:2},{value:"move",paraId:21,tocIndex:2},{value:" shape when dragging and dropping, thanks to interact.js. This is possible because ",paraId:21,tocIndex:2},{value:"interact.js",paraId:21,tocIndex:2},{value:' does not assume that it is necessarily running in the real DOM environment. In other words, we can "trick" G\'s graphics by disguising them as the DOM. By the same token, we can also use gesture libraries like ',paraId:21,tocIndex:2},{value:"hammer.js",paraId:22,tocIndex:2},{value:".",paraId:21,tocIndex:2},{value:"Back in the ",paraId:23,tocIndex:3},{value:"onmove",paraId:23,tocIndex:3},{value:" callback function, we need to change the position of the node, and the offset interact.js already tells us.",paraId:23,tocIndex:3},{value:"node1.translateLocal(dx, dy);\n",paraId:24,tocIndex:3},{value:"There are many other [transform operations](/en/api/basic/display-object#transform operations) like ",paraId:25,tocIndex:3},{value:"translateLocal",paraId:25,tocIndex:3},{value:", besides translation, you can also rotate and scale.",paraId:25,tocIndex:3},{value:"Changing the endpoint of an edge is also simple, and can be done by modifying its style attribute ",paraId:26,tocIndex:3},{value:"x1/y1",paraId:26,tocIndex:3},{value:", see ",paraId:26,tocIndex:3},{value:"Line",paraId:27,tocIndex:3},{value:" for further information.",paraId:26,tocIndex:3},{value:"edge.style.x1 = nx;\nedge.style.y1 = ny;\n",paraId:28,tocIndex:3},{value:"So this simple scene is complete, follow our subsequent tutorials to continue to understand the scene graph and camera.",paraId:29,tocIndex:3}]},5506:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(94524);const n=[{value:"通过 ",paraId:0},{value:"g-plugin-3d",paraId:1},{value:" 插件的支持，我们可以绘制 3D 图形，当然渲染器必须指定为 ",paraId:0},{value:"g-webgl",paraId:0},{value:"。",paraId:0},{value:"示例",paraId:2},{value:"创建画布和渲染器与之前的教程完全一致，注册 ",paraId:3,tocIndex:0},{value:"g-plugin-3d",paraId:4,tocIndex:0},{value:" 插件",paraId:3,tocIndex:0},{value:"import { Canvas, CanvasEvent } from '@antv/g';\nimport { Renderer } from '@antv/g-webgl';\nimport { Plugin as Plugin3D } from '@antv/g-plugin-3d';\n\n// create a renderer\nconst renderer = new Renderer();\nrenderer.registerPlugin(new Plugin3D());\n\n// create a canvas\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:5,tocIndex:0},{value:"在创建 3D 图形时，需要使用 ",paraId:6,tocIndex:1},{value:"材质",paraId:7,tocIndex:1},{value:" 和 ",paraId:6,tocIndex:1},{value:"几何",paraId:8,tocIndex:1},{value:"，它们都需要使用 GPU 底层资源（Buffer 和 Texture），创建时需要获取 GPU ",paraId:6,tocIndex:1},{value:"Device",paraId:9,tocIndex:1},{value:"：",paraId:6,tocIndex:1},{value:"(async () => {\n    // wait for canvas' initialization complete\n    await canvas.ready;\n\n    // use GPU device\n    const plugin = renderer.getPlugin('device-renderer');\n    const device = plugin.getDevice();\n})();\n",paraId:10,tocIndex:1},{value:"不同于各种各样的 2D 图形（Circle、Rect），3D 图形使用 Mesh（三角网格）描述，它的形状由 ",paraId:11,tocIndex:2},{value:"几何",paraId:12,tocIndex:2},{value:" 定义，外观样式由 ",paraId:11,tocIndex:2},{value:"材质",paraId:13,tocIndex:2},{value:" 定义。例如这里我们使用 ",paraId:11,tocIndex:2},{value:"CubeGeometry",paraId:14,tocIndex:2},{value:" 和 ",paraId:11,tocIndex:2},{value:"MeshBasicMaterial",paraId:15,tocIndex:2},{value:"：",paraId:11,tocIndex:2},{value:"import { MeshBasicMaterial, CubeGeometry, Mesh } from '@antv/g-plugin-3d';\n\n// 立方体几何\nconst cubeGeometry = new CubeGeometry(device, {\n    width: 200,\n    height: 200,\n    depth: 200,\n});\n// 基础材质\nconst basicMaterial = new MeshBasicMaterial(device);\n\nconst cube = new Mesh({\n    style: {\n        fill: '#1890FF',\n        opacity: 1,\n        geometry: cubeGeometry,\n        material: basicMaterial,\n    },\n});\n",paraId:16,tocIndex:2},{value:"创建好的 Mesh 和 2D 基础图形一样，可以进行变换。例如我们使用 \b",paraId:17,tocIndex:3},{value:"setPosition",paraId:17,tocIndex:3},{value:" 设置它的全局坐标：",paraId:17,tocIndex:3},{value:"cube.setPosition(300, 250, 0);\ncanvas.appendChild(cube);\n",paraId:18,tocIndex:3}]},79968:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(46989);const n=[{value:"在本教程中，我们将实现一个简单的 Scale-In 动画效果：",paraId:0},{value:"其中会涉及以下 API，如果你熟悉 CSS Animation 或者 ",paraId:1},{value:"Web Animations API",paraId:1},{value:"，使用时会相当轻松：",paraId:1},{value:"使用 ",paraId:2},{value:"animate",paraId:3},{value:" 创建一个 Animation 对象",paraId:2},{value:"使用 ",paraId:2},{value:"onfinish",paraId:4},{value:" 监听动画结束事件",paraId:2},{value:"最终示例：",paraId:5},{value:"官网示例",paraId:6},{value:"CodeSandbox 示例",paraId:7},{value:"在定义动画效果时，关键帧是一种非常好用的描述方式。通过用户定义对象在某几个“关键”时间点上的状态，渲染引擎自动完成插值让对象的这些属性连续变化。",paraId:8,tocIndex:0},{value:"我们很容易写出 Scale-In 效果对应的 CSS Animation，其中：",paraId:9,tocIndex:0},{value:"使用 ",paraId:10,tocIndex:0},{value:"animation",paraId:10,tocIndex:0},{value:" 定义了一组动画控制参数，例如 duration(0.5s), fill(both), easing 缓动函数",paraId:10,tocIndex:0},{value:"使用 ",paraId:10,tocIndex:0},{value:"keyframes",paraId:10,tocIndex:0},{value:" 定义了一组关键帧，这里对 transform 属性进行动画",paraId:10,tocIndex:0},{value:".scale-in-center {\n    animation: scale-in-center 0.5s cubic-bezier(0.25, 0.46, 0.45, 0.94) both;\n}\n@keyframes scale-in-center {\n    0% {\n        transform: scale(0);\n    }\n    100% {\n        transform: scale(1);\n    }\n}\n",paraId:11,tocIndex:0},{value:"如果理解了上述 CSS Animation 写法，那么就很容易将它转换成符合 Web Animations API 的代码：",paraId:12,tocIndex:0},{value:"circle.animate()",paraId:13,tocIndex:0},{value:" 将创建一个 ",paraId:13,tocIndex:0},{value:"Animation",paraId:14,tocIndex:0},{value:" 对象，上面有很多有用的属性和控制方法，我们很快就将看到",paraId:13,tocIndex:0},{value:"该方法拥有两个参数，第一个对应 keyframes，第二个则是动画控制参数",paraId:13,tocIndex:0},{value:"// 为 circle 创建一个 animation 对象\nconst scaleInCenter = circle.animate(\n    [\n        {\n            transform: 'scale(0)', // 起始关键帧\n        },\n        {\n            transform: 'scale(1)', // 结束关键帧\n        },\n    ],\n    {\n        duration: 500, // 持续时间\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)', // 缓动函数\n        fill: 'both', // 动画处于非运行状态时，该图形的展示效果\n    },\n);\n",paraId:15,tocIndex:0},{value:"恭喜你！此时这个 circle 已经可以运动起来了。",paraId:16,tocIndex:0},{value:"当我们想获知动画当前的状态，例如是否已经结束，或者想手动控制它的运行状态，例如暂停/恢复时，就需要使用到上一节创建的 Animation 对象。",paraId:17,tocIndex:1},{value:"例如我们想知道动画何时结束，有两种方式实现：",paraId:18,tocIndex:1},{value:"onfinsh",paraId:19,tocIndex:1},{value:" 设置一个回调函数",paraId:20,tocIndex:1},{value:"finished",paraId:21,tocIndex:1},{value:" 该对象是一个 Promise",paraId:20,tocIndex:1},{value:"animation.onfinish = (e) => {\n    console.log('finish!', e.target, e.target.playState);\n};\nanimation.finished.then(() => {\n    console.log('finish promise resolved');\n});\n",paraId:22,tocIndex:1},{value:"当我们想实现一组连续动画时，这个方法很好用。",paraId:23,tocIndex:1},{value:"再比如我们想手动暂停一个运行中的动画，就可以使用 ",paraId:24,tocIndex:1},{value:"pause()",paraId:25,tocIndex:1},{value:"：",paraId:24,tocIndex:1},{value:"animation.pause();\n",paraId:26,tocIndex:1},{value:"除了暂停，",paraId:27,tocIndex:1},{value:"Animation 完整方法",paraId:28,tocIndex:1},{value:"中还包含了恢复、停止、重启、反向播放、设置播放速度（加减速）等。",paraId:27,tocIndex:1},{value:"除了这个简单的 Scale-In 效果，我们还能实现更多复杂效果，例如：",paraId:29,tocIndex:2},{value:"offsetDistance",paraId:30,tocIndex:2},{value:" 属性可以实现",paraId:30,tocIndex:2},{value:"路径动画",paraId:31,tocIndex:2},{value:"lineDashOffset",paraId:30,tocIndex:2},{value:" 属性可以实现",paraId:30,tocIndex:2},{value:"蚂蚁线动画",paraId:32,tocIndex:2},{value:"lineDash",paraId:30,tocIndex:2},{value:" 属性可以实现",paraId:30,tocIndex:2},{value:"笔迹动画",paraId:33,tocIndex:2},{value:"Path 的 ",paraId:30,tocIndex:2},{value:"path",paraId:30,tocIndex:2},{value:" 属性可以实现",paraId:30,tocIndex:2},{value:"形变动画（Morph）",paraId:34,tocIndex:2}]},40881:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(42070);const n=[{value:"Box2D",paraId:0},{value:" 物理引擎提供了一系列针对刚体的仿真计算，例如重力和表面摩擦力。另外，在任意时刻也可以施加外力改变图形的位置和旋转角度，这为我们实现一些基于真实物理规则的布局提供了帮助。",paraId:0},{value:"通过 ",paraId:1},{value:"g-plugin-box2d",paraId:2},{value:" 插件的支持，我们可以给已有的大部分 2D 图形增加物理属性。",paraId:1},{value:"在该",paraId:3},{value:"示例",paraId:4},{value:"中，我们创建了一系列动态物体，让它们进行自由落体，最终停留在“U 形槽”中。",paraId:3},{value:"创建一个渲染器并注册插件：",paraId:5,tocIndex:0},{value:"import { Canvas, CanvasEvent } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\nimport { Plugin as PluginBox2D } from '@antv/g-plugin-box2d';\n\nconst renderer = new Renderer();\nconst plugin = new PluginBox2D();\nrenderer.registerPlugin(plugin);\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:6,tocIndex:0},{value:"此时我们的“物理世界”已经存在默认的重力 ",paraId:7,tocIndex:0},{value:"gravity",paraId:8,tocIndex:0},{value:"，如果要修改它，可以这样做：",paraId:7,tocIndex:0},{value:"const plugin = new PluginBox2D({\n    gravity: [0, 200],\n});\n",paraId:9,tocIndex:0},{value:"我们使用 ",paraId:10,tocIndex:1},{value:"Line",paraId:11,tocIndex:1},{value:" 创建一个平地，需要特别注意 ",paraId:10,tocIndex:1},{value:"rigid",paraId:12,tocIndex:1},{value:" 属性，设置为 ",paraId:10,tocIndex:1},{value:"static",paraId:10,tocIndex:1},{value:" 表明它不受重力等作用力影响：",paraId:10,tocIndex:1},{value:"const ground = new Line({\n    style: {\n        x1: 50,\n        y1: 400,\n        // 省略其他属性\n        rigid: 'static',\n    },\n});\ncanvas.appendChild(ground);\n",paraId:13,tocIndex:1},{value:"接下来我们创建一个受重力影响的“弹力球”，其中：",paraId:14,tocIndex:2},{value:"density",paraId:15,tocIndex:2},{value:" 表示物体密度，单位为千克/立方米",paraId:16,tocIndex:2},{value:"restitution",paraId:17,tocIndex:2},{value:" 表示弹力系数",paraId:16,tocIndex:2},{value:"const circle = new Circle({\n    style: {\n        fill: '#1890FF',\n        r: 50,\n        rigid: 'dynamic',\n        density: 10,\n        restitution: 0.5,\n    },\n});\ncanvas.appendChild(circle);\n",paraId:18,tocIndex:2},{value:"插件会自动完成仿真过程，你可以看到小球自由落体至地面并弹起。",paraId:19,tocIndex:3}]},46189:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(66847);const n=[{value:"相机（Camera）描述了我们观察世界的角度，视点、相机位置都会影响最终的成像。它适用于 2D 和 3D 场景。在创建 Canvas 画布时，我们已经内置了一个默认相机，它使用正交投影，后续可以随时改变它的投影模式以及其他参数。通过控制相机，我们能轻松实现某些过去需要移动整个画布的操作，甚至能实现相机动画。\b",paraId:0},{value:"在之前的教程中，我们已经掌握了如何创建场景、使用渲染器、监听事件。在本教程中，我们将在一个包含数千个图形的复杂场景中，通过相机实现场景的平移和缩放操作，",paraId:1},{value:"g-webgl",paraId:1},{value:" 渲染器将保证交互过程的流畅。",paraId:1},{value:"其中会涉及以下 API：",paraId:2},{value:"使用 ",paraId:3},{value:"getCamera()",paraId:4},{value:" 获取画布相机",paraId:3},{value:"使用 ",paraId:3},{value:"setZoom()",paraId:5},{value:" 设置相机缩放参数",paraId:3},{value:"使用 ",paraId:3},{value:"pan()",paraId:6},{value:" 平移相机",paraId:3},{value:"使用 ",paraId:3},{value:"createLandmark()",paraId:7},{value:" 创建相机动画",paraId:3},{value:"最终示例：",paraId:8},{value:"官网示例",paraId:9},{value:"CodeSandbox 示例",paraId:10},{value:"我们和之前一样创建一个画布，不同的是我们选择 ",paraId:11,tocIndex:0},{value:"g-webgl",paraId:11,tocIndex:0},{value:" 渲染器：",paraId:11,tocIndex:0},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-webgl';\n\n// 创建 WebGL 渲染器\nconst webglRenderer = new Renderer();\n\n// 创建画布\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: webglRenderer,\n});\n",paraId:12,tocIndex:0},{value:"这次我们的场景中包含大量的节点、边以及文本，节点和边的位置信息直接使用预计算的结果，我们通过 fetch 请求这个包含了结果的 JSON 数据：",paraId:13,tocIndex:1},{value:"fetch('https://gw.alipayobjects.com/os/basement_prod/xxxx.json')\n    .then((res) => res.json())\n    .then((data) => {\n        // 使用包含了节点、边位置信息的数据\n    });\n",paraId:14,tocIndex:1},{value:"我们使用 ",paraId:15,tocIndex:1},{value:"Line",paraId:16,tocIndex:1},{value:" 表现边，",paraId:15,tocIndex:1},{value:"Circle",paraId:17,tocIndex:1},{value:" 表现节点，",paraId:15,tocIndex:1},{value:"Text",paraId:18,tocIndex:1},{value:" 表现文本：",paraId:15,tocIndex:1},{value:"// 使用预计算结果渲染边\ndata.edges.forEach(({ startPoint, endPoint }) => {\n    const line = new Line({\n        style: {\n            x1: startPoint.x * 10,\n            y1: startPoint.y * 10,\n            x2: endPoint.x * 10,\n            y2: endPoint.y * 10,\n            stroke: '#1890FF',\n            lineWidth: 3,\n        },\n    });\n\n    canvas.appendChild(line);\n});\n// 省略渲染节点、文本\n",paraId:19,tocIndex:1},{value:"到这里都和之前的教程没有太大不同，接下来我们会给场景增加一些交互。",paraId:20,tocIndex:1},{value:"我们希望给整个场景添加缩放、平移这两个交互，通过相机来实现。",paraId:21,tocIndex:2},{value:"前面提到过，每个画布内置了一个相机，我们可以使用 ",paraId:22,tocIndex:3},{value:"getCamera",paraId:23,tocIndex:3},{value:" 获取画布相机：",paraId:22,tocIndex:3},{value:"const camera = canvas.getCamera();\n",paraId:24,tocIndex:3},{value:"我们希望通过鼠标滚轮实现对于整个场景的缩放，很自然的，我们使用 addEventListener 监听 wheel 事件。在获取到原生滚轮事件对象上携带的 deltaY 信息后，我们调用 ",paraId:25,tocIndex:4},{value:"setZoom()",paraId:26,tocIndex:4},{value:" 设置相机缩放参数，当然通过 ",paraId:25,tocIndex:4},{value:"getZoom()",paraId:27,tocIndex:4},{value:" 可以随时获取这个参数。当这个参数的值大于 1 时代表放大（好比我们拿着一个放大镜观察世界），小于 1 时代表缩小：",paraId:25,tocIndex:4},{value:"// 设置最小和最大缩放比例\nconst minZoom = 0;\nconst maxZoom = Infinity;\ncanvas.addEventListener(\n    'wheel',\n    (e) => {\n        e.preventDefault();\n        let zoom;\n        if (e.deltaY < 0) {\n            zoom = Math.max(\n                minZoom,\n                Math.min(maxZoom, camera.getZoom() / 0.95),\n            );\n        } else {\n            zoom = Math.max(\n                minZoom,\n                Math.min(maxZoom, camera.getZoom() * 0.95),\n            );\n        }\n\n        // 设置相机缩放参数\n        camera.setZoom(zoom);\n    },\n    { passive: false },\n);\n",paraId:28,tocIndex:4},{value:"有了缩放，很自然地我们也想实现利用鼠标拖拽完成场景的平移。在",paraId:29,tocIndex:5},{value:"入门教程",paraId:30,tocIndex:5},{value:"中我们借助 interact.js 实现了节点的拖拽，这里我们使用 hammer.js 帮助我们完成手势操作。",paraId:29,tocIndex:5},{value:"直接将我们的画布传给 hammer.js，并让它监听 pan 事件，得益于对 DOM API 的兼容，我们再次“欺骗”了它。hammer.js 会给事件对象加上 deltaX/Y，即鼠标移动过程中水平和垂直方向上的偏移量：",paraId:31,tocIndex:5},{value:"import Hammer from 'hammerjs';\nconst hammer = new Hammer(canvas);\n// 监听 pan 手势\nhammer.on('pan', (ev) => {\n    // 完成我们的逻辑\n    // ev.deltaX/Y 为水平/垂直方向的偏移量\n});\n",paraId:32,tocIndex:5},{value:"接下来让我们根据偏移量使用 ",paraId:33,tocIndex:5},{value:"pan()",paraId:34,tocIndex:5},{value:" 来平移相机，需要注意的是，当我们向右拖拽鼠标想让场景向右平移时，需要让相机向左移动，这也和我们的生活常识相符：",paraId:33,tocIndex:5},{value:"// 沿水平/垂直方向移动相机\ncamera.pan(-ev.deltaX, -ev.deltaY);\n",paraId:35,tocIndex:5},{value:"最后让我们做一个小小的优化，当放大场景时，我们希望移动的幅度小一点，反之当场景被缩小时，我们希望更快速地进行移动。因此我们可以根据相机当前的缩放参数来实现，使用 ",paraId:36,tocIndex:5},{value:"getZoom()",paraId:37,tocIndex:5},{value:" 获取它：",paraId:36,tocIndex:5},{value:"const zoom = Math.pow(2, camera.getZoom());\ncamera.pan(-ev.deltaX / zoom, -ev.deltaY / zoom);\n",paraId:38,tocIndex:5},{value:"既然平移相机等价于反向操作画布，那前者相比后者的优势是什么呢？",paraId:39,tocIndex:6},{value:"camera.pan(100, 100);\n// 等价于反向移动根节点\ncanvas.document.documentElement.translate(-100, -100);\n",paraId:40,tocIndex:6},{value:"简单来说，当我们改变根节点的位置时，整个画布中的图形都需要重绘。具体到内部实现，每个图形在世界坐标系下的变换矩阵都需要重新计算。把矩阵计算过程放在 Shader 中交给 GPU 完成能带来明显的性能提升，显然只有配合 ",paraId:41,tocIndex:6},{value:"g-webgl",paraId:41,tocIndex:6},{value:" 才能发挥效果。",paraId:41,tocIndex:6},{value:"矩阵计算过程可以分解成相机矩阵和每个图形的模型矩阵。后者是需要考虑父节点，因此当我们改变根节点时，每个图形的模型矩阵都需要在 CPU 端重新计算后传给 GPU，而如果只改变相机矩阵，将极大程度减少 CPU 的运算量：",paraId:42,tocIndex:6},{value:"// MVP 矩阵 = 相机矩阵 * 模型矩阵\nmat4 MVPMatrix = ProjectionViewMatrix * ModelMatrix;\n",paraId:43,tocIndex:6},{value:"除了使用 pan 平移相机，我们还可以进行以下",paraId:44,tocIndex:7},{value:"相机动作",paraId:45,tocIndex:7},{value:"：",paraId:44,tocIndex:7},{value:"dolly()",paraId:46,tocIndex:7},{value:" 沿 n 轴移动相机。正交投影下没有“近大远小”，因此不会对画面产生影响。",paraId:47,tocIndex:7},{value:"rotate()",paraId:48,tocIndex:7},{value:" 按相机方位角旋转，逆时针方向为正。",paraId:47,tocIndex:7},{value:"另外在 3D 场景中，我们还可以使用",paraId:49,tocIndex:7},{value:"透视投影",paraId:50,tocIndex:7},{value:"代替默认的正交投影。",paraId:49,tocIndex:7},{value:"最后，",paraId:51,tocIndex:7},{value:"相机动画",paraId:52,tocIndex:7},{value:"能让我们在不同视角间平滑切换。",paraId:51,tocIndex:7}]},51036:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(9600);const n=[{value:"The G API is as consistent as possible with the DOM API, so some of the DOM API-oriented libraries in the Web ecosystem can be accessed at very low cost, for example ",paraId:0},{value:"using the Hammer.js gesture library",paraId:1},{value:", ",paraId:0},{value:"using the Interact.js drag-and-drop library",paraId:2},{value:". For them, G's ",paraId:0},{value:"event API",paraId:3},{value:" and the DOM Events API are identical:",paraId:0},{value:"import Hammer from 'hammerjs';\n\n// Give Hammer.js the Circle as a DOM element directly\nconst hammer = new Hammer(circle);\nhammer.on('press', (e) => {\n    console.log(\"You're pressing me!\");\n    console.log(e.target); // circle\n});\n",paraId:4},{value:"Similarly, for ",paraId:5},{value:"D3",paraId:5},{value:", it is perfectly possible to take over its internal default SVG (which is also part of the DOM API) rendering, done using Canvas or WebGL, while retaining its data-driven capabilities.",paraId:5},{value:"In the following ",paraId:6},{value:"example",paraId:7},{value:', we use several tutorial examples from Fullstack D3 to switch the rendering API with a "one-line" code change while retaining most of the D3 style code We\'ll use a few examples from Fullstack D3 to implement ',paraId:6},{value:"D3 data processing + G rendering",paraId:6},{value:", while keeping most of the D3 style code. You can switch between Canvas, WebGL and SVG rendering at runtime.",paraId:6},{value:"Some stylized rendering plugins can also be used directly, such as ",paraId:8},{value:"g-plugin-rough-canvas-renderer",paraId:9},{value:" for hand-drawn styling of the bar chart above.",paraId:8},{value:"See: ",paraId:10},{value:"https://observablehq.com/@xiaoiver/d3-rough-barchart",paraId:10},{value:"It's worth mentioning that I first saw this idea in ",paraId:11},{value:"Sprite.js",paraId:11},{value:", but at the time it was not quite finished with the DOM API, so some of the D3 APIs (e.g. join) didn't work properly.",paraId:11},{value:'In theory, this could also solve the performance problems of other SVG-based drawing libraries, but there are some "limitations" to this solution.',paraId:12},{value:"Example bar chart from ",paraId:13,tocIndex:0},{value:"Fullstack D3",paraId:13,tocIndex:0},{value:'The "one line of code" is indeed a bit of a headline, after all the steps to create the G canvas and renderer cannot be missing.',paraId:14,tocIndex:0},{value:"const canvasRenderer = new CanvasRenderer();\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: canvasRenderer,\n});\n",paraId:15,tocIndex:0},{value:"Now we don't need D3 to create ",paraId:16,tocIndex:0},{value:"<svg>",paraId:16,tocIndex:0},{value:", we just need to give D3 the ",paraId:16,tocIndex:0},{value:"root node",paraId:17,tocIndex:0},{value:" of the G scene graph, the size of the ",paraId:16,tocIndex:0},{value:"canvas",paraId:18,tocIndex:0},{value:" is already specified at creation time.",paraId:16,tocIndex:0},{value:"// Before the change: D3 uses the DOM API to create `<svg>`\nconst wrapper = d3\n    .select('#wrapper')\n    .append('svg')\n    .attr('width', dimensions.width)\n    .attr('height', dimensions.height);\n\n// After the change: Give the root node of the G scene graph to D3\nconst wrapper = d3.select(canvas.document.documentElement);\n",paraId:19,tocIndex:0},{value:"That's all that's been changed, and you can now use the D3 syntax in full. For example, creating a ",paraId:20,tocIndex:0},{value:"<g>",paraId:20,tocIndex:0},{value:" and setting the style, G will make D3 think it is still manipulating the DOM API.",paraId:20,tocIndex:0},{value:"const bounds = wrapper\n    .append('g')\n    .style(\n        'transform',\n        `translate(${dimensions.margin.left}px, ${dimensions.margin.top}px)`,\n    );\n",paraId:21,tocIndex:0},{value:"Or use D3's ",paraId:22,tocIndex:0},{value:"event mechanism",paraId:22,tocIndex:0},{value:" to add some event interaction, such as modifying the column color in response to a mouse event.",paraId:22,tocIndex:0},{value:"binGroups\n    .on('mouseenter', function (e) {\n        d3.select(e.target).attr('fill', 'red');\n    })\n    .on('mouseleave', function (e) {\n        d3.select(e.target).attr('fill', 'cornflowerblue');\n    });\n",paraId:23,tocIndex:0},{value:"Example",paraId:24},{value:"When using D3 and third-party extensions, it is often necessary to use CSS selectors, for example ",paraId:25,tocIndex:1},{value:"d3-annotation",paraId:25,tocIndex:1},{value:" would use the following syntax.",paraId:25,tocIndex:1},{value:"var group = selection.select('g.annotations');\n",paraId:26,tocIndex:1},{value:"In order to get CSS selectors like ",paraId:27,tocIndex:1},{value:"g.annotations",paraId:27,tocIndex:1},{value:" to work properly, the ",paraId:27,tocIndex:1},{value:"g-plugin-css-selector",paraId:28,tocIndex:1},{value:" plugin is required, registered as follows.",paraId:27,tocIndex:1},{value:"import { Plugin } from '@antv/g-plugin-css-select';\nrenderer.registerPlugin(new Plugin());\n",paraId:29,tocIndex:1},{value:"In addition, CSS style sheets are often used in D3 projects, such as this ",paraId:30,tocIndex:1},{value:"example",paraId:31,tocIndex:1},{value:", which uses ",paraId:30,tocIndex:1},{value:"d3-annotation",paraId:30,tocIndex:1},{value:" to set the stroke color.",paraId:30,tocIndex:1},{value:".annotation path {\n    stroke: var(--accent-color);\n}\n",paraId:32,tocIndex:1},{value:"We can use the G-like DOM API's element query method ",paraId:33,tocIndex:1},{value:"querySelectorAll",paraId:34,tocIndex:1},{value:".",paraId:33,tocIndex:1},{value:"const paths = canvas.document.querySelectorAll('.annotation path');\npaths.forEach(() => {});\n",paraId:35,tocIndex:1},{value:"Or continue using D3's selector syntax.",paraId:36,tocIndex:1},{value:"svg.select('.annotation path').style('stroke', 'purple');\n",paraId:37,tocIndex:1},{value:"Before explaining the limitations of the program, it is necessary to understand the rationale behind it. We will expand on the following.",paraId:38,tocIndex:2},{value:"What kind of class libraries can be accessed seamlessly?",paraId:39,tocIndex:2},{value:"The completion of DOM API implementation in G.",paraId:39,tocIndex:2},{value:"Other gains",paraId:39,tocIndex:2},{value:'First of all, not all DOM API-based libraries are as "seamlessly accessible" to G as ',paraId:40,tocIndex:3},{value:"Hammer.js",paraId:40,tocIndex:3},{value:", ",paraId:40,tocIndex:3},{value:"interact.js",paraId:40,tocIndex:3},{value:", [D3](",paraId:40,tocIndex:3},{value:"https://github",paraId:40,tocIndex:3},{value:". com/d3/d3). Or rather, the libraries that are suitable for access have in common that they do not assume that they are in a ",paraId:40,tocIndex:3},{value:"real browser DOM environment",paraId:40,tocIndex:3},{value:".",paraId:40,tocIndex:3},{value:"Let's take D3 as an example, ",paraId:41,tocIndex:3},{value:"d3-selection",paraId:41,tocIndex:3},{value:" does not use ",paraId:41,tocIndex:3},{value:"window.document",paraId:41,tocIndex:3},{value:" directly when creating a DOM element, but takes it from the element's [ownerDocument](/en/api/ builtin-objects/node#ownerdocument) attribute of the element, so as long as the G graphic also has that attribute of the same name, it will work without calling the browser's real DOM API.",paraId:41,tocIndex:3},{value:"// @see https://github.com/d3/d3-selection/blob/main/src/creator.js#L6\n// get document\nvar document = this.ownerDocument;\n// create element with document\ndocument.createElement(name);\n",paraId:42,tocIndex:3},{value:"These libraries have the added benefit of being suitable for running test cases on the node side with ",paraId:43,tocIndex:3},{value:"jsdom",paraId:43,tocIndex:3},{value:" (D3's [practice](",paraId:43,tocIndex:3},{value:"https://github.com/d3/d3-selection/blob/main/test",paraId:43,tocIndex:3},{value:" /jsdom.js)).",paraId:43,tocIndex:3},{value:"Therefore, if ",paraId:44,tocIndex:3},{value:"X6",paraId:44,tocIndex:3},{value:" wants to access G in this way in the future, it needs to make sure that there is no usage like ",paraId:44,tocIndex:3},{value:"window.document",paraId:44,tocIndex:3},{value:" as well.",paraId:44,tocIndex:3},{value:'Finally G needs to avoid the assumption of a "browser real DOM environment" in its own internal implementation, e.g. when ',paraId:45,tocIndex:3},{value:"creating canvas",paraId:46,tocIndex:3},{value:", so that it can run in a WebWorker or even an applet environment.",paraId:45,tocIndex:3},{value:"With the appropriate access to the class library, whether it works properly depends on the extent to which the G for DOM API is implemented. Still using D3 as an example, before inserting an element into a document it will use ",paraId:47,tocIndex:4},{value:"compareDocumentPosition",paraId:47,tocIndex:4},{value:" to compare positions. If G does not implement this API, the runtime will report an error.",paraId:47,tocIndex:4},{value:"The core API of G is actually a lightweight version of ",paraId:48,tocIndex:4},{value:"jsdom",paraId:48,tocIndex:4},{value:'. Why "lightweight"? Because many functions such as HTML parsing and non-inline CSS styles have been omitted.',paraId:48,tocIndex:4},{value:"The current G implementation of the DOM API is as follows.",paraId:49,tocIndex:4},{value:"Node & Element API",paraId:50,tocIndex:4},{value:" Disguise the G graphic as a real DOM element",paraId:51,tocIndex:4},{value:"Event System",paraId:52,tocIndex:4},{value:" Provide complete event binding and propagation process",paraId:51,tocIndex:4},{value:"Web Animations API",paraId:53,tocIndex:4},{value:" Provides command-based animation capabilities",paraId:51,tocIndex:4},{value:"CustomElementRegistry",paraId:54,tocIndex:4},{value:" The graph is created by name, so D3 code like ",paraId:51,tocIndex:4},{value:"wrapper.append('g')",paraId:51,tocIndex:4},{value:" actually creates a ",paraId:51,tocIndex:4},{value:"Group",paraId:55,tocIndex:4},{value:" of G",paraId:51,tocIndex:4},{value:"MutationObserver For monitoring structural and attribute changes between elements.",paraId:51,tocIndex:4},{value:"The style property is calculated, so code like ",paraId:51,tocIndex:4},{value:"el.style('font-size', '1em')",paraId:51,tocIndex:4},{value:" in D3 that contains relative units will work.",paraId:51,tocIndex:4},{value:"D3's ecosystem is very large, and seamless access means that many capabilities are available out of the box.",paraId:56,tocIndex:5},{value:"In this ",paraId:57,tocIndex:5},{value:"example",paraId:58,tocIndex:5},{value:", we use ",paraId:57,tocIndex:5},{value:"d3-shape",paraId:57,tocIndex:5},{value:" and [d3-transition](",paraId:57,tocIndex:5},{value:"https://github.com/d3/",paraId:57,tocIndex:5},{value:" d3-transition) to implement the shape animation.",paraId:57,tocIndex:5},{value:"This leads us to think about another question, whether G's ",paraId:59,tocIndex:5},{value:"animation capabilities",paraId:60,tocIndex:5},{value:" should also be pluggable. In the above example, G only needs to provide rendering capabilities, and the animation of the ",paraId:59,tocIndex:5},{value:"d",paraId:59,tocIndex:5},{value:" attribute of ",paraId:59,tocIndex:5},{value:"path",paraId:59,tocIndex:5},{value:" is left entirely to D3.",paraId:59,tocIndex:5},{value:"We have selectively implemented most of the DOM API, which means that APIs such as ",paraId:61,tocIndex:7},{value:"innerHTML",paraId:61,tocIndex:7},{value:" are dropped.",paraId:61,tocIndex:7},{value:"el.innerHTML = '<div></div>';\n",paraId:62,tocIndex:7},{value:"So ",paraId:63,tocIndex:7},{value:"selection.html()",paraId:63,tocIndex:7},{value:" in D3 does not work for now.",paraId:63,tocIndex:7},{value:'If we want to implement this feature, G needs to think about "mixed" rendering. Currently only one renderer can be selected to render all graphics at the same time, and blended rendering requires HTML to co-exist with graphics rendered using Canvas / WebGL. Considering the order of rendering and interaction between these hybrid contents is not an easy task.',paraId:64,tocIndex:7},{value:"It is worth mentioning that the new Google Docs, from the official ",paraId:65,tocIndex:7},{value:"sample document",paraId:65,tocIndex:7},{value:", contains two SVG and one Canvas on the first page. The main part (mainly text) is drawn with Canvas / WebGL and supports text selection, while the image (top right corner, inside the document) is drawn with SVG.",paraId:65,tocIndex:7},{value:"Currently, G does not support external style sheets either, so external style sheets in D3 applications will not work.",paraId:66,tocIndex:8},{value:"However, inline usage is valid, such as the following usage in the example.",paraId:67,tocIndex:8},{value:"const barText = binGroups\n    .filter(yAccessor)\n    .append('text')\n    .attr('x', (d) => xScale(d.x0) + (xScale(d.x1) - xScale(d.x0)) / 2)\n    .attr('y', (d) => yScale(yAccessor(d)) - 5)\n    .text(yAccessor)\n    .attr('fill', 'darkgrey')\n    .style('text-anchor', 'middle')\n    .style('font-size', '12px')\n    .style('font-family', 'sans-serif');\n",paraId:68,tocIndex:8},{value:"The ",paraId:69,tocIndex:9},{value:"foreignObject",paraId:69,tocIndex:9},{value:" in SVG allows for embedded HTML, which, like innerHTML, is not supported at this time.",paraId:69,tocIndex:9}]},14745:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(96430);const n=[{value:"⚠️ GPGPU 相关能力需要支持 WebGPU 的浏览器环境（例如 Chrome 94+）。",paraId:0},{value:"在本教程中，我们将尝试使用 GPU 的并行计算能力，实现两个矩阵相乘，相较 CPU 获得 10 倍以上的性能提升。最终效果可以参考这个",paraId:1},{value:"示例",paraId:2},{value:"，矩阵尺寸越大性能提升效果越明显。",paraId:1},{value:"我们很容易写出一个能在 CPU 侧运行的算法，串行计算结果矩阵中每一个元素的值。但仔细想想第二个元素的计算并不依赖第一个元素的计算结果对吗？现在让我们从线程并行的角度来考虑这个问题，我们让每一个线程负责处理一个元素。如果对网格、线程组这些概念还不熟悉，可以参考",paraId:3},{value:"线程、共享内存与同步",paraId:4},{value:"。",paraId:3},{value:"下面我们通过两步完成该计算任务的创建：",paraId:5},{value:"创建画布，使用 WebGPU 渲染器，注册 GPGPU 插件",paraId:6},{value:"获取 Device",paraId:6},{value:"创建 Kernel，编写 Compute Shader",paraId:6},{value:"传入输入数据，获取计算结果",paraId:6},{value:"创建画布，使用渲染器的方式和之前渲染相关的教程并无差别，只是在创建渲染器时，需要确认在支持 WebGPU 的浏览器环境下运行。另外由于不涉及渲染，画布大小我们选择长宽为 1 即可。",paraId:7,tocIndex:0},{value:"import { Canvas, CanvasEvent } from '@antv/g';\nimport { DeviceRenderer, Renderer } from '@antv/g-webgpu';\nimport { Plugin, Kernel } from '@antv/g-plugin-gpgpu';\n\nconst { BufferUsage } = DeviceRenderer;\n\n// 选择目标平台为 WebGPU\nconst renderer = new Renderer();\n// 注册 GPGPU 插件\nrenderer.registerPlugin(new Plugin());\n\n// 创建画布\nconst $wrapper = document.getElementById('container');\nconst canvas = new Canvas({\n    container: $wrapper,\n    width: 1,\n    height: 1,\n    renderer,\n});\n",paraId:8,tocIndex:0},{value:"在创建一个计算任务时，我们需要获取 GPU 设备（Device），用它创建 Buffer 等底层对象。在执行这些操作前，需要确保画布的初始化工作（特别是渲染服务）准备就绪，有两种方式：",paraId:9,tocIndex:1},{value:"监听画布的 ",paraId:10,tocIndex:1},{value:"READY",paraId:11,tocIndex:1},{value:" 事件",paraId:10,tocIndex:1},{value:"等待 ",paraId:10,tocIndex:1},{value:"canvas.ready",paraId:10,tocIndex:1},{value:" 这个 Promise",paraId:10,tocIndex:1},{value:"随后就可以通过渲染器获取 Device：",paraId:12,tocIndex:1},{value:"import { CanvasEvent } from '@antv/g';\n\n// 等待画布准备就绪\ncanvas.addEventListener(CanvasEvent.READY, () => {\n    // 通过渲染器获取 Device\n    const plugin = renderer.getPlugin('device-renderer');\n    const device = plugin.getDevice();\n\n    // 使用 Device 创建 GPU 相关对象，见下节\n});\n\n// 或者\nawait canvas.ready;\nconst plugin = renderer.getPlugin('device-renderer');\nconst device = plugin.getDevice();\n",paraId:13,tocIndex:1},{value:'不同于 CUDA 中的 "single source"（Host 和 Device 代码都用 C++）编写，WebGPU 的 Device 代码需要通过 Compute Shader 使用 ',paraId:14,tocIndex:2},{value:"WGSL",paraId:14,tocIndex:2},{value:" 语言编写。",paraId:14,tocIndex:2},{value:"因此 ",paraId:15,tocIndex:2},{value:"g-plugin-gpgpu",paraId:15,tocIndex:2},{value:" 插件提供了 Kernel 用于描述计算任务，除了传入上一节获取的 ",paraId:15,tocIndex:2},{value:"device",paraId:15,tocIndex:2},{value:"，还需要通过 ",paraId:15,tocIndex:2},{value:"computeShader",paraId:15,tocIndex:2},{value:" 使用字符串描述：",paraId:15,tocIndex:2},{value:"import { Kernel } from '@antv/g-plugin-gpgpu';\n\nconst kernel = new Kernel(device, {\n    computeShader: `...`,\n});\n",paraId:16,tocIndex:2},{value:"回到我们的计算任务：两个矩阵相乘，我们让每一个线程负责最终结果矩阵中一个元素的计算，这样多个线程间就可以完全并行。",paraId:17,tocIndex:2},{value:"首先我们需要使用线性结构（一个数组）描述一个矩阵，前两个元素表示矩阵尺寸（行和列），后面跟着具体每一个元素。我们使用 WGSL 的 ",paraId:18,tocIndex:2},{value:"struct",paraId:18,tocIndex:2},{value:" 定义矩阵这个数据类型（类似 TS 中的 interface），其中的 ",paraId:18,tocIndex:2},{value:"f32",paraId:18,tocIndex:2},{value:" 是 WGSL（强类型语言）中的一种基础数据类型，当我们后续尝试从 Host 侧分配内存时，也要使用与之匹配的类型数组（Float32Array）：",paraId:18,tocIndex:2},{value:"// WGSL\nstruct Matrix {\n  size : vec2<f32>; // 矩阵尺寸（长度为 2 的向量）\n  numbers: array<f32>; // 矩阵元素（长度不固定的数组）\n};\n\n// 如果用 TS 描述\ninterface Matrix {\n  size : [number, number];\n  numbers: number[];\n}\n",paraId:19,tocIndex:2},{value:"然后我们需要定义输入和输出数据结构。我们声明了两个输入矩阵和一个保存计算结果的矩阵，从后往前看通过 ",paraId:20,tocIndex:2},{value:"Matrix",paraId:20,tocIndex:2},{value:" 声明了它们的类型（类似 TS），",paraId:20,tocIndex:2},{value:"<storage, read>",paraId:20,tocIndex:2},{value:" 分别定义了内存的用途和访问模式，其中 ",paraId:20,tocIndex:2},{value:"storage",paraId:20,tocIndex:2},{value:" 描述了内存的用途，而不同的用途又有对应的访问模式（读写）。例如这里三个矩阵都用于存储数据（可以从 Host 侧分配），其中两个输入矩阵为只读，结果矩阵可写：",paraId:20,tocIndex:2},{value:"// 第一个矩阵\n@group(0) @binding(0) var<storage, read> firstMatrix : Matrix;\n// 第二个矩阵\n@group(0) @binding(1) var<storage, read> secondMatrix : Matrix;\n// 结果矩阵\n@group(0) @binding(2) var<storage, read_write> resultMatrix : Matrix;\n",paraId:21,tocIndex:2},{value:"接下来就需要定义具体的算法了，每个线程都会执行相同的 Compute Shader 处理不同的数据（SIMD），这就要求每个线程知道自己的 ID，才能从全局数据中获取自己感兴趣的部分数据。在 WGSL 中通过 main 函数的入参获取，这里我们使用内置变量 ",paraId:22,tocIndex:2},{value:"global_invocation_id",paraId:22,tocIndex:2},{value:"，它的类型是 ",paraId:22,tocIndex:2},{value:"vec3<u32>",paraId:22,tocIndex:2},{value:" ，",paraId:22,tocIndex:2},{value:"xyz",paraId:22,tocIndex:2},{value:" 分量都从 0 开始，三者相乘不能超过 256。",paraId:22,tocIndex:2},{value:"@compute @workgroup_size(${WORKGROUP_SIZE_X}, ${WORKGROUP_SIZE_Y})\nfn main(\n  @builtin(global_invocation_id) global_id : vec3<u32> // 当前线程全局 ID\n) {\n  // 超出结果矩阵的线程直接返回\n  if (global_id.x >= u32(firstMatrix.size.x) || global_id.y >= u32(secondMatrix.size.y)) {\n    return;\n  }\n\n  // 写回结果矩阵尺寸\n  resultMatrix.size = vec2<f32>(firstMatrix.size.x, secondMatrix.size.y);\n\n  let resultCell = vec2<u32>(global_id.x, global_id.y);\n  var result = 0.0;\n  for (var i = 0u; i < u32(firstMatrix.size.y); i = i + 1u) {\n    let a = i + resultCell.x * u32(firstMatrix.size.y);\n    let b = resultCell.y + i * u32(secondMatrix.size.y);\n    result = result + firstMatrix.numbers[a] * secondMatrix.numbers[b];\n  }\n\n  // 结果矩阵中元素位置\n  let index = resultCell.y + resultCell.x * u32(secondMatrix.size.y);\n  // 计算结果写回结果矩阵\n  resultMatrix.numbers[index] = result;\n}\n",paraId:23,tocIndex:2},{value:"定义好了 Kernel，我们需要向它传递输入，结束后获取输出结果。分配内存的工作在 Host 侧执行，通过 Device 创建 Buffer(",paraId:24,tocIndex:3},{value:"createBuffer",paraId:25,tocIndex:3},{value:")，其中 ",paraId:24,tocIndex:3},{value:"usage",paraId:24,tocIndex:3},{value:" 需要与 Compute Shader 中定义的内存用途对应，同时进行内存初始数据的写入。",paraId:24,tocIndex:3},{value:"const firstMatrixBuffer = device.createBuffer({\n    usage: BufferUsage.STORAGE,\n    viewOrSize: firstMatrix, // new Float32Array([2 /* rows */, 4 /* columns */, 1, 2, 3, 4, 5, 6, 7, 8])\n});\nconst secondMatrixBuffer = device.createBuffer({\n    usage: BufferUsage.STORAGE,\n    viewOrSize: secondMatrix,\n});\nconst resultBuffer = device.createBuffer({\n    usage: BufferUsage.STORAGE | BufferUsage.COPY_SRC,\n    viewOrSize: resultMatrix,\n});\n",paraId:26,tocIndex:3},{value:"创建完 Buffer 之后，需要绑定到 Kernel 的指定位置（与 Compute Shader 中的 binding 对应）：",paraId:27,tocIndex:3},{value:"kernel.setBinding(0, firstMatrixBuffer);\nkernel.setBinding(1, secondMatrixBuffer);\nkernel.setBinding(2, resultBuffer);\n",paraId:28,tocIndex:3},{value:"使用 ",paraId:29,tocIndex:3},{value:"dispatch",paraId:29,tocIndex:3},{value:" 可以分配线程网格大小，执行计算管线。在矩阵乘法的例子中，如果线程组的大小为 ",paraId:29,tocIndex:3},{value:"1 * 1",paraId:29,tocIndex:3},{value:"，网格大小就是 ",paraId:29,tocIndex:3},{value:"M * N",paraId:29,tocIndex:3},{value:"：",paraId:29,tocIndex:3},{value:"const x = Math.ceil(firstMatrix[0] / WORKGROUP_SIZE_X);\nconst y = Math.ceil(secondMatrix[1] / WORKGROUP_SIZE_Y);\nkernel.dispatch(x, y);\n",paraId:30,tocIndex:3},{value:"在计算完成后，我们需要读取结果矩阵中的数据，这是一次 GPU 到 CPU 的异步读取操作：",paraId:31,tocIndex:3},{value:"const readback = device.createReadback();\nconst result = await readback.readBuffer(resultBuffer); // Float32Array([...])\n",paraId:32,tocIndex:3},{value:"上述矩阵乘法更多用于演示目的，在图场景中有非常多适合并行的布局和分析算法，我们可以从 CUDA 实现中进行移植，例如：",paraId:33,tocIndex:4},{value:"Fruchterman 布局算法",paraId:34,tocIndex:4},{value:"Pagerank",paraId:35,tocIndex:4},{value:"SSSP 单源最短路径",paraId:36,tocIndex:4},{value:"在图中节点/边数目达到一定规模时会带来非常可观的性能提升效果。以 pagerank 为例，在 1k 节点和 50w 条边的测试数据中，GPU 版本相较 CPU 版本有 100 倍以上的提升（300ms vs 30s）。",paraId:37,tocIndex:4}]},86355:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(60060);const n=[{value:"matter.js",paraId:0},{value:" 物理引擎提供了一系列针对刚体的仿真计算，例如重力和表面摩擦力。另外，在任意时刻也可以施加外力改变图形的位置和旋转角度，这为我们实现一些基于真实物理规则的布局提供了帮助。",paraId:0},{value:"通过 ",paraId:1},{value:"g-plugin-matterjs",paraId:2},{value:" 插件的支持，我们可以给已有的大部分 2D 图形增加物理属性。",paraId:1},{value:"在该",paraId:3},{value:"示例",paraId:4},{value:"中，我们创建了一系列动态物体，让它们进行自由落体，最终停留在“U 形槽”中。",paraId:3},{value:"创建一个渲染器并注册插件：",paraId:5,tocIndex:0},{value:"import { Canvas, CanvasEvent } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\nimport { Plugin as PluginMatterjs } from '@antv/g-plugin-matterjs';\n\nconst renderer = new Renderer();\nconst plugin = new PluginMatterjs();\nrenderer.registerPlugin(plugin);\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:6,tocIndex:0},{value:"在开发时，我们常常希望能把物理引擎中的世界也渲染出来，便于和“现实世界”对照。",paraId:7,tocIndex:1},{value:"matter.js \b 本身支持渲染。开启后配合 ",paraId:8,tocIndex:1},{value:"debugContainer",paraId:9,tocIndex:1},{value:" 可以绘制物理引擎世界中每个对象的 wireframe，便于 debug：",paraId:8,tocIndex:1},{value:"const plugin = new PluginMatterjs({\n    debug: true,\n    debugContainer: document.getElementById('container'),\n    debugCanvasWidth: 600,\n    debugCanvasHeight: 500,\n});\n",paraId:10,tocIndex:1},{value:"例如下图展示了三堵静态墙壁和一些动态物体的 wireframe：",paraId:11,tocIndex:1},{value:"我们使用 ",paraId:12,tocIndex:2},{value:"Line",paraId:13,tocIndex:2},{value:" 创建一个平地，需要特别注意 ",paraId:12,tocIndex:2},{value:"rigid",paraId:14,tocIndex:2},{value:" 属性，设置为 ",paraId:12,tocIndex:2},{value:"static",paraId:12,tocIndex:2},{value:" 表明它不受重力等作用力影响：",paraId:12,tocIndex:2},{value:"const ground = new Line({\n    style: {\n        x1: 50,\n        y1: 400,\n        // 省略其他属性\n        rigid: 'static',\n    },\n});\ncanvas.appendChild(ground);\n",paraId:15,tocIndex:2},{value:"接下来我们创建一个受重力影响的“弹力球”，其中：",paraId:16,tocIndex:3},{value:"density",paraId:17,tocIndex:3},{value:" 表示物体密度，单位为千克/立方米",paraId:18,tocIndex:3},{value:"restitution",paraId:19,tocIndex:3},{value:" 表示弹力系数",paraId:18,tocIndex:3},{value:"const circle = new Circle({\n    style: {\n        fill: '#1890FF',\n        r: 50,\n        rigid: 'dynamic',\n        density: 10,\n        restitution: 0.5,\n    },\n});\ncanvas.appendChild(circle);\n",paraId:20,tocIndex:3},{value:"插件会自动完成仿真过程，你可以看到小球自由落体至地面并弹起。",paraId:21,tocIndex:4},{value:"使用 ",paraId:22,tocIndex:4},{value:"applyForce",paraId:23,tocIndex:4},{value:" 可以向图形施加外力。在该 ",paraId:22,tocIndex:4},{value:"示例",paraId:24,tocIndex:4},{value:" 中，点击按钮可以向 Circle 施加一个 ",paraId:22,tocIndex:4},{value:"[0, 0]",paraId:22,tocIndex:4},{value:" 点处 ",paraId:22,tocIndex:4},{value:"[0, -10]",paraId:22,tocIndex:4},{value:" 的外力，因此受力会向上弹起：",paraId:22,tocIndex:4},{value:"plugin.applyForce(circle, [0, -10], [0, 0]);\n",paraId:25,tocIndex:4}]},89979:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(91575);const n=[{value:"In the previous section we showed ",paraId:0},{value:"How to take over the rendering of D3",paraId:1},{value:", and we can do the same for other SVG-based diagram libraries. ",paraId:0},{value:"Observable Plot",paraId:0},{value:" is a good example.",paraId:0},{value:"The chart library also supports passing ",paraId:2},{value:"document",paraId:2},{value:" objects to ",paraId:2},{value:"plot()",paraId:2},{value:", and we pass G's ",paraId:2},{value:"Document",paraId:3},{value:" object to.",paraId:2},{value:"import * as Plot from '@observablehq/plot';\nimport { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\n\nconst canvasRenderer = new Renderer();\nconst canvas = new Canvas({\n    container: 'container',\n    width: 640,\n    height: 400,\n    renderer: canvasRenderer,\n});\n\nconst chart = Plot.dot(data, {\n    x: 'weight',\n    y: 'height',\n    stroke: 'sex',\n}).plot({\n    // Pass in our Document object instead of `window.document`\n    document: canvas.document,\n});\n",paraId:4},{value:"It's worth mentioning that we don't need to call ",paraId:5},{value:"canvas.appendChild()",paraId:5},{value:" manually to add the chart to the canvas, Observable Plot does that internally.",paraId:5},{value:"DEMO in CodeSandbox",paraId:6},{value:"The top half of the figure below shows the rendering of the Observable Plot native SVG, and the bottom half shows the drawing using ",paraId:7},{value:"g-canvas",paraId:8},{value:".",paraId:7},{value:"Also thanks to taking over the rendering layer, we can use a plugin like ",paraId:9},{value:"g-plugin-rough-canvas-renderer",paraId:10},{value:" for hand-drawn style transformation.",paraId:9},{value:"DEMO in CodeSandbox",paraId:11}]},96946:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(22207);const n=[{value:"插件可以极大程度丰富渲染器的能力，在本教程中我们将使用 ",paraId:0},{value:"g-webgl",paraId:0},{value:" 渲染器，配合 ",paraId:0},{value:"g-plugin-3d",paraId:1},{value:" 插件渲染一个简单的立方体。更多用法可以参考",paraId:0},{value:"插件系统",paraId:2},{value:"。",paraId:0},{value:"其中会涉及以下 API：",paraId:3},{value:"使用 ",paraId:4},{value:"registerPlugin",paraId:5},{value:" 为渲染器注册插件",paraId:4},{value:"使用 ",paraId:4},{value:"getCamera",paraId:6},{value:" 获取画布相机",paraId:4},{value:"使用 ",paraId:4},{value:"setPosition",paraId:7},{value:" 设置相机位置",paraId:4},{value:"最终示例：",paraId:8},{value:"官网示例",paraId:9},{value:"CodeSandbox 示例",paraId:10},{value:"我们使用 ",paraId:11,tocIndex:0},{value:"g-webgl",paraId:11,tocIndex:0},{value:" 渲染器，并为其注册：",paraId:11,tocIndex:0},{value:"g-plugin-3d",paraId:12,tocIndex:0},{value:" 提供 3D 渲染能力",paraId:13,tocIndex:0},{value:"g-plugin-control",paraId:14,tocIndex:0},{value:" 提供交互能力",paraId:13,tocIndex:0},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-webgl';\nimport { Plugin as Plugin3D } from '@antv/g-plugin-3d';\nimport { Plugin as PluginControl } from '@antv/g-plugin-control';\n\n// 创建 WebGL 渲染器\nconst webglRenderer = new Renderer();\n\n// 注册 3D 插件\nwebglRenderer.registerPlugin(new Plugin3D());\n// 注册 Control 插件\nwebglRenderer.registerPlugin(new PluginControl());\n\n// 创建画布\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: webglRenderer,\n});\n",paraId:15,tocIndex:0},{value:"我们创建一个 ",paraId:16,tocIndex:1},{value:"200 * 200 * 200",paraId:16,tocIndex:1},{value:" 的立方体，并通过 ",paraId:16,tocIndex:1},{value:"map",paraId:16,tocIndex:1},{value:" 给它贴个图：",paraId:16,tocIndex:1},{value:"import {\n    MeshBasicMaterial,\n    CubeGeometry,\n    Mesh,\n    Plugin as Plugin3D,\n} from '@antv/g-plugin-3d';\n\nconst cubeGeometry = new CubeGeometry();\nconst basicMaterial = new MeshBasicMaterial({\n    map: 'https://gw.alipayobjects.com/mdn/rms_6ae20b/afts/img/A*_aqoS73Se3sAAAAAAAAAAAAAARQnAQ',\n});\n\nconst cube = new Mesh({\n    style: {\n        fill: '#1890FF',\n        opacity: 1,\n        width: 200,\n        height: 200,\n        depth: 200,\n        geometry: cubeGeometry,\n        material: basicMaterial,\n    },\n});\n\ncanvas.appendChild(cube);\n",paraId:17,tocIndex:1},{value:"然后使用 ",paraId:18,tocIndex:1},{value:"setPosition",paraId:19,tocIndex:1},{value:" 移动它到画布中央：",paraId:18,tocIndex:1},{value:"cube.setPosition(300, 250, 0);\n",paraId:20,tocIndex:1},{value:"现在让我们将相机位置稍稍调整一下，来到立方体的斜上方观察。",paraId:21,tocIndex:2},{value:"使用 ",paraId:22,tocIndex:2},{value:"getCamera",paraId:23,tocIndex:2},{value:" 获取画布相机",paraId:22,tocIndex:2},{value:"使用 ",paraId:22,tocIndex:2},{value:"setPosition",paraId:24,tocIndex:2},{value:" 设置相机位置",paraId:22,tocIndex:2},{value:"const camera = canvas.getCamera();\ncamera.setPosition(300, 0, 500);\n",paraId:25,tocIndex:2},{value:"让立方体旋转和其他基础图形一样，使用 ",paraId:26,tocIndex:3},{value:"rotate",paraId:27,tocIndex:3},{value:" 即可：",paraId:26,tocIndex:3},{value:"canvas.addEventListener(CanvasEvent.AFTER_RENDER, () => {\n    cube.rotate(0, 1, 0); // 绕 Y 轴旋转 1 度\n});\n",paraId:28,tocIndex:3}]},29046:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(91001);const n=[{value:"在大多数场景下，渲染引擎会自动在每一帧重绘，但在部分场景下，我们需要自己决定重绘的时机。",paraId:0},{value:"首先我们需要关闭渲染器的“自动渲染”：",paraId:1},{value:"const webglRenderer = new WebGLRenderer({\n    // 关闭自动渲染\n    enableAutoRendering: false,\n});\n",paraId:2},{value:"然后在合适的实际调用画布的",paraId:3},{value:"重绘方法",paraId:4},{value:"，例如手动在 ",paraId:3},{value:"rAF",paraId:3},{value:" 中调用：",paraId:3},{value:"// create a main loop\nconst tick = () => {\n    // call `render` in each frame\n    canvas.render();\n    requestAnimationFrame(tick);\n};\ntick();\n",paraId:5}]},8017:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(61496);const n=[{value:"The ",paraId:0},{value:"SceneGraph",paraId:0},{value:" is a data structure for organizing and managing 2D/3D virtual scenes as a directed acyclic graph. SceneGraphs provide two major capabilities.",paraId:0},{value:"describe parent-child relationships",paraId:1},{value:"automate some complex cascade calculations based on parent-child relationships",paraId:1},{value:"In the old version of G, we provided some related operations on ",paraId:2},{value:"Group/Shape",paraId:2},{value:", but there were a lot of problems, which led to a lot of hacking at the upper level when using it. In the new version, we refer to the DOM API and CSS selector, and give each node in the scene graph the following capabilities to significantly reduce the learning cost.",paraId:2},{value:"add/remove node/property methods in the same style as the DOM API",paraId:3},{value:"node query syntax similar to CSS selector",paraId:3},{value:"z-index",paraId:3},{value:" to control the display order",paraId:3},{value:"visibility control via `visibility",paraId:3},{value:"In addition, we refer to ",paraId:4},{value:"react-three-fiber",paraId:4},{value:" to define the scene graph using declarative syntax for easy component reuse.",paraId:4},{value:"Imagine we need to construct a simple solar system scenario with the following hierarchical relationships.",paraId:5,tocIndex:0},{value:"太阳系 solarSystem\n   |    |\n   |   太阳 sun\n   |\n 地球轨道 earthOrbit\n   |    |\n   |  地球 earth\n   |\n 月球轨道 moonOrbit\n      |\n     月球 moon\n",paraId:6,tocIndex:0},{value:"Their hierarchy can be easily constructed in G using ",paraId:7,tocIndex:0},{value:"Group",paraId:7,tocIndex:0},{value:" and ",paraId:7,tocIndex:0},{value:"Circle",paraId:7,tocIndex:0},{value:".",paraId:7,tocIndex:0},{value:"import { Group, Circle } from '@antv/g';\n\nconst solarSystem = new Group({\n    name: 'solarSystem',\n});\nconst earthOrbit = new Group({\n    name: 'earthOrbit',\n});\nconst moonOrbit = new Group({\n    name: 'moonOrbit',\n});\nconst sun = new Circle({\n    name: 'sun',\n    style: {\n        r: 100,\n    },\n});\nconst earth = new Circle({\n    name: 'earth',\n    style: {\n        r: 50,\n    },\n});\nconst moon = new Circle({\n    name: 'moon',\n    style: {\n        r: 25,\n    },\n});\n\nsolarSystem.appendChild(sun);\nsolarSystem.appendChild(earthOrbit);\nearthOrbit.appendChild(earth);\nearthOrbit.appendChild(moonOrbit);\nmoonOrbit.appendChild(moon);\n",paraId:8,tocIndex:0},{value:"⚠️ We don't need to use ",paraId:9,tocIndex:0},{value:"Canvas",paraId:9,tocIndex:0},{value:" at this point, the scene graph is an abstract data structure that only needs to interact with ",paraId:9,tocIndex:0},{value:"Canvas",paraId:9,tocIndex:0},{value:" when rendering.",paraId:9,tocIndex:0},{value:"After describing the hierarchical relationships, we usually need to further define the behavior of the objects in the scene graph. In the previous simple solar system model, we wanted to have the Earth rotate around the Sun and the Moon rotate around the Earth, updating their position properties in real time, ",paraId:10,tocIndex:0},{value:"DEMO",paraId:11,tocIndex:0},{value:". However, the calculation of the moon's trajectory (red dashed line in the figure below) seems to be complicated.",paraId:10,tocIndex:0},{value:'Therefore, we need to let the moon just concentrate on the "orbiting the Earth", and leave the matrix calculation behind the parent-child relationship to the scene map.',paraId:12,tocIndex:0},{value:"We provide three types of transformations: translation, scaling and rotation. The values of each of these can be divided into relative and absolute. For example, for the translation transformation, there is obviously a difference between translating to a certain point and translating a distance based on the current point. Like the amount of transformation, the ",paraId:13,tocIndex:1},{value:"coordinate system",paraId:13,tocIndex:1},{value:" also has the concept of relative and absolute, which was not clearly explained in the previous version of G. The lack of a supporting API makes it inconvenient to use.",paraId:13,tocIndex:1},{value:"Coordinate systems can be used to describe the position, rotation, and scaling of objects in a scene; the most famous coordinate system is the Euclidean coordinate system. In graphics we also use the center of gravity coordinate system. Euclidean space can contain N dimensions, in visualization scenes we use only 2D and 3D.",paraId:14,tocIndex:2},{value:'When we say that "the moon revolves around the earth", we have actually ignored the objects outside the earth. In the ',paraId:15,tocIndex:2},{value:'"local coordinate system "',paraId:15,tocIndex:2},{value:" of the Moon, it simply rotates around a point, although in the ",paraId:15,tocIndex:2},{value:'"world coordinate system "',paraId:15,tocIndex:2},{value:" of the entire solar system, the Earth still rotates around the Sun, and the Moon eventually follows the complex trajectory above. motion.",paraId:15,tocIndex:2},{value:"The concepts of local and world coordinate systems can be used in both two and three dimensional worlds.",paraId:16,tocIndex:2},{value:"The following image is from ",paraId:17,tocIndex:2},{value:"playcanvas",paraId:17,tocIndex:2},{value:", with the world coordinate system on the left and the local coordinate system on the right.",paraId:17,tocIndex:2},{value:"The world coordinate system is shared by all the nodes in the whole scene graph, so it has a fixed origin ",paraId:18,tocIndex:2},{value:"(0, 0)",paraId:18,tocIndex:2},{value:" and the orientation of the XYZ axes (XY axes in 2D scene) is also fixed, even if the box in the scene rotates itself, the world coordinate system will not change for it. But for its own local coordinate system, its origin is no longer ",paraId:18,tocIndex:2},{value:"(0, 0)",paraId:18,tocIndex:2},{value:" but the object's own position, and the axes naturally change, as the name implies, and are associated with the object itself.",paraId:18,tocIndex:2},{value:'Imagine at this point that we ask the box to "translate 10 units along the X-axis (red)", which has a completely different meaning in different coordinate systems. So when we want to transform an object, we first need to specify the coordinate system we are in.',paraId:19,tocIndex:2},{value:"In addition, the local coordinate system is also called ",paraId:20,tocIndex:2},{value:"model coordinate system",paraId:20,tocIndex:2},{value:", which is more convenient when describing the transformation of the model itself. In ",paraId:20,tocIndex:2},{value:"the figure below",paraId:20,tocIndex:2},{value:' two soldier models are placed, and if we want to make each soldier turn his head a little, it is obviously simpler to do it in the local coordinate system, because the "turn " this transformation is relative to the head of each model.',paraId:20,tocIndex:2},{value:"For translation operations, we provide APIs for moving absolute/relative distances in local/world coordinate systems.",paraId:21,tocIndex:3},{value:"name",paraId:22,tocIndex:3},{value:"params",paraId:22,tocIndex:3},{value:"return value",paraId:22,tocIndex:3},{value:"remarks",paraId:22,tocIndex:3},{value:"translate",paraId:22,tocIndex:3},{value:"[number, number]",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"Move relative to current position in ",paraId:22,tocIndex:3},{value:"world coordinate system",paraId:22,tocIndex:3},{value:"translateLocal",paraId:22,tocIndex:3},{value:"[number, number]",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"Move relative to current position in ",paraId:22,tocIndex:3},{value:"local coordinate system",paraId:22,tocIndex:3},{value:"setPosition",paraId:22,tocIndex:3},{value:"[number, number]",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"Sets the position in the ",paraId:22,tocIndex:3},{value:"world coordinate system",paraId:22,tocIndex:3},{value:".",paraId:22,tocIndex:3},{value:"setLocalPosition",paraId:22,tocIndex:3},{value:"[number, number]",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"Sets the position in the ",paraId:22,tocIndex:3},{value:"local coordinate system",paraId:22,tocIndex:3},{value:".",paraId:22,tocIndex:3},{value:"getPosition",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"[number, number]",paraId:22,tocIndex:3},{value:"Get the position in the ",paraId:22,tocIndex:3},{value:"world coordinate system",paraId:22,tocIndex:3},{value:"getLocalPosition",paraId:22,tocIndex:3},{value:"-",paraId:22,tocIndex:3},{value:"[number, number]",paraId:22,tocIndex:3},{value:"Get the position in the ",paraId:22,tocIndex:3},{value:"local coordinate system",paraId:22,tocIndex:3},{value:"Unlike panning, we can't provide a method like ",paraId:23,tocIndex:4},{value:"setScale",paraId:23,tocIndex:4},{value:" to set the scaling in the world coordinate system, so scaling in the global coordinate system is read-only, which is called ",paraId:23,tocIndex:4},{value:"lossyScale",paraId:23,tocIndex:4},{value:" in Unity.",paraId:23,tocIndex:4},{value:"name",paraId:24,tocIndex:4},{value:"params",paraId:24,tocIndex:4},{value:"return value",paraId:24,tocIndex:4},{value:"remarks",paraId:24,tocIndex:4},{value:"scaleLocal",paraId:24,tocIndex:4},{value:"[number, number]",paraId:24,tocIndex:4},{value:"-",paraId:24,tocIndex:4},{value:"Continued scaling with respect to the current scale in ",paraId:24,tocIndex:4},{value:"local coordinate system",paraId:24,tocIndex:4},{value:"setLocalScale",paraId:24,tocIndex:4},{value:"[number, number]",paraId:24,tocIndex:4},{value:"-",paraId:24,tocIndex:4},{value:"Set the scaling in ",paraId:24,tocIndex:4},{value:"local coordinate system",paraId:24,tocIndex:4},{value:"getScale",paraId:24,tocIndex:4},{value:"-",paraId:24,tocIndex:4},{value:"[number, number]",paraId:24,tocIndex:4},{value:"Get the scaling in ",paraId:24,tocIndex:4},{value:"world coordinate system",paraId:24,tocIndex:4},{value:"getLocalScale",paraId:24,tocIndex:4},{value:"-",paraId:24,tocIndex:4},{value:"[number, number]",paraId:24,tocIndex:4},{value:"Get the scaling in ",paraId:24,tocIndex:4},{value:"local coordinate system",paraId:24,tocIndex:4},{value:"In 3D scenes, rotations can be represented as matrices, axis angles, Euler angles and quaternions, which are interconvertible with each other. Although, considering future scalability, we use quaternions in the G internal implementation.",paraId:25,tocIndex:5},{value:"name",paraId:26,tocIndex:5},{value:"params",paraId:26,tocIndex:5},{value:"return value",paraId:26,tocIndex:5},{value:"remarks",paraId:26,tocIndex:5},{value:"rotateLocal",paraId:26,tocIndex:5},{value:"number",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"在 ",paraId:26,tocIndex:5},{value:"局部坐标系",paraId:26,tocIndex:5},{value:" 下，旋转一定的欧拉角，顺时针方向为正，单位为 ",paraId:26,tocIndex:5},{value:"degree",paraId:26,tocIndex:5},{value:"rotate",paraId:26,tocIndex:5},{value:"number",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"在 ",paraId:26,tocIndex:5},{value:"世界坐标系",paraId:26,tocIndex:5},{value:" 下，旋转一定的欧拉角",paraId:26,tocIndex:5},{value:"setEulerAngles",paraId:26,tocIndex:5},{value:"number",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"设置 ",paraId:26,tocIndex:5},{value:"世界坐标系",paraId:26,tocIndex:5},{value:" 下的欧拉角",paraId:26,tocIndex:5},{value:"setLocalEulerAngles",paraId:26,tocIndex:5},{value:"number",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"设置 ",paraId:26,tocIndex:5},{value:"局部坐标系",paraId:26,tocIndex:5},{value:" 下的欧拉角",paraId:26,tocIndex:5},{value:"setLocalRotation",paraId:26,tocIndex:5},{value:"quat",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"设置 ",paraId:26,tocIndex:5},{value:"局部坐标系",paraId:26,tocIndex:5},{value:" 下的四元数",paraId:26,tocIndex:5},{value:"setRotation",paraId:26,tocIndex:5},{value:"quat",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"设置 ",paraId:26,tocIndex:5},{value:"世界坐标系",paraId:26,tocIndex:5},{value:" 下的四元数",paraId:26,tocIndex:5},{value:"getEulerAngles",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"number",paraId:26,tocIndex:5},{value:"获取 ",paraId:26,tocIndex:5},{value:"世界坐标系",paraId:26,tocIndex:5},{value:" 下的欧拉角",paraId:26,tocIndex:5},{value:"getLocalEulerAngles",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"number",paraId:26,tocIndex:5},{value:"获取 ",paraId:26,tocIndex:5},{value:"局部坐标系",paraId:26,tocIndex:5},{value:" 下的欧拉角",paraId:26,tocIndex:5},{value:"getLocalRotation",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"quat",paraId:26,tocIndex:5},{value:"获取 ",paraId:26,tocIndex:5},{value:"局部坐标系",paraId:26,tocIndex:5},{value:" 下的四元数",paraId:26,tocIndex:5},{value:"getRotation",paraId:26,tocIndex:5},{value:"-",paraId:26,tocIndex:5},{value:"quat",paraId:26,tocIndex:5},{value:"获取 ",paraId:26,tocIndex:5},{value:"世界坐标系",paraId:26,tocIndex:5},{value:" 下的四元数",paraId:26,tocIndex:5},{value:"If we want to rotate a node around any point, we can create a parent node for it, move the parent node to a point and then rotate it.",paraId:27,tocIndex:5},{value:"Below we will complete the above solar system example by having the Earth rotate around the Sun and having the Moon rotate around the Earth.",paraId:28,tocIndex:5},{value:"First set the position of the solar system under the world coordinate system. Based on the parent-child relationship within the scene graph, the Sun, Earth's orbit, Earth, Moon's orbit and Moon are moved to ",paraId:29,tocIndex:6},{value:"(300, 250)",paraId:29,tocIndex:6},{value:" as shown in the following figure (left).",paraId:29,tocIndex:6},{value:"// 设置太阳系的位置\nsolarSystem.setPosition(300, 250);\n",paraId:30,tocIndex:6},{value:"Keeping the position of the Sun constant, we move the Earth's orbit by 100 along the X-axis, and similarly the Earth, the Moon's orbit and the Moon are all moved to ",paraId:31,tocIndex:6},{value:"(400, 250)",paraId:31,tocIndex:6},{value:" under the world coordinate system, as shown in the following figure (center).",paraId:31,tocIndex:6},{value:"earthOrbit.translate(100, 0);\n// earthOrbit.getLocalPosition() --\x3e (100, 0)\n// earthOrbit.getPosition() --\x3e (400, 250)\n",paraId:32,tocIndex:6},{value:"Then we move the lunar orbit, as shown in the following figure (right).",paraId:33,tocIndex:6},{value:"moonOrbit.translate(100, 0);\n",paraId:34,tocIndex:6},{value:"Finally, in each frame, we rotate the solar system and the Earth's orbit by 1 degree along the Z-axis in the local coordinate system (you can also make the Earth's orbit go faster).",paraId:35,tocIndex:6},{value:"solarSystem.rotateLocal(1);\nearthOrbit.rotateLocal(1);\n",paraId:36,tocIndex:6},{value:"For each node, it is only necessary to use the above transformation method, just like the moon only needs to orbit the earth, and the scene graph will calculate its position in the world coordinate system behind the scenes based on the parent-child relationship. Therefore we do not recommend to use methods like ",paraId:37,tocIndex:6},{value:"get/setMatrix()",paraId:37,tocIndex:6},{value:" to set the matrix manually.",paraId:37,tocIndex:6},{value:"在场景图中，我们需要构建父子关系，快速获取父子节点，有时还需要在子树中查询某一类型的节点列表。为此，我们参考 DOM API 中的 ",paraId:38,tocIndex:7},{value:"Node 接口",paraId:38,tocIndex:7},{value:" 在节点上定义了一系列属性与方法，同时提供了类似 CSS 选择器的节点查询方法，最大程度减少学习成本。",paraId:38,tocIndex:7},{value:"| 名称            | 属性/方法 | 返回值    | 备注                           |\n| --------------- | --------- | --------- | ------------------------------ | ------------------------------------ |\n| parentNode      | 属性      | ",paraId:39,tocIndex:8},{value:"Group    | null",paraId:39,tocIndex:8},{value:"                          | 父节点（如有）                       |\n| children        | 属性      | ",paraId:39,tocIndex:8},{value:"Group[]",paraId:39,tocIndex:8},{value:" | 子节点列表                     |\n| firstChild      | 属性      | ",paraId:39,tocIndex:8},{value:"Group    | null",paraId:39,tocIndex:8},{value:"                          | 返回子节点列表中第一个节点（如有）   |\n| lastChild       | 属性      | ",paraId:39,tocIndex:8},{value:"Group    | null",paraId:39,tocIndex:8},{value:"                          | 返回子节点列表中最后一个节点（如有） |\n| nextSibling     | 属性      | ",paraId:39,tocIndex:8},{value:"Group    | null",paraId:39,tocIndex:8},{value:"                          | 返回后一个兄弟节点（如有）           |\n| previousSibling | 属性      | ",paraId:39,tocIndex:8},{value:"Group    | null",paraId:39,tocIndex:8},{value:"                          | 返回前一个兄弟节点（如有）           |\n| contains        | 方法      | ",paraId:39,tocIndex:8},{value:"boolean",paraId:39,tocIndex:8},{value:" | 子树中是否包含某个节点（入参） |",paraId:39,tocIndex:8},{value:"参考 CSS 选择器，我们提供了以下查询方法，查询范围是当前节点的",paraId:40,tocIndex:9},{value:"整棵子树",paraId:40,tocIndex:9},{value:"，并不仅仅是直接的子节点列表，而是所有子孙节点。",paraId:40,tocIndex:9},{value:"| 名称 | 参数 | 返回值 | 备注 |\n| --- | --- | --- | --- | --- |\n| getElementById | ",paraId:41,tocIndex:9},{value:"(id: string)",paraId:41,tocIndex:9},{value:" | ",paraId:41,tocIndex:9},{value:"Group | null",paraId:41,tocIndex:9},{value:" | 通过 ",paraId:41,tocIndex:9},{value:"id",paraId:41,tocIndex:9},{value:" 查询子节点 |\n| getElementsByName | ",paraId:41,tocIndex:9},{value:"(name: string)",paraId:41,tocIndex:9},{value:" | ",paraId:41,tocIndex:9},{value:"Group[]",paraId:41,tocIndex:9},{value:" | 通过 ",paraId:41,tocIndex:9},{value:"name",paraId:41,tocIndex:9},{value:" 查询子节点列表 |\n| getElementsByClassName | ",paraId:41,tocIndex:9},{value:"(className: string)",paraId:41,tocIndex:9},{value:" | ",paraId:41,tocIndex:9},{value:"Group[]",paraId:41,tocIndex:9},{value:" | 通过 ",paraId:41,tocIndex:9},{value:"className",paraId:41,tocIndex:9},{value:" 查询子节点列表 |\n| getElementsByTagName | ",paraId:41,tocIndex:9},{value:"(tagName: string)",paraId:41,tocIndex:9},{value:" | ",paraId:41,tocIndex:9},{value:"Group[]",paraId:41,tocIndex:9},{value:" | 通过 ",paraId:41,tocIndex:9},{value:"tagName",paraId:41,tocIndex:9},{value:" 查询子节点列表 |\n| querySelector | ",paraId:41,tocIndex:9},{value:"(selector: string)",paraId:41,tocIndex:9},{value:" | ",paraId:41,tocIndex:9},{value:"Group ｜ null",paraId:41,tocIndex:9},{value:" | 查询满足条件的第一个子节点 |\n| querySelectorAll | ",paraId:41,tocIndex:9},{value:"(selector: string)",paraId:41,tocIndex:9},{value:" | ",paraId:41,tocIndex:9},{value:"Group[]",paraId:41,tocIndex:9},{value:" | 查询满足条件的所有子节点列表 |",paraId:41,tocIndex:9},{value:"下面我们以上面太阳系的例子，演示如何使用这些查询方法。",paraId:42,tocIndex:9},{value:"solarSystem.getElementsByName('sun');\n// [sun]\n\nsolarSystem.getElementsByTagName('circle');\nsolarSystem.getElementsByTagName(Shape.CIRCLE);\n// [sun, earth, moon]\n\nsolarSystem.querySelector('[name=sun]');\n// sun\n\nsolarSystem.querySelectorAll('[r=25]');\n// [moon]\n",paraId:43,tocIndex:9},{value:"名称",paraId:44,tocIndex:10},{value:"参数",paraId:44,tocIndex:10},{value:"返回值",paraId:44,tocIndex:10},{value:"备注",paraId:44,tocIndex:10},{value:"appendChild",paraId:44,tocIndex:10},{value:"(group: Group)",paraId:44,tocIndex:10},{value:"Group",paraId:44,tocIndex:10},{value:"添加子节点，返回添加的节点",paraId:44,tocIndex:10},{value:"insertBefore",paraId:44,tocIndex:10},{value:"(group: Group, reference?: Group)",paraId:44,tocIndex:10},{value:"Group",paraId:44,tocIndex:10},{value:"添加子节点，在某个子节点之前（如有），返回添加的节点",paraId:44,tocIndex:10},{value:"removeChild",paraId:44,tocIndex:10},{value:"(group: Group)",paraId:44,tocIndex:10},{value:"Group",paraId:44,tocIndex:10},{value:"删除子节点，返回被删除的节点",paraId:44,tocIndex:10},{value:"| 名称         | 参数                         | 返回值 | 备注       |\n| ------------ | ---------------------------- | ------ | ---------- | -------------------- |\n| getAttribute | ",paraId:45,tocIndex:11},{value:"(name: string)",paraId:45,tocIndex:11},{value:"             | ",paraId:45,tocIndex:11},{value:"null  | any",paraId:45,tocIndex:11},{value:"       | 根据属性名获取属性值 |\n| setAttribute | ",paraId:45,tocIndex:11},{value:"(name: string, value: any)",paraId:45,tocIndex:11},{value:" | 无     | 设置属性值 |",paraId:45,tocIndex:11},{value:"⚠️ 兼容旧版 ",paraId:46,tocIndex:11},{value:"attr(name: string, value?: any)",paraId:46,tocIndex:11},{value:"，获取以及设置属性值。",paraId:46,tocIndex:11},{value:"名称",paraId:47,tocIndex:13},{value:"参数",paraId:47,tocIndex:13},{value:"返回值",paraId:47,tocIndex:13},{value:"备注",paraId:47,tocIndex:13},{value:"hide",paraId:47,tocIndex:13},{value:"无",paraId:47,tocIndex:13},{value:"无",paraId:47,tocIndex:13},{value:"隐藏节点",paraId:47,tocIndex:13},{value:"show",paraId:47,tocIndex:13},{value:"无",paraId:47,tocIndex:13},{value:"无",paraId:47,tocIndex:13},{value:"展示节点",paraId:47,tocIndex:13},{value:"另外我们也可以通过 ",paraId:48,tocIndex:13},{value:"visibility",paraId:48,tocIndex:13},{value:" 属性控制：",paraId:48,tocIndex:13},{value:"const group = new Group();\n\ngroup.hide();\n// or group.setAttribute('visibility', false);\n\ngroup.show();\n// or group.setAttribute('visibility', true);\n",paraId:49,tocIndex:13},{value:"类似 CSS，我们可以通过 ",paraId:50,tocIndex:14},{value:"zIndex",paraId:50,tocIndex:14},{value:" 属性控制渲染次序，有两点需要注意：",paraId:50,tocIndex:14},{value:"只会影响渲染顺序，并不会改变场景图中的节点结构",paraId:51,tocIndex:14},{value:"只在当前上下文内生效",paraId:51,tocIndex:14},{value:"名称",paraId:52,tocIndex:14},{value:"参数",paraId:52,tocIndex:14},{value:"返回值",paraId:52,tocIndex:14},{value:"备注",paraId:52,tocIndex:14},{value:"setZIndex",paraId:52,tocIndex:14},{value:"number",paraId:52,tocIndex:14},{value:"无",paraId:52,tocIndex:14},{value:"设置 ",paraId:52,tocIndex:14},{value:"zIndex",paraId:52,tocIndex:14},{value:"toFront",paraId:52,tocIndex:14},{value:"无",paraId:52,tocIndex:14},{value:"无",paraId:52,tocIndex:14},{value:"置顶",paraId:52,tocIndex:14},{value:"toBack",paraId:52,tocIndex:14},{value:"无",paraId:52,tocIndex:14},{value:"无",paraId:52,tocIndex:14},{value:"置底",paraId:52,tocIndex:14},{value:"const group = new Group();\n\ngroup.setZIndex(100);\n// or group.setAttribute('zIndex', 100);\n",paraId:53,tocIndex:14},{value:"场景图的层次结构非常适合使用声明式语法描述，参考 ",paraId:54,tocIndex:15},{value:"react-three-fiber",paraId:54,tocIndex:15},{value:"，我们也可以为 G 实现一个 ",paraId:54,tocIndex:15},{value:"React Renderer",paraId:54,tocIndex:15},{value:"，它具有以下优势：",paraId:54,tocIndex:15},{value:"声明式语法便于描述层次结构",paraId:55,tocIndex:15},{value:"便于组件复用",paraId:55,tocIndex:15},{value:"天生容易和 React 生态结合",paraId:55,tocIndex:15},{value:"使用声明式语法定义场景图结构，省略了大量对于 ",paraId:56,tocIndex:16},{value:"appendChild",paraId:56,tocIndex:16},{value:" 的手动调用",paraId:56,tocIndex:16},{value:"如果需要调用 ",paraId:56,tocIndex:16},{value:"Group",paraId:56,tocIndex:16},{value:" 上的方法，可以使用 ",paraId:56,tocIndex:16},{value:"useRef",paraId:56,tocIndex:16},{value:" 获取引用",paraId:56,tocIndex:16},{value:"提供例如 ",paraId:56,tocIndex:16},{value:"useFrame",paraId:56,tocIndex:16},{value:" 这样的 hook，完成动画",paraId:56,tocIndex:16},{value:'import React, { useRef, useState } from \'react\';\nimport { Group, Circle, useFrame } from \'@antv/react-g-fiber\';\n\nconst SolarSystem = () => {\n    // 创建对于 Group 的引用\n    const solarSystem = useRef();\n    const earthOrbit = useRef();\n\n    // 每一帧调用\n    useFrame(() => {\n        solarSystem.rotateLocal(1);\n        earthOrbit.rotateLocal(1);\n    });\n\n    const [hovered, setHover] = useState(false);\n\n    return;\n    <Group name="solarSystem" ref={solarSystem} position={[300, 250]}>\n        <Circle name="sun" r={100} />\n        <Group name="earthOrbit" ref={earthOrbit} localPosition={[100, 0]}>\n            <Circle name="earth" r={50} />\n            <Group name="moonOrbit" localPosition={[100, 0]}>\n                <Circle\n                    name="moon"\n                    r={25}\n                    fill={hovered ? \'yellow\' : \'red\'}\n                    onPointerOver={(event) => setHover(true)}\n                    onPointerOut={(event) => setHover(false)}\n                />\n            </Group>\n        </Group>\n    </Group>;\n};\n',paraId:57,tocIndex:16},{value:"在渲染组件时才需要指定渲染引擎：",paraId:58,tocIndex:17},{value:"import ReactDOM from 'react-dom';\nimport { Canvas } from '@antv/react-g-fiber';\nimport { SolarSystem } from './SolarSystem';\n\nReactDOM.render(\n    <Canvas width={600} height={500} renderer=\"webgl\">\n        <SolarSystem />\n    </Canvas>,\n    document.getElementById('root'),\n);\n",paraId:59,tocIndex:17},{value:"在实际使用中，如何将场景图中的节点与 HTML 结合是一个问题，尤其当 HTML 变得复杂时，就不仅仅是一个 HUD 问题了：",paraId:60,tocIndex:18},{value:"Canvas/WebGL 可以渲染类似按钮这样的简单组件，但类似输入框、表单这样的复杂组件成本太高",paraId:61,tocIndex:18},{value:"SVG 虽然可以使用 ",paraId:61,tocIndex:18},{value:"foreignObject",paraId:61,tocIndex:18},{value:"，兼顾基础图形和 HTML 的渲染，但存在性能问题",paraId:61,tocIndex:18},{value:"因此我们应该让渲染引擎做它们擅长的事情：让 Canvas/WebGL 高效地绘制基础图形，让 HTML 来渲染复杂组件。两者之间的",paraId:62,tocIndex:18},{value:"联动",paraId:62,tocIndex:18},{value:"才是我们该关心的问题。",paraId:62,tocIndex:18},{value:"参考 ",paraId:63,tocIndex:18},{value:"drei",paraId:63,tocIndex:18},{value:" 我们可以提供一个 HTML 容器节点。在渲染时该节点会被 G 跳过，但它的位置依然会通过场景图计算，只是最终通过修改 CSS 样式生效：",paraId:63,tocIndex:18},{value:"import { Group, Circle, HTML } from '@antv/react-g-fiber';\n\nconst SolarSystem = () => (\n    <Group>\n        <Circle r={100} />\n        <HTML prepend>\n            <h1>hello</h1>\n            <p>world</p>\n        </HTML>\n    </Group>\n);\n",paraId:64,tocIndex:18},{value:"该容器中的内容会添加在 ",paraId:65,tocIndex:18},{value:"<canvas>",paraId:65,tocIndex:18},{value:" 之后。但毕竟是特殊节点，一些会功能受限，例如：",paraId:65,tocIndex:18},{value:"无法通过 ",paraId:66,tocIndex:18},{value:"z-index",paraId:66,tocIndex:18},{value:" 让它夹在两个 ",paraId:66,tocIndex:18},{value:"Circle",paraId:66,tocIndex:18},{value:" 之间",paraId:66,tocIndex:18},{value:"无法在内部嵌套其他基础图形节点",paraId:66,tocIndex:18},{value:"选择兼容 DOM API 与 CSS 选择器，除了降低学习成本，还有一个很大的好处，那就是很容易与一些已有生态结合，例如 D3，因为大家的节点定义都是基于统一的接口。",paraId:67,tocIndex:19},{value:"SpriteJS 就是这么做的，节点描述、处理逻辑仍由 D3 完成，渲染则替换成了自身实现的 Canvas/WebGL： ",paraId:68,tocIndex:19},{value:"https://spritejs.org/demo/#/d3/bar",paraId:68,tocIndex:19},{value:"虽然旧版 G 4.0 中提供的场景图相关功能并不完整，但毕竟上层 G2、G6 也使用了一部分 API，我们会尽可能兼容它们。",paraId:69,tocIndex:20},{value:"由于之前变换方法不全，因此 G6 使用了 ",paraId:70,tocIndex:21},{value:"@antv/matrix-util",paraId:70,tocIndex:21},{value:"，让用户可以通过 ",paraId:70,tocIndex:21},{value:"get/setMatrix",paraId:70,tocIndex:21},{value:" 直接操作变换矩阵：",paraId:70,tocIndex:21},{value:"import { transform } from '@antv/matrix-util';\ntransform(m, [\n    ['t', x, y], // translate with vector (x, y)\n    ['r', Math.PI], // rotate\n    ['s', 2, 2], // scale at x-axis and y-axis\n]);\n",paraId:71,tocIndex:21},{value:"我们建议去除该依赖，直接使用节点的变换方法：",paraId:72,tocIndex:21},{value:"group\n    .translate(x, y)\n    .rotateLocal(180) // rotate in degrees\n    .scaleLocal(2, 2);\n",paraId:73,tocIndex:21},{value:"场景图应该能够脱离渲染引擎存在，这样在描述组件时才不需要考虑具体渲染引擎（",paraId:74,tocIndex:22},{value:"g-canvas/svg/webgl",paraId:74,tocIndex:22},{value:"）。因此不再建议使用 ",paraId:74,tocIndex:22},{value:"canvas.addGroup",paraId:74,tocIndex:22},{value:" 和 ",paraId:74,tocIndex:22},{value:"canvas.addShape",paraId:74,tocIndex:22},{value:" 这样的方法。",paraId:74,tocIndex:22},{value:"// 不建议使用旧版\nimport { Canvas } from 'g-canvas';\nconst canvas = new Canvas();\nconst circle = canvas.addShape('circle', { style: { r: 25 } });\n\n// 建议使用新版\n// 定义组件\nimport { Circle, Canvas } from '@antv/g';\nconst circle = new Circle({ style: { r: 25 } });\n// 渲染组件\nconst canvas = new Canvas({});\ncanvas.appendChild(circle);\n",paraId:75,tocIndex:22},{value:"G6 使用了 ",paraId:76,tocIndex:23},{value:"find",paraId:76,tocIndex:23},{value:" 方法查询符合条件的节点：",paraId:76,tocIndex:23},{value:"group.find((element) => element.get('className') === 'link-point-left');\n",paraId:77,tocIndex:23},{value:"这类简单的查询可以使用 ",paraId:78,tocIndex:23},{value:"getElementsByClassName",paraId:78,tocIndex:23},{value:" 或者 ",paraId:78,tocIndex:23},{value:"queryAllSelector",paraId:78,tocIndex:23},{value:" 代替：",paraId:78,tocIndex:23},{value:"group.getElementsByClassName('link-point-left');\n// or\ngroup.queryAllSelector('.link-point-left');\n",paraId:79,tocIndex:23},{value:"但要注意，和 DOM API 一致，查询范围不仅仅局限在直接的子节点列表，而是一整棵子树。",paraId:80,tocIndex:23},{value:"修复了旧版 ",paraId:81,tocIndex:24},{value:"z-index",paraId:81,tocIndex:24},{value:" 的 bug，API 不变。",paraId:81,tocIndex:24},{value:"World vs Local Space. Why do we need them both?",paraId:82,tocIndex:25},{value:"PlayCanvas Docs - Manipulating Entities",paraId:82,tocIndex:25},{value:"What dose 'lossyScale' actually means?",paraId:82,tocIndex:25}]},66559:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(5364);const n=[{value:"有了",paraId:0},{value:"场景图",paraId:1},{value:"的知识，在本教程中我们来创造一个“太阳系”，月球绕着地球转、地球绕着太阳转。",paraId:0},{value:"其中会涉及以下 API：",paraId:2},{value:"使用 ",paraId:3},{value:"appendChild",paraId:4},{value:" 创建场景中各个节点的父子关系",paraId:3},{value:"使用 ",paraId:3},{value:"translate",paraId:5},{value:" 移动节点",paraId:3},{value:"使用 ",paraId:3},{value:"rotate",paraId:6},{value:" 让节点旋转",paraId:3},{value:"使用 ",paraId:3},{value:"getElementsByName",paraId:7},{value:" 在场景图中查询节点",paraId:3},{value:"使用 ",paraId:3},{value:"addEventListener",paraId:8},{value:" 监听画布事件",paraId:3},{value:"最终示例：",paraId:9},{value:"官网示例",paraId:10},{value:"CodeSandbox 示例",paraId:11},{value:"它具有以下层次关系：",paraId:12,tocIndex:0},{value:"太阳系 solarSystem\n   |    |\n   |   太阳 sun\n   |\n 地球轨道 earthOrbit\n   |    |\n   |  地球 earth\n   |\n 月球轨道 moonOrbit\n      |\n     月球 moon\n",paraId:13,tocIndex:0},{value:"从 ",paraId:14,tocIndex:0},{value:"@antv/g",paraId:14,tocIndex:0},{value:" 核心包中引入基础对象 ",paraId:14,tocIndex:0},{value:"Group",paraId:15,tocIndex:0},{value:" 和 ",paraId:14,tocIndex:0},{value:"Circle",paraId:16,tocIndex:0},{value:"。前者无可渲染实体，仅表示逻辑上的“容器”概念，适合“太阳系”、“地球轨道”、“月球轨道”这样的抽象概念，而后者用来表现太阳、地球和月球。当我们想表示“从属”关系时，就可以使用 ",paraId:14,tocIndex:0},{value:"appendChild",paraId:14,tocIndex:0},{value:"，例如“太阳属于太阳系”：",paraId:14,tocIndex:0},{value:"import { Group, Circle } from '@antv/g';\n\n// 太阳系\nconst solarSystem = new Group({\n    name: 'solarSystem',\n});\n// 地球轨道\nconst earthOrbit = new Group({\n    name: 'earthOrbit',\n});\n// 月球轨道\nconst moonOrbit = new Group({\n    name: 'moonOrbit',\n});\n// 太阳\nconst sun = new Circle({\n    name: 'sun',\n    style: {\n        r: 100,\n    },\n});\n// 地球\nconst earth = new Circle({\n    name: 'earth',\n    style: {\n        r: 50,\n    },\n});\n// 月球\nconst moon = new Circle({\n    name: 'moon',\n    style: {\n        r: 25,\n    },\n});\n\n// 太阳属于太阳系\nsolarSystem.appendChild(sun);\n// 地球轨道也属于太阳系\nsolarSystem.appendChild(earthOrbit);\nearthOrbit.appendChild(earth);\nearthOrbit.appendChild(moonOrbit);\nmoonOrbit.appendChild(moon);\n",paraId:17,tocIndex:0},{value:"后续随时可以通过 ",paraId:18,tocIndex:0},{value:"getElementsByName",paraId:19,tocIndex:0},{value:" 在场景图中查询节点：",paraId:18,tocIndex:0},{value:"canvas.getElementsByName('sun'); // [sun]\n",paraId:20,tocIndex:0},{value:"此时我们使用 ",paraId:21,tocIndex:1},{value:"setPosition",paraId:22,tocIndex:1},{value:" 将整个太阳系移动到画布中央，基于场景图内的父子关系，太阳、地球轨道、地球、月球轨道和月球都被移动到了 ",paraId:21,tocIndex:1},{value:"(300, 250)",paraId:21,tocIndex:1},{value:"，如下图（左）所示：",paraId:21,tocIndex:1},{value:"// 设置太阳系的位置\nsolarSystem.setPosition(300, 250);\n",paraId:23,tocIndex:1},{value:"保持太阳位置不变，我们沿 X 轴移动地球轨道 100，同样地球、月球轨道和月球也都被移动到了世界坐标系下",paraId:24,tocIndex:1},{value:"(400, 250)",paraId:24,tocIndex:1},{value:"，如下图（中）所示：",paraId:24,tocIndex:1},{value:"earthOrbit.translate(100, 0);\n// earthOrbit.getLocalPosition() --\x3e (100, 0)\n// earthOrbit.getPosition() --\x3e (400, 250)\n",paraId:25,tocIndex:1},{value:"然后我们移动月球轨道，如下图（右）所示：",paraId:26,tocIndex:1},{value:"moonOrbit.translate(100, 0);\n",paraId:27,tocIndex:1},{value:"现在我们需要让地球和月球都旋转起来。首先使用 ",paraId:28,tocIndex:2},{value:"addEventListener",paraId:29,tocIndex:2},{value:" 给画布添加一个事件监听器，监听 ",paraId:28,tocIndex:2},{value:"AFTER_RENDER",paraId:30,tocIndex:2},{value:" 事件，该事件会在每一帧渲染完毕后触发。然后我们分别让太阳系和地球轨道在局部坐标系中沿 Z 轴旋转 1 度（你也可以让地球轨道转的更快点）：",paraId:28,tocIndex:2},{value:"import { CanvasEvent } from '@antv/g';\n\n// 当画布每一帧渲染完毕时...\ncanvas.addEventListener(CanvasEvent.AFTER_RENDER, () => {\n    // 太阳系自转\n    solarSystem.rotateLocal(1);\n    // 地球轨道自转\n    earthOrbit.rotateLocal(1);\n});\n",paraId:31,tocIndex:2}]},54857:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(77585);const n=[{value:"After describing the objects to be rendered by the scene graph, we need to give them to the renderer. Which renderer to use is introduced by the user on demand and can be switched at runtime.",paraId:0},{value:"We currently provide a variety of ",paraId:1,tocIndex:0},{value:"renderers",paraId:2,tocIndex:0},{value:" that users can introduce on-demand like plugins, but at least one is required.",paraId:1,tocIndex:0},{value:"import { Renderer as CanvasRenderer } from '@antv/g-canvas';\nimport { Renderer as WebGLRenderer } from '@antv/g-webgl';\n",paraId:3,tocIndex:0},{value:"This allows you to choose one of the renderers introduced when creating ",paraId:4,tocIndex:0},{value:"Canvas",paraId:5,tocIndex:0},{value:", e.g. if we introduce a Canvas and a WebGL renderer, we can choose between the two.",paraId:4,tocIndex:0},{value:"import { Canvas } from '@antv/g';\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    // renderer: new CanvasRenderer(),\n    renderer: new WebGLRenderer(),\n});\n",paraId:6,tocIndex:0},{value:"Many rendering engines choose the default renderer for the user, for example Pixi.js gives preference to WebGL and downgrades to Canvas if it is not supported. in G this choice is left to the user.",paraId:7,tocIndex:0},{value:"If multiple renderers are introduced, they can be switched at runtime. Currently all DEMOs on the G website can be switched in the ",paraId:8,tocIndex:1},{value:"renderer",paraId:8,tocIndex:1},{value:" panel without interrupting the animation. In G6, for example, you can dynamically determine whether you need to switch to the WebGL renderer by the number of nodes and edges.",paraId:8,tocIndex:1},{value:"import { Renderer as WebGLRenderer } from '@antv/g-webgl';\nimport { Renderer as SvgRenderer } from '@antv/g-svg';\n\nconst webglRenderer = new WebGLRenderer();\nconst svgRenderer = new SvgRenderer();\n\nif (tooManyShapes) {\n    canvas.setRenderer(webglRenderer);\n} else {\n    canvas.setRenderer(svgRenderer);\n}\n",paraId:9,tocIndex:1}]},4550:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(45767);const n=[{value:"Yoga",paraId:0},{value:" 是 Facebook 提供的跨平台布局引擎，基于 Flex，属性和 CSS Flex 完全一致，因此也可以阅读 ",paraId:0},{value:"MDN flex 布局的基本概念",paraId:0},{value:" 获取更多概念知识。",paraId:0},{value:"通过 ",paraId:1},{value:"g-plugin-yoga",paraId:2},{value:" 插件的支持，我们可以给已有 2D 图形增加 Flex 属性。",paraId:1},{value:"在该",paraId:3},{value:"示例",paraId:4},{value:"中，我们创建了一个常见的自适应布局效果：",paraId:3},{value:"创建一个渲染器并注册插件：",paraId:5,tocIndex:0},{value:"import { Canvas, CanvasEvent } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\nimport { Plugin as PluginYoga } from '@antv/g-plugin-yoga';\n\nconst renderer = new Renderer();\nconst plugin = new PluginYoga();\nrenderer.registerPlugin(plugin);\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:6,tocIndex:0},{value:"我们使用 ",paraId:7,tocIndex:1},{value:"Rect",paraId:8,tocIndex:1},{value:" 创建一个淡蓝色背景容器。",paraId:7,tocIndex:1},{value:"首先通过 ",paraId:9,tocIndex:1},{value:"display: 'flex'",paraId:9,tocIndex:1},{value:" 将它声明为一个 Flex 容器。目前我们仅支持 ",paraId:9,tocIndex:1},{value:"Rect",paraId:10,tocIndex:1},{value:" 和 ",paraId:9,tocIndex:1},{value:"Group",paraId:11,tocIndex:1},{value:" 作为 Flex 容器，详见",paraId:9,tocIndex:1},{value:"声明 Flex 容器",paraId:12,tocIndex:1},{value:"。",paraId:9,tocIndex:1},{value:"然后使用 ",paraId:13,tocIndex:1},{value:"flexDirection",paraId:14,tocIndex:1},{value:" 属性让子元素竖向排列。",paraId:13,tocIndex:1},{value:"最后使用 ",paraId:15,tocIndex:1},{value:"padding",paraId:16,tocIndex:1},{value:" 在四周留白：",paraId:15,tocIndex:1},{value:"const root = new Rect({\n  id: 'root',\n  style: {n\n    fill: '#C6E5FF',\n    width: 500,\n    height: 300,\n    x: 50,\n    y: 50,\n    display: 'flex', // 声明为 Flex 容器\n    flexDirection: 'column',\n    padding: [10, 10, 10, 10],\n  },\n});\ncanvas.appendChild(root);\n",paraId:17,tocIndex:1},{value:"接下来我们往容器中添加第一个元素，一个固定高度的 Header。",paraId:18,tocIndex:2},{value:"注意宽度我们使用了百分比 ",paraId:19,tocIndex:2},{value:"width: '100%'",paraId:19,tocIndex:2},{value:"，即父元素（淡蓝色容器）的宽度。",paraId:19,tocIndex:2},{value:"const topPanel = new Rect({\n    style: {\n        fill: 'white',\n        stroke: 'grey',\n        lineWidth: 1,\n        opacity: 0.8,\n        width: '100%',\n        height: 60,\n        marginBottom: 10,\n    },\n});\n",paraId:20,tocIndex:2},{value:"固定 Header 之后，我们希望下方区域占满容器的剩余空间。",paraId:21,tocIndex:3},{value:"这里我们创建了一个 ",paraId:22,tocIndex:3},{value:"Group",paraId:23,tocIndex:3},{value:"，没有继续使用 ",paraId:22,tocIndex:3},{value:"Rect",paraId:24,tocIndex:3},{value:" 的原因是我们不希望它作为容器本身被渲染出来。",paraId:22,tocIndex:3},{value:"使用 ",paraId:25,tocIndex:3},{value:"flexGrow",paraId:26,tocIndex:3},{value:" 这样它的高度会根据父容器自适应，同时声明自身也是一个 Flex 容器，后续会添加更多子元素。",paraId:25,tocIndex:3},{value:"const bottomPanel = new Group({\n    style: {\n        display: 'flex',\n        width: '100%',\n        flexGrow: 1,\n    },\n});\n",paraId:27,tocIndex:3},{value:"接下来我们继续划分刚创建的下方区域，这次创建一个水平方向的两栏布局。",paraId:28,tocIndex:4},{value:"bottomPanel.appendChild(leftPanel);\nbottomPanel.appendChild(rightPanel);\n",paraId:29,tocIndex:4},{value:"居中也是一个常见的需求，例如顶部 Header 中使用 ",paraId:30,tocIndex:5},{value:"justifyContent",paraId:31,tocIndex:5},{value:" 和 ",paraId:30,tocIndex:5},{value:"alignItems",paraId:32,tocIndex:5},{value:" 实现：",paraId:30,tocIndex:5},{value:"const topPanel = new Rect({\n    style: {\n        display: 'flex',\n        justifyContent: 'center',\n        alignItems: 'center',\n    },\n});\ntopPanel.appendChild(\n    new Text({\n        style: {\n            fontFamily: 'PingFang SC',\n            fontSize: 24,\n            fill: '#1890FF',\n            text: '1',\n        },\n    }),\n);\n",paraId:33,tocIndex:5}]},62615:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(2361);const n=[{value:" ",paraId:0},{value:" ",paraId:1},{value:" ",paraId:2},{value:" ",paraId:2},{value:" ",paraId:2},{value:"As the underlying rendering engine of AntV, G is dedicated to provide consistent and high performance 2D / 3D graphics rendering capabilities for upper layer products, adapting all underlying rendering APIs (Canvas2D / SVG / WebGL / WebGPU / CanvasKit / Node.js) on the web side. In particular, it provides GPGPU support for algorithms suitable for parallel computing in graph scenarios.",paraId:3},{value:"\n  ",paraId:4},{value:"Easy-to-use API",paraId:5,tocIndex:0},{value:"。The graphics and event system is compatible with DOM Element & Event API, and the animation system is compatible with Web Animations API, which can be adapted to the existing ecology of Web side such as D3, Hammer.js gesture library, etc. at a very low cost.",paraId:5,tocIndex:0},{value:"Support multiple rendering environments",paraId:6,tocIndex:0},{value:"。Support Canvas2D / SVG / WebGL / WebGPU / CanvasKit and runtime switching, and also server-side rendering.",paraId:6,tocIndex:0},{value:"High performance rendering and computing",paraId:7,tocIndex:0},{value:"。WebGPU-based GPGPU support for parallelizable algorithms. ",paraId:7,tocIndex:0},{value:"webgpu-graph",paraId:8,tocIndex:0},{value:" is a library of graph analysis algorithms using GPU acceleration.",paraId:7,tocIndex:0},{value:"Extensible plug-in mechanism and rich set of plug-ins：",paraId:9,tocIndex:0},{value:"Rendering Related\n",paraId:10,tocIndex:0},{value:"g-plugin-canvas-renderer",paraId:11,tocIndex:0},{value:" Rendering 2D graphics based on Canvas2D.",paraId:12,tocIndex:0},{value:"g-plugin-canvaskit-renderer",paraId:13,tocIndex:0},{value:" Rendering 2D graphics based on ",paraId:12,tocIndex:0},{value:"Skia",paraId:12,tocIndex:0},{value:".",paraId:12,tocIndex:0},{value:"g-plugin-svg-renderer",paraId:14,tocIndex:0},{value:" Rendering 2D graphics based on SVG.",paraId:12,tocIndex:0},{value:"g-plugin-device-renderer",paraId:15,tocIndex:0},{value:" Rendering 2D graphics based on GPUDevice.",paraId:12,tocIndex:0},{value:"g-plugin-html-renderer",paraId:16,tocIndex:0},{value:" Rendering DOM with HTML.",paraId:12,tocIndex:0},{value:"g-plugin-3d",paraId:17,tocIndex:0},{value:" Extended 3D capabilities.",paraId:12,tocIndex:0},{value:"g-plugin-rough-canvas-renderer",paraId:18,tocIndex:0},{value:" Perform hand-drawn style rendering with ",paraId:12,tocIndex:0},{value:"rough.js",paraId:12,tocIndex:0},{value:" and Canvas2D.",paraId:12,tocIndex:0},{value:"g-plugin-rough-svg-renderer",paraId:19,tocIndex:0},{value:" Perform hand-drawn style rendering with ",paraId:12,tocIndex:0},{value:"rough.js",paraId:12,tocIndex:0},{value:" and SVG.",paraId:12,tocIndex:0},{value:"Picking\n",paraId:10,tocIndex:0},{value:"g-plugin-canvas-picker",paraId:20,tocIndex:0},{value:" Do picking with Canvas2D and mathematical calculations.",paraId:21,tocIndex:0},{value:"g-plugin-svg-picker",paraId:22,tocIndex:0},{value:" Do picking with SVG and DOM API.",paraId:21,tocIndex:0},{value:"Accessibility\n",paraId:10,tocIndex:0},{value:"g-plugin-a11y",paraId:23,tocIndex:0},{value:" Provides SEO, screen reader support and keyboard navigation.",paraId:24,tocIndex:0},{value:"Interaction\n",paraId:10,tocIndex:0},{value:"g-plugin-dom-interaction",paraId:25,tocIndex:0},{value:" Binds event listeners with DOM API.",paraId:26,tocIndex:0},{value:"g-plugin-control",paraId:27,tocIndex:0},{value:" Provides camera interaction for 3D scenes.",paraId:26,tocIndex:0},{value:"g-plugin-dragndrop",paraId:28,tocIndex:0},{value:" Provides Drag 'n' Drop based on PointerEvents.",paraId:26,tocIndex:0},{value:"Physics Engine\n",paraId:10,tocIndex:0},{value:"g-plugin-box2d",paraId:29,tocIndex:0},{value:" Based on ",paraId:30,tocIndex:0},{value:"Box2D",paraId:30,tocIndex:0},{value:".",paraId:30,tocIndex:0},{value:"g-plugin-matterjs",paraId:31,tocIndex:0},{value:" Based on ",paraId:30,tocIndex:0},{value:"matter.js",paraId:30,tocIndex:0},{value:".",paraId:30,tocIndex:0},{value:"g-plugin-physx",paraId:32,tocIndex:0},{value:" Based on ",paraId:30,tocIndex:0},{value:"PhysX",paraId:30,tocIndex:0},{value:".",paraId:30,tocIndex:0},{value:"Layout Engine\n",paraId:10,tocIndex:0},{value:"g-plugin-yoga",paraId:33,tocIndex:0},{value:" Provides Flex layout capabilities based on Yoga.",paraId:34,tocIndex:0},{value:"GPGPU\n",paraId:10,tocIndex:0},{value:"g-plugin-gpgpu",paraId:35,tocIndex:0},{value:" Provides GPGPU capabilities based on WebGPU.",paraId:36,tocIndex:0},{value:"CSS Selector\n",paraId:10,tocIndex:0},{value:"g-plugin-css-select",paraId:37,tocIndex:0},{value:" Supports for retrieval in the scene graph using CSS selectors.",paraId:38,tocIndex:0},{value:"Full ",paraId:39,tocIndex:0},{value:"API Spec",paraId:40,tocIndex:0},{value:".",paraId:39,tocIndex:0},{value:"We currently support both CDN and NPM Module usage.",paraId:41,tocIndex:1},{value:"Import the core and renderer code in UMD format:",paraId:42,tocIndex:2},{value:'\x3c!-- G Core --\x3e\n<script\n    src="https://unpkg.com/@antv/g/dist/index.umd.min.js"\n    type="application/javascript"\n><\/script>\n\x3c!-- G Renderers, such as Canvas2D, SVG and WebGL --\x3e\n<script\n    src="https://unpkg.com/@antv/g-canvas/dist/index.umd.min.js"\n    type="application/javascript"\n><\/script>\n\x3c!-- <script src="https://unpkg.com/@antv/g-svg/dist/index.umd.min.js" type="application/javascript"><\/script>\n<script src="https://unpkg.com/@antv/g-webgl/dist/index.umd.min.js" type="application/javascript"><\/script> --\x3e\n',paraId:43,tocIndex:2},{value:"Then we can use some core objects such as ",paraId:44,tocIndex:2},{value:"Canvas",paraId:45,tocIndex:2},{value:" and ",paraId:44,tocIndex:2},{value:"Circle",paraId:46,tocIndex:2},{value:" under the namespace ",paraId:44,tocIndex:2},{value:"window.G",paraId:44,tocIndex:2},{value:":",paraId:44,tocIndex:2},{value:"const { Circle, Canvas, CanvasEvent } = window.G;\n\n// create a Canvas2D renderer\nconst canvasRenderer = new window.G.Canvas2D.Renderer();\n\n// create a canvas\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: canvasRenderer,\n});\n\n// create a Circle\nconst circle = new Circle({\n    style: {\n        r: 50,\n        fill: '#1890FF',\n        stroke: '#F04864',\n        lineWidth: 4,\n        cursor: 'pointer',\n    },\n});\n\n// wait for the initialization of Canvas\ncanvas.addEventListener(CanvasEvent.READY, () => {\n    // append a Circle to canvas\n    canvas.appendChild(circle);\n});\n",paraId:47,tocIndex:2},{value:"Demo in CodeSandbox",paraId:48,tocIndex:2},{value:"Install core and renderer from NPM：",paraId:49,tocIndex:3},{value:"# Core\n$ npm install @antv/g --save\n\n# Canvas2D Renderer\n$ npm install @antv/g-canvas --save\n# SVG Renderer\n$ npm install @antv/g-svg --save\n# WebGL Renderer\n$ npm install @antv/g-webgl --save\n",paraId:50,tocIndex:3},{value:"Then we can import some core objects such as ",paraId:51,tocIndex:3},{value:"Canvas",paraId:52,tocIndex:3},{value:" and ",paraId:51,tocIndex:3},{value:"Circle",paraId:53,tocIndex:3},{value:" from ",paraId:51,tocIndex:3},{value:"@antv/g",paraId:51,tocIndex:3},{value:":",paraId:51,tocIndex:3},{value:"import { Canvas, CanvasEvent, Circle } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: new Renderer(),\n});\n\nconst circle = new Circle({\n    style: {\n        r: 50,\n        fill: '#1890FF',\n        stroke: '#F04864',\n        lineWidth: 4,\n        cursor: 'pointer',\n    },\n});\n\ncanvas.addEventListener(CanvasEvent.READY, () => {\n    canvas.appendChild(circle);\n});\n",paraId:54,tocIndex:3},{value:"DEMO in CodeSandbox",paraId:55,tocIndex:3},{value:"DEMO in StackBlitz",paraId:56,tocIndex:3}]},35339:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(40113);const n=[{value:"使用",paraId:0,tocIndex:0},{value:"场景图",paraId:1,tocIndex:0},{value:"构建",paraId:0,tocIndex:0}]},5647:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(66668);const n=[{value:"在目前 monorep 中，各个包的依赖关系如下：",paraId:0,tocIndex:0},{value:"@antv/g",paraId:1,tocIndex:0},{value:" 核心包，依赖注入使用 mana-syringe",paraId:1,tocIndex:0},{value:"@antv/g-canvas/svg/webgl",paraId:1,tocIndex:0},{value:" 渲染器包，依赖 ",paraId:1,tocIndex:0},{value:"@antv/g",paraId:1,tocIndex:0},{value:"，内部注册了一系列插件：\n",paraId:1,tocIndex:0},{value:"例如 ",paraId:2,tocIndex:0},{value:"@antv/g-canvas",paraId:2,tocIndex:0},{value:" 依赖 ",paraId:2,tocIndex:0},{value:"@antv/g-plugin-canvas-renderer",paraId:2,tocIndex:0},{value:" 等四个插件",paraId:2,tocIndex:0},{value:"@antv/g-plugin-xxx",paraId:1,tocIndex:0},{value:" 插件包，依赖 ",paraId:1,tocIndex:0},{value:"@antv/g",paraId:1,tocIndex:0},{value:"，部分插件也会依赖其他插件",paraId:1,tocIndex:0},{value:"特别的，",paraId:3,tocIndex:0},{value:"g-webgl",paraId:3,tocIndex:0},{value:" 使用 wasm 转译 GLSL 到 WGSL。",paraId:3,tocIndex:0},{value:"在构建时我们选择 ",paraId:4,tocIndex:0},{value:"father",paraId:4,tocIndex:0},{value:" 构建 CJS 与 ESM，webpack4 构建 UMD。",paraId:4,tocIndex:0},{value:"构建时使用 father：",paraId:5,tocIndex:1},{value:'// 根目录 package.json\n"build": "father build",\n',paraId:6,tocIndex:1},{value:"在 ",paraId:7,tocIndex:1},{value:"fatherrc",paraId:7,tocIndex:1},{value:" 中选择 ",paraId:7,tocIndex:1},{value:"babel",paraId:7,tocIndex:1},{value:" 模式：",paraId:7,tocIndex:1},{value:"{\n  cjs: 'babel',\n  esm: 'babel',\n  umd: false,\n  nodeResolveOpts: {\n    mainFields: ['module', 'browser', 'main'],\n  },\n  pkgs: [\n    'g-math',\n    // 省略其他构建包\n  ]\n}\n",paraId:8,tocIndex:1},{value:"运行后在每个子包下 ",paraId:9,tocIndex:1},{value:"/es",paraId:9,tocIndex:1},{value:" 和 ",paraId:9,tocIndex:1},{value:"/lib",paraId:9,tocIndex:1},{value:" 下就会生成对应源文件的 ESM 和 CJS 文件了。",paraId:9,tocIndex:1},{value:"使用 webpack4 构建 UMD，以 ",paraId:10,tocIndex:2},{value:"g-canvas",paraId:10,tocIndex:2},{value:" 为例，在配置文件中排除掉：",paraId:10,tocIndex:2},{value:"module.exports = {\n    ...common,\n    externals: {\n        '@antv/g': {\n            commonjs: '@antv/g',\n            commonjs2: '@antv/g',\n            amd: '@antv/g',\n            root: 'G', // 运行时通过 window.G 获取\n        },\n        'mana-syringe': {\n            commonjs: 'mana-syringe',\n            commonjs2: 'mana-syringe',\n            amd: 'mana-syringe',\n            root: ['G', 'ManaSyringe'], // 运行时通过 window.G.ManaSyringe 获取\n        },\n    },\n    output: {\n        library: ['G', 'Canvas2D'], // 暴露 window.G.Canvas2D\n        libraryTarget: 'umd',\n        filename: 'index.umd.min.js',\n    },\n};\n",paraId:11,tocIndex:2},{value:"特别的 ",paraId:12,tocIndex:3},{value:"g-webgl",paraId:12,tocIndex:3},{value:" 需要使用 WASM，因此多加一个插件：",paraId:12,tocIndex:3},{value:"plugins: [\n    new WasmPackPlugin({\n        crateDirectory: path.join(__dirname, 'rust'), // crate 放在 /rust 下\n        forceMode: 'production',\n    }),\n],\n",paraId:13,tocIndex:3}]},68326:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(43217);const n=[{value:"支持以下渐变效果，可应用在 ",paraId:0,tocIndex:0},{value:"fill",paraId:0,tocIndex:0},{value:" ",paraId:0,tocIndex:0},{value:"stroke",paraId:0,tocIndex:0},{value:" 属性上。不支持动画（直接应用，无渐变效果）。",paraId:0,tocIndex:0},{value:"可以在",paraId:1,tocIndex:0},{value:"示例",paraId:2,tocIndex:0},{value:"中切换 Canvas2D/SVG/WebGL 查看效果。",paraId:1,tocIndex:0},{value:"线性渐变：",paraId:3,tocIndex:0},{value:"stroke: 'l(0) 0:#ffffff 0.5:#7ec2f3 1:#1890ff';\n",paraId:4,tocIndex:0},{value:"放射状/环形渐变：",paraId:5,tocIndex:0},{value:"fill: 'r(0.5, 0.5, 0.1) 0:#ffffff 1:#1890ff';\n",paraId:6,tocIndex:0},{value:"纹理：",paraId:7,tocIndex:0},{value:"fill: 'p(a)https://gw.alipayobjects.com/zos/rmsportal/ibtwzHXSxomqbZCPMLqS.png';\n",paraId:8,tocIndex:0},{value:"通过以下 API 创建：",paraId:9,tocIndex:2},{value:"createLinearGradient",paraId:10,tocIndex:2},{value:"createRadialGradient",paraId:10,tocIndex:2},{value:" 由于 xyr 使用的是相对值，需要结合当前图形包围盒计算",paraId:10,tocIndex:2},{value:"createPattern",paraId:10,tocIndex:2},{value:"需要注意的是可以使用缓存减少重复创建的成本，例如以图片 URL、颜色值等为 key。",paraId:11,tocIndex:2},{value:"在 defs 中可以定义 pattern、渐变，然后通过 fill 属性引用 url：",paraId:12,tocIndex:3},{value:'<defs>\n    <pattern\n        patternUnits="userSpaceOnUse"\n        id="_pattern_3_4"\n        width="3"\n        height="3"\n    >\n        <image\n            href="https://gw.alipayobjects.com/zos/rmsportal/ibtwzHXSxomqbZCPMLqS.png"\n        >\n        </image>\n    </pattern>\n\n    <radialGradient cx="0.5" cy="0.5" r="0.5" id="_pattern_2_5">\n        <stop offset="0" stop-color="#ffffff"></stop>\n        <stop offset="1" stop-color="#1890ff"></stop>\n    </radialGradient>\n\n    <linearGradient x1="0" y1="0" x2="1" y2="0" id="_pattern_1_6">\n        <stop offset="0" stop-color="#ffffff"></stop>\n        <stop offset="0.5" stop-color="#7ec2f3"></stop>\n        <stop offset="1" stop-color="#1890ff"></stop>\n    </linearGradient>\n</defs>\n',paraId:13,tocIndex:3},{value:"在开发时发现 Chrome 无法正常展示 stroke 为 url 的水平直线，只要直线不是水平都能正常展示：",paraId:14,tocIndex:4},{value:'<line x1="0" y1="0" x2="20" y2="0" stroke-width="20" stroke="url(#utrim)" />\n',paraId:15,tocIndex:4},{value:"有人向 Chrome 反映了这个 bug，目前修复办法只能是稍微调整一下（注意下面给 y2 加了一点点偏移）让直线不是完全水平。。。",paraId:16,tocIndex:4},{value:"https://stackoverflow.com/questions/14680240/did-chrome-break-svg-stroke-url",paraId:17,tocIndex:4},{value:'<line\n    x1="0"\n    y1="0"\n    x2="100%"\n    y2="0.01"\n    stroke-width="20"\n    stroke="url(#utrim)"\n/>\n',paraId:18,tocIndex:4},{value:"当然可以在 Shader 中做渐变，但问题是需要支持多个 colorStop，可以通过 attribute 实现但还是挺麻烦。",paraId:19,tocIndex:5},{value:"https://stackoverflow.com/questions/61862262/webgl-shader-for-directional-linear-gradient",paraId:19,tocIndex:5},{value:"纹理支持通过 Canvas 创建，因此可以用 Canvas2D 创建 Gradient，例如 PIXI.js 就是这么做的： ",paraId:20,tocIndex:5},{value:"https://pixijs.io/examples/#/textures/gradient-basic.js",paraId:20,tocIndex:5},{value:"以线性渐变为例，可以创建一个定长的 OffscreenCanvas 例如 256 * 1（高度 1 就够），多次 addColorStop 之后用这个 OffscreenCanvas 创建纹理。 ",paraId:21,tocIndex:5},{value:"https://github.com/ShukantPal/pixi-essentials/blob/master/packages/gradients/src/GradientFactory.ts",paraId:21,tocIndex:5},{value:"但是对于 RadialGradient，还是需要创建一个 256 ",paraId:22,tocIndex:5},{value:"256，wrapTS 都设置为 clamp to edge 即可。值得一提的是纹理大小（32",paraId:22,tocIndex:5},{value:" 32）一定要小于 Canvas 大小，不然会出现走样问题。",paraId:22,tocIndex:5},{value:"WebGL1 对于 NPOT(power of 2 即长宽都是 2 的平方、立方）这样的纹理是不支持 REPEAT 这样的 wrap mode 的，也不支持 mipmap。WebGL2 则没有这样的限制。",paraId:23,tocIndex:6},{value:"https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL",paraId:24,tocIndex:6},{value:"WebGL1 can only use non power of 2 textures with filtering set to NEAREST or LINEAR and it can not generate a mipmap for them. Their wrapping mode must also be set to CLAMP_TO_EDGE. On the other hand if the texture is a power of 2 in both dimensions then WebGL can do higher quality filtering, it can use mipmap, and it can set the wrapping mode to REPEAT or MIRRORED_REPEAT.",paraId:25,tocIndex:6},{value:"因此在一些渲染引擎中能看到：",paraId:26,tocIndex:6},{value:"PIXI.js 中不允许对 NPOT 这样的纹理进行平铺。",paraId:27,tocIndex:6},{value:"Babylon.js 会进行 resize，当然这会造成额外性能开销。",paraId:27,tocIndex:6},{value:"https://doc.babylonjs.com/advanced_topics/webGL2#power-of-two-textures",paraId:27,tocIndex:6},{value:"我们暂时限制纹理必须为 POT，否则不支持平铺。",paraId:28,tocIndex:6}]},80860:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(82858);const n=[{value:"画一条线到底有多难。",paraId:0},{value:"最近的一期 WebGL / WebGPU Meetup 上一个“老生常谈”的话题又出现了，来自 Pixi.js 团队的“如何用 WebGL 画一条直线”：",paraId:1,tocIndex:0},{value:"https://www.khronos.org/assets/uploads/developers/presentations/Crazy_Panda_How_to_draw_lines_in_WebGL.pdf",paraId:1,tocIndex:0},{value:"之前我在知乎上总结过一篇：",paraId:2,tocIndex:0},{value:"在 WebGL 中绘制直线",paraId:2,tocIndex:0},{value:"。结合上面的分享完善下目前 G 的实现。",paraId:2,tocIndex:0},{value:"WebGL 原生是提供了 LINES 这样的 primitive 的，但在实际使用中往往并不好用。尤其是涉及到地理信息的展示，直接使用原生的 gl.LINES 进行绘制存在一些问题：",paraId:3,tocIndex:1},{value:"线宽无法设置，Chrome 下试图设置 lineWidth 会得到警告，相关 ISSUE ：\n",paraId:4,tocIndex:1},{value:"MDN ：As of January 2017 most implementations of WebGL only support a minimum of 1 and a maximum of 1 as the technology they are based on has these same limits.",paraId:5,tocIndex:1},{value:"无法定义相邻线段间的连接形状 lineJoin 以及端点形状 lineCap",paraId:4,tocIndex:1},{value:"因此我们得考虑将线段转换成其他几何图形进行绘制。",paraId:6,tocIndex:1},{value:"因此目前几乎所有的引擎都采用了在 CPU 侧进行三角化，根据 Cap、Joint 类型增加顶点。Mapbox 也是如此。另外也有在 Shader 中进行的例如 Geo.js，大量计算在 Fragment Shader 中进行。",paraId:7,tocIndex:2},{value:"下图来自 Pixi.js 团队的分享 PPT：",paraId:8,tocIndex:2},{value:"在 G 中，除了 Line、Polyline、Path 这些基础图形，在实现 stroke 描边时，也需要使用这一实现。",paraId:9,tocIndex:2},{value:"在绘制大量直线、折线甚至是曲线时，最好能尽可能共享顶点数据。",paraId:10,tocIndex:4},{value:"一种简单的做法是将线段看作一个 instance，这样一组线段（line strip）就可以重复绘制多次（端点数目 - 1）: ",paraId:11,tocIndex:4},{value:"https://wwwtyro.net/2019/11/18/instanced-lines.html",paraId:11,tocIndex:4},{value:"其中 instanced geometry 如下：",paraId:12,tocIndex:4},{value:"vec2 point = pointA + xBasis * position.x + yBasis * width * position.y;\n",paraId:13,tocIndex:4},{value:"https://wwwtyro.net/2019/11/18/instanced-lines.html",paraId:14,tocIndex:5},{value:"https://www.khronos.org/assets/uploads/developers/presentations/Crazy_Panda_How_to_draw_lines_in_WebGL.pdf",paraId:14,tocIndex:5}]},29086:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(19077);const n=[{value:"This plug-in can be introduced when 3D graphics are needed in the scene, and it has some common 3D graphics built in.",paraId:0},{value:"3D graphics drawing is only supported by the ",paraId:1,tocIndex:0},{value:"g-webgl",paraId:1,tocIndex:0},{value:" and ",paraId:1,tocIndex:0},{value:"g-webgpu",paraId:1,tocIndex:0},{value:" renderers.",paraId:1,tocIndex:0},{value:"import { Renderer as WebGLRenderer } from '@antv/g-webgl';\n// Creating a WebGL renderer\nconst webglRenderer = new WebGLRenderer();\n",paraId:2,tocIndex:0},{value:"Then you need to register the 3D plug-in.",paraId:3,tocIndex:0},{value:"import { Plugin } from '@antv/g-plugin-3d';\nwebglRenderer.registerPlugin(new Plugin());\n",paraId:4,tocIndex:0},{value:"Finally, specify this renderer when creating the canvas.",paraId:5,tocIndex:0},{value:"import { Canvas } from '@antv/g';\n\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer: webglRenderer, // 指定 WebGL 渲染器\n});\n",paraId:6,tocIndex:0},{value:"Material",paraId:7,tocIndex:1},{value:"Geometry",paraId:8,tocIndex:1},{value:"Light",paraId:9,tocIndex:1},{value:"Mesh",paraId:10,tocIndex:1}]},21278:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(18473);const n=[{value:'Since the canvas is usually presented as a "black box", the content cannot be textualized and read aloud by Screen Reader. Of course this is only one feature of accessibility, and for different types of people with different impairments, features such as text extraction, keyboard navigation, etc. can be provided.',paraId:0},{value:"One of the best in the area of graphics is ",paraId:1},{value:"https://www.highcharts.com/blog/accessibility/",paraId:1},{value:" where there is a lot of practice to be found.",paraId:1},{value:"Create plug-ins and register them in the renderer.",paraId:2,tocIndex:0},{value:"import { Plugin as PluginA11y } from '@antv/g-plugin-a11y';\nrenderer.registerPlugin(new PluginA11y());\n",paraId:3,tocIndex:0},{value:"In some renderers (e.g. ",paraId:4,tocIndex:2},{value:"g-canvas",paraId:5,tocIndex:2},{value:" / ",paraId:4,tocIndex:2},{value:"g-webgl",paraId:6,tocIndex:2},{value:" / ",paraId:4,tocIndex:2},{value:"g-canvaskit",paraId:7,tocIndex:2},{value:"), it is not possible to use the browser's own search function (Command + F) to locate a match once the text has been drawn, which is also not SEO friendly.",paraId:4,tocIndex:2},{value:"In this ",paraId:8,tocIndex:2},{value:"example",paraId:9,tocIndex:2},{value:", we enable ",paraId:8,tocIndex:2},{value:"enableExtractingText",paraId:8,tocIndex:2},{value:" to use the above functionality.",paraId:8,tocIndex:2},{value:"const plugin = new Plugin({\n    enableExtractingText: true,\n});\ncanvasRenderer.registerPlugin(plugin);\n",paraId:10,tocIndex:2},{value:"In the implementation we have added DOM elements inside the ",paraId:11,tocIndex:2},{value:"canvas container",paraId:12,tocIndex:2},{value:" for real-time synchronization with the visible text in the canvas.",paraId:11,tocIndex:2},{value:'<div\n    id="g-a11y-text-extractor-mask"\n    style="position: absolute; inset: 0px; z-index: 99; pointer-events: none; user-select: none; overflow: hidden;"\n>\n    <div\n        id="g-a11y-text-extractor-text-94"\n        style="line-height: 1; position: absolute; white-space: pre; word-break: keep-all; color: transparent !important; transform-origin: 0px 0px; transform: translate(0px, 0px) translate(-50%, -100%) matrix3d(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 320, 350, 0, 1); font-size: 10px; font-family: sans-serif;"\n    >\n        Humidity\n    </div>\n</div>\n',paraId:13,tocIndex:2},{value:"There are the following considerations.",paraId:14,tocIndex:2},{value:"When rendering with ",paraId:15,tocIndex:2},{value:"g-svg",paraId:16,tocIndex:2},{value:", the above DOM content will not be added because SVG naturally supports ",paraId:15,tocIndex:2},{value:"<foreignObject>",paraId:15,tocIndex:2},{value:".",paraId:15,tocIndex:2},{value:"Since browsers have a minimum font size limit (",paraId:15,tocIndex:2},{value:"12px",paraId:15,tocIndex:2},{value:" in Chrome), text that is too small will be rendered inconsistently",paraId:15,tocIndex:2},{value:"Use the Tab key to navigate and read aloud the content of the text.",paraId:17,tocIndex:3},{value:"https://developer.mozilla.org/zh-CN/docs/Web/Accessibility/ARIA/Attributes",paraId:18,tocIndex:3},{value:"We provide the ",paraId:19,tocIndex:5},{value:"animation",paraId:20,tocIndex:5},{value:" feature, but some users with cognitive impairments can be nauseated or distracted by animated content.",paraId:19,tocIndex:5},{value:"CSS media queries provide ",paraId:21,tocIndex:5},{value:"prefers-reduced-motion",paraId:21,tocIndex:5},{value:', which can help us detect if the user has turned on browser/system "reduced-motion" feature, which allows us to respond to the user\'s request to reduce the animation in the scene as much as possible.',paraId:21,tocIndex:5},{value:".animation {\n    animation: vibrate 0.3s linear infinite both;\n}\n\n@media (prefers-reduced-motion: reduce) {\n    .animation {\n        animation: none;\n    }\n}\n",paraId:22,tocIndex:5},{value:"In addition to media queries via CSS, JS also has a corresponding API: ",paraId:23,tocIndex:5},{value:"https://developer.mozilla.org/en-US/docs/Web/API/Window/matchMedia：",paraId:23,tocIndex:5},{value:"const mql = window.matchMedia('(prefers-reduced-motion: reduce)');\nmql.matches;\n",paraId:24,tocIndex:5},{value:"d-motion: reduce)'); mql.matches;",paraId:25,tocIndex:5},{value:"",paraId:26,tocIndex:5}]},46038:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(26015);const n=[{value:"In addition to rendering the drawing out, sometimes we want to perform transformations such as scaling on the drawing in an interactive form, for example ",paraId:0},{value:"Fabric.js",paraId:0},{value:" and ",paraId:0},{value:"Konva.js",paraId:0},{value:" provide the ability to do so. As an example, in the following figure, after selecting the graph with the mouse, controls for auxiliary operations appear, allowing the target graph to be moved by dragging and dropping the mask, and the graph to be scaled by dragging and dropping the anchor point.",paraId:0},{value:"Example",paraId:1},{value:"This plugin relies on ",paraId:2,tocIndex:0},{value:"g-plugin-dragndrop",paraId:3,tocIndex:0},{value:" for drag-and-drop capabilities, so it needs to be used with the following registration.",paraId:2,tocIndex:0},{value:"import { Plugin as PluginDragndrop } from '@antv/g-plugin-dragndrop';\nimport { Plugin as PluginAnnotation } from '@antv/g-plugin-annotation';\n\nrenderer.registerPlugin(new PluginDragndrop());\nrenderer.registerPlugin(new PluginAnnotation());\n",paraId:4,tocIndex:0},{value:"The plugin provides two modes which can be switched via ",paraId:5,tocIndex:1},{value:"setDrawingMode",paraId:6,tocIndex:1},{value:".",paraId:5,tocIndex:1},{value:"Drawing mode. This mode allows drawing graphics in preset steps.",paraId:7,tocIndex:1},{value:"Edit mode. In this mode, select ",paraId:7,tocIndex:1},{value:"selectable",paraId:7,tocIndex:1},{value:" graphics and the corresponding editing component will appear, so you can finish editing operations such as panning and resizing the graphics through component interaction.",paraId:7,tocIndex:1},{value:"After entering drawing mode, use ",paraId:8,tocIndex:2},{value:"setDrawer",paraId:9,tocIndex:2},{value:" to set the drawing tool for the corresponding graph and start drawing. For example, we want to draw a line.",paraId:8,tocIndex:2},{value:"plugin.setDrawingMode(true);\nplugin.setDrawer(DrawerTool.Polyline);\n// or\nplugin.setDrawer('polyline');\n",paraId:10,tocIndex:2},{value:"We currently offer the following drawing tools.",paraId:11,tocIndex:2},{value:"export enum DrawerTool {\n  Circle = 'circle',\n  Rect = 'rect',\n  Polygon = 'polygon',\n  Polyline = 'polyline',\n}\n",paraId:12,tocIndex:2},{value:"A series of events will be triggered during the drawing process. In Fabric.js, you need to set the brush before you can draw. When using this plugin, you need to listen to the Draw Finished event and use the draw point data carried in the event object to create the base drawing and add it to the canvas.",paraId:13,tocIndex:2},{value:"annotationPlugin.addEventListener('draw:complete', ({ type, path }) => {\n    // use any brush you preferred\n    const brush = {\n        stroke: 'black',\n        strokeWidth: 10,\n        selectable: true,\n    };\n});\n",paraId:14,tocIndex:2},{value:"Press the mouse to determine the position of the point, which can then be used to draw any figure such as ",paraId:15,tocIndex:3},{value:"Circle",paraId:16,tocIndex:3},{value:".",paraId:15,tocIndex:3},{value:"Press the mouse, drag and drop and then lift to finish drawing.",paraId:17,tocIndex:4},{value:"The following keyboard shortcuts are supported.",paraId:18,tocIndex:4},{value:"esc",paraId:19,tocIndex:4},{value:" to cancel drawing",paraId:19,tocIndex:4},{value:"Press the mouse in sequence to determine the vertices, double-click the mouse or successive vertices close to each other is considered to be the end of the drawing, the line between the vertices form the final fold line.",paraId:20,tocIndex:5},{value:"The following keyboard shortcuts are supported.",paraId:21,tocIndex:5},{value:"esc",paraId:22,tocIndex:5},{value:" to cancel drawing",paraId:22,tocIndex:5},{value:"shift",paraId:22,tocIndex:5},{value:" + ",paraId:22,tocIndex:5},{value:"Z",paraId:22,tocIndex:5},{value:" to undo the latest line segment",paraId:22,tocIndex:5},{value:"space",paraId:22,tocIndex:5},{value:" to finish drawing",paraId:22,tocIndex:5},{value:"Press the mouse in sequence to determine the vertices and close them to form a polygon.",paraId:23,tocIndex:6},{value:"The following keyboard shortcuts are supported.",paraId:24,tocIndex:6},{value:"esc",paraId:25,tocIndex:6},{value:" to cancel drawing",paraId:25,tocIndex:6},{value:"shift",paraId:25,tocIndex:6},{value:" + ",paraId:25,tocIndex:6},{value:"Z",paraId:25,tocIndex:6},{value:" to undo the latest line segment",paraId:25,tocIndex:6},{value:"space",paraId:25,tocIndex:6},{value:" to finish drawing",paraId:25,tocIndex:6},{value:"The base graph can be made interactive by turning on ",paraId:26,tocIndex:7},{value:"selectable",paraId:26,tocIndex:7},{value:".",paraId:26,tocIndex:7},{value:"circle.style.selectable = true;\n",paraId:27,tocIndex:7},{value:"We currently support the following ",paraId:28,tocIndex:7},{value:"basic graphics",paraId:28,tocIndex:7},{value:": ",paraId:28,tocIndex:7},{value:"Circle",paraId:29,tocIndex:7},{value:"、",paraId:28,tocIndex:7},{value:"Ellipse",paraId:30,tocIndex:7},{value:"、",paraId:28,tocIndex:7},{value:"Rect",paraId:31,tocIndex:7},{value:"、",paraId:28,tocIndex:7},{value:"Image",paraId:32,tocIndex:7},{value:"、",paraId:28,tocIndex:7},{value:"Line",paraId:33,tocIndex:7},{value:"、",paraId:28,tocIndex:7},{value:"Polyline",paraId:34,tocIndex:7},{value:"In addition ",paraId:35,tocIndex:7},{value:"anchorsVisibility",paraId:35,tocIndex:7},{value:" can control anchor visibility. ",paraId:35,tocIndex:7},{value:"maskDraggable",paraId:35,tocIndex:7},{value:" can control whether the mask is draggable or not.",paraId:35,tocIndex:7},{value:"We support selecting single or multiple graphics either interactively or via API.",paraId:36,tocIndex:8},{value:"To select a graphic via API, you can call the ",paraId:37,tocIndex:8},{value:"selectDisplayObject",paraId:38,tocIndex:8},{value:" method. When the graphic is selected, a mask will appear on top of it, which contains several anchor points.",paraId:37,tocIndex:8},{value:"Clicking on the graphic will complete a single selection, which is the most common way. We support the following two ways to complete multiple selections.",paraId:39,tocIndex:8},{value:"Hold down ",paraId:40,tocIndex:8},{value:"shift",paraId:40,tocIndex:8},{value:" and click to add a selection while keeping the selected shape",paraId:40,tocIndex:8},{value:"Hold down ",paraId:40,tocIndex:8},{value:"shift",paraId:40,tocIndex:8},{value:" and drag a rectangle to complete a region swipe",paraId:40,tocIndex:8},{value:"As opposed to selecting a graphic, there are two ways to unselect it.",paraId:41,tocIndex:9},{value:"Click on a blank area of the canvas or another graphic.",paraId:42,tocIndex:9},{value:"To unselect a graphic via API, call ",paraId:42,tocIndex:9},{value:"deselectDisplayObject",paraId:43,tocIndex:9},{value:" method.",paraId:42,tocIndex:9},{value:"After selecting the shape, drag and drop it on the mask to move it.",paraId:44,tocIndex:10},{value:"The corresponding ",paraId:45,tocIndex:10},{value:"event",paraId:46,tocIndex:10},{value:" will be triggered during and after the movement.",paraId:45,tocIndex:10},{value:"You can also use the keyboard up/down/left/right arrow keys to move the drawing after it is selected, and the step length can be configured by ",paraId:47,tocIndex:10},{value:"arrowKeyStepLength",paraId:48,tocIndex:10},{value:".",paraId:47,tocIndex:10},{value:"Dragging the anchor point can change the size of the graphic. Take the following figure as an example, when dragging the anchor point in the bottom right corner, it actually fixes the top left corner first, and then modifies the width and height of the image.",paraId:49,tocIndex:11},{value:"When creating a plugin, you can pass in some initialization configuration.",paraId:50,tocIndex:12},{value:"If or not draw mode, the default value is ",paraId:51,tocIndex:13},{value:"true",paraId:51,tocIndex:13},{value:".",paraId:51,tocIndex:13},{value:"Automatically switch in some scenes, the default value is ",paraId:52,tocIndex:14},{value:"false",paraId:52,tocIndex:14},{value:".",paraId:52,tocIndex:14},{value:"Clicking on an interactive drawing in drawing mode will automatically switch to editing mode.",paraId:53,tocIndex:14},{value:"Clicking on a blank area in edit mode will automatically switch to draw mode.",paraId:53,tocIndex:14},{value:"The default value is ",paraId:54,tocIndex:15},{value:"false",paraId:54,tocIndex:15},{value:" to delete the selected interactive graphics using keyboard shortcuts.",paraId:54,tocIndex:15},{value:"When enabled, you can use the ",paraId:55,tocIndex:15},{value:"Delete",paraId:55,tocIndex:15},{value:" / ",paraId:55,tocIndex:15},{value:"Esc",paraId:55,tocIndex:15},{value:" / ",paraId:55,tocIndex:15},{value:"Backspace",paraId:55,tocIndex:15},{value:" keys to delete the selected interactive graphics.",paraId:55,tocIndex:15},{value:"Whether to support continuous pressing of ",paraId:56,tocIndex:16},{value:"shift",paraId:56,tocIndex:16},{value:" for frame selection, the default value is ",paraId:56,tocIndex:16},{value:"true",paraId:56,tocIndex:16},{value:".",paraId:56,tocIndex:16},{value:"After closing, each frame selection will clear the previous result and re-select.",paraId:57,tocIndex:16},{value:"In edit mode, use the keyboard up, down, left and right arrow keys to move the graph in steps, the default value is ",paraId:58,tocIndex:17},{value:"4",paraId:58,tocIndex:17},{value:".",paraId:58,tocIndex:17},{value:"Some of the styles of the auxiliary actions component support customization, so you can pass in style configurations during initialization, for example to make the fill color of the mask black.",paraId:59,tocIndex:18},{value:"const plugin = new PluginAnnotation({\n    selectableStyle: {\n        selectionFill: 'black',\n    },\n});\n",paraId:60,tocIndex:18},{value:"We currently support the following style configurations.",paraId:61,tocIndex:18},{value:"export interface SelectableStyle {\n    /**\n     * Mask\n     */\n    selectionFill: string;\n    selectionFillOpacity: number;\n    selectionStroke: string;\n    selectionStrokeOpacity: number;\n    selectionStrokeWidth: number;\n    /**\n     * Anchors\n     */\n    anchorFill: string;\n    anchorStroke: string;\n    anchorSize: string | number;\n    anchorFillOpacity: number;\n    anchorStrokeOpacity: number;\n}\n",paraId:62,tocIndex:18},{value:"In addition to specifying it when initializing the plugin, it can be modified at any time later using the ",paraId:63,tocIndex:18},{value:"updateSelectableStyle",paraId:64,tocIndex:18},{value:" method.",paraId:63,tocIndex:18},{value:"For the mask fill color, you can refer to ",paraId:65,tocIndex:19},{value:"fill",paraId:66,tocIndex:19},{value:" for the value, e.g.",paraId:65,tocIndex:19},{value:"const plugin = new PluginAnnotation({\n    selectableStyle: {\n        selectionFill: 'rgba(0, 0, 0, 0.5)',\n    },\n});\n",paraId:67,tocIndex:19},{value:"For the opacity of the mask fill color, you can refer to ",paraId:68,tocIndex:20},{value:"fillOpacity",paraId:69,tocIndex:20},{value:" for the value.",paraId:68,tocIndex:20},{value:"Stroke color of the mask. You can refer to ",paraId:70,tocIndex:21},{value:"stroke",paraId:71,tocIndex:21},{value:" for the value.",paraId:70,tocIndex:21},{value:"const plugin = new PluginAnnotation({\n    selectableStyle: {\n        selectionStroke: 'rgba(0, 0, 0, 0.5)',\n    },\n});\n",paraId:72,tocIndex:21},{value:"Mask stroke opacity, you can refer to ",paraId:73,tocIndex:22},{value:"strokeOpacity",paraId:74,tocIndex:22},{value:" for the value.",paraId:73,tocIndex:22},{value:"Stroke width of the mask. You can refer to ",paraId:75,tocIndex:23},{value:"strokeWidth",paraId:76,tocIndex:23},{value:" for the value.",paraId:75,tocIndex:23},{value:"The mask stroke dashed line. You can refer to ",paraId:77,tocIndex:24},{value:"lineDash",paraId:78,tocIndex:24},{value:" for the value.",paraId:77,tocIndex:24},{value:"The anchor fill color.",paraId:79,tocIndex:25},{value:"The opacity of the anchor fill color.",paraId:80,tocIndex:26},{value:"The anchor stroke color.",paraId:81,tocIndex:27},{value:"The opacity of the anchor stroke color.",paraId:82,tocIndex:28},{value:"The width of the anchor stroke line.",paraId:83,tocIndex:29},{value:"The size of the anchor point. For now we only support circular anchors, so this property is equivalent to the radius of a circle.",paraId:84,tocIndex:30},{value:"Auxiliary drawing style for the component. The initial value is specified by the constructor ",paraId:85,tocIndex:31},{value:"drawStyle",paraId:85,tocIndex:31},{value:" parameter and can be updated by ",paraId:85,tocIndex:31},{value:"updateDrawerStyle",paraId:86,tocIndex:31},{value:".",paraId:85,tocIndex:31},{value:"For example, if we want to specify the stroke color of a rectangular drawing component.",paraId:87,tocIndex:31},{value:"const annotationPlugin = new AnnotationPlugin({\n    drawerStyle: {\n        rectStroke: 'red',\n    },\n});\n",paraId:88,tocIndex:31},{value:"See ",paraId:89,tocIndex:32},{value:"fill",paraId:90,tocIndex:32},{value:", the default value is ",paraId:89,tocIndex:32},{value:"'none'",paraId:89,tocIndex:32},{value:".",paraId:89,tocIndex:32},{value:"See ",paraId:91,tocIndex:33},{value:"fillOpacity",paraId:92,tocIndex:33},{value:", the default value is ",paraId:91,tocIndex:33},{value:"1",paraId:91,tocIndex:33},{value:".",paraId:91,tocIndex:33},{value:"See ",paraId:93,tocIndex:34},{value:"stroke",paraId:94,tocIndex:34},{value:", the default value is ",paraId:93,tocIndex:34},{value:"'#FAAD14'",paraId:93,tocIndex:34},{value:".",paraId:93,tocIndex:34},{value:"See ",paraId:95,tocIndex:35},{value:"strokeOpacity",paraId:96,tocIndex:35},{value:", the default value is ",paraId:95,tocIndex:35},{value:"1",paraId:95,tocIndex:35},{value:".",paraId:95,tocIndex:35},{value:"See ",paraId:97,tocIndex:36},{value:"strokeWidth",paraId:98,tocIndex:36},{value:", the default value is ",paraId:97,tocIndex:36},{value:"2.5",paraId:97,tocIndex:36},{value:".",paraId:97,tocIndex:36},{value:"You can refer to ",paraId:99,tocIndex:37},{value:"lineDash",paraId:100,tocIndex:37},{value:", the default value is ",paraId:99,tocIndex:37},{value:"6",paraId:99,tocIndex:37},{value:".",paraId:99,tocIndex:37},{value:"The size of the drawn vertex of the folded line. For now, we only support circular vertices, so this property is equivalent to the radius of a circle, and the default value is ",paraId:101,tocIndex:38},{value:"6",paraId:101,tocIndex:38},{value:".",paraId:101,tocIndex:38},{value:"In the following figure, the hollow circle is the drawn vertex and the solid line is the drawn line segment; the solid circle is the vertex being drawn and the dashed line is the line segment being drawn.",paraId:102,tocIndex:38},{value:"See ",paraId:103,tocIndex:39},{value:"fill",paraId:104,tocIndex:39},{value:", the default value is ",paraId:103,tocIndex:39},{value:"'#FFFFFF'",paraId:103,tocIndex:39},{value:".",paraId:103,tocIndex:39},{value:"See ",paraId:105,tocIndex:40},{value:"fillOpacity",paraId:106,tocIndex:40},{value:", the default value is ",paraId:105,tocIndex:40},{value:"1",paraId:105,tocIndex:40},{value:".",paraId:105,tocIndex:40},{value:"See ",paraId:107,tocIndex:41},{value:"stroke",paraId:108,tocIndex:41},{value:", the default value is ",paraId:107,tocIndex:41},{value:"'#FAAD14'",paraId:107,tocIndex:41},{value:".",paraId:107,tocIndex:41},{value:"See ",paraId:109,tocIndex:42},{value:"strokeOpacity",paraId:110,tocIndex:42},{value:", the default value is ",paraId:109,tocIndex:42},{value:"1",paraId:109,tocIndex:42},{value:".",paraId:109,tocIndex:42},{value:"See ",paraId:111,tocIndex:43},{value:"strokeWidth",paraId:112,tocIndex:43},{value:", the default value is ",paraId:111,tocIndex:43},{value:"2",paraId:111,tocIndex:43},{value:".",paraId:111,tocIndex:43},{value:"The color of the drawn line segment of the fold line, see ",paraId:113,tocIndex:44},{value:"stroke",paraId:114,tocIndex:44},{value:", the default value is ",paraId:113,tocIndex:44},{value:"'#FAAD14'",paraId:113,tocIndex:44},{value:".",paraId:113,tocIndex:44},{value:"The line width of the drawn line segment of the folded line, refer to ",paraId:115,tocIndex:45},{value:"strokeWidth",paraId:116,tocIndex:45},{value:", the default value is ",paraId:115,tocIndex:45},{value:"2",paraId:115,tocIndex:45},{value:".",paraId:115,tocIndex:45},{value:"The size of the vertex being drawn by the fold. For now we only support circular vertices, so this property is equivalent to the radius of a circle, and the default value is ",paraId:117,tocIndex:46},{value:"6",paraId:117,tocIndex:46},{value:".",paraId:117,tocIndex:46},{value:"See ",paraId:118,tocIndex:47},{value:"fill",paraId:119,tocIndex:47},{value:", the default value is ",paraId:118,tocIndex:47},{value:"'#FFFFFF'",paraId:118,tocIndex:47},{value:".",paraId:118,tocIndex:47},{value:"See ",paraId:120,tocIndex:48},{value:"fillOpacity",paraId:121,tocIndex:48},{value:", the default value is ",paraId:120,tocIndex:48},{value:"1",paraId:120,tocIndex:48},{value:".",paraId:120,tocIndex:48},{value:"See ",paraId:122,tocIndex:49},{value:"stroke",paraId:123,tocIndex:49},{value:", the default value is ",paraId:122,tocIndex:49},{value:"'#FAAD14'",paraId:122,tocIndex:49},{value:".",paraId:122,tocIndex:49},{value:"See ",paraId:124,tocIndex:50},{value:"strokeOpacity",paraId:125,tocIndex:50},{value:", the default value is ",paraId:124,tocIndex:50},{value:"0.2",paraId:124,tocIndex:50},{value:".",paraId:124,tocIndex:50},{value:"See ",paraId:126,tocIndex:51},{value:"strokeWidth",paraId:127,tocIndex:51},{value:", the default value is ",paraId:126,tocIndex:51},{value:"2",paraId:126,tocIndex:51},{value:".",paraId:126,tocIndex:51},{value:"The fold line is drawing line color, see ",paraId:128,tocIndex:52},{value:"stroke",paraId:129,tocIndex:52},{value:", the default value is ",paraId:128,tocIndex:52},{value:"'#FAAD14'",paraId:128,tocIndex:52},{value:".",paraId:128,tocIndex:52},{value:"The line width of the line segment being drawn, refer to ",paraId:130,tocIndex:53},{value:"strokeWidth",paraId:131,tocIndex:53},{value:", the default value is ",paraId:130,tocIndex:53},{value:"2.5",paraId:130,tocIndex:53},{value:".",paraId:130,tocIndex:53},{value:"The following APIs can be called through plugin instances, e.g.",paraId:132,tocIndex:54},{value:"const plugin = new PluginAnnotation();\n\ncircle.style.selectable = true;\nplugin.selectDisplayObject(circle);\n",paraId:133,tocIndex:54},{value:"Sets whether draw mode is enabled.",paraId:134,tocIndex:55},{value:"// 进入绘制模式\nplugin.setDrawingMode(true);\n\n// 进入编辑模式\nplugin.setDrawingMode(false);\n",paraId:135,tocIndex:55},{value:"In drawing mode, we provide the ability to draw the following graphics.",paraId:136,tocIndex:56},{value:"circle",paraId:137,tocIndex:56},{value:"rect",paraId:137,tocIndex:56},{value:"polyline",paraId:137,tocIndex:56},{value:"polygon",paraId:137,tocIndex:56},{value:"For example, to draw a rectangle.",paraId:138,tocIndex:56},{value:"plugin.setDrawingMode(true);\nplugin.setDrawer('rect');\n",paraId:139,tocIndex:56},{value:"Selects a graphic. Does not apply the cancel operation to other selected graphs.",paraId:140,tocIndex:57},{value:"plugin.selectedDisplayObject(circle);\n",paraId:141,tocIndex:57},{value:"Deselects a graphic.",paraId:142,tocIndex:58},{value:"plugin.deselectedDisplayObject(circle);\n",paraId:143,tocIndex:58},{value:"Get the list of currently selected graphs.",paraId:144,tocIndex:59},{value:"plugin.getSelectedDisplayObjects(); // [circle, path]\n",paraId:145,tocIndex:59},{value:"Update the [style](/en/plugins/annotation#assist manipulation component style) of the interactive component in real time, e.g. modify the mask fill color in ",paraId:146,tocIndex:60},{value:"example",paraId:147,tocIndex:60},{value:".",paraId:146,tocIndex:60},{value:"plugin.updateSelectableStyle({\n    selectionFill: 'red',\n});\n",paraId:148,tocIndex:60},{value:"Update the style of the auxiliary drawing component, e.g.",paraId:149,tocIndex:61},{value:"plugin.updateDrawerStyle({\n    rectStroke: 'red',\n});\n",paraId:150,tocIndex:61},{value:"Sometimes the definition of the target graph is modified and needs to be sensed and regenerated by the auxiliary operation component, in which case the method can be called manually.",paraId:151,tocIndex:62},{value:"circle.style.cx = 100;\ncircle.style.cy = 100;\n\nplugin.markSelectableUIAsDirty(circle);\n",paraId:152,tocIndex:62},{value:"Different events will be triggered in different modes, for example, drawing mode will trigger on plug-ins, while editing mode will trigger on graphics.",paraId:153,tocIndex:63},{value:'Unlike the "free drawing" mode of Fabric.js, the plugin listens for events triggered at different drawing stages, gets the geometry information contained in the event object, creates the corresponding shapes and applies custom styles to complete the drawing.',paraId:154,tocIndex:64},{value:"The following events are supported.",paraId:155,tocIndex:64},{value:"export enum DrawerEvent {\n  START = 'draw:start',\n  MOVE = 'draw:move',\n  MODIFIED = 'draw:modify',\n  COMPLETE = 'draw:complete',\n  CANCEL = 'draw:cancel',\n}\n",paraId:156,tocIndex:64},{value:"The event object contains the following data, where the key properties are",paraId:157,tocIndex:64},{value:"type",paraId:158,tocIndex:64},{value:" The type of graph to draw. Currently supports ",paraId:158,tocIndex:64},{value:"rect",paraId:158,tocIndex:64},{value:" ",paraId:158,tocIndex:64},{value:"polyline",paraId:158,tocIndex:64},{value:" ",paraId:158,tocIndex:64},{value:"polygon",paraId:158,tocIndex:64},{value:"path",paraId:158,tocIndex:64},{value:" draws a list of graph vertices, like: ",paraId:158,tocIndex:64},{value:"[{ x: 0, y: 0 }, { x: 100, y: 100 }...]",paraId:158,tocIndex:64},{value:"plugin.addEventListener(DrawerEvent.COMPLETE, ({ type, path }) => {});\n",paraId:159,tocIndex:64},{value:"At the end of the drawing, the auxiliary drawing UI is automatically hidden and we can use the vertex data to draw the final shape.",paraId:160,tocIndex:68},{value:"plugin.addEventListener(DrawerEvent.COMPLETE, ({ type, path }) => {\n    // use any brush you preferred\n    const brush = {\n        stroke: 'black',\n        strokeWidth: 10,\n        selectable: true,\n    };\n\n    if (type === 'polyline') {\n        const polyline = new Polyline({\n            style: {\n                ...brush,\n                points: path.map(({ x, y }) => [x, y]),\n            },\n        });\n        canvas.appendChild(polyline);\n    }\n});\n",paraId:161,tocIndex:68},{value:"When a drawing is selected, unselected, moved, or changed in size, the corresponding event is triggered.",paraId:162,tocIndex:69},{value:"export enum SelectableEvent {\n  SELECTED = 'selected',\n  DESELECTED = 'deselected',\n  MODIFIED = 'modified',\n  MOVED = 'moved',\n  MOVING = 'moving',\n}\n",paraId:163,tocIndex:69},{value:"Triggered when the target graphic is selected. In ",paraId:164,tocIndex:70},{value:"example",paraId:165,tocIndex:70},{value:", we listen to the selected event of the image.",paraId:164,tocIndex:70},{value:"import { SelectableEvent } from '@antv/g-plugin-annotation';\n\nimage.addEventListener('selected', () => {});\n// or\nimage.addEventListener(SelectableEvent.SELECTED, () => {});\n",paraId:166,tocIndex:70},{value:"Triggered when the target graphic is deselected. In ",paraId:167,tocIndex:71},{value:"example",paraId:168,tocIndex:71},{value:", we listen to the deselected event of the image.",paraId:167,tocIndex:71},{value:"import { SelectableEvent } from '@antv/g-plugin-annotation';\n\nimage.addEventListener('deselected', () => {});\n// or\nimage.addEventListener(SelectableEvent.DESELECTED, () => {});\n",paraId:169,tocIndex:71},{value:"When dragging a mask, the target graphic will move with it, and this process will continue to trigger in-motion events, similar to ",paraId:170,tocIndex:72},{value:"dragging",paraId:170,tocIndex:72},{value:" in ",paraId:170,tocIndex:72},{value:"g-plugin-dragndrop",paraId:171,tocIndex:72},{value:".",paraId:170,tocIndex:72},{value:"import { SelectableEvent } from '@antv/g-plugin-annotation';\n\nimage.addEventListener('moving', () => {});\n// or\nimage.addEventListener(SelectableEvent.MOVING, () => {});\n",paraId:172,tocIndex:72},{value:"The following information is carried on this event object.",paraId:173,tocIndex:72},{value:"image.addEventListener('moving', (e) => {\n    const { movingX, movingY, dx, dy } = e.detail;\n});\n",paraId:174,tocIndex:72},{value:"This event is triggered when the dragging is finished, similar to ",paraId:175,tocIndex:73},{value:"dragend",paraId:175,tocIndex:73},{value:" in ",paraId:175,tocIndex:73},{value:"g-plugin-dragndrop",paraId:176,tocIndex:73},{value:".",paraId:175,tocIndex:73},{value:"import { SelectableEvent } from '@antv/g-plugin-annotation';\n\nimage.addEventListener('moved', () => {});\n// or\nimage.addEventListener(SelectableEvent.MOVED, () => {});\n",paraId:177,tocIndex:73},{value:"Dragging and dropping on the anchor point scales the drawing, and this process also continuously triggers modification events.",paraId:178,tocIndex:74},{value:"import { SelectableEvent } from '@antv/g-plugin-annotation';\n\nimage.addEventListener('modified', () => {});\n// or\nimage.addEventListener(SelectableEvent.MODIFED, () => {});\n",paraId:179,tocIndex:74}]},34866:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(20299);const n=[{value:"Supports ",paraId:0},{value:"Box2D",paraId:0},{value:" physics engine (rigid bodies only). 2D graphics are initialized to start the simulation, and in addition to gravity and surface friction, external forces can be applied at any time to change the position and rotation angle of the graphics.",paraId:0},{value:"The WASM method is loaded at runtime and the UMD is used for entry.",paraId:1},{value:"version 2.4 ",paraId:2},{value:"https://github.com/Birch-san/box2d-wasm",paraId:2},{value:"version 2.3 & 2.2 ",paraId:2},{value:"https://github.com/kripken/box2d.js",paraId:2},{value:"Currently using Box2D latest version 2.4, refer to the documentation: ",paraId:3},{value:"https://box2d.org/documentation/。",paraId:3},{value:"The following 2D graphics are supported: ",paraId:4},{value:"Circle",paraId:5},{value:", ",paraId:4},{value:"Rect",paraId:6},{value:", ",paraId:4},{value:"Line",paraId:7},{value:", ",paraId:4},{value:"Image",paraId:8},{value:" and ",paraId:4},{value:"Polygon",paraId:9},{value:".",paraId:4},{value:"In this ",paraId:10},{value:"example",paraId:11},{value:', we create a series of dynamic objects that will free fall and end up in a "U-shaped slot".',paraId:10},{value:"Create plug-ins and register them in the renderer.",paraId:12,tocIndex:0},{value:"import { Plugin as PluginBox2D } from '@antv/g-plugin-box2d';\nrenderer.registerPlugin(new PluginBox2D());\n",paraId:13,tocIndex:0},{value:"Use the relevant physical properties in 2D graphics.",paraId:14,tocIndex:0},{value:"new Circle({\n    style: {\n        rigid: 'dynamic', // Dynamic objects, involved in force calculations\n        density: 10, // Density: 10 kg/m2\n        r: 10, // Radius: corresponds to 10 meters in the physical world\n    },\n});\n",paraId:15,tocIndex:0},{value:"Global physical world configuration.",paraId:16,tocIndex:1},{value:"The gravity direction vector, the default value is ",paraId:17,tocIndex:2},{value:"[0, 100]",paraId:17,tocIndex:2},{value:".",paraId:17,tocIndex:2},{value:"For example, if it is set to ",paraId:18,tocIndex:2},{value:"[100, 100]",paraId:18,tocIndex:2},{value:", the object will naturally move to the lower right corner: ",paraId:18,tocIndex:2},{value:"[100, 100]",paraId:18,tocIndex:2},{value:".",paraId:18,tocIndex:2},{value:"new PluginBox2D({\n  gravity: [100, 100],\n}),\n",paraId:19,tocIndex:2},{value:"Simulation time interval, default value is ",paraId:20,tocIndex:3},{value:"1/60",paraId:20,tocIndex:3},{value:"Calculate the number of acceleration iterations, the default value is ",paraId:21,tocIndex:4},{value:"8",paraId:21,tocIndex:4},{value:", the higher the calculation overhead",paraId:21,tocIndex:4},{value:"Calculate the number of position iterations, the default value is ",paraId:22,tocIndex:5},{value:"3",paraId:22,tocIndex:5},{value:", the higher the computation overhead",paraId:22,tocIndex:5},{value:"It is possible to listen to the surface contact of two objects.",paraId:23,tocIndex:6},{value:"new PluginBox2D({\n  onContact: (objectA, objectB) => {\n    // The surfaces of two objects come into contact\n  }\n}),\n",paraId:24,tocIndex:6},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md105",paraId:25,tocIndex:6},{value:"Box2D uses the following physical units: meters, kilograms, and seconds.",paraId:26,tocIndex:7},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_loose_ends.html#autotoc_md124",paraId:27,tocIndex:7},{value:"Box2D uses MKS (meters, kilograms, and seconds) units and radians for angles.",paraId:28,tocIndex:7},{value:"Most of the following properties are supported for runtime modification, such as modifying the density.",paraId:29,tocIndex:7},{value:"circle.style.density = 100;\n",paraId:30,tocIndex:7},{value:"Rigid body type.",paraId:31,tocIndex:8},{value:"'static'",paraId:32,tocIndex:8},{value:" Static objects, such as the ground",paraId:32,tocIndex:8},{value:"'dynamic'",paraId:32,tocIndex:8},{value:" Dynamic objects, calculation of forces",paraId:32,tocIndex:8},{value:"Density, kg/m2. Static objects are 0.",paraId:33,tocIndex:9},{value:"Line speed, the default value is ",paraId:34,tocIndex:10},{value:"[0, 0]",paraId:34,tocIndex:10},{value:".",paraId:34,tocIndex:10},{value:"Angular velocity, the default value is ",paraId:35,tocIndex:11},{value:"0",paraId:35,tocIndex:11},{value:".",paraId:35,tocIndex:11},{value:"Gravity factor, the default value is ",paraId:36,tocIndex:12},{value:"1",paraId:36,tocIndex:12},{value:".",paraId:36,tocIndex:12},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md60",paraId:37,tocIndex:12},{value:"Damping, the default value is ",paraId:38,tocIndex:13},{value:"0",paraId:38,tocIndex:13},{value:".",paraId:38,tocIndex:13},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md59",paraId:39,tocIndex:13},{value:"AngularDamping, the default value is ",paraId:40,tocIndex:14},{value:"0",paraId:40,tocIndex:14},{value:".",paraId:40,tocIndex:14},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md59",paraId:41,tocIndex:14},{value:"Fixed rotation angle, the default value is ",paraId:42,tocIndex:15},{value:"false",paraId:42,tocIndex:15},{value:".",paraId:42,tocIndex:15},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md62",paraId:43,tocIndex:15},{value:"The default value is ",paraId:44,tocIndex:16},{value:"false",paraId:44,tocIndex:16},{value:"。",paraId:44,tocIndex:16},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md63",paraId:45,tocIndex:16},{value:"Friction, The default value is ",paraId:46,tocIndex:17},{value:"[0 - 1]",paraId:46,tocIndex:17},{value:".",paraId:46,tocIndex:17},{value:"The recovery force, in the range ",paraId:47,tocIndex:18},{value:"[0 - 1]",paraId:47,tocIndex:18},{value:". For example, if a ball falls to the ground, it will not bounce if the restoring force is 0.",paraId:47,tocIndex:18},{value:"In addition to the simulation by initializing parameters, the position and rotation angle of the object can be changed at any moment by applying external forces.",paraId:48,tocIndex:19},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md71",paraId:49,tocIndex:19},{value:"void b2Body::ApplyForce(const b2Vec2& force, const b2Vec2& point);\nvoid b2Body::ApplyTorque(float torque);\nvoid b2Body::ApplyLinearImpulse(const b2Vec2& impulse, const b2Vec2& point);\nvoid b2Body::ApplyAngularImpulse(float impulse);\n",paraId:50,tocIndex:19},{value:"const plugin = new PluginBox2D();\nplugin.applyForce(circle, [0, 0], [0, 0]);\n",paraId:51,tocIndex:20},{value:"Box2D provides a series of descriptions of the connections between the physics that cause the forces to occur.",paraId:52,tocIndex:24},{value:"https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md82",paraId:53,tocIndex:24},{value:"Using liquidfun: ",paraId:54,tocIndex:25},{value:"https://github.com/Birch-san/box2d-wasm/blob/c04514c040/README.md#alternative-distributions",paraId:54,tocIndex:25}]},38758:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(19267);const n=[{value:"Use CanvasRenderingContext2D to draw the path of individual shapes, for example using ",paraId:0},{value:"arcTo()",paraId:0},{value:" Draws ",paraId:0},{value:"Circle",paraId:1},{value:".",paraId:0},{value:"In addition to being used for final rendering, you also need to draw in the off-screen canvas before using ",paraId:2},{value:"isPointInPath()",paraId:2},{value:" .",paraId:2},{value:"The plugin provides two Tokens, which are injected via Token when used.",paraId:3,tocIndex:0},{value:"export const PathGeneratorFactory = Syringe.defineToken('PathGeneratorFactory');\nexport const PathGenerator = Syringe.defineToken('PathGenerator');\n",paraId:4,tocIndex:0},{value:"For example, you can currently see the factory method injected into ",paraId:5,tocIndex:1},{value:"g-plugin-canvas-renderer",paraId:6,tocIndex:1},{value:" and ",paraId:5,tocIndex:1},{value:"g-plugin-canvas-picker",paraId:7,tocIndex:1},{value:" in both plugins. You can see that the factory method is injected via the token ",paraId:5,tocIndex:1},{value:"PathGeneratorFactory",paraId:5,tocIndex:1},{value:", and passing ",paraId:5,tocIndex:1},{value:"nodeName",paraId:8,tocIndex:1},{value:" will give you the drawing method for the corresponding graphic path: ",paraId:5,tocIndex:1},{value:"PathGeneratorFactory",paraId:5,tocIndex:1},{value:".",paraId:5,tocIndex:1},{value:"@inject(PathGeneratorFactory)\nprivate pathGeneratorFactory: (tagName: Shape | string) => PathGenerator<any>;\n\nconst circlePathGenerator = this.pathGeneratorFactory(Shape.CIRCLE);\n",paraId:9,tocIndex:1},{value:"The path drawing method specific to each base drawing accepts as parameters the CanvasRenderingContext2D context and the parsed drawing style property.",paraId:10,tocIndex:2},{value:"export type PathGenerator<T extends ParsedBaseStyleProps> = (\n  context: CanvasRenderingContext2D,\n  attributes: T,\n) => void;\n",paraId:11,tocIndex:2},{value:"Take Circle as an example.",paraId:12,tocIndex:2},{value:"function generatePath(\n    context: CanvasRenderingContext2D,\n    parsedStyle: ParsedCircleStyleProps,\n) {\n    const { r } = parsedStyle;\n    context.arc(r.value, r.value, r.value, 0, Math.PI * 2, false);\n}\n",paraId:13,tocIndex:2}]},69779:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(1472);const n=[{value:"Provides Canvas2D-based pickup capabilities.",paraId:0},{value:"The ",paraId:1,tocIndex:0},{value:"g-canvas",paraId:2,tocIndex:0},{value:" renderer is built in by default, so there is no need to introduce it manually.",paraId:1,tocIndex:0},{value:"import { Renderer as CanvasRenderer } from '@antv/g-canvas';\n// Create a renderer with the plugin built in\nconst canvasRenderer = new CanvasRenderer();\n",paraId:3,tocIndex:0},{value:"Pickups based on the Canvas2D API implementation.",paraId:4,tocIndex:1},{value:"Use the R-Tree spatial index to find a series of graph bounding boxes hit by a pickup point",paraId:5,tocIndex:1},{value:"Find the topmost graph among these graphs, based on the ",paraId:5,tocIndex:1},{value:"z-index",paraId:5,tocIndex:1},{value:"Use mathematical calculations to determine precisely whether the figure is hit or miss, e.g. Circle measures whether the distance to the center of the circle is less than the radius",paraId:5,tocIndex:1},{value:"The solution is CPU-based, so the optimization point is whether the enclosing box intersection operation is fast enough.",paraId:6,tocIndex:1}]},28243:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(74384);const n=[{value:"Provides Canvas2D-based rendering capabilities.",paraId:0},{value:"The ",paraId:1,tocIndex:0},{value:"g-canvas",paraId:2,tocIndex:0},{value:" renderer is built in by default, so there is no need to introduce it manually.",paraId:1,tocIndex:0},{value:"import { Renderer as CanvasRenderer } from '@antv/g-canvas';\n// Create a renderer with the plugin built in\nconst canvasRenderer = new CanvasRenderer();\n",paraId:3,tocIndex:0},{value:"When rendering the base graphics using ",paraId:4,tocIndex:2},{value:"CanvasRenderingContext2D",paraId:4,tocIndex:2},{value:", you can implement this interface after using ",paraId:4,tocIndex:2},{value:"g-plugin- canvas-path-generator",paraId:5,tocIndex:2},{value:" to generate the graphical path, implement this interface to finish drawing the style.",paraId:4,tocIndex:2},{value:"export interface StyleRenderer {\n    render: (\n        context: CanvasRenderingContext2D,\n        parsedStyle: ParsedBaseStyleProps,\n        object: DisplayObject,\n        renderingService: RenderingService,\n    ) => void;\n}\n",paraId:6,tocIndex:2},{value:"We provide different extension points for different types of graphics. For example, in ",paraId:7,tocIndex:2},{value:"g-plugin-rough-canvas-renderer",paraId:8,tocIndex:2},{value:", we use the API provided by rough.js for ",paraId:7,tocIndex:2},{value:"Circle",paraId:9,tocIndex:2},{value:" to add a hand-drawn style.",paraId:7,tocIndex:2},{value:"@singleton({\n  token: CanvasRenderer.CircleRendererContribution,\n})\nexport class CircleRenderer implements CanvasRenderer.StyleRenderer {\n  render(\n    context: CanvasRenderingContext2D,\n    parsedStyle: ParsedCircleStyleProps,\n    object: DisplayObject<any, any>,\n  ) {\n    const { r } = parsedStyle as ParsedCircleStyleProps;\n    // rough.js use diameter instead of radius\n    // @see https://github.com/rough-stuff/rough/wiki#circle-x-y-diameter--options\n    context.roughCanvas.circle(r.value, r.value, r.value * 2, generateRoughOptions(object));\n  }\n}\n",paraId:10,tocIndex:2}]},52310:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(21798);const n=[{value:"Use ",paraId:0},{value:"Skia",paraId:0},{value:" to draw 2D graphics. Load ",paraId:0},{value:"Canvaskit",paraId:0},{value:" in WASM format asynchronously at runtime, and wrap [WebGL2RenderingContext](",paraId:0},{value:"https://developer",paraId:0},{value:" .mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext) into ",paraId:0},{value:"SkSurface",paraId:0},{value:", which in turn is drawn by the ",paraId:0},{value:"<canvas>",paraId:0},{value:" element on the page.",paraId:0},{value:"Skia offers more features than the Canvas2D API, such as text paragraph layout, ",paraId:1},{value:"Lottie animation",paraId:1},{value:", and more. In addition to Chrome and Android, some cross-platform solutions such as ",paraId:1},{value:"Flutter",paraId:1},{value:", ",paraId:1},{value:"Weex",paraId:1},{value:" weex) also use it as the underlying rendering engine.",paraId:1},{value:"The ",paraId:2,tocIndex:0},{value:"g-canvaskit",paraId:3,tocIndex:0},{value:" renderer is built-in by default, so there is no need to introduce it manually.",paraId:2,tocIndex:0},{value:"import { Renderer as CanvaskitRenderer } from '@antv/g-canvaskit';\n// Create the CanvasKit renderer, which has the plugin built in\nconst canvaskitRenderer = new CanvaskitRenderer();\n",paraId:4,tocIndex:0},{value:"The ",paraId:5,tocIndex:2},{value:"Lottie",paraId:5,tocIndex:2},{value:" animation was created with the ",paraId:5,tocIndex:2},{value:"Bodymovin",paraId:5,tocIndex:2},{value:" plugin for After Effects and exported to JSON format.",paraId:5,tocIndex:2},{value:"The full method signature is as follows, which contains the following parameters.",paraId:6,tocIndex:2},{value:"name Animation name, required",paraId:7,tocIndex:2},{value:"jsonStr Lottie description file in JSON format, required",paraId:7,tocIndex:2},{value:"bounds The display area, which accepts data in the format ",paraId:7,tocIndex:2},{value:"[left, top, width, height]",paraId:7,tocIndex:2},{value:", is optional. Not filled will try to use the size defined in the description file, i.e. ",paraId:7,tocIndex:2},{value:"[0, 0, width, height]",paraId:7,tocIndex:2},{value:"assets Additional resource files, optional",paraId:7,tocIndex:2},{value:"Returns a ",paraId:8,tocIndex:2},{value:"ManagedSkottieAnimation",paraId:8,tocIndex:2},{value:" object",paraId:8,tocIndex:2},{value:"playAnimation(name: string, jsonStr: string, bounds?: InputRect, assets?: any): ManagedSkottieAnimation;\n",paraId:9,tocIndex:2},{value:"First create the renderer and get the g-plugin-canvaskit-renderer via ",paraId:10,tocIndex:2},{value:"getPlugin",paraId:11,tocIndex:2},{value:".",paraId:10,tocIndex:2},{value:"import { Renderer } from '@antv/g-canvaskit';\n\nconst canvaskitRenderer = new Renderer({\n    wasmDir: '/',\n});\nconst plugin = canvaskitRenderer.getPlugin('canvaskit-renderer');\n",paraId:12,tocIndex:2},{value:"Then wait for the canvas initialization to complete and load the Lottie animation description file.",paraId:13,tocIndex:2},{value:"(async () => {\n    const cdn = 'https://storage.googleapis.com/skia-cdn/misc/';\n\n    const [_, jsonstr] = await Promise.all([\n        canvas.ready,\n        fetch(cdn + 'lego_loader.json').then((response) => response.text()),\n    ]);\n\n    const animation = plugin.playAnimation(\n        'sk_legos',\n        jsonstr,\n        [-50, 0, 350, 300],\n    );\n})();\n",paraId:14,tocIndex:2},{value:"If you want to remove the animation, you can call the ",paraId:15,tocIndex:2},{value:"delete()",paraId:15,tocIndex:2},{value:" method on the returned animation object.",paraId:15,tocIndex:2},{value:"animation.delete();\n",paraId:16,tocIndex:2},{value:'For example, particle effects such as fireworks, flames, etc. require generating and animating a large number of "particles", which are usually programmed in the GPU through the shader, e.g. interpolation calculations to change the position of each particle should be done in the GPU instead of the CPU.',paraId:17,tocIndex:3},{value:"CanvasKit provides a Skia-based programming language ",paraId:18,tocIndex:3},{value:"SkSL(Skia's shading language)",paraId:18,tocIndex:3},{value:" implementation, which is syntactically very close to GLSL and is used in the shader to control particle generation and animation. and animation in the shader, which is a certain threshold for developers who have not been exposed to shader programming.",paraId:18,tocIndex:3},{value:"In this ",paraId:19,tocIndex:3},{value:"example",paraId:20,tocIndex:3},{value:", we have implemented some particle effects.",paraId:19,tocIndex:3},{value:"First create the renderer and get the ",paraId:21,tocIndex:3},{value:"g-plugin-canvaskit-renderer",paraId:22,tocIndex:3},{value:" plugin via ",paraId:21,tocIndex:3},{value:"getPlugin",paraId:23,tocIndex:3},{value:".",paraId:21,tocIndex:3},{value:"import { Renderer } from '@antv/g-canvaskit';\n\nconst canvaskitRenderer = new Renderer({\n    wasmDir: '/',\n});\nconst plugin = canvaskitRenderer.getPlugin('canvaskit-renderer');\n",paraId:24,tocIndex:3},{value:"Then call the plugin's ",paraId:25,tocIndex:3},{value:"createParticles",paraId:26,tocIndex:3},{value:" to create the particle effect, transform the canvas to adjust the position of the particles in the callback function at each frame, and finally start the particle generation with ",paraId:25,tocIndex:3},{value:"start",paraId:27,tocIndex:3},{value:".",paraId:25,tocIndex:3},{value:"const textParticles = plugin.createParticles(JSON.stringify(text), (canvas) => {\n    canvas.translate(250, 250);\n});\ntextParticles.start(Date.now() / 1000.0, true);\n",paraId:28,tocIndex:3},{value:"Finally, let's look at the key particle effect definitions.",paraId:29,tocIndex:3},{value:"MaxCount",paraId:30,tocIndex:3},{value:"Drawable The type of particle, usually ",paraId:30,tocIndex:3},{value:"'SkCircleDrawable'",paraId:30,tocIndex:3},{value:", can be modified in size",paraId:30,tocIndex:3},{value:"Code SkSL code to control the life cycle of the particles, such as how the position and color should change in each frame",paraId:30,tocIndex:3},{value:"Bindings",paraId:30,tocIndex:3},{value:"const text = {\n    MaxCount: 2000,\n    Drawable: {\n        Type: 'SkCircleDrawable',\n        Radius: 1,\n    },\n    Code: [\n        'void effectSpawn(inout Effect effect) {',\n        '  effect.rate = 1000;',\n        '}',\n        '',\n        'void spawn(inout Particle p) {',\n        '  p.lifetime = mix(1, 3, rand(p.seed));',\n        '  float a = radians(mix(250, 290, rand(p.seed)));',\n        '  float s = mix(10, 30, rand(p.seed));',\n        '  p.vel.x = cos(a) * s;',\n        '  p.vel.y = sin(a) * s;',\n        '  p.pos += text(rand(p.seed)).xy;',\n        '}',\n        '',\n        'void update(inout Particle p) {',\n        '  float4 startColor = float4(1, 0.196, 0.078, 1);',\n        '  float4 endColor   = float4(1, 0.784, 0.078, 1);',\n        '  p.color = mix(startColor, endColor, p.age);',\n        '}',\n        '',\n    ],\n    Bindings: [\n        {\n            Type: 'SkTextBinding',\n            Name: 'text',\n            Text: 'AntV',\n            FontSize: 96,\n        },\n    ],\n};\n",paraId:31,tocIndex:3},{value:"If you want to remove the particle effect, you can call the ",paraId:32,tocIndex:3},{value:"delete()",paraId:32,tocIndex:3},{value:" method on the returned object.",paraId:32,tocIndex:3},{value:"particles.delete();\n",paraId:33,tocIndex:3}]},11627:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(21932);const n=[{value:"Provides camera interaction for 3D scenes, internally using Hammer.js to respond to mouse-over, scroll-wheel events. Depending on the [camera type](/en/api/camera#camera#camera type), different interactions are provided.",paraId:0},{value:"Create the ",paraId:1,tocIndex:0},{value:"g-webgl",paraId:1,tocIndex:0},{value:" renderer and register the plugin.",paraId:1,tocIndex:0},{value:"import { Renderer as WebGLRenderer } from '@antv/g-webgl';\nimport { Plugin } from '@antv/g-plugin-control';\n// 创建 WebGL 渲染器\nconst webglRenderer = new WebGLRenderer();\n// 注册 3D 插件\nwebglRenderer.registerPlugin(new Plugin());\n",paraId:2,tocIndex:0},{value:"Example",paraId:3,tocIndex:0},{value:"：",paraId:4,tocIndex:0}]},54627:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(36871);const n=[{value:"When finding nodes in the scene graph, we can use some ",paraId:0},{value:"advanced query methods",paraId:1},{value:" similar to the DOM API.",paraId:0},{value:"getElementById",paraId:2},{value:" Find a single element by id in the subtree of the current node",paraId:2},{value:"getElementsByName",paraId:2},{value:" Find a list of elements by name in the subtree of the current node",paraId:2},{value:"getElementsByClassName",paraId:2},{value:" Find a list of elements by className under the subtree of the current node",paraId:2},{value:"getElementsByTagName",paraId:2},{value:" Find a list of elements by tagName under the subtree of the current node",paraId:2},{value:"Suppose we construct the following scenegraph.",paraId:3},{value:"solarSystem<Group>\n   |    |\n   |   sun<Circle name='sun' />\n   |\n earthOrbit<Group>\n   |    |\n   |  earth<Circle>\n   |\n moonOrbit<Group>\n      |\n     moon<Circle r='25' />\n",paraId:4},{value:"We can use the following query methods.",paraId:5},{value:"solarSystem.getElementsByName('sun');\n// [sun]\n\nsolarSystem.getElementsByTagName('circle');\nsolarSystem.getElementsByTagName(Shape.CIRCLE);\n// [sun, earth, moon]\n",paraId:6},{value:"When we want to use more complex query criteria like CSS selectors, we have the option to install the plugin.",paraId:7},{value:"querySelector",paraId:8},{value:"querySelectorAll",paraId:8},{value:"Once the installation is complete the attribute selector can be used.",paraId:9},{value:"solarSystem.querySelector('[name=sun]');\n// sun\n\nsolarSystem.querySelectorAll('[r=25]');\n// [moon]\n",paraId:10},{value:"Create plug-ins and register them in the renderer.",paraId:11,tocIndex:0},{value:"import { Plugin } from '@antv/g-plugin-css-select';\nwebglRenderer.registerPlugin(new Plugin());\n",paraId:12,tocIndex:0},{value:"We can use something like the DOM API + CSS selector for node queries in the scene graph, ",paraId:13,tocIndex:0},{value:"full example",paraId:14,tocIndex:0},{value:".",paraId:13,tocIndex:0},{value:"solarSystem.getElementsByName('sun');\n// [sun]\n\nsolarSystem.getElementsByTagName('circle');\nsolarSystem.getElementsByTagName(Shape.CIRCLE);\n// [sun, earth, moon]\n\nsolarSystem.querySelector('[name=sun]');\n// sun\n\nsolarSystem.querySelectorAll('[r=25]');\n// [moon]\n",paraId:15,tocIndex:0}]},15761:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(28853);const n=[{value:"In terms of naming convention, all plugin names start with ",paraId:0},{value:"g-plugin-",paraId:0},{value:". Let's take a deeper look into the structure of the plugin by analyzing ",paraId:0},{value:"g-plugin-canvas-renderer",paraId:0},{value:", which uses Canvas2D rendering and is one of the core plugins of ",paraId:0},{value:"g-canvas",paraId:0},{value:".",paraId:0},{value:"https://github.com/antvis/G/tree/next/packages/g-plugin-canvas-renderer",paraId:1,tocIndex:0},{value:"As you can see from the ",paraId:2,tocIndex:1},{value:"peerDependencies",paraId:2,tocIndex:1},{value:" of ",paraId:2,tocIndex:1},{value:"package.json",paraId:2,tocIndex:1},{value:", the most core dependency of a plugin is ",paraId:2,tocIndex:1},{value:"@antv/g",paraId:2,tocIndex:1},{value:", the core layer of G, which contains core objects such as dependency injection, canvas, base graphics, events, etc.",paraId:2,tocIndex:1},{value:'"peerDependencies": {\n    "@antv/g-lite": "^1.0.0"\n},\n',paraId:3,tocIndex:1},{value:"Opening the plugin's entry file, we can find that a plugin that inherits from ",paraId:4,tocIndex:2},{value:"AbstractRendererPlugin",paraId:4,tocIndex:2},{value:" needs to implement two methods.",paraId:4,tocIndex:2},{value:"init",paraId:5,tocIndex:2},{value:" Loading modules in containers",paraId:5,tocIndex:2},{value:"destroy",paraId:5,tocIndex:2},{value:" Unloading modules in containers",paraId:5,tocIndex:2},{value:"import { AbstractRendererPlugin, Module } from '@antv/g';\nimport { DOMInteractionPlugin } from './DOMInteractionPlugin';\n\n// Define the module for this plugin\nconst containerModule = Module((register) => {\n    register(ImagePool);\n    // ...Omit registration of other dependencies\n    register(CanvasRendererPlugin);\n    register(LoadImagePlugin);\n});\n\nexport class Plugin extends AbstractRendererPlugin {\n    name = 'canvas-renderer';\n    init(): void {\n        this.container.load(containerModule, true);\n    }\n    destroy(): void {\n        this.container.unload(containerModule);\n    }\n}\n",paraId:6,tocIndex:2},{value:"In the module we can register dependencies with the current container (one per canvas) or the global container (shared by all canvases) via ",paraId:7,tocIndex:2},{value:"register",paraId:7,tocIndex:2},{value:". It is also possible to mount it to an extension point defined in the core layer (which you will see shortly).",paraId:7,tocIndex:2},{value:"Here we have registered a ",paraId:8,tocIndex:2},{value:"CanvasRendererPlugin",paraId:8,tocIndex:2},{value:", let's go ahead and take a deeper look.",paraId:8,tocIndex:2},{value:"The ",paraId:9,tocIndex:3},{value:"inject",paraId:9,tocIndex:3},{value:" provided by ",paraId:9,tocIndex:3},{value:"mana-syringe",paraId:9,tocIndex:3},{value:" allows us to get objects we care about, such as the original configuration when creating the canvas, the default camera, the context, and other services, with the injection of dependencies done by the container.",paraId:9,tocIndex:3},{value:"We also register ourselves with ",paraId:10,tocIndex:3},{value:"RenderingPluginContribution",paraId:10,tocIndex:3},{value:", an extension point provided by the G core layer, so that a set of rendering service plugins containing it are called when the core layer rendering service runs.",paraId:10,tocIndex:3},{value:"import { inject, singleton } from '@antv/g';\n\n// Realization of extension points\n@singleton({ contrib: RenderingPluginContribution })\nexport class CanvasRendererPlugin implements RenderingPlugin {\n    @inject(CanvasConfig)\n    private canvasConfig: CanvasConfig;\n\n    @inject(DefaultCamera)\n    private camera: Camera;\n\n    @inject(ContextService)\n    private contextService: ContextService<CanvasRenderingContext2D>;\n\n    @inject(SceneGraphService)\n    private sceneGraphService: SceneGraphService;\n\n    // 渲染服务\n    @inject(RenderingContext)\n    private renderingContext: RenderingContext;\n}\n",paraId:11,tocIndex:3},{value:"The next step is to select the appropriate execution timing through a series of ",paraId:12,tocIndex:3},{value:"hooks",paraId:12,tocIndex:3},{value:" provided by the rendering service, e.g. to process the next DPR when the rendering service is initialized.",paraId:12,tocIndex:3},{value:"apply(renderingService: RenderingService) {\n    // When the rendering service is initialized...\n    renderingService.hooks.init.tap(CanvasRendererPlugin.tag, () => {\n        // Contextual services using container injection\n        const context = this.contextService.getContext();\n        const dpr = this.contextService.getDPR();\n        // scale all drawing operations by the dpr\n        // @see https://www.html5rocks.com/en/tutorials/canvas/hidpi/\n        context && context.scale(dpr, dpr);\n\n        // Rendering Context Service with Container Injection\n        this.renderingContext.root.addEventListener(ElementEvent.MOUNTED, handleMounted);\n        this.renderingContext.root.addEventListener(ElementEvent.UNMOUNTED, handleUnmounted);\n        this.renderingContext.root.addEventListener(ElementEvent.BOUNDS_CHANGED, handleBoundsChanged);\n    });\n}\n",paraId:13,tocIndex:3},{value:"All plugins follow the above structure implementation.",paraId:14,tocIndex:3},{value:"There are also dependencies between plugins, for example ",paraId:15,tocIndex:4},{value:"g-plugin-gpgpu",paraId:16,tocIndex:4},{value:" depends on ",paraId:15,tocIndex:4},{value:"g-plugin-device-renderer",paraId:17,tocIndex:4},{value:". You need to exclude dependencies when building UMD independently, see ",paraId:15,tocIndex:4},{value:"build instructions",paraId:18,tocIndex:4},{value:" for details.",paraId:15,tocIndex:4}]},49910:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(2085);const n=[{value:"Provides WebGL 1/2 and WebGPU-based rendering capabilities, and also includes GPU-based pickup capabilities. All 2D base graphics provided by the built-in G Core package, while exposing the ability to extend other custom 2D/3D graphics.",paraId:0},{value:"The ",paraId:1,tocIndex:0},{value:"g-webgl",paraId:1,tocIndex:0},{value:" and ",paraId:1,tocIndex:0},{value:"g-webgpu",paraId:1,tocIndex:0},{value:" renderers are built in by default, so there is no need to introduce them manually.",paraId:1,tocIndex:0},{value:"import { Renderer as WebGLRenderer } from '@antv/g-webgl';\nconst renderer = new WebGLRenderer();\n",paraId:2,tocIndex:0},{value:"It represents a GPU device (as opposed to a Host, which usually refers to a CPU) and provides a unified HAL hardware adaptation layer for WebGL 1/2 and WebGPU implementations. The WebGPU ",paraId:3,tocIndex:1},{value:"related API",paraId:3,tocIndex:1},{value:" has been heavily referenced in the design of the related APIs.",paraId:3,tocIndex:1},{value:"Since device initialization may be asynchronous (e.g. ",paraId:4,tocIndex:1},{value:"adapter.requestDevice()",paraId:4,tocIndex:1},{value:" for WebGPU), two ways to obtain a Device are provided.",paraId:4,tocIndex:1},{value:"import { CanvasEvent } from '@antv/g';\n\n// Listening for canvas ready events\ncanvas.addEventListener(CanvasEvent.READY, () => {\n    // Get Device by Renderer\n    const plugin = renderer.getPlugin('device-renderer');\n    const device = plugin.getDevice();\n});\n\n// Or wait for the canvas to be ready\nawait canvas.ready;\n// Get Device by Renderer\nconst plugin = renderer.getPlugin('device-renderer');\nconst device = plugin.getDevice();\n",paraId:5,tocIndex:1},{value:"After acquiring a Device, you can use it to create a series of GPU-related resources, such as Buffer, Texture, etc.",paraId:6,tocIndex:1},{value:"Buffer represents a piece of memory used in GPU operations that can be specified at creation time to initialize the data and subsequently modify some of it. The data is stored in a linear layout. When you need to read the data on the CPU side (Host), you need to do it by ",paraId:7,tocIndex:2},{value:"Readback",paraId:8,tocIndex:2},{value:".",paraId:7,tocIndex:2},{value:"export interface Buffer {\n    setSubData(\n        dstByteOffset: number,\n        src: ArrayBufferView,\n        srcByteOffset?: number,\n        byteLength?: number,\n    ): void;\n\n    destroy(): void;\n}\n",paraId:9,tocIndex:2},{value:"The Buffer is created in the following way and needs to be specified.",paraId:10,tocIndex:3},{value:"viewOrSize must be filled, specify the initialization data or Buffer size",paraId:11,tocIndex:3},{value:"usage Mandatory, memory usage, fully refer to ",paraId:11,tocIndex:3},{value:"WebGPU Buffer Usage",paraId:11,tocIndex:3},{value:"hint Optional, only valid in WebGL environment",paraId:11,tocIndex:3},{value:"interface Device {\n    createBuffer(descriptor: BufferDescriptor): Buffer;\n}\n\nexport interface BufferDescriptor {\n    viewOrSize: ArrayBufferView | number;\n    usage: BufferUsage;\n    hint?: BufferFrequencyHint;\n}\n\nexport enum BufferUsage {\n    MAP_READ = 0x0001,\n    MAP_WRITE = 0x0002,\n    COPY_SRC = 0x0004,\n    COPY_DST = 0x0008,\n    INDEX = 0x0010,\n    VERTEX = 0x0020,\n    UNIFORM = 0x0040,\n    STORAGE = 0x0080,\n    INDIRECT = 0x0100,\n    QUERY_RESOLVE = 0x0200,\n}\n\nexport enum BufferFrequencyHint {\n    Static = 0x01,\n    Dynamic = 0x02,\n}\n",paraId:12,tocIndex:3},{value:"For example, when used with ",paraId:13,tocIndex:3},{value:"g-plugin-gpgpu",paraId:14,tocIndex:3},{value:", to allocate input and output Buffer.",paraId:13,tocIndex:3},{value:"const buffer = device.createBuffer({\n    usage: BufferUsage.STORAGE | BufferUsage.COPY_SRC,\n    viewOrSize: new Float32Array([1, 2, 3, 4]),\n});\n",paraId:15,tocIndex:3},{value:"dstByteOffset required, the offset in the target Buffer, in Byte units",paraId:16,tocIndex:4},{value:"src Mandatory, type is ArrayBufferView",paraId:16,tocIndex:4},{value:"srcByteOffset optional, the starting offset in src, in Byte",paraId:16,tocIndex:4},{value:"byteLength optional, the length in src, in Byte",paraId:16,tocIndex:4},{value:"For example, to modify a variable in Uniform, which is located at the 20th bytes in the original Buffer.",paraId:17,tocIndex:4},{value:"paramBuffer.setSubData(\n    5 * Float32Array.BYTES_PER_ELEMENT,\n    new Float32Array([maxDisplace]),\n);\n",paraId:18,tocIndex:4},{value:"Free Buffer resources.",paraId:19,tocIndex:5},{value:"buffer.destroy();\n",paraId:20,tocIndex:5},{value:"Sometimes we need to read data from the GPU side (Device) Buffer or Texture on the CPU side (Host), and this is done with the Readback object, which provides asynchronous read methods.",paraId:21,tocIndex:6},{value:"interface Device {\n    createReadback(): Readback;\n}\n",paraId:22,tocIndex:7},{value:"Reads the Buffer contents asynchronously.",paraId:23,tocIndex:8},{value:"Implemented in WebGPU by ",paraId:24,tocIndex:8},{value:"copyBufferToBuffer",paraId:24,tocIndex:8},{value:", and in WebGL2 by ",paraId:24,tocIndex:8},{value:"fenceSync",paraId:24,tocIndex:8},{value:".",paraId:24,tocIndex:8},{value:"WebGL2 is implemented by ",paraId:24,tocIndex:8},{value:"fenceSync",paraId:24,tocIndex:8},{value:"WebGL1 does not support",paraId:24,tocIndex:8},{value:"The list of parameters is as follows.",paraId:25,tocIndex:8},{value:"srcBuffer Mandatory, source Buffer",paraId:26,tocIndex:8},{value:"srcByteOffset optional, the starting offset of the target Buffer, default is 0, i.e. read from scratch",paraId:26,tocIndex:8},{value:"dstBuffer optional, the content of the read is stored to the target ArrayBufferView, not filled automatically created, and finally returned as a result",paraId:26,tocIndex:8},{value:"dstOffset optional, the target ArrayBufferView offset, default is 0, that is, write from the beginning",paraId:26,tocIndex:8},{value:"length check or fill, the length of the read, the default is all",paraId:26,tocIndex:8},{value:"The return value is the result of reading the ArrayBufferView.",paraId:27,tocIndex:8},{value:"export interface Readback {\n    readBuffer(\n        srcBuffer: Buffer,\n        srcByteOffset?: number,\n        dstBuffer?: ArrayBufferView,\n        dstOffset?: number,\n        length?: number,\n    ): Promise<ArrayBufferView>;\n}\n",paraId:28,tocIndex:8},{value:"For example, when used with ",paraId:29,tocIndex:8},{value:"g-plugin-gpgpu",paraId:30,tocIndex:8},{value:", reads the result of the calculation.",paraId:29,tocIndex:8},{value:"const result = await readback.readBuffer(resultBuffer); // Float32Array([...])\n",paraId:31,tocIndex:8},{value:"Reads the texture content.",paraId:32,tocIndex:9},{value:"WebGL1 is implemented via ",paraId:33,tocIndex:9},{value:"readPixels",paraId:33,tocIndex:9},{value:"WebGL2 is implemented with ",paraId:33,tocIndex:9},{value:"fenceSync",paraId:33,tocIndex:9},{value:" as readBuffer.",paraId:33,tocIndex:9},{value:"WebGPU uses ",paraId:33,tocIndex:9},{value:"copyTextureToBuffer",paraId:33,tocIndex:9},{value:" and then uses readBuffer in the same way as readBuffer",paraId:33,tocIndex:9},{value:"The list of parameters is as follows.",paraId:34,tocIndex:9},{value:"texture must be filled, source Texture",paraId:35,tocIndex:9},{value:"x must be filled, the starting x-coordinate of the read area",paraId:35,tocIndex:9},{value:"y must be filled, the starting y-coordinate of the read area",paraId:35,tocIndex:9},{value:"width must be filled, the width of the read area",paraId:35,tocIndex:9},{value:"height must be filled, the height of the read area",paraId:35,tocIndex:9},{value:"dstBuffer Mandatory, the content of the read area will be stored in the target ArrayBufferView and returned as a result.",paraId:35,tocIndex:9},{value:"dstOffset optional, the target ArrayBufferView offset, default is 0, i.e. write from scratch",paraId:35,tocIndex:9},{value:"length is optional, the length of the read, default is all",paraId:35,tocIndex:9},{value:"The return value is the result of reading the ArrayBufferView.",paraId:36,tocIndex:9},{value:"export interface Readback {\n    readTexture(\n        t: Texture,\n        x: number,\n        y: number,\n        width: number,\n        height: number,\n        dstBuffer: ArrayBufferView,\n        dstOffset?: number,\n        length?: number,\n    ): Promise<ArrayBufferView>;\n}\n",paraId:37,tocIndex:9},{value:"For example, when implementing GPU-based color-coded pickups.",paraId:38,tocIndex:9},{value:"const pickedColors = await readback.readTexture(\n    this.pickingTexture,\n    rect.x,\n    rect.y,\n    rect.width,\n    rect.height,\n    new Uint8Array(rect.width * rect.height * 4),\n);\n",paraId:39,tocIndex:9},{value:"Releases the Readback resource.",paraId:40,tocIndex:10},{value:"readback.destroy();\n",paraId:41,tocIndex:10},{value:"Textures are a very common GPU resource.",paraId:42,tocIndex:11},{value:"export interface Texture {\n    setImageData(data: TexImageSource | ArrayBufferView[]): void;\n}\n",paraId:43,tocIndex:11},{value:"interface Device {\n    createTexture(descriptor: TextureDescriptor): Texture;\n}\n\nexport interface TextureDescriptor {\n    dimension: TextureDimension;\n    pixelFormat: Format;\n    width: number;\n    height: number;\n    depth: number;\n    numLevels: number;\n    usage: TextureUsage;\n    pixelStore?: Partial<{\n        packAlignment: number,\n        unpackAlignment: number,\n        unpackFlipY: boolean,\n    }>;\n}\n",paraId:44,tocIndex:12},{value:"For example, after loading the image successfully, set the texture content.",paraId:45,tocIndex:13},{value:"const image = new window.Image();\nimage.onload = () => {\n    // Set the texture content as Image\n    texture.setImageData(image);\n};\nimage.onerror = () => {};\nimage.crossOrigin = 'Anonymous';\nimage.src = src;\n",paraId:46,tocIndex:13},{value:"Frees the Texture resource.",paraId:47,tocIndex:14},{value:"texture.destroy();\n",paraId:48,tocIndex:14},{value:"interface Device {\n    createSampler(descriptor: SamplerDescriptor): Sampler;\n}\n\nexport interface SamplerDescriptor {\n    wrapS: WrapMode;\n    wrapT: WrapMode;\n    wrapQ?: WrapMode;\n    minFilter: TexFilterMode;\n    magFilter: TexFilterMode;\n    mipFilter: MipFilterMode;\n    minLOD?: number;\n    maxLOD?: number;\n    maxAnisotropy?: number;\n    compareMode?: CompareMode;\n}\n",paraId:49,tocIndex:16},{value:"Frees the Sampler resource.",paraId:50,tocIndex:17},{value:"sampler.destroy();\n",paraId:51,tocIndex:17},{value:"There are two ways to create.",paraId:52,tocIndex:19},{value:"interface Device {\n    createRenderTarget(descriptor: RenderTargetDescriptor): RenderTarget;\n    createRenderTargetFromTexture(texture: Texture): RenderTarget;\n}\n\nexport interface RenderTargetDescriptor {\n    pixelFormat: Format;\n    width: number;\n    height: number;\n    sampleCount: number;\n    texture?: Texture;\n}\n",paraId:53,tocIndex:19},{value:"Frees the RenderTarget resource.",paraId:54,tocIndex:20},{value:"renderTarget.destroy();\n",paraId:55,tocIndex:20},{value:"interface Device {\n    createProgram(program: ProgramDescriptor): Program;\n}\n\nexport interface ProgramDescriptor {\n    vert?: string;\n    frag?: string;\n    preprocessedVert?: string;\n    preprocessedFrag?: string;\n    preprocessedCompute?: string;\n}\n",paraId:56,tocIndex:22},{value:"Frees the Program resource.",paraId:57,tocIndex:23},{value:"program.destroy();\n",paraId:58,tocIndex:23},{value:"Unlike ",paraId:59,tocIndex:24},{value:"g-plugin-canvas-picker",paraId:60,tocIndex:24},{value:" and ",paraId:59,tocIndex:24},{value:"g-plugin-svg-picker",paraId:61,tocIndex:24},{value:', which are CPU-based picking schemes, we use A GPU-based approach called "color coding".',paraId:59,tocIndex:24},{value:"This approach consists of the following steps.",paraId:62,tocIndex:24},{value:'assign a separate "color" to each graph for picking When pickup is needed (triggering ',paraId:63,tocIndex:24},{value:"interaction event",paraId:64,tocIndex:24},{value:" or via ",paraId:63,tocIndex:24},{value:"element(s) FromPoint",paraId:65,tocIndex:24},{value:' API), use the "color" assigned in the previous step. Use the "color" assigned in the previous step instead of the real color to render into the Framebuffer (size does not need to be full screen, usually only 1x1). Also use ',paraId:63,tocIndex:24},{value:"setViewOffset",paraId:66,tocIndex:24},{value:" to set the offset for the camera so that only the pickup area (usually 1x1) needs to be rendered instead of the full screen.",paraId:63,tocIndex:24},{value:"read the texture pixel values from the Framebuffer and map them back to the graphics",paraId:63,tocIndex:24},{value:"If you need to get all the graphics where the target points overlap together instead of the topmost one (e.g. using ",paraId:63,tocIndex:24},{value:"elementsFromPoint",paraId:67,tocIndex:24},{value:'), set the pickups of the picked graphics to "Color" is empty. Repeat step 2/3 until no graphics can be picked up',paraId:63,tocIndex:24}]},51052:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(38053);const n=[{value:"Bind events based on the DOM API.",paraId:0},{value:"Every renderer is built-in by default, so there is no need to introduce it manually.",paraId:1,tocIndex:0},{value:"import { Renderer as SvgRenderer } from '@antv/g-svg';\nconst svgRenderer = new SvgRenderer();\n",paraId:2,tocIndex:0}]},80475:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(29236);const n=[{value:"Drag and drop based on [PointerEvents](/en/api/event#interaction events). In this ",paraId:0},{value:"example",paraId:1},{value:", we listen to the drag event of the soccer ball to move it to the right position and the dragover event of the goal to change the transparency when the soccer ball crosses the goal area.",paraId:0},{value:"import { Renderer as CanvasRenderer } from '@antv/g-canvas';\nimport { Plugin } from '@antv/g-plugin-dragndrop';\n\nconst canvasRenderer = new CanvasRenderer();\ncanvasRenderer.registerPlugin(new Plugin());\n",paraId:2,tocIndex:0},{value:"We provide the following configuration items that can be passed in when creating plugins, for example ",paraId:3,tocIndex:1},{value:"overlap",paraId:4,tocIndex:1},{value:".",paraId:3,tocIndex:1},{value:"new Plugin({\n    overlap: 'center',\n});\n",paraId:5,tocIndex:1},{value:'Since there is no "style" on ',paraId:6,tocIndex:2},{value:"Document",paraId:7,tocIndex:2},{value:", when we want to drag and drop on a blank area of the canvas, we cannot do so.",paraId:6,tocIndex:2},{value:"// wrong\ncanvas.document.style.draggable = true;\n\n// correct\nconst plugin = new Plugin({\n    // we can drag the whole document from empty space now!\n    isDocumentDraggable: true,\n});\n",paraId:8,tocIndex:2},{value:"In this ",paraId:9,tocIndex:2},{value:"example",paraId:10,tocIndex:2},{value:", dragging in a blank area pans the camera with ",paraId:9,tocIndex:2},{value:"camera.pan()",paraId:11,tocIndex:2},{value:" to achieve the visual effect of the entire canvas moving.",paraId:9,tocIndex:2},{value:"const camera = canvas.getCamera();\ncanvas.addEventListener('drag', function (e) {\n    if (e.target === canvas.document) {\n        camera.pan(-e.movementX, -e.movementY);\n    }\n});\n",paraId:12,tocIndex:2},{value:"In the above example we have ",paraId:13,tocIndex:2},{value:"e.target === canvas.document",paraId:13,tocIndex:2},{value:" to avoid moving non-",paraId:13,tocIndex:2},{value:"Document",paraId:14,tocIndex:2},{value:' elements like "soccer". element also causes the camera to move.',paraId:13,tocIndex:2},{value:"Similarly, if we want to make ",paraId:15,tocIndex:3},{value:"Document",paraId:16,tocIndex:3},{value:' a "placeable area", we can use this configuration item.',paraId:15,tocIndex:3},{value:"// wrong\ncanvas.document.style.droppable = true;\n\n// correct\nconst plugin = new Plugin({\n    isDocumentDroppable: true,\n});\n",paraId:17,tocIndex:3},{value:"In this ",paraId:18,tocIndex:3},{value:"example",paraId:19,tocIndex:3},{value:", when we drag the soccer to a blank area, the console prints the following message.",paraId:18,tocIndex:3},{value:"canvas.addEventListener('drop', function (e) {\n    if (e.target === canvas.document) {\n        console.log('drop on document');\n    }\n});\n",paraId:20,tocIndex:3},{value:"We provide the following configurations for what conditions are met to determine ",paraId:21,tocIndex:4},{value:"dragstart",paraId:21,tocIndex:4},{value:": based on drag distance and time, respectively. Only if all these conditions are met, a series of drag events such as ",paraId:21,tocIndex:4},{value:"dragstart",paraId:21,tocIndex:4},{value:" will be triggered.",paraId:21,tocIndex:4},{value:"This configuration item is used to configure the detection threshold of the drag distance in pixels, and only ",paraId:22,tocIndex:4},{value:"greater than",paraId:22,tocIndex:4},{value:" this value will be passed. The default value is 0.",paraId:22,tocIndex:4},{value:"In this ",paraId:23,tocIndex:4},{value:"example",paraId:24,tocIndex:4},{value:", we have configured this option to 10, i.e. only dragging more than 10 pixels will trigger a drag event.",paraId:23,tocIndex:4},{value:"const plugin = new Plugin({\n    dragstartDistanceThreshold: 10,\n});\n",paraId:25,tocIndex:4},{value:"This configuration item is used to configure the detection threshold of drag and drop time in milliseconds, and only ",paraId:26,tocIndex:5},{value:"greater than",paraId:26,tocIndex:5},{value:" this value will be passed. The default value is 0.",paraId:26,tocIndex:5},{value:"In this ",paraId:27,tocIndex:5},{value:"example",paraId:28,tocIndex:5},{value:", we have configured this option to 100, i.e. the drag event will only be triggered if the drag exceeds 100 milliseconds.",paraId:27,tocIndex:5},{value:"const plugin = new Plugin({\n    dragstartTimeThreshold: 100,\n});\n",paraId:29,tocIndex:5},{value:"Used to determine if the graph in the drag is in the ",paraId:30,tocIndex:6},{value:"dropzone",paraId:30,tocIndex:6},{value:", supports the following two values.",paraId:30,tocIndex:6},{value:"'pointer'",paraId:31,tocIndex:6},{value:" Default value. The mouse position enters the ",paraId:31,tocIndex:6},{value:"dropzone",paraId:31,tocIndex:6},{value:" area by determining",paraId:31,tocIndex:6},{value:"'center'",paraId:31,tocIndex:6},{value:" The center of the dropzone is determined if the center of the dropzone is in the dropzone.",paraId:31,tocIndex:6},{value:"In addition to passing in when the plugin is initialized, you can also use ",paraId:32,tocIndex:7},{value:"setOptions",paraId:32,tocIndex:7},{value:" to modify the above configuration items at any time later:",paraId:32,tocIndex:7},{value:"plugin.setOptions({\n    dragstartTimeThreshold: 200,\n});\n",paraId:33,tocIndex:7},{value:"Drag and Drop related events are both bubbly.",paraId:34,tocIndex:8},{value:"After registering the plugin, you need to set the ",paraId:35,tocIndex:9},{value:"draggable",paraId:35,tocIndex:9},{value:" property to ",paraId:35,tocIndex:9},{value:"true",paraId:35,tocIndex:9},{value:" in order to make the graphics support drag and drop. For example, for the soccer ball above.",paraId:35,tocIndex:9},{value:"const ball = new Image({\n    style: {\n        draggable: true, // 表示该图形支持拖拽\n        x: 300,\n        y: 200,\n        width: 100,\n        height: 100,\n        src: 'https://en.js.cx/clipart/ball.svg',\n        cursor: 'pointer',\n    },\n});\n",paraId:36,tocIndex:9},{value:"At this point, you can listen to drag-related events for the graph, including the following three types of events, the ",paraId:37,tocIndex:9},{value:"target",paraId:38,tocIndex:9},{value:" of the event object are the graph being dragged.",paraId:37,tocIndex:9},{value:"dragstart triggered at the start of dragging ",paraId:39,tocIndex:9},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/dragstart_event",paraId:39,tocIndex:9},{value:"drag Triggered frequently during dragging ",paraId:39,tocIndex:9},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/drag_event",paraId:39,tocIndex:9},{value:"dragend Triggered at the end of the drag ",paraId:39,tocIndex:9},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/dragend_event",paraId:39,tocIndex:9},{value:"drag The related events are all [PointerEvents](/en/api/event#interaction events), so you can access the properties on the event object in the event listener.",paraId:40,tocIndex:9},{value:"For example, when we start dragging, we record the offset from mouse position to the position of the dragged element ",paraId:41,tocIndex:9},{value:"shiftX/Y",paraId:41,tocIndex:9},{value:", both under ",paraId:41,tocIndex:9},{value:"Canvas/world coordinate system",paraId:42,tocIndex:9},{value:". In the ",paraId:41,tocIndex:9},{value:"drag",paraId:41,tocIndex:9},{value:" event we call ",paraId:41,tocIndex:9},{value:"setPosition",paraId:43,tocIndex:9},{value:" to finish the panning of the dragged drawing.",paraId:41,tocIndex:9},{value:"https://javascript.info/mouse-drag-and-drop#correct-positioning",paraId:44,tocIndex:9},{value:"let shiftX = 0;\nlet shiftY = 0;\nfunction moveAt(target, canvasX, canvasY) {\n    target.setPosition(canvasX - shiftX, canvasY - shiftY);\n}\n\nball.addEventListener('dragstart', function (e) {\n    e.target.style.opacity = 0.5;\n    ballText.style.text = 'ball dragstart';\n\n    const [x, y] = e.target.getPosition();\n    shiftX = e.canvasX - x;\n    shiftY = e.canvasY - y;\n\n    moveAt(e.target, e.canvasX, e.canvasY);\n});\nball.addEventListener('drag', function (e) {\n    moveAt(e.target, e.canvasX, e.canvasY);\n    ballText.style.text = `ball drag movement: ${e.movementX}, ${e.movementY}`;\n});\nball.addEventListener('dragend', function (e) {\n    e.target.style.opacity = 1;\n    ballText.style.text = 'ball dragend';\n});\n",paraId:45,tocIndex:9},{value:"Similarly, we can enable ",paraId:46,tocIndex:10},{value:"droppable",paraId:46,tocIndex:10},{value:" for graphics that support placement.",paraId:46,tocIndex:10},{value:"const gate = new Image({\n    style: {\n        droppable: true, // Indicates that the graph supports the placement of\n        x: 50,\n        y: 100,\n        width: 200,\n        height: 100,\n        src: 'https://en.js.cx/clipart/soccer-gate.svg',\n    },\n});\n",paraId:47,tocIndex:10},{value:"At this point you can listen to drag/drop related events in the placement area, including the following three types of events, the ",paraId:48,tocIndex:10},{value:"target",paraId:49,tocIndex:10},{value:" of the event object are the graphics of the placement area.",paraId:48,tocIndex:10},{value:"dragenter has the graphic being dragged into the area ",paraId:50,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/dragenter_event",paraId:50,tocIndex:10},{value:"dragleave has graphics being dragged out of the area ",paraId:50,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/dragleave_event",paraId:50,tocIndex:10},{value:"dragover has the graphic being drawn over the area ",paraId:50,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/dragover_event",paraId:50,tocIndex:10},{value:"drop has the graphic placed in the area ",paraId:50,tocIndex:10},{value:"https://developer.mozilla.org/zh-CN/docs/Web/API/Document/drop_event",paraId:50,tocIndex:10},{value:"For example, let's have the goal listen for events related to.",paraId:51,tocIndex:10},{value:"gate.addEventListener('dragenter', function (e) {\n    e.target.style.opacity = 0.6;\n    gateText.style.text = 'gate dragenter';\n});\ngate.addEventListener('dragleave', function (e) {\n    e.target.style.opacity = 1;\n    gateText.style.text = 'gate dragleave';\n});\ngate.addEventListener('dragover', function (e) {\n    e.target.style.opacity = 0.6;\n    gateText.style.text = 'gate dragover';\n});\ngate.addEventListener('drop', function (e) {\n    e.target.style.opacity = 1;\n    gateText.style.text = 'gate drop';\n});\n",paraId:52,tocIndex:10},{value:"The ",paraId:53,tocIndex:12},{value:"drag",paraId:53,tocIndex:12},{value:" series of events has a sequential triggering order with other interaction events. Take the ",paraId:53,tocIndex:12},{value:"pointer",paraId:53,tocIndex:12},{value:" series of events as an example, in a typical drag and drop process, the following events are triggered in sequence.",paraId:53,tocIndex:12},{value:"pointerdown",paraId:54,tocIndex:12},{value:" press",paraId:54,tocIndex:12},{value:"pointermove * n",paraId:54,tocIndex:12},{value:" dragging a certain distance, and then the dragging process will be decided",paraId:54,tocIndex:12},{value:"dragstart",paraId:54,tocIndex:12},{value:" Start dragging",paraId:54,tocIndex:12},{value:"drag",paraId:54,tocIndex:12},{value:" Dragging in progress",paraId:54,tocIndex:12},{value:"pointermove",paraId:54,tocIndex:12},{value:"drag",paraId:54,tocIndex:12},{value:" dragging",paraId:54,tocIndex:12},{value:"pointermove",paraId:54,tocIndex:12},{value:"drag",paraId:54,tocIndex:12},{value:" dragging",paraId:54,tocIndex:12},{value:"pointermove",paraId:54,tocIndex:12},{value:"dragend",paraId:54,tocIndex:12},{value:" end of drag",paraId:54,tocIndex:12},{value:"pointerup",paraId:54,tocIndex:12},{value:" lifting",paraId:54,tocIndex:12},{value:"In the Drag'n'drop implementation of HTML, only one ",paraId:55,tocIndex:13},{value:"click",paraId:55,tocIndex:13},{value:" and ",paraId:55,tocIndex:13},{value:"drag",paraId:55,tocIndex:13},{value:" event will be triggered at the same time: ",paraId:55,tocIndex:13},{value:"https://plnkr.co/edit/5mdl7oTg0dPWXIip",paraId:55,tocIndex:13},{value:"We have also kept this setting in our implementation, so that ",paraId:56,tocIndex:13},{value:"click",paraId:56,tocIndex:13},{value:" is not triggered after the ",paraId:56,tocIndex:13},{value:"dragend",paraId:56,tocIndex:13},{value:" event is fired.",paraId:56,tocIndex:13}]},98132:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(89394);const n=[{value:"Provides GPGPU capabilities based on WebGPU. Writing Compute Shaders directly in WGSL is ideal for porting existing CUDA algorithms.",paraId:0},{value:"For example, there are very many layout and analysis algorithms suitable for parallelism in graph scenarios.",paraId:1},{value:"Fruchterman layout algorithm",paraId:2},{value:"Pagerank",paraId:3},{value:"SSSP",paraId:4},{value:"The performance improvement is very impressive when the number of nodes/edges in the graph reaches a certain size. In the case of pagerank, for example, the GPU version has more than 100 times better performance than the CPU version (300ms vs. 30s) for 1k nodes and 50w edges.",paraId:5},{value:"Can only be used with the ",paraId:6,tocIndex:0},{value:"g-webgpu",paraId:6,tocIndex:0},{value:" renderer.",paraId:6,tocIndex:0},{value:"import { Renderer } from '@antv/g-webgpu';\nimport { Plugin } from '@antv/g-plugin-gpgpu';\n\nconst webgpuRenderer = new Renderer();\nwebgpuRenderer.registerPlugin(new Plugin());\n",paraId:7,tocIndex:0},{value:"When creating a compute task, we need to get the GPU device (Device) and use it to create the underlying objects such as Buffer. In the [READY](/en/api/canvas#canvas-specific events) event handler of the canvas, we can get the Device through the renderer.",paraId:8,tocIndex:1},{value:"import { CanvasEvent } from '@antv/g';\n\n// Waiting for the canvas to be ready\ncanvas.addEventListener(CanvasEvent.READY, () => {\n    // Get Device by Renderer\n    const plugin = renderer.getPlugin('device-renderer');\n    const device = plugin.getDevice();\n\n    // Use Device to create GPU-related objects, see the following section\n});\n",paraId:9,tocIndex:1},{value:"Therefore, the g-plugin-gpgpu plugin provides the Kernel to describe the computational task, which, in addition to passing in the device obtained in the previous section, needs to be described by the computeShader using the string.",paraId:10,tocIndex:2},{value:"import { Kernel } from '@antv/g-plugin-gpgpu';\n\nconst kernel = new Kernel(device, {\n    computeShader: `...`,\n});\n",paraId:11,tocIndex:2},{value:"Once the Kernel is defined, we need to pass it the input and get the output when we are done. The allocation of memory is performed on the Host side, creating a Buffer from the Device, where ",paraId:12,tocIndex:3},{value:"usage",paraId:12,tocIndex:3},{value:" needs to correspond to the memory usage defined in the Compute Shader, and writing the initial memory data.",paraId:12,tocIndex:3},{value:"const firstMatrixBuffer = device.createBuffer({\n    usage: BufferUsage.STORAGE,\n    viewOrSize: firstMatrix, // new Float32Array([2 /* rows */, 4 /* columns */, 1, 2, 3, 4, 5, 6, 7, 8])\n});\n",paraId:13,tocIndex:3},{value:"After creating the Buffer, it needs to be bound to the specified location in the Kernel (corresponding to the binding in the Compute Shader).",paraId:14,tocIndex:3},{value:"kernel.setBinding(0, firstMatrixBuffer);\n",paraId:15,tocIndex:3},{value:"Using ",paraId:16,tocIndex:4},{value:"dispatch",paraId:16,tocIndex:4},{value:" you can allocate the thread grid size and execute the computation pipeline. In the matrix multiplication example, if the size of the thread group is ",paraId:16,tocIndex:4},{value:"1 * 1",paraId:16,tocIndex:4},{value:", the grid size is ",paraId:16,tocIndex:4},{value:"M * N",paraId:16,tocIndex:4},{value:".",paraId:16,tocIndex:4},{value:"const x = Math.ceil(firstMatrix[0] / WORKGROUP_SIZE_X);\nconst y = Math.ceil(secondMatrix[1] / WORKGROUP_SIZE_Y);\nkernel.dispatch(x, y);\n",paraId:17,tocIndex:4},{value:"After the computation is complete, we need to read the data in the result matrix, which is an asynchronous GPU-to-CPU read operation.",paraId:18,tocIndex:4},{value:"const readback = device.createReadback();\nconst result = await readback.readBuffer(resultBuffer); // Float32Array([...])\n",paraId:19,tocIndex:4}]},40772:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(36500);const n=[{value:"In the process of continuous iteration, it is difficult to think through all the features that need to be supported at the beginning of development, and sometimes it is necessary to use the power of the community to continuously produce new feature points or optimize existing features. This requires the system to have a certain degree of scalability. The plug-in pattern is often the approach of choice, with the following advantages.",paraId:0},{value:"Single responsibility. Plug-in code is decoupled from the system code in engineering, can be developed independently, and the complexity of the internal logic of the framework isolated to developers.",paraId:1},{value:"Can be dynamically introduced and configured.",paraId:1},{value:"Plugin systems can be found in a wide range of popular software, such as webpack, VS Code, and Chrome.",paraId:2},{value:"To make the rendering engine also well extensible, we also have a built-in plugin system that allows different renderers to extend their capabilities at runtime. The full set of currently supported plugins is listed below.",paraId:3},{value:"Extensible plug-in mechanism and rich set of plug-ins：",paraId:4,tocIndex:0},{value:"Rendering Related\n",paraId:5,tocIndex:0},{value:"g-plugin-canvas-renderer",paraId:6,tocIndex:0},{value:" Rendering 2D graphics based on Canvas2D.",paraId:7,tocIndex:0},{value:"g-plugin-svg-renderer",paraId:8,tocIndex:0},{value:" Rendering 2D graphics based on SVG.",paraId:7,tocIndex:0},{value:"g-plugin-device-renderer",paraId:9,tocIndex:0},{value:" Rendering 2D graphics based on GPUDevice.",paraId:7,tocIndex:0},{value:"g-plugin-html-renderer",paraId:10,tocIndex:0},{value:" Rendering DOM with HTML.",paraId:7,tocIndex:0},{value:"g-plugin-3d",paraId:11,tocIndex:0},{value:" Extended 3D capabilities.",paraId:7,tocIndex:0},{value:"g-plugin-rough-canvas-renderer",paraId:12,tocIndex:0},{value:" Perform hand-drawn style rendering with ",paraId:7,tocIndex:0},{value:"rough.js",paraId:7,tocIndex:0},{value:" and Canvs2D.",paraId:7,tocIndex:0},{value:"g-plugin-rough-svg-renderer",paraId:13,tocIndex:0},{value:" Perform hand-drawn style rendering with ",paraId:7,tocIndex:0},{value:"rough.js",paraId:7,tocIndex:0},{value:" and SVG.",paraId:7,tocIndex:0},{value:"g-plugin-canvaskit-renderer",paraId:14,tocIndex:0},{value:" Rendering 2D graphics based on ",paraId:7,tocIndex:0},{value:"Skia",paraId:7,tocIndex:0},{value:".",paraId:7,tocIndex:0},{value:"Picking\n",paraId:5,tocIndex:0},{value:"g-plugin-canvas-picker",paraId:15,tocIndex:0},{value:" Do picking with Canvas2D and mathematical calculations.",paraId:16,tocIndex:0},{value:"g-plugin-svg-picker",paraId:17,tocIndex:0},{value:" Do picking with SVG and DOM API.",paraId:16,tocIndex:0},{value:"Interaction\n",paraId:5,tocIndex:0},{value:"g-plugin-dom-interaction",paraId:18,tocIndex:0},{value:" Binds event listeners with DOM API.",paraId:19,tocIndex:0},{value:"g-plugin-control",paraId:20,tocIndex:0},{value:" Provides camera interaction for 3D scenes.",paraId:19,tocIndex:0},{value:"g-plugin-dragndrop",paraId:21,tocIndex:0},{value:" Provides Drag 'n' Drop based on PointerEvents.",paraId:19,tocIndex:0},{value:"g-plugin-annotation",paraId:22,tocIndex:0},{value:" Perform transformations on graphics in an interactive form like ",paraId:19,tocIndex:0},{value:"Fabric.js",paraId:19,tocIndex:0},{value:" and ",paraId:19,tocIndex:0},{value:"Konva.js",paraId:19,tocIndex:0},{value:".",paraId:19,tocIndex:0},{value:"Physics Engine\n",paraId:5,tocIndex:0},{value:"g-plugin-box2d",paraId:23,tocIndex:0},{value:" Based on ",paraId:24,tocIndex:0},{value:"Box2D",paraId:24,tocIndex:0},{value:".",paraId:24,tocIndex:0},{value:"g-plugin-matterjs",paraId:25,tocIndex:0},{value:" Based on ",paraId:24,tocIndex:0},{value:"matter.js",paraId:24,tocIndex:0},{value:".",paraId:24,tocIndex:0},{value:"g-plugin-physx",paraId:26,tocIndex:0},{value:" Based on ",paraId:24,tocIndex:0},{value:"PhysX",paraId:24,tocIndex:0},{value:".",paraId:24,tocIndex:0},{value:"Layout Engine\n",paraId:5,tocIndex:0},{value:"g-plugin-yoga",paraId:27,tocIndex:0},{value:" Provides Flex layout capabilities based on Yoga.",paraId:28,tocIndex:0},{value:"GPGPU\n",paraId:5,tocIndex:0},{value:"g-plugin-gpgpu",paraId:29,tocIndex:0},{value:" Provides GPGPU capabilities based on WebGPU.",paraId:30,tocIndex:0},{value:"CSS Selector\n",paraId:5,tocIndex:0},{value:"g-plugin-css-select",paraId:31,tocIndex:0},{value:" Supports for retrieval in the scene graph using CSS selectors.",paraId:32,tocIndex:0},{value:"A11y\n",paraId:5,tocIndex:0},{value:"g-plugin-a11y",paraId:33,tocIndex:0},{value:" Provides accessibility features.",paraId:34,tocIndex:0},{value:"Import the core and renderer code",paraId:35,tocIndex:1},{value:" in UMD format first, then import plugin code in the same way.",paraId:36,tocIndex:1},{value:'<script src="https://unpkg.com/@antv/g-plugin-rough-canvas-renderer@1.7.16/dist/index.umd.min.js"><\/script>\n',paraId:37,tocIndex:1},{value:"Then we can use plugin under the namespace ",paraId:38,tocIndex:1},{value:"window.G",paraId:38,tocIndex:1},{value:", take ",paraId:38,tocIndex:1},{value:"g-plugin-rough-canvas-renderer",paraId:39,tocIndex:1},{value:" as an example:",paraId:38,tocIndex:1},{value:"const plugin = new window.G.RoughCanvasRenderer.Plugin();\n",paraId:40,tocIndex:1},{value:"CodeSandbox Example",paraId:41,tocIndex:1},{value:"Install core and renderer from NPM",paraId:42,tocIndex:2},{value:" first, then we can install plugins in the same way. Take ",paraId:43,tocIndex:2},{value:"g-plugin-rough-canvas-renderer",paraId:44,tocIndex:2},{value:" as an example:",paraId:43,tocIndex:2},{value:"npm install @antv/g-plugin-rough-canvas-renderer --save\n",paraId:45,tocIndex:2},{value:"Then we can ",paraId:46,tocIndex:2},{value:"registerPlugin",paraId:47,tocIndex:2},{value:" on renderer:",paraId:46,tocIndex:2},{value:"import { Plugin } from '@antv/g-plugin-rough-canvas-renderer';\n\nrenderer.registerPlugin(new Plugin());\n",paraId:48,tocIndex:2},{value:"These ",paraId:49,tocIndex:3},{value:"renderers",paraId:50,tocIndex:3},{value:" essentially consist of a set of plug-ins through which their capabilities can also be extended.",paraId:49,tocIndex:3},{value:"renderer.registerPlugin(new Plugin());\n",paraId:51,tocIndex:3}]},66161:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(38090);const n=[{value:"Supports ",paraId:0},{value:"matter.js",paraId:0},{value:" physics engine (rigid bodies only). 2D graphics are initialized to start the simulation, and in addition to gravity and surface friction, external forces can be applied at any time to change the position and rotation angle of the graphics.",paraId:0},{value:"The following 2D graphics are supported: ",paraId:1},{value:"Circle",paraId:2},{value:", ",paraId:1},{value:"Rect",paraId:3},{value:", ",paraId:1},{value:"Line",paraId:4},{value:", ",paraId:1},{value:"Image",paraId:5},{value:" and ",paraId:1},{value:"Polygon",paraId:6},{value:".",paraId:1},{value:"In this ",paraId:7},{value:"example",paraId:8},{value:', we create a series of dynamic objects that will free fall and end up in a "U-shaped slot".',paraId:7},{value:"Create plug-ins and register them in the renderer.",paraId:9,tocIndex:0},{value:"import { Plugin as PluginMatterjs } from '@antv/g-plugin-matterjs';\nrenderer.registerPlugin(new PluginMatterjs());\n",paraId:10,tocIndex:0},{value:"Use the relevant physical properties in 2D graphics.",paraId:11,tocIndex:0},{value:"new Circle({\n    style: {\n        rigid: 'dynamic', // Dynamic objects, involved in force calculations\n        density: 10, // Density: 10 kg/m2\n        r: 10, // Radius: corresponds to 10 meters in the physical world\n    },\n});\n",paraId:12,tocIndex:0},{value:"Global physical world configuration.",paraId:13,tocIndex:1},{value:"matter.js itself supports rendering. With ",paraId:14,tocIndex:2},{value:"debugContainer",paraId:15,tocIndex:2},{value:" on, you can draw a wireframe of each object in the physics engine world for debug.",paraId:14,tocIndex:2},{value:"const plugin = new PluginMatterjs({\n    debug: true,\n    debugContainer: document.getElementById('container'),\n    debugCanvasWidth: 600,\n    debugCanvasHeight: 500,\n});\n",paraId:16,tocIndex:2},{value:"For example, the following figure shows a wireframe with three static walls and some dynamic objects.",paraId:17,tocIndex:2},{value:"The type is ",paraId:18,tocIndex:3},{value:"HTMLElement",paraId:18,tocIndex:3},{value:", matter.js will create ",paraId:18,tocIndex:3},{value:"<canvas>",paraId:18,tocIndex:3},{value:" inside the container for rendering.",paraId:18,tocIndex:3},{value:"The width of the ",paraId:19,tocIndex:4},{value:"<canvas>",paraId:19,tocIndex:4},{value:" of type ",paraId:19,tocIndex:4},{value:"number",paraId:19,tocIndex:4},{value:" for debugging.",paraId:19,tocIndex:4},{value:"The height of the ",paraId:20,tocIndex:5},{value:"<canvas>",paraId:20,tocIndex:5},{value:" of type ",paraId:20,tocIndex:5},{value:"number",paraId:20,tocIndex:5},{value:" for debugging.",paraId:20,tocIndex:5},{value:"The direction of gravity vector, the default value is ",paraId:21,tocIndex:6},{value:"[0, 1]",paraId:21,tocIndex:6},{value:".",paraId:21,tocIndex:6},{value:"https://brm.io/matter-js/docs/classes/Engine.html#property_gravity",paraId:22,tocIndex:6},{value:"For example, if set to ",paraId:23,tocIndex:6},{value:"[1, 1]",paraId:23,tocIndex:6},{value:", the object will naturally move to the lower right corner.",paraId:23,tocIndex:6},{value:"new PluginMatterjs({\n  gravity: [1, 1],\n}),\n",paraId:24,tocIndex:6},{value:"Type is ",paraId:25,tocIndex:7},{value:"number",paraId:25,tocIndex:7},{value:", the gravity scaling factor.",paraId:25,tocIndex:7},{value:"https://brm.io/matter-js/docs/classes/Engine.html#property_gravity.scale",paraId:26,tocIndex:7},{value:"Simulation time interval, default value is ",paraId:27,tocIndex:8},{value:"1/60",paraId:27,tocIndex:8},{value:"Calculate the number of acceleration iterations, the default value is ",paraId:28,tocIndex:9},{value:"4",paraId:28,tocIndex:9},{value:", the higher the calculation overhead",paraId:28,tocIndex:9},{value:"https://brm.io/matter-js/docs/classes/Engine.html#property_velocityIterations",paraId:29,tocIndex:9},{value:"Calculate the number of position iterations, the default value is ",paraId:30,tocIndex:10},{value:"6",paraId:30,tocIndex:10},{value:", the higher the computation overhead",paraId:30,tocIndex:10},{value:"https://brm.io/matter-js/docs/classes/Engine.html#property_positionIterations",paraId:31,tocIndex:10},{value:"Most of the following properties are supported for runtime modification, such as modifying the density.",paraId:32,tocIndex:11},{value:"circle.style.density = 100;\n",paraId:33,tocIndex:11},{value:"Rigid body type.",paraId:34,tocIndex:12},{value:"'static'",paraId:35,tocIndex:12},{value:" Static objects, such as the ground",paraId:35,tocIndex:12},{value:"'dynamic'",paraId:35,tocIndex:12},{value:" Dynamic objects, calculation of forces",paraId:35,tocIndex:12},{value:"Density, kg/m2. Static objects are 0.",paraId:36,tocIndex:13},{value:"https://brm.io/matter-js/docs/classes/Body.html#property_density",paraId:37,tocIndex:13},{value:"Line speed, the default value is ",paraId:38,tocIndex:14},{value:"[0, 0]",paraId:38,tocIndex:14},{value:".",paraId:38,tocIndex:14},{value:"https://brm.io/matter-js/docs/classes/Body.html#property_velocity",paraId:39,tocIndex:14},{value:"Angular velocity, the default value is ",paraId:40,tocIndex:15},{value:"0",paraId:40,tocIndex:15},{value:".",paraId:40,tocIndex:15},{value:"https://brm.io/matter-js/docs/classes/Body.html#property_angularVelocity",paraId:41,tocIndex:15},{value:"Friction, the range is ",paraId:42,tocIndex:16},{value:"[0 - 1]",paraId:42,tocIndex:16},{value:", and the default value is ",paraId:42,tocIndex:16},{value:"0.1",paraId:42,tocIndex:16},{value:". ",paraId:42,tocIndex:16},{value:"0",paraId:42,tocIndex:16},{value:" means the object will slide indefinitely, ",paraId:42,tocIndex:16},{value:"1",paraId:42,tocIndex:16},{value:" means the object will stop immediately after the force is applied.",paraId:42,tocIndex:16},{value:"https://brm.io/matter-js/docs/classes/Body.html#property_friction",paraId:43,tocIndex:16},{value:"Defines the friction force in air, ",paraId:44,tocIndex:17},{value:"0",paraId:44,tocIndex:17},{value:" means no gravity, the higher the value the more significant the deceleration of the object moving in space, the default value is ",paraId:44,tocIndex:17},{value:"0.01",paraId:44,tocIndex:17},{value:".",paraId:44,tocIndex:17},{value:"https://brm.io/matter-js/docs/classes/Body.html#property_frictionAir",paraId:45,tocIndex:17},{value:"The default value is ",paraId:46,tocIndex:18},{value:"0.5",paraId:46,tocIndex:18},{value:".",paraId:46,tocIndex:18},{value:"https://brm.io/matter-js/docs/classes/Body.html#property_frictionStatic",paraId:47,tocIndex:18},{value:"The recovery force, in the range ",paraId:48,tocIndex:19},{value:"[0 - 1]",paraId:48,tocIndex:19},{value:". For example, if a ball falls to the ground, it will not bounce if the restoring force is 0.",paraId:48,tocIndex:19},{value:"In addition to the simulation by initializing parameters, the position and rotation angle of the object can be changed at any moment by applying external forces.",paraId:49,tocIndex:20},{value:"Method signature, applying a force to a figure at a point.",paraId:50,tocIndex:21},{value:"applyForce(object: DisplayObject, force: [number, number], point: [number, number])\n",paraId:51,tocIndex:21},{value:"const plugin = new PluginMatterjs();\nplugin.applyForce(circle, [10, 0], [0, 0]);\n",paraId:52,tocIndex:21}]},52461:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(40311);const n=[{value:"Hand-drawn style rendering using the Canvas version of ",paraId:0},{value:"rough.js",paraId:0},{value:", ",paraId:0},{value:"example",paraId:1},{value:".",paraId:0},{value:"First you need to use the ",paraId:2,tocIndex:0},{value:"g-canvas",paraId:3,tocIndex:0},{value:" renderer, register the plugin and it will replace the rendering of 2D graphics in ",paraId:2,tocIndex:0},{value:"g-plugin-canvas-renderer",paraId:4,tocIndex:0},{value:".",paraId:2,tocIndex:0},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-canvas';\nimport { Plugin as PluginRoughCanvasRenderer } from '@antv/g-plugin-rough-canvas-renderer';\n\n// create a renderer\nconst renderer = new Renderer();\nrenderer.registerPlugin(new PluginRoughCanvasRenderer());\n\n// create a canvas & use `g-canvas`\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:5,tocIndex:0},{value:'Note that once the plugin is used, "Dirty Rectangle Rendering" is not available, which means that any change in the style properties of any graphic will result in a full redraw of the canvas.',paraId:6,tocIndex:0},{value:"In addition, we support all 2D graphics, among which ",paraId:7,tocIndex:0},{value:"Text",paraId:8,tocIndex:0},{value:", ",paraId:7,tocIndex:0},{value:"Image",paraId:9,tocIndex:0},{value:" and ",paraId:7,tocIndex:0},{value:"HTML",paraId:10,tocIndex:0},{value:" have no hand-drawn style.",paraId:7,tocIndex:0},{value:"In addition to the style properties of 2D graphics, the configuration items provided byrough.js can also be used.",paraId:11,tocIndex:1},{value:"rough.js doesn't support ",paraId:12,tocIndex:2},{value:"opacity",paraId:12,tocIndex:2},{value:", but we can achieve it with ",paraId:12,tocIndex:2},{value:"globalAlpha",paraId:12,tocIndex:2},{value:", same as ",paraId:12,tocIndex:2},{value:"g-plugin-canvas-renderer",paraId:13,tocIndex:2},{value:".",paraId:12,tocIndex:2},{value:"Note, however, that ",paraId:14,tocIndex:2},{value:"fillOpacity",paraId:14,tocIndex:2},{value:" and ",paraId:14,tocIndex:2},{value:"strokeOpacity",paraId:14,tocIndex:2},{value:" do not work because rough.js does not open the relevant configuration items.",paraId:14,tocIndex:2},{value:"circle.style.opacity = 0.5;\n",paraId:15,tocIndex:2},{value:"rough.js does not support ",paraId:16,tocIndex:3},{value:"shadow",paraId:16,tocIndex:3},{value:" related effects, but we do provide them.",paraId:16,tocIndex:3},{value:"Configuration items can be found in ",paraId:17,tocIndex:3},{value:"shadow",paraId:18,tocIndex:3},{value:".",paraId:17,tocIndex:3},{value:"circle.style.shadowColor = '#000';\ncircle.style.shadowBlur = 0;\ncircle.style.shadowOffsetX = 0;\ncircle.style.shadowOffsetY = 0;\n",paraId:19,tocIndex:3},{value:"rough.js provides many ",paraId:20,tocIndex:4},{value:"configuration items",paraId:20,tocIndex:4},{value:" that affect the hand-drawn effect, all of which work properly. ",paraId:20,tocIndex:4},{value:"example",paraId:21,tocIndex:4},{value:"The default value is ",paraId:22,tocIndex:4},{value:"1",paraId:22,tocIndex:4},{value:", indicating the degree of hand-drawn style. ",paraId:22,tocIndex:4},{value:"0",paraId:22,tocIndex:4},{value:" means no hand-drawn effect, the larger the number the more obvious the stylization effect, but more than ",paraId:22,tocIndex:4},{value:"10",paraId:22,tocIndex:4},{value:" will completely lose the original shape and it is meaningless.",paraId:22,tocIndex:4},{value:"circle.style.roughness = 2;\n",paraId:23,tocIndex:4},{value:"The degree of curvature of the line, the default value is ",paraId:24,tocIndex:5},{value:"1",paraId:24,tocIndex:5},{value:". ",paraId:24,tocIndex:5},{value:"0",paraId:24,tocIndex:5},{value:" represents a straight line. ",paraId:24,tocIndex:5},{value:"example",paraId:25,tocIndex:5},{value:"circle.style.bowing = 2;\n",paraId:26,tocIndex:5},{value:"Fill style, supporting the following enumerated values, ",paraId:27,tocIndex:6},{value:"example",paraId:28,tocIndex:6},{value:"：",paraId:27,tocIndex:6},{value:"'hachure'",paraId:29,tocIndex:6},{value:"'solid'",paraId:29,tocIndex:6},{value:"'zigzag'",paraId:29,tocIndex:6},{value:"'cross-hatch'",paraId:29,tocIndex:6},{value:"'dots'",paraId:29,tocIndex:6},{value:"'dashed'",paraId:29,tocIndex:6},{value:"'zigzag-line'",paraId:29,tocIndex:6},{value:"circle.style.fillStyle = 'zigzag';\n",paraId:30,tocIndex:6},{value:"Numeric value representing the width of the hachure lines. Default value of the fillWeight is set to half the strokeWidth of that shape.",paraId:31,tocIndex:7},{value:"When using dots styles to fill the shape, this value represents the diameter of the dot.",paraId:32,tocIndex:7},{value:"circle.style.fillWeight = 2;\n",paraId:33,tocIndex:7},{value:"Numerical value (in degrees) that defines the angle of the hachure lines. Default value is ",paraId:34,tocIndex:8},{value:"-41",paraId:34,tocIndex:8},{value:" degrees.",paraId:34,tocIndex:8},{value:"circle.style.hachureAngle = 30;\n",paraId:35,tocIndex:8},{value:"Numerical value that defines the average gap, in pixels, between two hachure lines. Default value of the hachureGap is set to four times the ",paraId:36,tocIndex:9},{value:"strokeWidth",paraId:36,tocIndex:9},{value:" of that shape.",paraId:36,tocIndex:9},{value:"When drawing ellipses, circles, and arcs, RoughJS approximates curveStepCount number of points to estimate the shape. Default value is ",paraId:37,tocIndex:10},{value:"9",paraId:37,tocIndex:10},{value:".",paraId:37,tocIndex:10},{value:"When drawing ellipses, circles, and arcs, Let RoughJS know how close should the rendered dimensions be when compared to the specified one. Default value is 0.95 - which means the rendered dimensions will be at least 95% close to the specified dimensions. A value of 1 will ensure that the dimensions are almost 100% accurate.",paraId:38,tocIndex:11},{value:"If you want the stroke to be dashed (This does not affect the hachure and other fills of the shape), set this property. The value is an array of numbers as described in setLineDash method of canvas",paraId:39,tocIndex:12},{value:"circle.style.lineDash = [10, 10];\n",paraId:40,tocIndex:12},{value:"When using dashed strokes, this property sets the line dash offset or phase. This is akin to the lineDashOffset of canvas",paraId:41,tocIndex:13},{value:"circle.style.lineDashOffset = 10;\n",paraId:42,tocIndex:13},{value:"This property is similar to the strokeLineDash property but it affects the fills, not the stroke. eg. when you want hachure lines to be dashed.",paraId:43,tocIndex:14},{value:"circle.style.fillLineDash = [10, 10];\n",paraId:44,tocIndex:14},{value:"This property is similar to the strokeLineDashOffset property but it affects the fills, not the stroke.",paraId:45,tocIndex:15},{value:"circle.style.fillLineDashOffset = 10;\n",paraId:46,tocIndex:15},{value:"If this property is set to true, roughjs does not apply multiple strokes to sketch the shape.",paraId:47,tocIndex:16},{value:"circle.style.disableMultiStroke = true;\n",paraId:48,tocIndex:16},{value:"If this property is set to true, roughjs does not apply multiple strokes to sketch the hachure lines to fill the shape.",paraId:49,tocIndex:17},{value:"circle.style.disableMultiStrokeFill = true;\n",paraId:50,tocIndex:17},{value:"Simplification can be set to simplify the shape by the specified factor. The value can be between 0 and 1.",paraId:51,tocIndex:18},{value:"When filling a shape using the dashed style, this property indicates the nominal length of dash (in pixels). If not set, it defaults to the hachureGap value.",paraId:52,tocIndex:19},{value:"When filling a shape using the dashed style, this property indicates the nominal gap between dashes (in pixels). If not set, it defaults to the hachureGap value.",paraId:53,tocIndex:20},{value:"When filling a shape using the zigzag-line style, this property indicates the nominal width of the zig-zag triangle in each line. If not set, it defaults to the hachureGap value.",paraId:54,tocIndex:21},{value:"In ",paraId:55,tocIndex:23},{value:"g-plugin-canvas-picker",paraId:56,tocIndex:23},{value:" we use the spatial index for quick filtering and the mathematical calculation of the geometric definition of the figure for exact picking.",paraId:55,tocIndex:23},{value:"However, in the hand-drawn style, it seems impossible and unnecessary to do exact picking, so we still use this plugin.",paraId:57,tocIndex:23}]},52980:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(39644);const n=[{value:"Hand-drawn style rendering using the SVG version of ",paraId:0},{value:"rough.js",paraId:0},{value:", ",paraId:0},{value:"example",paraId:1},{value:".",paraId:0},{value:"First you need to use the ",paraId:2,tocIndex:0},{value:"g-svg",paraId:3,tocIndex:0},{value:" renderer, register the plugin and it will replace the rendering of 2D graphics in ",paraId:2,tocIndex:0},{value:"g-plugin-svg-renderer",paraId:4,tocIndex:0},{value:".",paraId:2,tocIndex:0},{value:"import { Canvas } from '@antv/g';\nimport { Renderer } from '@antv/g-svg';\nimport { Plugin as PluginRoughSVGRenderer } from '@antv/g-plugin-rough-svg-renderer';\n\n// create a renderer\nconst renderer = new Renderer();\nrenderer.registerPlugin(new PluginRoughSVGRenderer());\n\n// create a canvas & use `g-svg`\nconst canvas = new Canvas({\n    container: 'container',\n    width: 600,\n    height: 500,\n    renderer,\n});\n",paraId:5,tocIndex:0},{value:"In addition, we support all 2D graphics, among which ",paraId:6,tocIndex:0},{value:"Text",paraId:7,tocIndex:0},{value:", ",paraId:6,tocIndex:0},{value:"Image",paraId:8,tocIndex:0},{value:" and ",paraId:6,tocIndex:0},{value:"HTML",paraId:9,tocIndex:0},{value:" have no hand-drawn style.",paraId:6,tocIndex:0},{value:"In addition to the style properties of 2D graphics, the configuration items provided by rough.js can also be used. See ",paraId:10,tocIndex:1},{value:"g-plugin-rough-canvas-renderer",paraId:11,tocIndex:1},{value:".",paraId:10,tocIndex:1},{value:"Non-",paraId:12,tocIndex:2},{value:"solid",paraId:12,tocIndex:2},{value:" fill styles leave a lot of white space, and these blank areas do not trigger interaction events. This is inconsistent with ",paraId:12,tocIndex:2},{value:"g-plugin-canvas-renderer",paraId:13,tocIndex:2},{value:".",paraId:12,tocIndex:2}]},66062:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(41451);const n=[{value:"Provides SVG-based pickup capability.",paraId:0},{value:"The ",paraId:1,tocIndex:0},{value:"g-svg",paraId:2,tocIndex:0},{value:" renderer is built in by default, so there is no need to introduce it manually.",paraId:1,tocIndex:0},{value:"import { Renderer as SvgRenderer } from '@antv/g-svg';\n// Create a renderer with the plugin built in\nconst svgRenderer = new SvgRenderer();\n",paraId:3,tocIndex:0},{value:"Get ",paraId:4,tocIndex:1},{value:"SVGElement",paraId:4,tocIndex:1},{value:" directly using ",paraId:4,tocIndex:1},{value:"elementFromPoint",paraId:4,tocIndex:1},{value:". Find it and query ",paraId:4,tocIndex:1},{value:"DisplayObject",paraId:4,tocIndex:1},{value:" by ",paraId:4,tocIndex:1},{value:"id",paraId:4,tocIndex:1},{value:" to return it.",paraId:4,tocIndex:1}]},23793:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(86762);const n=[{value:"Provides SVG-based rendering capabilities.",paraId:0},{value:"The ",paraId:1,tocIndex:0},{value:"g-svg",paraId:2,tocIndex:0},{value:" renderer is built in by default, so there is no need to introduce it manually.",paraId:1,tocIndex:0},{value:"import { Renderer as SvgRenderer } from '@antv/g-svg';\n// Create a renderer with the plugin built in\nconst svgRenderer = new SvgRenderer();\n",paraId:3,tocIndex:0},{value:"The plugin exposes the following contributions.",paraId:4,tocIndex:1},{value:"This contribution provides the lifecycle of SVG elements from creation, update to destruction.",paraId:5,tocIndex:2},{value:"export interface ElementLifeCycleContribution {\n    createElement: (object: DisplayObject) => SVGElement;\n    shouldUpdateElementAttribute: (\n        object: DisplayObject,\n        attributeName: string,\n    ) => boolean;\n    updateElementAttribute: (object: DisplayObject, $el: SVGElement) => void;\n    destroyElement: (object: DisplayObject, $el: SVGElement) => void;\n}\n",paraId:6,tocIndex:2},{value:"Different renderer plugins can implement the above interface to manage the lifecycle of each graphic using a custom approach. For example, the following code shows two SVG-based renderer plugins, the former built for ",paraId:7,tocIndex:2},{value:"g-svg",paraId:8,tocIndex:2},{value:", which provides rendering capabilities for default SVG elements, and the latter which implements hand-drawn style rendering with rough.js on top of that.",paraId:7,tocIndex:2},{value:"// g-plugin-svg-renderer\n@singleton({ token: ElementLifeCycleContribution })\nexport class DefaultElementLifeCycleContribution\n    implements ElementLifeCycleContribution {}\n\n// g-plugin-svg-rough-renderer\n@singleton({ token: ElementLifeCycleContribution })\nexport class RoughElementLifeCycleContribution\n    implements ElementLifeCycleContribution {}\n",paraId:9,tocIndex:2},{value:"This method uses the DOM API to create the corresponding SVGElement based on the incoming base drawing, and is called when the ",paraId:10,tocIndex:3},{value:"ElementEvent.MOUNTED",paraId:11,tocIndex:3},{value:" event is triggered.",paraId:10,tocIndex:3},{value:"Redrawing is expressed as attribute update in SVG, but some attributes (e.g. [visibility](/en/api/basic/display-object#hidden display), ",paraId:12,tocIndex:4},{value:"z-index",paraId:13,tocIndex:4},{value:", etc.) of updates we have a unified internal implementation and do not intend to open up custom capabilities. So there needs to be a judgment method to decide whether to trigger an attribute update or not.",paraId:12,tocIndex:4},{value:"This method gets called when ",paraId:14,tocIndex:4},{value:"MOUNTED",paraId:15,tocIndex:4},{value:" triggered for the first time and ",paraId:14,tocIndex:4},{value:"ElementEvent.ATTR_MODIFIED",paraId:16,tocIndex:4},{value:" for subsequent property updates.",paraId:14,tocIndex:4},{value:"After passing the attribute update judgment method, the update attribute logic is executed.",paraId:17,tocIndex:5},{value:"This method is called when ",paraId:18,tocIndex:6},{value:"ElementEvent.UNMOUNTED",paraId:19,tocIndex:6},{value:" is triggered when the drawing is removed from the canvas.",paraId:18,tocIndex:6}]},30412:function(e,a,t){t.r(a),t.d(a,{texts:function(){return n}});t(53334);const n=[{value:"Yoga",paraId:0},{value:" is a cross-platform layout engine provided by Facebook, based on Flex, with exactly the same properties as CSS Flex, so you can also read [MDN Basic Concepts of flex layout](",paraId:0},{value:"https://developer.mozilla.org/zh-",paraId:0},{value:" CN/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox) for more conceptual knowledge.",paraId:0},{value:"Examples:",paraId:1},{value:"Container-related configuration",paraId:2},{value:"Sub-element related configuration",paraId:3},{value:"Adaptive layout",paraId:4},{value:"Text Line Feed",paraId:5},{value:"Apply animations to relevant properties",paraId:6},{value:"The plugin uses ",paraId:7},{value:"yoga-layout-prebuilt",paraId:7},{value:", the package size is large, and we will subsequently use a lightweight version of our own developed layout engine.",paraId:7},{value:"Create plug-ins and register them in the renderer.",paraId:8,tocIndex:0},{value:"import { Renderer } from '@antv/g-canvas';\nimport { Plugin } from '@antv/g-plugin-yoga';\n\nconst renderer = new Renderer();\nrenderer.registerPlugin(new Plugin());\n",paraId:9,tocIndex:0},{value:"With ",paraId:10,tocIndex:0},{value:"display: 'flex'",paraId:10,tocIndex:0},{value:" you can declare a graph to use Flex layout. Currently we only support ",paraId:10,tocIndex:0},{value:"Rect",paraId:11,tocIndex:0},{value:" and ",paraId:10,tocIndex:0},{value:"Group",paraId:12,tocIndex:0},{value:" as Flex containers.",paraId:10,tocIndex:0},{value:"// Declare a container\nconst container = new Rect({\n    style: {\n        width: 500, // Size\n        height: 300,\n        display: 'flex', // Declaring the use of flex layouts\n        justifyContent: 'center',\n        alignItems: 'center',\n        x: 0,\n        y: 0,\n        fill: '#C6E5FF',\n    },\n});\ncanvas.appendChild(container);\n\n// Declare child elements, no need to set the position manually, calculated by the layout engine\nconst node1 = new Rect({\n    style: {\n        fill: 'white',\n        width: 100,\n        height: 100,\n    },\n});\nconst node2 = new Rect({\n    style: {\n        fill: 'white',\n        width: 100,\n        height: 100,\n    },\n});\ncontainer.appendChild(node1);\ncontainer.appendChild(node2);\n",paraId:13,tocIndex:0},{value:"Different properties support different units, such as absolute pixel values of type ",paraId:14,tocIndex:1},{value:"number",paraId:14,tocIndex:1},{value:", percentages of type ",paraId:14,tocIndex:1},{value:"'100%'",paraId:14,tocIndex:1},{value:" string, and the special meaning of ",paraId:14,tocIndex:1},{value:"'auto'",paraId:14,tocIndex:1},{value:".",paraId:14,tocIndex:1},{value:"Use ",paraId:15,tocIndex:2},{value:"display: 'flex'",paraId:15,tocIndex:2},{value:" to declare a Flex container, all the immediate children inside the container will be laid out according to the layout engine calculation, only ",paraId:15,tocIndex:2},{value:"Rect",paraId:16,tocIndex:2},{value:" and ",paraId:15,tocIndex:2},{value:"Group",paraId:17,tocIndex:2},{value:" are supported as containers for now.",paraId:15,tocIndex:2},{value:"// or using Group\n// const container = new Group({\nconst container = new Rect({\n    style: {\n        width: 500,\n        height: 300,\n        display: 'flex',\n        justifyContent: 'center',\n        alignItems: 'center',\n        x: 0,\n        y: 0,\n        fill: '#C6E5FF',\n    },\n});\n",paraId:18,tocIndex:2},{value:"There is no type restriction for child elements inside the container, for example, you can see in the following figure that ",paraId:19,tocIndex:2},{value:"Image",paraId:20,tocIndex:2},{value:" can also be laid out normally according to the calculation result.",paraId:19,tocIndex:2},{value:"In addition, the container supports nesting, for example, Node1 in the above image is also a Flex container itself, so the text in it can be centered horizontally and vertically.",paraId:21,tocIndex:2},{value:"The Layout property is used to set the effect of its own layout in the container, for example by adjusting it relative to existing results.",paraId:22,tocIndex:3},{value:"The following values are supported and can be used with top / right / botton / left, exactly as in CSS.",paraId:23,tocIndex:4},{value:"relative",paraId:24,tocIndex:4},{value:" Default value, relative to the normal layout position",paraId:24,tocIndex:4},{value:"absolute",paraId:24,tocIndex:4},{value:" Absolute positioning relative to the parent container",paraId:24,tocIndex:4},{value:"Node1 uses ",paraId:25,tocIndex:4},{value:"relative",paraId:25,tocIndex:4},{value:" in the image below left and ",paraId:25,tocIndex:4},{value:"absolute",paraId:25,tocIndex:4},{value:" in the image below right for absolute positioning.",paraId:25,tocIndex:4},{value:"Animatable",paraId:26,tocIndex:5},{value:"Supports absolute values with percentages, e.g. ",paraId:27,tocIndex:5},{value:"{ top: 10 }",paraId:27,tocIndex:5},{value:", ",paraId:27,tocIndex:5},{value:"{ top: '50%' }",paraId:27,tocIndex:5},{value:". Size relative to the parent element when a percentage string is passed in.",paraId:27,tocIndex:5},{value:"For example, in the figure below, Node1 uses ",paraId:28,tocIndex:5},{value:"absolute",paraId:28,tocIndex:5},{value:" for absolute positioning, with ",paraId:28,tocIndex:5},{value:"top",paraId:28,tocIndex:5},{value:" and ",paraId:28,tocIndex:5},{value:"left",paraId:28,tocIndex:5},{value:" set to 10.",paraId:28,tocIndex:5},{value:"In the following figure, Node1 is positioned absolutely using ",paraId:29,tocIndex:5},{value:"absolute",paraId:29,tocIndex:5},{value:", and ",paraId:29,tocIndex:5},{value:"top",paraId:29,tocIndex:5},{value:" takes ",paraId:29,tocIndex:5},{value:"'50%'",paraId:29,tocIndex:5},{value:", which is half the height of the parent element.",paraId:29,tocIndex:5},{value:"In the following figure, Node1 uses ",paraId:30,tocIndex:5},{value:"absolute",paraId:30,tocIndex:5},{value:" for absolute positioning and ",paraId:30,tocIndex:5},{value:"top",paraId:30,tocIndex:5},{value:" takes ",paraId:30,tocIndex:5},{value:"-50",paraId:30,tocIndex:5},{value:".",paraId:30,tocIndex:5},{value:"Animatable",paraId:31,tocIndex:6},{value:"Set its own width and height size. The default value is ",paraId:32,tocIndex:6},{value:"'auto'",paraId:32,tocIndex:6},{value:".",paraId:32,tocIndex:6},{value:"Supports both percentage and absolute values, taking the percentage relative to the parent element size.",paraId:33,tocIndex:6},{value:"For example, in the following figure Node1 sets a slightly larger aspect.",paraId:34,tocIndex:6},{value:"Max-min constraint, priority over other attributes. Can be used with ",paraId:35,tocIndex:7},{value:"flexGrow",paraId:36,tocIndex:7},{value:".",paraId:35,tocIndex:7},{value:"Default value is NaN, i.e. no constraint. Support percentage and absolute values, take percentage relative to parent element size, e.g. ",paraId:37,tocIndex:7},{value:"{ minWidth: 50% }",paraId:37,tocIndex:7},{value:".",paraId:37,tocIndex:7},{value:"For example, the following Node1 is set to ",paraId:38,tocIndex:7},{value:"{ flexGrow: 1, maxWidth: 50% }",paraId:38,tocIndex:7},{value:", so it can only occupy up to half the width of its parent element.",paraId:38,tocIndex:7},{value:"Animatable",paraId:39,tocIndex:8},{value:"The data type is ",paraId:40,tocIndex:8},{value:"[number | string, number | string, number | string, number | string]",paraId:40,tocIndex:8},{value:", which sets the top-right and bottom-left padding at once.",paraId:40,tocIndex:8},{value:"The following values are supported and can be found in ",paraId:41,tocIndex:8},{value:"CSS padding properties",paraId:41,tocIndex:8},{value:".",paraId:41,tocIndex:8},{value:"Absolute pixel value, negative values are not supported, e.g. ",paraId:42,tocIndex:8},{value:"10",paraId:42,tocIndex:8},{value:"Percentage strings, negative values are not supported, e.g. ",paraId:42,tocIndex:8},{value:"'50%'",paraId:42,tocIndex:8},{value:", take the percentage relative to the width of ",paraId:42,tocIndex:8},{value:"itself",paraId:42,tocIndex:8},{value:"For example, the following two ways of writing are equivalent.",paraId:43,tocIndex:8},{value:"{\n    padding: [10, 0, 10, 0],\n}\n{\n    paddingTop: 10,\n    paddingRight: 0,\n    paddingBottom: 10,\n    paddingLeft: 0,\n}\n",paraId:44,tocIndex:8},{value:"Animatable",paraId:45,tocIndex:9},{value:"The data type is ",paraId:46,tocIndex:9},{value:"number | string",paraId:46,tocIndex:9},{value:", and the padding is set uniformly from top right to bottom left.",paraId:46,tocIndex:9},{value:"Animatable",paraId:47,tocIndex:10},{value:"Set the top-right-bottom-left padding separately.",paraId:48,tocIndex:10},{value:"Animatable",paraId:49,tocIndex:11},{value:"type PixelsOrPercentage = number | string;\ntype YogaSize = PixelsOrPercentage | 'auto';\n",paraId:50,tocIndex:11},{value:"The data type is ",paraId:51,tocIndex:11},{value:"[YogaSize, YogaSize, YogaSize, YogaSize]",paraId:51,tocIndex:11},{value:", which sets the top-right-bottom-left margin at once.",paraId:51,tocIndex:11},{value:"The following values are supported and can be found in ",paraId:52,tocIndex:11},{value:"CSS margin properties",paraId:52,tocIndex:11},{value:".",paraId:52,tocIndex:11},{value:"absolute pixel values, negative values are supported, e.g. ",paraId:53,tocIndex:11},{value:"10",paraId:53,tocIndex:11},{value:" ",paraId:53,tocIndex:11},{value:"-50",paraId:53,tocIndex:11},{value:"Percentage strings, negative values are supported, e.g. ",paraId:53,tocIndex:11},{value:"'50%'",paraId:53,tocIndex:11},{value:" ",paraId:53,tocIndex:11},{value:"'-20%'",paraId:53,tocIndex:11},{value:", relative to the width of the ",paraId:53,tocIndex:11},{value:"parent element",paraId:53,tocIndex:11},{value:" when taking the percentage",paraId:53,tocIndex:11},{value:"'auto'",paraId:53,tocIndex:11},{value:", let the layout engine choose the right margin, can achieve the centering of the element",paraId:53,tocIndex:11},{value:"For example, in the following figure, Node1 has set ",paraId:54,tocIndex:11},{value:"marginRight: 10",paraId:54,tocIndex:11},{value:" and ",paraId:54,tocIndex:11},{value:"marginLeft: -50",paraId:54,tocIndex:11},{value:" respectively.",paraId:54,tocIndex:11},{value:"The following figure shows the effect of ",paraId:55,tocIndex:11},{value:"marginTop: '50%'",paraId:55,tocIndex:11},{value:", with the parent element width (500) as the base.",paraId:55,tocIndex:11},{value:"The following image shows the effect of ",paraId:56,tocIndex:11},{value:"margin: [0, 'auto', 0, 'auto']",paraId:56,tocIndex:11},{value:" to center the element horizontally.",paraId:56,tocIndex:11},{value:"Animatable",paraId:57,tocIndex:12},{value:"See ",paraId:58,tocIndex:12},{value:"margin",paraId:59,tocIndex:12},{value:" for details.",paraId:58,tocIndex:12},{value:"Animatable",paraId:60,tocIndex:13},{value:"See ",paraId:61,tocIndex:13},{value:"margin",paraId:62,tocIndex:13},{value:" for details.",paraId:61,tocIndex:13},{value:"Not supported at this time.",paraId:63,tocIndex:14},{value:"From ",paraId:64,tocIndex:16},{value:"MDN's description",paraId:64,tocIndex:16},{value:"When using the flex layout, the first two axes that come to mind are the main axis and the cross axis. The main axis is defined by ",paraId:65,tocIndex:16},{value:"flexDirection",paraId:65,tocIndex:16},{value:", and the other axis is perpendicular to it.",paraId:65,tocIndex:16},{value:"The following values are supported.",paraId:66,tocIndex:16},{value:"'row'",paraId:67,tocIndex:16},{value:" default value",paraId:67,tocIndex:16},{value:"'row-reverse'",paraId:67,tocIndex:16},{value:"'column'",paraId:67,tocIndex:16},{value:"'column-reverse'",paraId:67,tocIndex:16},{value:"The left image below shows the default effect, and the right image below shows the `'column''.",paraId:68,tocIndex:16},{value:"From ",paraId:69,tocIndex:17},{value:"MDN's description",paraId:69,tocIndex:17},{value:"：",paraId:69,tocIndex:17},{value:"Although flexbox is a one-dimensional model, it is possible to make our flex items apply to multiple rows. When doing so, you should treat each row as a new flex container. Any spatial distribution will occur on that row, without affecting the other rows of that spatial distribution.",paraId:70,tocIndex:17},{value:"The following values are supported.",paraId:71,tocIndex:17},{value:"'wrap'",paraId:72,tocIndex:17},{value:"'no-wrap'",paraId:72,tocIndex:17},{value:" default value",paraId:72,tocIndex:17},{value:"'wrap-reverse'",paraId:72,tocIndex:17},{value:"In this ",paraId:73,tocIndex:17},{value:"example",paraId:74,tocIndex:17},{value:", you can add child elements to the container by clicking the ",paraId:73,tocIndex:17},{value:"appendChild",paraId:73,tocIndex:17},{value:" button. The image on the left below shows the effect of the container's default ",paraId:73,tocIndex:17},{value:"no-wrap",paraId:73,tocIndex:17},{value:" (note that the child element is compressed in width because line breaks are not allowed), and the image on the right below is set to ",paraId:73,tocIndex:17},{value:"wrap",paraId:73,tocIndex:17},{value:" with automatic line breaks.",paraId:73,tocIndex:17},{value:"Animatable",paraId:75,tocIndex:18},{value:"This property deals with child elements adding space to the main axis. After the Flex container has allocated space for the child elements for the first time, if there is any space left, it will allocate it a second time according to the flexGrow property of those child elements.",paraId:76,tocIndex:18},{value:"The default value is 0, and values greater than or equal to 0 are supported as weights for allocating the remaining space.",paraId:77,tocIndex:18},{value:"For example, in the figure below, Node1 and Node2 are both set to the initial size ",paraId:78,tocIndex:18},{value:"{ width: 100, height: 100 }",paraId:78,tocIndex:18},{value:", but Node1 is additionally set to ",paraId:78,tocIndex:18},{value:"{ flexGrow: 1 }",paraId:78,tocIndex:18},{value:', so it will take up all the remaining space on the main axis of the container (total width 500 - Node2 width 100 = 400), which has the effect of being "stretched" by.',paraId:78,tocIndex:18},{value:"If you want Node1 and Node2 to split the space equally, you can set ",paraId:79,tocIndex:18},{value:"{ flexGrow: 1 }",paraId:79,tocIndex:18},{value:" on Node2 as well.",paraId:79,tocIndex:18},{value:"You can adjust this ",paraId:80,tocIndex:18},{value:"example",paraId:81,tocIndex:18},{value:' to see the effect. This is particularly suitable for implementing "adaptive" layouts, where when the container width is modified, the remaining space changes as well.',paraId:80,tocIndex:18},{value:"Also, the allocation of the remaining space takes into account constraints like ",paraId:82,tocIndex:18},{value:"min/maxWidth/Height",paraId:83,tocIndex:18},{value:" on the child elements, and in this [example](/ examples/plugins#yoga examples/plugins#yoga-available-space), Node1 also has ",paraId:82,tocIndex:18},{value:"{ maxWidth: 200 }",paraId:82,tocIndex:18},{value:" set, so even if there is more space left in the container, it will not be allocated to it (note the blank part of the container on the right side of the image below).",paraId:82,tocIndex:18},{value:"Likewise, ",paraId:84,tocIndex:18},{value:"minWidth",paraId:84,tocIndex:18},{value:" can be used as a lower limit when there is not enough space left, for example, the minimum width of Node1 in the following figure is set to 50, so even if the container is only 100 wide, it will be guaranteed to be displayed at the following width.",paraId:84,tocIndex:18},{value:"Animatable",paraId:85,tocIndex:19},{value:"This property handles the shrinking of child elements. If there is not enough space in the container to align the elements, then the flexShrink property of a child element can be set to a positive integer to shrink the space it occupies below flexBasis. As with the flexGrow attribute, different values can be assigned to control how much the child element shrinks, i.e. giving a larger value to the flexShrink attribute can shrink it more than a smaller value given to a sibling.",paraId:86,tocIndex:19},{value:"The default value is 1, and values greater than or equal to 0 are supported.",paraId:87,tocIndex:19},{value:"For example, in the following figure, when the container is not wide enough to accommodate the initial width set by Node1 and Node2, it will be scaled according to flexShrink, which is set to 1 for both word nodes and therefore scaled to the same extent.",paraId:88,tocIndex:19},{value:"Animatable",paraId:89,tocIndex:20},{value:"From ",paraId:90,tocIndex:20},{value:"MDN's description",paraId:90,tocIndex:20},{value:"Before considering the role of these properties, it is important to understand the concept of available space.",paraId:91,tocIndex:20},{value:"Yoga Example",paraId:92,tocIndex:20},{value:"Defines the default space size for this element on the main axis.",paraId:93,tocIndex:20},{value:"The default value is NaN.",paraId:94,tocIndex:20},{value:"From ",paraId:95,tocIndex:21},{value:"MDN's description",paraId:95,tocIndex:21},{value:"A key feature of flexbox is the ability to set the alignment of flex elements along the major and cross-axis directions, as well as the space allocation between them.",paraId:96,tocIndex:21},{value:"This property is used to align elements in the major axis direction.",paraId:97,tocIndex:22},{value:"The following enumeration values are supported.",paraId:98,tocIndex:22},{value:"'flex-start'",paraId:99,tocIndex:22},{value:" the default value",paraId:99,tocIndex:22},{value:"'flex-end'",paraId:99,tocIndex:22},{value:"'center'",paraId:99,tocIndex:22},{value:"'space-between'",paraId:99,tocIndex:22},{value:"'space-around'",paraId:99,tocIndex:22},{value:"'space-evenly'",paraId:99,tocIndex:22},{value:"In this ",paraId:100,tocIndex:22},{value:"example",paraId:101,tocIndex:22},{value:", the effect of ",paraId:100,tocIndex:22},{value:"center",paraId:100,tocIndex:22},{value:" / ",paraId:100,tocIndex:22},{value:"space-between",paraId:100,tocIndex:22},{value:" / ",paraId:100,tocIndex:22},{value:"space-around",paraId:100,tocIndex:22},{value:" is shown.",paraId:100,tocIndex:22},{value:"This property allows elements to be aligned in the cross-axis direction.",paraId:102,tocIndex:23},{value:"The following enumeration values are supported.",paraId:103,tocIndex:23},{value:"'stretch'",paraId:104,tocIndex:23},{value:" the default value",paraId:104,tocIndex:23},{value:"'auto'",paraId:104,tocIndex:23},{value:"'baseline'",paraId:104,tocIndex:23},{value:"'center'",paraId:104,tocIndex:23},{value:"'flex-start'",paraId:104,tocIndex:23},{value:"'flex-end'",paraId:104,tocIndex:23},{value:"'space-between'",paraId:104,tocIndex:23},{value:"'space-around'",paraId:104,tocIndex:23},{value:"The following figure shows the ",paraId:105,tocIndex:23},{value:"center",paraId:105,tocIndex:23},{value:" effect.",paraId:105,tocIndex:23},{value:"For child elements to override the existing ",paraId:106,tocIndex:24},{value:"alignItems",paraId:107,tocIndex:24},{value:" value in the container.",paraId:106,tocIndex:24},{value:"In the following figure, the container sets ",paraId:108,tocIndex:24},{value:"alignItems",paraId:108,tocIndex:24},{value:" to the default value of ",paraId:108,tocIndex:24},{value:"stretch",paraId:108,tocIndex:24},{value:", but Node1 can set itself out of the original Node2 and Node3 layout effect by using ",paraId:108,tocIndex:24},{value:"alignSelf: center",paraId:108,tocIndex:24},{value:".",paraId:108,tocIndex:24},{value:"How the container allocates space around child elements only takes effect if ",paraId:109,tocIndex:25},{value:"flexWrap",paraId:110,tocIndex:25},{value:" takes the value ",paraId:109,tocIndex:25},{value:"wrap",paraId:109,tocIndex:25},{value:".",paraId:109,tocIndex:25},{value:"The following enumeration values are supported.",paraId:111,tocIndex:25},{value:"'stretch'",paraId:112,tocIndex:25},{value:"'center'",paraId:112,tocIndex:25},{value:"'flex-start'",paraId:112,tocIndex:25},{value:" the default value",paraId:112,tocIndex:25},{value:"'flex-end'",paraId:112,tocIndex:25},{value:"'space-between'",paraId:112,tocIndex:25},{value:"'space-around'",paraId:112,tocIndex:25},{value:"In this ",paraId:113,tocIndex:25},{value:"example",paraId:114,tocIndex:25},{value:", the ",paraId:113,tocIndex:25},{value:"center",paraId:113,tocIndex:25},{value:" / ",paraId:113,tocIndex:25},{value:"space-between",paraId:113,tocIndex:25},{value:" / ",paraId:113,tocIndex:25},{value:"space-around",paraId:113,tocIndex:25},{value:" effects are shown in order.",paraId:113,tocIndex:25},{value:"Yes, the layout is calculated separately within each container and affects the inner child elements.",paraId:115,tocIndex:27},{value:"Not supported at the moment. If the container itself does not need to be rendered, you should use Group. above example we chose Rect to better show the container size.",paraId:116,tocIndex:28},{value:"setPosition/setLocalPosition()",paraId:117},{value:"Once a container uses Flex, all child elements inside it should be positioned using Flex-related properties. While the use of ",paraId:118,tocIndex:29},{value:"setPosition",paraId:118,tocIndex:29},{value:" is not prohibited, it will obviously conflict with the layout engine's calculations.",paraId:118,tocIndex:29},{value:"Yes. However, the reference values for using percentages are not the same for different attributes.",paraId:119,tocIndex:30},{value:"For example ",paraId:120,tocIndex:30},{value:"width/height",paraId:121,tocIndex:30},{value:" relative to the width and height of the parent element.",paraId:120,tocIndex:30},{value:"{\n    width: '100%',\n    height: '50%'\n}\n",paraId:122,tocIndex:30},{value:"Currently ",paraId:123,tocIndex:31},{value:"Text",paraId:124,tocIndex:31},{value:" already supports multi-line text with automatic line break, but requires user to set ",paraId:123,tocIndex:31},{value:"wordWrapWidth",paraId:123,tocIndex:31},{value:" manually to break the line when it is exceeded.",paraId:123,tocIndex:31},{value:"In Flex layout, when text is a child element, there is no need for user to set text line width manually, just turn on ",paraId:125,tocIndex:31},{value:"wordWrap",paraId:125,tocIndex:31},{value:" with ",paraId:125,tocIndex:31},{value:"width",paraId:125,tocIndex:31},{value:" and you can.",paraId:125,tocIndex:31},{value:"const text = new Text({\n    style: {\n        fontFamily: 'PingFang SC',\n        fontSize: 32,\n        fill: '#1890FF',\n        text: '这是测试文字，这是测试文字，这是测试文字，这是测试文字',\n        wordWrap: true, // Turn on automatic line feeds\n        width: '100%',\n    },\n});\n",paraId:126,tocIndex:31},{value:"In this ",paraId:127,tocIndex:31},{value:"example",paraId:128,tocIndex:31},{value:", you can always change the line width of the text that needs a line break, as shown below for ",paraId:127,tocIndex:31},{value:"width: '100%'",paraId:127,tocIndex:31},{value:".",paraId:127,tocIndex:31},{value:"Flex layout adds many new properties, such as ",paraId:129,tocIndex:32},{value:"padding",paraId:130,tocIndex:32},{value:" ",paraId:129,tocIndex:32},{value:"margin",paraId:131,tocIndex:32},{value:", etc. It is possible to animate these properties in CSS.",paraId:129,tocIndex:32},{value:"Some of these properties are currently supported and can be viewed in this ",paraId:132,tocIndex:32},{value:"example",paraId:133,tocIndex:32},{value:".",paraId:132,tocIndex:32},{value:"node1.animate(\n    [\n        { top: 0, left: 0, width: 100, marginAll: 0, paddingLeft: 0 },\n        { top: 100, left: 100, width: 200, marginAll: 20, paddingLeft: 50 },\n    ],\n    {\n        duration: 1000,\n        easing: 'cubic-bezier(0.250, 0.460, 0.450, 0.940)',\n        fill: 'both',\n        iterations: Infinity,\n        direction: 'alternate-reverse',\n    },\n);\n",paraId:134,tocIndex:32},{value:"You need to specify a plane before you can apply a 2D layout engine like Yoga.",paraId:135,tocIndex:33},{value:"For example, ",paraId:136,tocIndex:33},{value:"react-three-flex",paraId:136,tocIndex:33},{value:" uses ",paraId:136,tocIndex:33},{value:"xy",paraId:136,tocIndex:33},{value:" ",paraId:136,tocIndex:33},{value:"yz",paraId:136,tocIndex:33},{value:" ",paraId:136,tocIndex:33},{value:"xz",paraId:136,tocIndex:33},{value:".",paraId:136,tocIndex:33}]}}]);